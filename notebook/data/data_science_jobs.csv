№,id,title,salary,experience,job_type,description,key_skills,company,location
112,79184755,Data Centre Infrastructure Services Engineer (onsite),з/п не указана,3–6 лет,"Полная занятость,полный день","Data Centre Infrastructure Services Engineer Location: Atyrau, 14/14 Duties: Support Data Center infrastructure and environment Backend Hardware Support and Maintenance Install, manage and support IT Data Storage systems: NetApp, EMC/DELL, HP 3par, EVA, MSA Install, manage and support server computing systems: rack mounted servers, Blade Enclosures, converged systems, etc. (HP Blade Enclosures, Cisco UCS, HP Proliant etc. ) Install, manage and support backup systems: Tape Libraries (HP StoreOnes, EMC Data Domain) Install, configure, and administer Windows Server 2008 and 2012 Server for Physical Platforms Perform hardware and software recovery Monitor & report using special monitoring tools to maintain awareness and control of the backend infrastructure hardware, software and environment Fulfil requests for escorted access to server rooms and data center premises Perform Health, Safety, Security Environment inspection of Server Rooms Perform Weekly reporting Ensure proper housekeeping of the Server Rooms Monitor IT backend infrastructure hardware, peripherals, spare parts and consumables inventory and maintains Configuration file for equipment in production server rooms and operational stocks Manage Software upgrades and patches processes Available 24x7 for emergency situations & procedures as power shutdowns, network outages, hardware failures and disaster recovery procedures Hardware installation, decommission and replacement via Change Management Support Incident Management Support Request Management using ITSM tool service tickets Support Asset Management, Configuration & Capacity Management Remote sites maintenance and support Perform Power and Capacity Calculation Perform hardware related data collection and update of landscape files within Landscape Management Install, Configure Data Center, Hardware and Services Monitoring applications and appliances. (Netbotz EMS, Solarwinds SAM, HP One view, HP SIM, IRS, Vertiv Trellis etc.) Assist in development of Operational Level Agreements, Service Level Agreements and Contract Scopes related to IT data center Hardware and Facilities Business Continuity Management support including Business Continuity Plan/Disaster Recovery Plan assurance Coordinate Power Outages and Facilities Management Maintenance Support Risk issues resolution and Risk Management team Support Production Operations infrastructure services Support Technical Directorate infrastructure service Support SAP, Physical Security (CCTV, ACS), Opentext (Enterprise Document Management System) servers infrastructure Support migration of services from physical platform to virtual environment Supervise team engineers and perform team activities planning Design, support procurement, installation, upgrading, operation, control, maintenance and effective use of data center infrastructure Develop and maintain documentation related to ITSM policies, strategies and processes Education: Bachelor’s Degree or higher in Engineering, Information Technology or related field. Knowledge: Networking fundamentals: TCP/IP, file transfer and secure file transfer protocols, Internet Information Server systems/software administration: server roles installation and configuration, security levels and permissions, installation of third-party software, backup systems Back-end Infrastructure Systems (Servers, Tape Libraries, Virtual Infrastructure components, etc.) Working with multi-vendor monitoring and management tools/protocols such as iLO, CIMC, IPMI, SNMP Technological processes of Data Center – air cooling (air conditioning equipment), power supply ( Uninterrupted Power Supply, Power Distribution Units, Emergency Generator Units), fire safety (Fire Suppression Systems) IT service delivery & support processes based on international standards, best practices and frameworks (ISO 270001/2, COBIT, ITIL, ISO 9001 etc.) Uptime Institute Data Center Certification and TIA and ASHRAE Standards English – upper-intermediate Experience: 3+ year experience in: Supporting Backend hardware equipment (HPE, DELL, VCE, EMC, Cisco, NetApp etc.) Compilation of work plans, equipment upgrades, project surveys, repair and maintenance works with Data Centers Infrastructure Monitoring of Data Center - temperature indicators Certification: Preferred to have: Certified Data Center Professional(CDCP) Preferred to have: ITIL Foundation Preferred to have: Data Center foundations Preferred to have: Microsoft Certified Associate.","Data Centre,NetApp,EMC/DELL,HP 3par,EVA,MSA,Tape Libraries,Windows Server 2008,Windows Server 2012,Server Rooms,ITSM,Incident Management,Asset Management,Request Management,Business Continuity Management,Disaster Recovery,Opentext,TCP/IP,ISO 270001/2,COBIT,ITIL,ISO 9001,Английский язык,CDCP,Английский — B2 — Средне-продвинутый",iQ-SOLUTIONS,
135,79045942,Senior Site Reliability Engineer (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Since 2003, Murano has been developing software that simplifies and optimizes the customer's daily work and contributes to the digitalization of key US industries as well. Besides the client projects, the company maintains and develops its product based on the .NET platform: the world’s leading insurance submission, application, and policy management system, which is used by more than half of independent insurance agencies in the United States. Murano's head office locates in Los Angeles, and its team works from different cities and countries worldwide. This vacancy is opened on our outsourcing project. Project of our client produces a complete view of the health customer, to unlock and activate health insights in order to revolutionize health decision-making in real time. Through machine learning and programmatic automation, the company interprets the hard-to-read signals of the health journey to understand the connection points between relevance and engagement. This is achieved by unifying real-time Digital Determinants of Health, offline and clinical data to create a unique and precise view of the health ecosystem that refines, improves and increases its view over time. What you’ll be doing: Deploying, configuring, monitoring and maintaining multiple big data stores, across multiple datacenters. Perform planning, configuration, deployment and maintenance work relevant to the environment. Managing the large-scale Linux infrastructure to ensure maximum uptime. Developing and documenting system configuration standards and procedures. Performance and reliability testing. This may include reviewing configuration, software choices/versions, hardware specs, etc. Advancing our technology stack with innovative ideas and new creative solutions. Who are you: Collaboration is in your DNA. You enjoy contributing to a mutual cause, that is why you know when the team succeeds, you succeed. You are always looking for ways to grow your skills. You are hungry to learn new technologies and share your insights with your team. You like a big picture perspective and also digging into the fine details. You can think strategically but also dive into complex systems and break them down and build them back better. You are a proactive problem solver. You are irked by an unreliable infrastructure and your first instinct is to find ways to fix it. What you'll need: Multi-faceted Alluxio and Hadoop understanding, including the Kerberos, for data storage and Trino, Hive, and Impala for data retrieval. Experience managing Kafka clusters on Linux. Thorough understanding of Linux (we use CentOS in production). Experience administering SQL/NoSQL databases (we use MySQL, PostgreSQL, MongoDB). Any scripting language (Python/Ruby/Shell etc). Understanding of basic networking concepts (TCP/IP stack, DNS, CDN, load balancing). Must be willing and able to East Coast U.S. hours 9am-6pm EST Bonus, but not required: Ability to work with Cassandra cluster from installation through troubleshooting and maintenance. Puppet configuration management tool. Experience with scalable infrastructure monitoring solutions such as Icinga, Prometheus, Graphite, Grafana and ELK. Experience with container technologies such as Docker and Kubernetes. Train/mentor junior-level staff. Experience in AdTech or High-Frequency Trading. Experience with Security-related best practices. Waiting for your CV!",Английский — C1 — Продвинутый,Murano Software,
207,78617195,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Rubius – IT-компания со смелым характером. Мы разрабатываем софт для клиентов из различных отраслей – от промышленности и нефтегаза до ритейла и медицины. Обосновались в Томске, работаем по всему миру: наше программное обеспечение используют в США, Европе и Азии. Наши решения используют Apple, Tesla, Kaspersky, Amazon, IBM, Uber, Netflix, Газпром, РЖД и другие. В группу компаний входят представительства в США (Нью-Йорк), Казахстане (Алматы, резиденты Astana hub), ОАЭ (Дубай). В нашем профиле на hh.ru мы постарались подробно рассказать о нас, обязательно загляните:) Одна из наших команд, которая занимается искусственным интеллектом, приглашает Data Engineer, так как команда расширяется. Вам предстоит работать с большими данными совместно с аналитиками и командой ML. Мы ищем человека, который умеет собирать витрины, джойнить данные и проверять полученный результат. У нас есть экспертиза по синтезу аудио и видео, анализу изображений и видео, компьютерному зрению, предиктивной аналитике, обработке текстовых данных и тд. Мы исследуем разные сферы от логистики до медицины, погружаемся в сферы наших крупных заказчиков с головой, чтобы помочь оптимизировать процессы. Также команда разработала свой продукт для видео аналитики Visius. Чем предстоит заниматься: проектировать и собирать витрины данных по разработанному ТЗ проектировать, разрабатывать и поддерживать ETL-процессы для загрузки данных из/в Data Lake тестировать результаты преобразования данных и проверять их целостность писать документацию - комментировать код работать с data-аналитиками для создания новых и оптимизации существующих витрин Добро пожаловать к нам в команду, если есть: понимание основных операций ДБ и DWH опыт работы с Hadoop технологиями (Spark, Hive и тд) хорошее знание SQL, Python опыт работы с Azure/Yandex облачными платформами опыт работы с Airflow, Kafka будем плюсом Что мы предлагаем: Сотрудники компании – главная ценность Rubius. Мы поддерживаем свободу творчества и полёт инженерной мысли. Стремимся, чтобы каждый участник нашей команды раскрыл свой потенциал. Мы стараемся максимально заботиться о наших сотрудниках. Здесь удалённые и офисные команды чувствуют себя максимально комфортно. Про работу и оплату белая и своевременная заработная плата в зависимости от компетенций и уровня официальное трудоустройство до 10% ежемесячной премии за хорошие результаты помощь с home office возможно трудоустройство в нашей компании в Казахстане (для желающих получить заветную карту Visa) Про рост и развитие индивидуальный трек развития по желанию бесплатное обучение английскому языку бонус за профессиональное развитие (курсы, подкасты, литература по хард и софт скиллам) компенсация 50% за профессиональную сертификацию внутренние митапы на разные темы Про офис, плюшки и атмосферу оплачиваемые занятия спортом (даже в домашних условиях) программа ДМС после испытательного срока скидка для вас и родственников в Rubius Academy бонусы к рождению детей и свадьбе классные корпоративы и активности развитая и комфортная корпоративная культура, без иерархии и бюрократии А ещё у нас есть лучший офис в Томске, где тебя всегда ждут, сообщества по интересам (футбол, теннис, своя музыкальная группа, шахматный клуб...) и коллектив, где прислушиваются к мнению каждого. Подробнее о нашей компании можно почитать в нашем профиле на hh.ru. Там же есть ссылочки на наши сайты и соцсети. Откликайтесь!",,Rubius,"Томск, улица Нахимова, 13/1"
209,78617302,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Rubius – IT-компания со смелым характером. Мы разрабатываем софт для клиентов из различных отраслей – от промышленности и нефтегаза до ритейла и медицины. Обосновались в Томске, работаем по всему миру: наше программное обеспечение используют в США, Европе и Азии. Наши решения используют Apple, Tesla, Kaspersky, Amazon, IBM, Uber, Netflix, Газпром, РЖД и другие. В группу компаний входят представительства в США (Нью-Йорк), Казахстане (Алматы, резиденты Astana hub), ОАЭ (Дубай). В нашем профиле на hh.ru мы постарались подробно рассказать о нас, обязательно загляните:) Одна из наших команд, которая занимается искусственным интеллектом, приглашает Data Engineer, так как команда расширяется. Вам предстоит работать с большими данными совместно с аналитиками и командой ML. Мы ищем человека, который умеет собирать витрины, джойнить данные и проверять полученный результат. У нас есть экспертиза по синтезу аудио и видео, анализу изображений и видео, компьютерному зрению, предиктивной аналитике, обработке текстовых данных и тд. Мы исследуем разные сферы от логистики до медицины, погружаемся в сферы наших крупных заказчиков с головой, чтобы помочь оптимизировать процессы. Также команда разработала свой продукт для видео аналитики Visius. Чем предстоит заниматься: проектировать и собирать витрины данных по разработанному ТЗ проектировать, разрабатывать и поддерживать ETL-процессы для загрузки данных из/в Data Lake тестировать результаты преобразования данных и проверять их целостность писать документацию - комментировать код работать с data-аналитиками для создания новых и оптимизации существующих витрин Добро пожаловать к нам в команду, если есть: понимание основных операций ДБ и DWH опыт работы с Hadoop технологиями (Spark, Hive и тд) хорошее знание SQL, Python опыт работы с Azure/Yandex облачными платформами опыт работы с Airflow, Kafka будем плюсом Что мы предлагаем: Сотрудники компании – главная ценность Rubius. Мы поддерживаем свободу творчества и полёт инженерной мысли. Стремимся, чтобы каждый участник нашей команды раскрыл свой потенциал. Мы стараемся максимально заботиться о наших сотрудниках. Здесь удалённые и офисные команды чувствуют себя максимально комфортно. Про работу и оплату белая и своевременная заработная плата в зависимости от компетенций и уровня официальное трудоустройство до 10% ежемесячной премии за хорошие результаты помощь с home office возможно трудоустройство в нашей компании в Казахстане (для желающих получить заветную карту Visa) Про рост и развитие индивидуальный трек развития по желанию бесплатное обучение английскому языку бонус за профессиональное развитие (курсы, подкасты, литература по хард и софт скиллам) компенсация 50% за профессиональную сертификацию внутренние митапы на разные темы Про офис, плюшки и атмосферу оплачиваемые занятия спортом (даже в домашних условиях) программа ДМС после испытательного срока скидка для вас и родственников в Rubius Academy бонусы к рождению детей и свадьбе классные корпоративы и активности развитая и комфортная корпоративная культура, без иерархии и бюрократии А ещё у нас есть лучший офис в Томске, где тебя всегда ждут, сообщества по интересам (футбол, теннис, своя музыкальная группа, шахматный клуб...) и коллектив, где прислушиваются к мнению каждого. Подробнее о нашей компании можно почитать в нашем профиле на hh.ru. Откликайтесь!",,Rubius,"Томск, улица Нахимова, 13/1"
212,79184755,Data Centre Infrastructure Services Engineer (onsite),з/п не указана,3–6 лет,"Полная занятость,полный день","Data Centre Infrastructure Services Engineer Location: Atyrau, 14/14 Duties: Support Data Center infrastructure and environment Backend Hardware Support and Maintenance Install, manage and support IT Data Storage systems: NetApp, EMC/DELL, HP 3par, EVA, MSA Install, manage and support server computing systems: rack mounted servers, Blade Enclosures, converged systems, etc. (HP Blade Enclosures, Cisco UCS, HP Proliant etc. ) Install, manage and support backup systems: Tape Libraries (HP StoreOnes, EMC Data Domain) Install, configure, and administer Windows Server 2008 and 2012 Server for Physical Platforms Perform hardware and software recovery Monitor & report using special monitoring tools to maintain awareness and control of the backend infrastructure hardware, software and environment Fulfil requests for escorted access to server rooms and data center premises Perform Health, Safety, Security Environment inspection of Server Rooms Perform Weekly reporting Ensure proper housekeeping of the Server Rooms Monitor IT backend infrastructure hardware, peripherals, spare parts and consumables inventory and maintains Configuration file for equipment in production server rooms and operational stocks Manage Software upgrades and patches processes Available 24x7 for emergency situations & procedures as power shutdowns, network outages, hardware failures and disaster recovery procedures Hardware installation, decommission and replacement via Change Management Support Incident Management Support Request Management using ITSM tool service tickets Support Asset Management, Configuration & Capacity Management Remote sites maintenance and support Perform Power and Capacity Calculation Perform hardware related data collection and update of landscape files within Landscape Management Install, Configure Data Center, Hardware and Services Monitoring applications and appliances. (Netbotz EMS, Solarwinds SAM, HP One view, HP SIM, IRS, Vertiv Trellis etc.) Assist in development of Operational Level Agreements, Service Level Agreements and Contract Scopes related to IT data center Hardware and Facilities Business Continuity Management support including Business Continuity Plan/Disaster Recovery Plan assurance Coordinate Power Outages and Facilities Management Maintenance Support Risk issues resolution and Risk Management team Support Production Operations infrastructure services Support Technical Directorate infrastructure service Support SAP, Physical Security (CCTV, ACS), Opentext (Enterprise Document Management System) servers infrastructure Support migration of services from physical platform to virtual environment Supervise team engineers and perform team activities planning Design, support procurement, installation, upgrading, operation, control, maintenance and effective use of data center infrastructure Develop and maintain documentation related to ITSM policies, strategies and processes Education: Bachelor’s Degree or higher in Engineering, Information Technology or related field. Knowledge: Networking fundamentals: TCP/IP, file transfer and secure file transfer protocols, Internet Information Server systems/software administration: server roles installation and configuration, security levels and permissions, installation of third-party software, backup systems Back-end Infrastructure Systems (Servers, Tape Libraries, Virtual Infrastructure components, etc.) Working with multi-vendor monitoring and management tools/protocols such as iLO, CIMC, IPMI, SNMP Technological processes of Data Center – air cooling (air conditioning equipment), power supply ( Uninterrupted Power Supply, Power Distribution Units, Emergency Generator Units), fire safety (Fire Suppression Systems) IT service delivery & support processes based on international standards, best practices and frameworks (ISO 270001/2, COBIT, ITIL, ISO 9001 etc.) Uptime Institute Data Center Certification and TIA and ASHRAE Standards English – upper-intermediate Experience: 3+ year experience in: Supporting Backend hardware equipment (HPE, DELL, VCE, EMC, Cisco, NetApp etc.) Compilation of work plans, equipment upgrades, project surveys, repair and maintenance works with Data Centers Infrastructure Monitoring of Data Center - temperature indicators Certification: Preferred to have: Certified Data Center Professional(CDCP) Preferred to have: ITIL Foundation Preferred to have: Data Center foundations Preferred to have: Microsoft Certified Associate.","Data Centre,NetApp,EMC/DELL,HP 3par,EVA,MSA,Tape Libraries,Windows Server 2008,Windows Server 2012,Server Rooms,ITSM,Incident Management,Asset Management,Request Management,Business Continuity Management,Disaster Recovery,Opentext,TCP/IP,ISO 270001/2,COBIT,ITIL,ISO 9001,Английский язык,CDCP,Английский — B2 — Средне-продвинутый",iQ-SOLUTIONS,
227,78183519,Sr. Azure Data Architect \ Sr. Azure Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Компания #AWARA IT — это компания, которая сочетает в себе любовь к самым перспективным и интересным технологиям мира и уверенность, что эти технологии должны нести лучшие из лучших : )  Наша команда – страстные фанаты и профессионалы своего дела. Непрерывное обучение и развитие являются частью нашего корпоративного ДНК. Мы сосредоточены на качестве поддержки наших клиентов и на реализации новых проектов, в результате - множество интересных и нестандартных задач и широкое поле возможностей для проявления себя!  Команда #AWARA IT работает на широком технологическом стеке, мы находимся в постоянном поиске лучших решений и новейших технологий для нас и наших клиентов. Наши ожидания: Высшее техническое образование Понимание Cloud based инфраструктуры, IaaS \ PaaS \ SaaS Понимание рынка программного обеспечения в направлении Data, Big Data, BI, Advanced Analytic. Понимание и глубокие технологические знания технологического стэка Azure Data Services. Отличные коммуникативные навыки Умение работать в условиях многозадачности Английский язык - разговорный уровень является обязательным, для свободного общения и участия в проектах. Обязанности: Участие в проектах по реализации и внедрению программных продуктов классa DWH \ BI на базе облачной платформы и сервисов Azure Анализ и оценка требований клиента, с последующим формированием плана работ Проектирование и разработка витрин данных для анализа и моделирования Проектирование и реализация корпоративного хранилища данных (DWH – Azure Synapse, Azure DB`s, Azure Services) Анализ производительности баз данных, хранилищ данных и их Performance tuning Проектирование реализация и настройка, настройка и внедрение процессов ETL \ ELT (Azure Data Factory, Azure Functions, Spark) Проектирование и реализация DataLake \ Delta Lake Мониторинг и оптимизация процессов сборки витрин Загрузка и обработка данных из различных источников Поддержка и развития базы знаний  Требования: Знания Azure Data Services – Azure Data Factory, Azure Data Lake, Azure SQL DB, Azure PostgreeSQL, Azure CosmosDB, Azure Synapse, Azure Spark, Azure Functions. Желателен опыт администрирования и работы с SQL Server \ Azure SQL DB, Azure Synapse. Опыт разработки и реализации Data Governance подходов и практик. Опыт работы с потоками данных и их загрузкой (ETL\ELT, батчи, потоковая обработка) Опыт поддержки инфраструктуры данных (devops, аналитические базы данных, ETL-инструменты, BI-инструменты) Опыт проектирования и реализации хранилищ данных (DWH) Хорошее знание и опыт работы со стэком Azure Data Services Желателен опыт разработки на Python/Scala/Java Знание и опыт работы и реализации MDM – Master Data Management будет очень весомым преимуществом. Условия: Официальное трудоустройство в соответствии с ТК РK с первого дня Полностью ""белая"" заработная плата, премии по итогам успешных проектов ДМС после прохождения испытательного срока Гибкое начало рабочего дня (по договоренности с руководителем отдела), удаленная работа. Возможен гибридный график работы по желанию. Сертификация и обучение за счет компании Печеньки, шахматные турниры, корпоративные мозгобойни и многое другое","SQL,PostgreSQL,Azure Synapse,Azure Data Factory,Azure Spark,Azure DataBricks,Azure DB`s,Azure Function,Python,Hadoop,ETL,ELT,DataLake,DeltaLake,DWH,Cистемы управления базами данных,Базы данных,Spark,Работа с базами данных,Моделирование,Умение работать с клиентами",Авара Ай Ти Казахстан,
237,79045942,Senior Site Reliability Engineer (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Since 2003, Murano has been developing software that simplifies and optimizes the customer's daily work and contributes to the digitalization of key US industries as well. Besides the client projects, the company maintains and develops its product based on the .NET platform: the world’s leading insurance submission, application, and policy management system, which is used by more than half of independent insurance agencies in the United States. Murano's head office locates in Los Angeles, and its team works from different cities and countries worldwide. This vacancy is opened on our outsourcing project. Project of our client produces a complete view of the health customer, to unlock and activate health insights in order to revolutionize health decision-making in real time. Through machine learning and programmatic automation, the company interprets the hard-to-read signals of the health journey to understand the connection points between relevance and engagement. This is achieved by unifying real-time Digital Determinants of Health, offline and clinical data to create a unique and precise view of the health ecosystem that refines, improves and increases its view over time. What you’ll be doing: Deploying, configuring, monitoring and maintaining multiple big data stores, across multiple datacenters. Perform planning, configuration, deployment and maintenance work relevant to the environment. Managing the large-scale Linux infrastructure to ensure maximum uptime. Developing and documenting system configuration standards and procedures. Performance and reliability testing. This may include reviewing configuration, software choices/versions, hardware specs, etc. Advancing our technology stack with innovative ideas and new creative solutions. Who are you: Collaboration is in your DNA. You enjoy contributing to a mutual cause, that is why you know when the team succeeds, you succeed. You are always looking for ways to grow your skills. You are hungry to learn new technologies and share your insights with your team. You like a big picture perspective and also digging into the fine details. You can think strategically but also dive into complex systems and break them down and build them back better. You are a proactive problem solver. You are irked by an unreliable infrastructure and your first instinct is to find ways to fix it. What you'll need: Multi-faceted Alluxio and Hadoop understanding, including the Kerberos, for data storage and Trino, Hive, and Impala for data retrieval. Experience managing Kafka clusters on Linux. Thorough understanding of Linux (we use CentOS in production). Experience administering SQL/NoSQL databases (we use MySQL, PostgreSQL, MongoDB). Any scripting language (Python/Ruby/Shell etc). Understanding of basic networking concepts (TCP/IP stack, DNS, CDN, load balancing). Must be willing and able to East Coast U.S. hours 9am-6pm EST Bonus, but not required: Ability to work with Cassandra cluster from installation through troubleshooting and maintenance. Puppet configuration management tool. Experience with scalable infrastructure monitoring solutions such as Icinga, Prometheus, Graphite, Grafana and ELK. Experience with container technologies such as Docker and Kubernetes. Train/mentor junior-level staff. Experience in AdTech or High-Frequency Trading. Experience with Security-related best practices. Waiting for your CV!",Английский — C1 — Продвинутый,Murano Software,
279,78718263,Senior / Lead Data Software Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","DESCRIPTION We are looking for an open-minded Senior / Lead Data Engineer to develop and maintain data-driven architecture. On our projects, we are developing pipelines to build business-related data products and design cloud-based platform solutions to support DataHub functionality. WHAT YOU’LL DO Design and implement data pipelines Perform data ingestion processes to include existing data sources in the new platform Participate in platform engineering, including cloud-based solutions to support solution architecture, such as Ingestion Frameworks, Platform Orchestrators, Exploratory environments etc Conduct MLOps activities to build production-ready cloud-based solutions to support existing ML pipelines Take part in the design of on-prem to cloud migration activities WHAT YOU HAVE Solid experience in Java, Python or Scala Proficiency in SQL Understanding of common Big Data problems (splitability, massive parallel processing, load-balancing, data locality, streaming, etc.) and related technologies (Apache Spark, Map-Reduce, HDFS) Acquaintance with data modeling: relational/dimensional data, SCD, snowflaking, etc English level – B1+, both written and spoken NICE TO HAVE Familiarity with common data-related architectures such as Data-Hub/Data Lake Experience in cloud-based solutions, GCP, Terraform, Kubernetes TECHNOLOGIES Apache Spark, Kubernetes, Hadoop, Cloud Storage (S3, ADLS, GS, etc.), Cloud Functions, Airflow, Apache Kafka, Jenkins, Terraform, Avro, Parquet WE OFFER Outstanding career development opportunities with a transparent roadmap to accelerate your journey Knowledge sharing within the community of 61,300+ industry’s top professionals worldwide Various opportunities for self-development: hard & soft skills internal training courses, mentoring programs, and unlimited access to 8,000+ LinkedIn Learning courses Free English classes with certified teachers Competitive compensation, regular assessments, and salary reviews Participation in the Employee Stock Purchase Plan Flexible working schedule Friendly team, and enjoyable working environment Relocation opportunities within our offices in 50+ countries Social package – medical & family care Five trust days a year (sick leave without a medical certificate) ABOUT EPAM EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to numerous innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to learn and grow continuously. No matter where you are located, you will join a dedicated, creative, and diverse community to help you discover your fullest potential",,"Epam Kazakhstan (Эпам Казахстан),ТОО",
287,78587217,ECommerce Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Accountabilities: Own development of ETL data pipelines, taking responsibility for designing, data modelling, coding, testing, scalability, operability, and ongoing metrics. Collaborate with product manager, business stakeholders, BI engineers, data analysts, data scientists, IT to deliver sustainable and quality results Partner with Sector team to leverage global solutions and best practices Build tools and libraries that reduce new pipeline development time Create metrics to measure the quality and validity of 2nd and 3rd party vendor data Research existing solutions internally and externally to identify gaps between business needs and offerings Research and document data abnormalities and track them as bugs with the engineering teams responsible Key Skills/Experience Required : Bachelor’s Degree (Computer Science or related preferred) 2+ years of professional experience using Python or similar programming language Knowledge of engineering best practices for the full software development life cycle, including coding standards, code reviews, source control management, continuous integrations, testing, and operations RDBMS databases and SQL language Microsoft Azure stack, AWS and GCP is a plus Nice to have: Knowledge of Web Scraping, Airflow, Kubernetes and Docker","azure,SQL,Airflow,Kubernetes,Docker,RDBMS,Python,data engineer,eComm,Databases,Английский — B2 — Средне-продвинутый",PepsiCo,"Москва, Сокол, Ленинградский проспект, 72к4"
560,79244489,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
582,79244492,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
679,79244493,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
755,77652440,Разработчик (Команда УБП) Big Data,з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Организация, планирование и реализация технологических задач Подготовка оценки работ по задачам Проектирование функциональной модели системы Написание функций и хранимых процедур для преобразования и агрегации данных, создание витрин, отчетов Участие в проектной деятельности, процессах доработки и внедрения, а также оптимизации системы управления бизнес-планированием Участие в проведении технологической экспертизы по задачам на реализацию системы Участие в разработке документации, функциональных и нефункциональных требований по развитию системы Проведение работ по обнаружению ошибок и принятию мер для их устранения с целью обеспечения непрерывного и бесперебойного функционирования системы Требования: Опыт разработки и проектирования не менее 2 лет Опыт работы с хранилищами данных (DWH), Data lakes Отличное знание SQL Уверенное знание процедурных языков PL/SQL или PL/pgSQL Опыт работы с реляционными БД (MS SQL, Oracle, PosgreSQL) Понимание архитектуры БД/Хранилищ данных Опыт работы в Банковской/Финансовой сфере Знание основ программной инженерии, жизненного цикла разработки программного обеспечения, управления требованиями. Будет плюсом: Опыт разработки решений BI систем Опыт работы с колоночными БД (Vertica, Clickhouse, GreenPlum/Arenadata) Проектирование и/или разработка процессов ETL Опыт миграции учетных систем","DWH,SQL,PostgreSQL,PL/SQL,ETL,Работа с базами данных,Data lakes","ннотех, Группа компаний",
880,77652420,Разработчик (Команда УБП) Big Data,з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Организация, планирование и реализация технологических задач Подготовка оценки работ по задачам Проектирование функциональной модели системы Написание функций и хранимых процедур для преобразования и агрегации данных, создание витрин, отчетов Участие в проектной деятельности, процессах доработки и внедрения, а также оптимизации системы управления бизнес-планированием Участие в проведении технологической экспертизы по задачам на реализацию системы Участие в разработке документации, функциональных и нефункциональных требований по развитию системы Проведение работ по обнаружению ошибок и принятию мер для их устранения с целью обеспечения непрерывного и бесперебойного функционирования системы Требования: Опыт разработки и проектирования не менее 2 лет Опыт работы с хранилищами данных (DWH), Data lakes Отличное знание SQL Уверенное знание процедурных языков PL/SQL или PL/pgSQL Опыт работы с реляционными БД (MS SQL, Oracle, PosgreSQL) Понимание архитектуры БД/Хранилищ данных Опыт работы в Банковской/Финансовой сфере Знание основ программной инженерии, жизненного цикла разработки программного обеспечения, управления требованиями. Будет плюсом: Опыт разработки решений BI систем Опыт работы с колоночными БД (Vertica, Clickhouse, GreenPlum/Arenadata) Проектирование и/или разработка процессов ETL Опыт миграции учетных систем","DWH,SQL,PostgreSQL,PL/SQL,ETL,Работа с базами данных,Data lakes","ннотех, Группа компаний",
2613,78587217,ECommerce Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Accountabilities: Own development of ETL data pipelines, taking responsibility for designing, data modelling, coding, testing, scalability, operability, and ongoing metrics. Collaborate with product manager, business stakeholders, BI engineers, data analysts, data scientists, IT to deliver sustainable and quality results Partner with Sector team to leverage global solutions and best practices Build tools and libraries that reduce new pipeline development time Create metrics to measure the quality and validity of 2nd and 3rd party vendor data Research existing solutions internally and externally to identify gaps between business needs and offerings Research and document data abnormalities and track them as bugs with the engineering teams responsible Key Skills/Experience Required : Bachelor’s Degree (Computer Science or related preferred) 2+ years of professional experience using Python or similar programming language Knowledge of engineering best practices for the full software development life cycle, including coding standards, code reviews, source control management, continuous integrations, testing, and operations RDBMS databases and SQL language Microsoft Azure stack, AWS and GCP is a plus Nice to have: Knowledge of Web Scraping, Airflow, Kubernetes and Docker","azure,SQL,Airflow,Kubernetes,Docker,RDBMS,Python,data engineer,eComm,Databases,Английский — B2 — Средне-продвинутый",PepsiCo,"Москва, Сокол, Ленинградский проспект, 72к4"
4849,78306430,Python Backend Developer / Data Engineer,до 250 000 руб. на руки,1–3 года,"Полная занятость,удаленная работа","DataGo! (ex OWOX Russia) — одна из сильнейших команд в сфере маркетинговой аналитики в СНГ со своими собственными продуктами, решениями и центром экспертизы с многолетним опытом. DataGo! дает качественные данные аналитикам и прикладные отчеты маркетологам и product менеджерам. • Нам доверяют более 100 крупнейших клиентов РФ в сферах: E-commerce, Banking, Telecom, Pharma. • Официальный партнер Яндекс.Метрика и Яндекс.Cloud. • Самое большое количество успешных кейсов с использованием Google Cloud и Google Analytics среди всех партнеров Google в СНГ. Сейчас мы ищем человека с опытом на стыке бэкенд-разработки и дата-инженерии, который усилит нашу продуктовую команду и попадет в самое сердце разработки DataGo! Чем предстоит заниматься: Разрабатывать и улучшать наш продукт – стриминг данных – с помощью FastAPI Сервис высоконагруженный – около 4000 RPS Работать с интеграциями – разрабатывать коннекторы и пайплайны на aiohttp, asyncio Собирать, обрабатывать и доставлять данные в базы заказчиков (CLickhouse/GBQ) с помощью Airflow. Для нас важно: Наличие опыта разработки на Python (Pandas, Numpy), с асинхронным стэком в частности (FastAPI, asyncio, aiohttp) – от 2-ух лет Опыт работы с БД: Clickhouse, PostgreSQL, будет плюсом – GBQ Опыт разработки и общее понимание архитектуры высоконагруженных, масштабируемых сервисов Навыки работы с виртуальными машинами, Сelery, Redis, RabbitMQ, Nginx Навыки работы с облачными серверами – Google Cloud, Яндекс Облако. Что мы предлагаем: Оформление в аккредитованную Т-компанию со всеми преимуществами или оформление сотрудничества за рубежом, в любом случае - полностью удаленная работа из любой точки мира Конкурентную заработную плату до 250 000 рублей на руки Возможность работать в команде, которая сохранила дух стартапа – нас немного, мы очень классные и не позволяем никакой бюрократии влезать в наши процессы. Если считаешь, что все вышесказанное про тебя — ждём отклик!","Python,asyncio,aiohttp,FastAPI,Pandas,Numpy,ClickHouse,PostgreSQL,Google BigQuery,Celery,Nginx,Pytest,Airflow",DataGo!,
6342,78077596,QA engineer в команду разработки Data Office,з/п не указана,3–6 лет,"Полная занятость,полный день",,,"Лента, федеральная розничная сеть, Офис",
6439,78267157,Data Engineer (Backend),з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Проектирование и разработка программно-технологической инфраструктуры витрин и хранилищ аналитических данных, ETL потоков данных, BI. Разработка и интеграционных модулей для получения/обмена аналитическими данными. Всесторонняя поддержка бизнеса со стороны данных. Ведение ETL процессов в средних и верхних слоях данных. Построение роадмапа и непосредственное участие в процессе по обмену данными. Программирование витрин DataMart, бэкенд разработка. Требования: Опыт проектной деятельности по Agile (SCRUM, Kanban). Стек технологий: PostgreSQL, Python, nosql, приветствуется R или C++, Apache Spark, Hadoop, MapReduce, Airflow, Data Analysis, Data Mining, Dashboards. Приветствуется ML и Data Science, Java платформы, микросервисная архитектура, REST и SOAP, BPMN, UML, иные нотации и инструментальное ПО описания процессов, моделей и потоков данных Data Governance и Data Lineage. Крайне приветствуется опыт систем мастер-данных UNIDATA и т.п., BI и OLAP инструментарий. Приветствуется опыт BigData и AI. Приветствуется опыт в информационной безопасности (ФСТЭК, ФСБ). Приветствуется опыт межведомственного и межсистемного взаимодействия (СМЭВ, ПГУ, Электронное правительство). Условия: Официальное трудоустройство в соответствии с ТК РФ. Конкурентная заработная плата и ежегодные бонусы. ДМС + стоматология. Гибкое начало рабочего дня и удаленный формат работы.","Python,PostgreSQL,Java,SQL,BPMN,R,C++,NoSQL,ETL,Apache Spark,Hadoop,Airflow,Data Analysis,Data Mining,UNIDATA,BigData,AI,DataMart",Цифромед,"Москва, Деловой центр, Международная, Тестовская, Тестовская улица, 10"
6555,79244492,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
6558,79244488,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
6685,75697706,Junior Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Задачи Анализ бизнес и функциональных требований к витринам данных Анализ и профилирование данных систем-источников, подготовка прототипов витрин данных Взаимодействие с разработчиками Участие в демонстрациях и сдаче продукта заказчику Подготовка документации Участие во внедрении и сопровождении программного продукта Наши ожидания от кандидата Аналитический склад мышления, системный подход, опыт коммуникации Опыт работы от года с данными: анализ, профилирование Знание SQL (типы данных, операции и функции, умение писать запросы) Опыт работы от года с офисными программами и программами для доступа к данным Опыт работы с Jira, Confluence Аналитический склад ума Развитые коммуникативные навыки Стремление к самообразованию Мы готовы предложить потека выгоднее для каждого сотрудника и льготные условия кредитования Бесплатная подписка СберПрайм+ Скидки на продукты компаний-партнеров: Okko, Сбер Маркет, Delivery Club, Самокат, Сбер Еаптека и другие ДМС с первого дня и льготное страхование для близких Корпоративная пенсионная программа Курсы для будущих родителей, материальная поддержка и тематическое сообщество для молодых мам Детский отдых и подарки за счет Компании Обучение за счет Компании: онлайн курсы в Виртуальной школе Сбера и неограниченный доступ к библиотеке, обучение в Корпоративном университете, тренинги, митапы и возможность получить новую квалификацию Реферальная программа для сотрудников: можно пригласить в команду знакомых профессионалов и получить вознаграждение до 100 тыс. рублей Скидки на отдых в лучшем в мире курортном комплексе «Mriya Resort & SPA» в Ялте.",,Сбер. Data Science,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
6687,79225796,Data Analyst,от 230 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Головной офис компании находится в USA, California, Irvine. Команда разработки распределена по миру и находится в разных странах и часовых поясах. Бизнес компании растет, интегрируется с банками, в связи с чем растет и количество клиентов, данных. С 2016 мы непрерывно работаем над доработкой наших систем, занимаемся оптимизацией уже разработанных алгоритмов и внедряем новые решения, позволяющие автоматизировать бизнес компании, оптимизировать расходы. Как следствие, мы хотим анализировать качество и эффективность наших систем. Чем предстоит заниматься: Создание и поддержка панелей мониторинга и отчетов, которые обеспечивают бизнес-задачи компании Обработка больших объемов данных и участие в повышении эффективности бизнес-процессов Анализ данных, выявление тенденций и создание предложений по улучшению бизнес-процессов Анализом данных из web и мобильного приложения Визуализацией данных Консультаций других отделов по вопросам аналитики данных Что будет важным для нас: Опыт работы в качестве дата-аналитика не менее 3 лет Опыт работы с базами данных MySQL/ MariaDB, SQL, Python Владение инструментами: Tableau, AppMetrica, Google Analytics Знание статистических методов и анализа данных Умение презентовать результаты своей работы Английский язык - C1 (для коммуникации с англоговорящими коллегами) Готовность работать в диапазоне с 18:00-00:00 Мск (утро и день Калифорнии) Что мы предлагаем: Участие в высоконагруженном проекте с нетривиальными задачами Поддержку инициатив и профессиональный апгрейд Удалённую работу с гибким графиком и оплатой на зарубежное П Оплачиваемый отпуск, больничные, спорт, английский в Skyeng Оплату конференций Релокационную поддержку Уровень обсуждается по результатам. Есть ежегодный пересмотр. ЗП фиксируем в долларах.","SQL,Python,Tableau,Анализ данных,Английский язык,Визуализация данных,Английский — C1 — Продвинутый",Americor Funding Inc,рвайн
6688,79146431,Data Analyst,от 150 000 руб. на руки,1–3 года,"Полная занятость,полный день","Команда профессионалов, за плечами которой создание нескольких успешных FinTech проектов в странах Юго-Восточной Азии, развивает новый, еще более амбициозный проект. Мы решаем интересную и крутую задачу – построение онлайн-банка в Азии. Мы ищем Data Analyst в команду DWH, которая на текущий момент состоит из 7 человек. Мы отвечаем за данные, их качество и строим центр принятия решений, чтобы ответы на вопросы бизнеса были точно и однозначно интерпретируемы. Основные обязанности: Собирать требования и формализировать/прототипизировать задачи для доработок корпоративного хранилища данных Разрабатывать отчеты и дашборды в PowerBI Анализировать продуктовые метрики и ключевые бизнес-показатели Заниматься разработкой и доработкой агрегатов Учавствовать в автоматизации аналитических процессов (sql / dbt) Работать с БД PosgreSQL Выдвигать гипотезы, проверять их и делать выводы на основе данных. Заниматься ad-hoc аналитикой Требования: Сильные знания SQL, умение работать с реляционными СУБД (мы используем Postgres) Практические навыки в data-аналитике, продуктовой аналитике, бизнес-аналитике от двух лет Умение самостоятельно принимать решения на основе данных, аргументировать их и рассказывать о своих результатах Знание PowerBI, DAX, или глубокие знания схожих инструментов аналитики Хорошее знание мат. статистики и теории вероятности, системное мышление и аналитический склад ума Знание основ Python. Опыт применения Python в автоматизации и работе с данными (как плюс) Знание английского языка (B2+) Образование: Оконченное высшее образование Что мы предлагаем: Комфортный офис в Москва-Сити с возможностью работать из любой точки мира Официальное трудоустройство, конкурентная заработная плата Гибкий рабочий график для оптимального баланса между работой и личной жизнью Высокий уровень корпоративной культуры, корпоративные мероприятия Прекрасная возможность профессионального развития в молодой и динамично развивающейся компании","SQL,PostgreSQL,Power BI,Аналитическое мышление,Анализ данных,Математическая статистика,Системное мышление,Python,Английский — B2 — Средне-продвинутый",Ок Софт,"Москва, Центральный административный округ, Пресненский район, Московский международный деловой центр Москва-Сити"
6689,79242005,Data analyst,от 400 000 до 650 000 KZT на руки,1–3 года,"Полная занятость,полный день","Aventus Group – международная группа Fintech компаний. Мы создаем и развиваем успешные digital продукты на 3 континентах уже более 13 лет. Сейчас мы в поиске Data analyst. Присоединяйтесь к Aventus Group и становитесь важной частью большого объединения профессионалов, создающих Fintech историю по всему миру! Рассматриваем кандидатов только с опытом работы! Тебе предстоит: Анализ показателей деятельности компаний группы и отдельных подразделений, формирование и предоставление аналитической отчетности на регулярной основе Статистика по запросам подразделений Построение дополнительных отчетов на основании внешних и внутренних данных Участие в развитии и автоматизации системы отчетности в компаниях группы Создание четко сформулированных и лаконичных заданий, тестирование их внедрения, активное выяснение недостающих требований. Для нас важно: Высшее/неоконченное высшее математическое/статистическое/экономическое образование Опыт работы с инструментами BI Знание SQL на хорошем уровне (умение составлять запросы) Умение работать с большими объемами информации Логическое системное мышление Способность быстро адаптироваться к новым условиям, внимательность к деталям Знанием английского языка на уровне Intermediate и выше будет являться преимуществом Опыт работы в банке и/или микро кредитной компании (МФО) в должности аналитика будет являться преимуществом. Мы предлагаем: Рыночный уровень зарплаты (обсуждаем индивидуально с каждым) Быстрое развитие (практика на крупных международных финансовых проектах) Полный рабочий день (8 часов) Работа в офисе или гибридно Коллектив компетентных профессионалов Компенсацию страховки, спорта и курсов английского языка Отпуск 24 дня, официальное трудоустройство. нтересно? Тогда отправляй свое резюме, мы ждем тебя!",,МФО Credit365 Kazakhstan (Кредит 365 Казахстан),
6690,79004258,Junior Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Для нового проекта/продукта в Кипрский офис ищем командного и эффективного аналитика-данных помогающего продукту работать с большим объемом данных, прогнозировать пользовательское поведение, создавать механики по взаимодействию с пользователем и другие креативные задачи влияющие на опыт пользователя и его вовлеченность на площадке. так, тебе предстоит: Анализ данных и разработка сегментации пользователей на основе больших массивов данных покупательской корзины, транзакций, товаров и услуг Разработка автоматизированных инструментов, позволяющих бизнесу кастомизировать пользователей и эффективно на них воздействовать Поиск инсайтов, анализ (больших, сложных) наборов данных, характеризующих поведение миллионов пользователей, для решения и создания гипотез по заданным механикам Предоставление рекомендаций на основе данных для формирования гипотез по поведению пользователей Генерация гипотезы продукта с командой, проведение тестирования, анализа влияния новых функций на показатели продукта Взаимодействие с разработчиками для реализации промышленных алгоритмов анализа данных и разработки инструментов управления и взаимодействия с клиентами Сотрудничество с различными бизнес-подразделениями (IT/дизайн/аналитики) с целью анализа данных, интерпретации выводов и предложения следующих эффективных действий. Ключевой проект: Центр Управления Продажами – это создание систем управления, где у нас есть покупательская корзина, транзакции, товары и услуги. За основу взята система Battle Pass. На базе данной системы и идёт построение пользовательского окружения. Наши пожелания: Вы имеете опыт работы системным/data-аналитиком от года и сильный математический бэкграунд в работе со статистическими данными Умеете читать код на Python+Python Data Visualization Tools (matplotlib, seaborn) Базово работаете с SQL: извлечения, обновления, добавление и удаление информации из нее меете практический опыт работы с библиотекой для работы с данными Pandas Опыт работы с нормализацией данных (Basic Data Preparation). Будут приветствоваться навыки: A/B тестирования Power BI Upper Intermediate English. Мы предлагаем: Работу в уникальной и быстро развивающейся сфере в дружном коллективе График работы - 5/2 Возможность гибкого начала рабочего дня с 8 до 11 Лист нетрудоспособности (больничный лист) и отпускные – оплачиваются в 100% размере Ежегодный отпуск - 28 дней  Любим настолки, квесты, выезды, гулянки и другие тусовки в оффлайне и онлайне Учимся и помогаем учиться Ездим на профессиональные конференции, поощряем командировки в другие страны Финансируем профессиональное обучение и повышение квалификации Рост и развитие в компании: регулярная обратная связь каждому сотруднику, обучающие мероприятия и широкий доступ к материалам, в том числе ведущих образовательных платформ.","Python,SQL,Data Analysis,Английский — B2 — Средне-продвинутый",Профитсайз,город Лимасол
6691,78694897,Аналитик данных / Data Analyst / BI-аналитик,от 160 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","щем аналитика данных в нашу команду Friflex.com – международная IT-компания, аккредитованная Т-компания. Развиваем собственное продуктовое направление idSport.ai (пример продукта: idChess.com). В продуктах много данных, на основе которых нужно делать выводы: составлять и проверять гипотезы, проводить A/B-тесты, а также собирать показатели в DWH (хранилище) и визуализировать метрики в BI.  Ключевые задачи: Составление дэшбордов по метрикам продуктов (выборки данных из разных БД, построение DWH, визуализация метрик) Формулирование и проверка гипотез. Проектирование A/B-тестов Работа в продуктовой команде, влияние на: метрики продуктов, фичи, радость клиентов Основные требования: Отличное знание SQL, понимание основ реляционных баз данных Опыт работы с DWH Опыт работы с BI-системами Опыт с Python и библиотек анализа данных (Pandas, SciPy) Приемлемые для статистических выводов знания в области математической статистики Принятие решений на основе данных. Data-centic подход Опыт работы с гипотезами. Опыт A/B-тестов Желателен опыт с системами аналитики, трекинга. Приветствуется высшее образование в сфере информационных технологий Проактивный подход, бодрость духа Условия: оформление в штат полностью «белая зарплата», оформление по ТК РФ работа в офисе, Москва, полная занятость. Возможен гибридный график и удаленная работа интересные, прикладные задачи с обратной связью от пользователей участие во внутренних митапах, внешних митапах и профильных конференциях.","A/B тесты,Product Development,Unit-экономика,SQL,Scrum,Статистический анализ,SciPy,Статистика,Анализ данных,Pandas,Tableau,Mathematical Statistics,Математическая статистика,Базы данных,BI,PowerBI,Python,Git,Business intelligence,Power BI,Data Analysis,PostgreSQL,Анализ поведения пользователей",Фрифлекс,"Москва, Проектируемый проезд № 4062, 6с16"
6692,79012615,Аналитик данных / Data Analyst (Junior),от 40 000 до 60 000 руб. на руки,не требуется,"Полная занятость,удаленная работа","Мы - небольшой частный инвестиционный фонд, который занимается роботизированным квант-трейдингом (к “квантовой физике” и “квантовым компьютерам” это отношения не имеет, загуглите) на рынке криптовалют с применением нейросетей. Мы ищем амбициозных, которым интересна тема финансов и количественного анализа. Для нас не важен твой предыдущий опыт, а важны твои soft skills, а именно - математический склад ума и любовь к формулам, целеустремленность, желание всецело и глубоко погрузиться в тему и умение искать правильные подходы к анализу большого объема данных. Что мы предлагаем: Старт карьеры квант-аналитика - самой трендовой профессии на Уолл Стрит. нтересную работу. Ты научишься хорошо разбираться в сфере квант-трейдинга и финансовых рынках. Возможность прокачать свой интеллект. Ты поймешь математику финансовых рынков и научишься применять математические формулы на практике. Профессиональный рост. Ты научишься выстраивать прибыльные торговые стратегии, основываясь на математических расчетах и работать с торговыми роботами. Работу на пике тренда. Ты научишься продумывать архитектуры нейросетей и обучать их, применительно к трейдингу. Полностью удаленную работу, но на полный рабочий день. Что нужно от тебя: Высшее физико-математическое или экономическое образование. Наш идеальный кандидат - также студент старших курсов физико-математических и экономических специальностей или недавний выпускник. Хорошее понимание математического анализа, линейной алгебры, теории вероятностей, математической статистики и дифференциальных уравнений. Базовые навыки программирования на Python (или способность в сжатые сроки этому обучиться). Английский язык на уровне В2 и выше. Способность анализировать большие объемы информации. Желание стать крутым специалистом в аналитике финансовых данных. Упорство в достижении целей, несмотря на трудности. Желательно, но не обязательно знание: Теории случайных процессов Стохастической финансовой математики Аналогичный опыт работы не обязателен! Что ты будешь делать: зучать литературу, лекции и вебинары крупных специалистов в данной теме. Анализировать и систематизировать полученную информацию. Презентовать изученную информацию нашей команде. На основе приобретенных знаний помогать в разработке торговых стратегий, включающих применение нейросетей. Если ты любишь математику, интересуешься темой финансов и чувствуешь, что все перечисленное близко тебе, присоединяйся к нашей команде!","Английский язык,Аналитический склад ума,Анализ данных,Работа с большим объемом информации,Математическая статистика,Подготовка презентаций,Математический анализ,Английский — B2 — Средне-продвинутый",Щербин Алексей Сергеевич,
6693,79110745,Data Engineer,от 4 000 до 6 000 EUR до вычета налогов,3–6 лет,"Полная занятость,удаленная работа","щу Data Engineer в SportTech компанию Sportradar. Sportradar - крупнейший провайдер спортивных данных в мире, работают с FIFA, UEFA, NBA, NHL, ITF и многими другими. Торгуются на Nasdaq. Нанятый человек присоединится к annotation/labeling команде в computer vision продуктах, состоящей из 3 (будет 4) SW Engineers, 1 MLOps и 1 Product Manager’а. Annotation является частью более крупной команды Automated content, состоящей из 70 человек (аналитика, дополненная реальность). Задачи Взаимодействие с data scientist’ами и аналитиками, работа над поиском новых способов генерации и улучшения качества данных. Data modeling, создание и поддержка датасетов и инструментов для их генерации. Развитие ETL и data ingestion пайплайнов. Стек: Python, Pandas, Postgres, SQLAlchemy, Airflow, AWS (RDS, S3, Step Functions, EC2). Требования Разговорный английский Опыт работы Data Engineer от 2х лет, предпочтительно с подготовкой датасетов для ML Представление о статистическом анализе данных, методах ML Python, SQL, AWS (RDS, S3, Step Functions, EC2) Плюсом будет: Airflow, Spark, Pandas, AWS SQS, SNS, EventBridge, Lambda. Этапы интервью 30 минут звонок с рекрутером, я проверю англ, отвечу на вопросы, уточню пожелания. После 2 инженера проведут техническое интервью (1-2 собеседования). Условия Первые 6 месяцев работа удаленная, не из РФ/РБ, по b2b контракту. ЗП до 6k EUR gross + после 6 мес, RSU и годовой бонус (об этом ниже). После - релокация с официальным трудоустройством на Кипр или в Словению, возможно в Сербию. Если вы уже легализовались в Европе, то добавляются спания, Австрия, Германия, Польша, Словакия. Условия в этих странах варьируются, например где-то есть фитнес в офисе, где-то нет. Где-то будет сложнее устроить человека с РФ паспортом, где-то проще. К ЗП добавится страховка, годовой бонус до 10% (обычно он в районе 6-8%), RSU в размере ~30% от годового дохода, а вот пересмотра фиксированной части ЗП в сторону увеличения, скорее всего, не будет. Часы работы гибкие, нужно пересекаться в часы, о которых договоритесь с командой. Посещение офиса от 3х дней в неделю. Если поселитесь очень далеко, то можно попробовать договориться на меньше.","Python,SQL,AWS,Английский — B2 — Средне-продвинутый",4CV Recruitment Services,
6695,79120615,Data engineer,от 180 000 до 250 000 руб. на руки,1–3 года,"Полная занятость,полный день","В крупную исследовательскую компанию, специализирующуюся на анализе рыночных данных продаж товаров потребительского спроса, требуется Data engineer. Обязанности: Системный анализ, инженерная аналитика разработке архитектуры данных и структур баз данных Работа с базами данных, формирование логики наполнения и хранения данных. Cоздание, настройка, администрирование потоков данных Разработка базовой архитектуры Работа в BigData Разработка и оптимизация SQL запросов. Подготовка витрин данных. Разработка и совершенствование аналитического продукта, позволяющего клиенту отслеживать продажи и увеличивать эффективность инвестиций в аптечном канале сбыта. Обработка массива данных и подготовка информации для расчетов, автоматизация расчетов, работа с базами данных. Подготовка данных (Выборка, очистка, генерация признаков, интеграция, формирование). нтерпретация данных, постановка задач для построения дашбордов. Требования: Высшее техническое образование, предпочтительные профили: экономика/финансы/математика/физика. Знание специализированных программных средств для работы с базами данных. Умение формировать логичные аналитические материалы и экспертные заключения. Умение анализировать, обобщать статистические данные (в том числе используя VBA MS Office) Знание классических алгоритмов и структур данных. Условия: комфортный офис в БЦ Магистраль Плаза возможность гибридного графика работы конкурентная ЗП профессиональный рост","SQL,Python,Анализ данных,Работа с базами данных,Аналитическое мышление,Аналитика,Data Analysis,Базы данных,VBA,Статистический анализ,PostgreSQL,Databases",РВ,
6696,79235299,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","В Национальную Компанию ""КазАтомПром"" ведётся конкурсный отбор на вакансию ""Менеджер отдела управления данными"". АО «НАК «Казатомпром» является национальным оператором Республики Казахстан по импорту–экспорту урана, редких металлов, ядерного топлива для атомных электрических станций. Начиная с 2009 года Казахстан является мировым лидером по добыче природного урана. Мы ждём от Вас: Высшее образование: Высшее техническое/гуманитарное образование Опыт работы в профессиональной среде - не менее 1-ого года в сферах: нформационные системы / Автоматизация и управление / Бизнес-аналитика / Проектный менеджмент. Вам предстоит: Подготовка, обработка и интерпретация данных для выработки практических рекомендаций Выявление в данных инсайтов, построение гипотез, построение предиктивных моделей Проведение ad-hoc анализов (Python, SQL, визуализация данных) Разработка ETL процессов, витрин данных, создание интерактивных дэшбордов Анализ источников данных и выявление проблем с качеством исходных данных Автоматизация процессов сбора, обработки и визуализации данных Внедрение практик по аналитике данных с целью повышения эффективности бизнеса Активная работа с DWH с целью повышения эффекта от функции хранилища данных. Знания и навыки: Уверенное владение Python (pandas, scikit-learn) для выполнения задач по анализу данных Уверенное владение SQL для получения и обработки данных, опыт работы с базами данных (PostgreSQL, Oracle) Опыт работы с любым BI-инструментом (предпочтительно Power BI), опыт построения дэшбордов Опыт работы с классическими алгоритмами машинного обучения Умение презентовать результаты анализа команде Высокие аналитические навыки, стремление к получению новых знаний Знание и понимание основ системы менеджмента в области охраны здоровья, обеспечения безопасности труда, охраны окружающей среды Знание правил миграции и распространения мастер данных Знание требований к формированию записей объектов мастер данных Навык разработки внутренних нормативных документов Навыки выявления неактуальных и/или некорректных записей Навыки эффективной коммуникации Навыки анализа данных Умение консолидировать, обрабатывать и анализировать информацию с помощью инструментов MS Office Знание и применение методов проектного управления Знание и понимание основ системы менеджмента в области охраны здоровья, обеспечения безопасности труда, охраны окружающей среды. Навыки работы на компьютере: Продвинутые Python, SQL, Power BI - обязательно. Мы предлагаем: Стабильный оклад + премиальные Работать в бизнес-центре ""А"" класса Полный рабочий день, 5/2 Получить колоссальный опыт работы в крупнейшей в мире компании производителей природного урана Наши работники обеспечены солидным социальным пакетом, который, помимо материальной помощи, гарантированных трудовых отпусков, также включает в себя добровольное медицинское обслуживание, единовременные материальные выплаты к юбилейным датам, рождению ребенка, бракосочетанию и в случае тяжелых жизненных ситуаций Так же в Компании разработана эффективная система мотивации и создаются условия для максимального развития персонала Предоставляем возможность подготовки, переподготовки и повышения квалификации с помощью широкого спектра обучающих программ, курсов, тренингов и семинаров: от дистанционных курсов до стажировки за рубежом. Благодарим Вас за интерес, проявленный к вакансии! Каждое резюме подлежит тщательному рассмотрению. Мы обязательно предоставим обратную связь в течение 7-10 рабочих дней, если готовы будем пригласить Вас на следующие этапы отбора. Если мы с Вами не связались, не расстраивайтесь и обязательно откликайтесь на другие наши вакансии, которые соответствуют Вашему профилю, целям и интересам.",,Частное учреждение Samruk Business Academy,
6697,77411849,Data Analyst (senior),от 200 000 до 300 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Кто мы Мы молодой и амбициозный start-up в быстрорастущей сфере e-commerce. Мы делаем систему аналитики и автоматизации для продавцов на маркетплейсах (Wildberries, Ozon и т. д.). Наши цели Мы хотим за 2023 год стать устойчивым лидером рынка в России и приступить к завоеванию новых рынков Азии Что нам нужно для достижения наших целей Нам нужна сильная команда, способная находить новые решения, умеющая подстраиваться под изменения рынка и действительно желающая стать лидером на рынке SaaS. Команда, которая знает как достигать поставленных целей и готова быстро обучаться чтобы подстраиваться под гибкий рынок. Сейчас мы ищем data аналитика. Описание вакансии: Задачи: Понимать бизнес проблемы поставщиков маркетплейсов и придумывать решения с использованием данных Анализировать данные (как данные маркетплейсов, так и поведение пользователей у нас на сайте) вытаскивать неочевидные закономерности, придумывать фичи и оценивать с помощью данных вклад придуманных другими фичей Помогать разработчикам создавать (или даже самому разрабатывать) дашборды для пользователей Работать с большими и шумными данными Строить дашборды в superset и дописывать etl-задачи на Presto/Athena Обязательно должен знать: Отличное знание SQL Методы проведения A/B экспериментов Базовое знание python Хорошее знание Python и опыт работы с Git будет плюсом Желательно: Базовые навыки в машинном обучении Высшее математическое образование Условия работы: Официальную удаленную работу в графике 5/2 в часовом поясе МСК (работать можно из любой точки мира) Возможность в короткие сроки прокачать свои скилы и реальные перспективы карьерного роста Участие в создании большой истории про любовь продавцов к цифрам и анализу данных","Python,SQL,Лидерство,SaaS,ETL,Умение анализировать,Умение организовывать работу",ANABAR,
6699,79157478,Data Analyst / Аналитик данных,от 60 000 руб. на руки,1–3 года,"Полная занятость,удаленная работа","Привет! Я Никита - коммерческий директор агентства «Next Level». Мы занимаемся комплексным digital -маркетингом, охватываем все виды рекламы и основные площадки по размещению.  в рамках переговоров с представителями крупного и среднего бизнеса мы наблюдаем большой запрос на кастомную аналитику, которая предлагает нечто большее, чем стандартный функционал Я.Метрики или Google Analytics. Вместе с тобой, мне бы хотелось, придумать формат аналитики, который позволит бизнесу смелее инвестировать в рекламу, видя обоснования на цифрах. Если тебе хочется испытать свои навыки в реальной ситуации и построить систему, приносящую доход, а может быть придумать что-то уникальное для рынка, то мы, и лично я, тебя всячески поддержим и поможем применить идеи в жизнь! Чем необходимо будет заниматься: Построение аналитических моделей на основании маркетинговых и данных бизнеса, для последующего обоснования рекламных инвестиций Поиск и внедрение новых подходов на рынке маркетинговой аналитики Поиск данных для рыночной аналитики Чего ожидаем мы: Знание языка Python (Pandas, Numpy) Знание R code (Ggplot, tdplyr) Уметь выкачивать данные из Я.Метрики (api logs), Google Analytics, ga4 Понимание реляционных и нереляционных БД Знание SQL Что мы предлагаем: График работы: 5/2, понедельник-пятница, с 10.00-19.00 либо с 09.00-18.00 Конкурентную заработную плату (готовы обсуждать в индивидуальном порядке) Возможность постоянного профессионального роста: внешнее и внутреннее обучение Удалённый или гибридный формат работы Молодой, сплоченный коллектив, дружественный микроклимат в отделе","Python,SQL,Базы данных,Numpy,Data Analysis,Удаленная работа,Pandas,Google Analytics,Яндекс.Метрика",Некст Левел,"Нижний Новгород, улица Тимирязева, 9"
6700,79127460,Аналитик данных / Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Мы ЛУЧШАЯ СЕТЬ СТУДЙ ЛАЗЕРНОЙ ЭПЛЯЦ по версии AURORA AWARDS Beauty&Health 2019. Лазерная эпиляция - это самый эффективный и безболезненный способ удаления волос навсегда. У нас одни из самый мощных диодных аппаратов лазерной эпиляции в Москве. Эффект виден с первого раза. Клиенты приходят к нам снова и рекомендуют своим друзьям. Миссия #IZUM: збавить людей от проблем связанных с удалением нежелательных волос повышая их чувство уверенности в себе. #IZUM ищет аналитика данных. Вместе с Вами мы будем: Разрабатывать новые системы метрик и показателей продаж и бизнеса в целом. Собирать данные и анализировать показатели продаж и бизнеса в целом. Формировать требования к настройке crm и участвовать в настройке. Мы ждем от тебя: Высшее техническое или экономическое образование. Обладаете опытом построения аналитики в компании, или большим желанием его получить. Понимаете как внедрять сервисы аналитики. Что у нас есть для Вас: Возможность карьерного роста до Руководителя направления или бизнес-единицы и выхода на уровень дохода 250 тыс. и более. Мы всегда в движении, с нами не бывает скучно. Бесплатные процедуры лазерной эпиляции для себя и членов семьи. Условия: График работы: 5/2 Офис в 5 минутах от метро Преображенская площадь. Оформление по договору с самозанятым (позднее по трудовому договору или ГПХ). Этапы отбора: Телефонное интервью. Собеседование с руководителем. Тестовый период (обсуждается индивидуально). С кем мы не будем работать: ""Удалёнщики"". Не готовыми брать ответственность на себя. Не готовыми развиваться, чтобы вести проекты ""под ключ"". Нам нужен единомышленник, который ГОТОВ РАСТ каждый год Х5-Х10. Если все что выше про Вас, то смело отправляйте резюме и можете быть уверенным, мы точно сработаемся! Хорошего дня и до встречи в офисе) Станьте прямым участником развития бизнеса! С уважением, команда #IZUM","Экономический анализ,Аналитика продаж,Бюджетирование,Ценообразование,Аналитика,roistat,Экономическое моделирование",#IZUM,"Москва, Преображенская площадь, Электрозаводская, Электрозаводская улица, 29с1"
6701,79209147,Аналитик-разработчик / Data Analyst в команду агентской аналитики в Яндекс,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Команда агентской аналитики занимается аналитической поддержкой рекламных агентств – партнёров Яндекса. Это одно из важнейших направлений, потому что именно на агентский канал приходится большая доля рекламных доходов Яндекса. Команда помогает ответить на такие вопросы: Как агентства влияют на выручку Яндекса? Как помочь агентствам быстрее развиваться и увеличивать обороты? Как помочь sales-подразделению эффективнее работать с агентствами? Вам предстоит: Разрабатывать процессы поставки данных Строить прогнозы Анализировать эффективность бонусной программы Разрабатывать новые аналитические отчёты, поддерживать и развивать существующие нтегрировать аналитические инструменты во внутренние и внешние системы Оптимизировать и автоматизировать ручной труд sales-подразделений. Вам будет комфортно с нами работать, если вы: Можете придумывать итерационные решения: сначала создаёте простые решения, а потом развиваете и усложняете их Знаете любой диалект SQL Знакомы с популярными Python-библиотеками для обработки и анализа данных Разбираетесь в Excel зучали основы статистики Умеете формулировать гипотезы и проверять их. Будет плюсом, если вы: Разрабатывали ETL-процессы Представляете, как устроена реклама в интернете Знакомы с Директом, Дисплеем, Метрикой и другими инструментами для рекламы. Компания предложит: Сильную команду, с которой можно экспериментировать и расти Работу с современными технологиями и инструментами Социальный пакет: ДМС, в том числе для родственников, со скидкой 80%, скидки от компаний-партнёров Компенсацию оплаты питания, фрукты и снеки в офисе Корпоративную жилищную программу Обучение: внутренняя библиотека, курсы, конференции Гибкий график, в том числе возможность гибридного формата работы офис-дом.","Data Analysis,SQL,Python,Анализ данных,MS Excel,Статистика,ETL,Реклама,Яндекс.Директ,Яндекс.Метрика",Remokate,
6703,79237039,Data Analyst\ Аналитик данных (Бизнес аналитик),з/п не указана,1–3 года,"Полная занятость,полный день","ФУНКЦОНАЛЬНЫЕ ОБЯЗАННОСТ ПО ДОЛЖНОСТ: подготовка / создание отчетов и ведение мониторингов, актуализация отчетов и составление необходимой документации к данным отчетам разработка и формирование дашбордов, анализ и ведение бюджетных показателей, ведение проектов проведение аналитической и научно-исследовательской работы с целью сбора, оценки и анализа получаемой информации, а также выработки практических рекомендаций подготовка цифровых данных по запросам работа с хранилищем данных внесение предложений по совершенствованию деятельности, связанной с выполнением своих обязанностей. ТРЕБОВАНЯ: высшее образование, опыт работы от 2х лет и более навыки работы с Excel, Power BI, SQL, Python, знания реляционных СУБД (Оракл, Postgres) и структур данных методы сбора, оценки и анализа информации навыки системного подхода к решению задач владения современными средствами, методами и технологиями работы с информацией.","SQL,Python,Анализ данных,Аналитическое мышление,MS PowerPoint",Банк ЦентрКредит,
6705,79061359,Аналитик данных / Data Analytics,з/п не указана,1–3 года,"Полная занятость,полный день","Компания «ЮрСпектр» является надежным партнером для сотен тысяч пользователей наших корпоративных клиентов, предоставляя уникальную правовую информацию и сервисы по электронному документообороту. Наши продукты: - онлайн-сервис готовых правовых решений ""ilex"" - справочно-правовая система ""КонсультантПлюс"" - сервисы для обмена электронными документами podpis.by и ilex. Накладные. ООО «ЮрСпектр» уже более 23 лет является надежным, ответственным и заботливым работодателем для более 900 сотрудников в разных регионах Беларуси! С нами у Вас будет возможность: - развиваться как профессионал своего дела, с возможностью постоянно наращивать свои знания и получать экспертный опыт - работать в инновационной компании с современными методологиями, инструментами и технологиями - иметь гарантии и уверенность в завтрашнем дне - найти новых коллег-единомышленников!  Присоединяйся к нашей команде в качестве аналитика данных Ваш будущий функционал это: обработка информации, которая поступает от пользователей сервиса ilex (как пользователь осуществляет поиск, какими функциями чаще пользуется, частота открытия документов и т.д.) выдвижение гипотез, проверка и анализ полученных данных, касающиеся поведения пользователей сервиса ilex подготовка аналитических отчетов взаимодействие с различными подразделениями компании в соответствии с их персональными запросами. Что для нас важно: хорошее знание SQL (postgresql) навыки планирования и алгоритмизации опыт работы c BI инструментами (Apache Superset / Google Data Studio / Power BI /Tableau ) хорошее владение Python (pandas, numpy) уверенное знание Excel (в т.ч. сводные таблицы). преимуществом будут: наличие высшего образования в области вычислительной математики, статистики, анализа данных и т.п. опыт работы с финансовыми показателями релевантный опыт работы (Финансовый аналитик, Бизнес аналитик, Data Scientist, Data Engineer, Системный аналитик, Product Analyst, Bi Analyst, маркетолог-аналитик). Мы с радостью готовы предложить Вам: смешанный формат работы: преимущественно удалённая работа +офис по необходимости менторство в период адаптации, мы обучим вас всем необходимым инструментам для работы толерантный подход к ошибкам, если они связаны с проверкой гипотез, поиском новых точек роста и стремлением улучшить работу возможность развиваться как профессионал своего дела, постоянно наращивая свои знания и получать экспертный опыт различные интеграционные мероприятия с ведущими спикерами России и Беларуси офис в центре города, недалеко от ст.м. Молодежная гибкий график (начало рабочего дня с 8 до 10, окончание с 17 до 19, сокращенный на 1 час рабочий день по пятницам) корпоративную социальную политику в соответствии с законодательством (плюс 3 социальных дня в году за счёт компании). Если Вас заинтересовала данная вакансия, присылайте своё резюме, будем рады видеть Вас в нашей команде!","Работа с большим объемом информации,Деловая переписка,Аналитическое мышление,Python,SQL,Tableau,MS Excel",ЮрСпектр,"Минск, Молодежная, Пинская улица, 28А"
6706,79199364,Data analyst (betting),от 100 000 руб. на руки,1–3 года,"Полная занятость,полный день","Привет, наши друзья - компания Megapari в поисках Аналитика данных! Задачи: Анализ данных платежных систем и собственной платформы звлечение, преобразование, осуществление контроля корректности и полноты данных Формирование отчетов, визуализация данных Создание аналитических моделей данных Участие в автоматизации аналитических процессов Требования: Опыт в роли аналитика 1+ лет Высшее техническое (предпочтительно) или экономическое образование Понимание что такое платежные системы и как они работают Умение наглядно представлять важную информацию и делать выводы, основываясь на полученных результатах Опыт работы с зарубежными бухгалтерскими программами (Хero, SAP и пр.) Google Sheets/Excel (высокий уровень) SQL и Python (будут преимуществом) Условия: Заработная плата (фикс), зависит от уровня ваших скиллов Комфортный офис в Москва Сити (формат работы - офис) График фултайм (5/2) с гибким началом рабочего дня Участие в крупном международном проекте","Анализ данных,Excel,Data Analysis,Google таблицы,Аналитическое мышление,Работа с большим объемом информации",HR ME,
6707,78710089,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Lesta Games ведёт разработку игровых проектов в различных жанрах, а также экспериментирует с инструментами и технологиями. Мы выпускаем легендарные игры «Мир танков», «Мир кораблей», Tanks Blitz и трудимся над новыми перспективными проектами. Наши продукты выходят на различных игровых платформах: PC, мобильные устройства. Мы не планируем останавливаться на достигнутом – впереди много работы, чтобы сделать наши проекты ещё более успешными. Офисы Lesta Games находятся в Минске, Санкт-Петербурге, Москве и Ташкенте. У нас работают более 1500 сотрудников. Сейчас мы в поиске талантливого Data Analyst в нашу команду Business Intelligence (BI), которая активно взаимодействует с направлениями Publishing (Monetization, Marketing, Content, Community Communications, CRM, Support) и Development (Game Balance, Terra – Game Mods and Maps, Game Economy Design). Основные задачи на этой позиции: аналитические исследования, поиск, формулировка и проверка гипотез разработка и поддержка автоматизированных отчётов в Fine BI, Plotly одноразовые выгрузки данных (ad hoc), автоматизация выгрузок при необходимости проработка логирования для игровых нововведений совместно с командами разработки, а впоследствии – ведение этих нововведений (см. первые 3 пункта) ведение документации по логам и дашбордам выполнение поручений руководителя в рамках вашей функции. Чем предстоит заниматься: собирать необходимую информацию из баз данных, преобразовывать и визуализировать её для успешного представления заказчикам разрабатывать метрики и методологии, необходимые для подготовки аналитических отчётов по оценке эффективности запущенных в оперирование игровых режимов, ивентов и акций искать аномалии и инсайты, позволяющие увеличить эффективность продукта или его частей формализовывать требования, планировать и проводить исследования, проектировать эксперименты и оценивать их эффективность для продюсеров, продуктовых, проектных и маркетинговых менеджеров. Технические навыки: опыт работы с SQL – Impala SQL, Oracle SQL Python - на уровне библиотек pandas, numpy, matplotlib, scikit-learn, odbc (знание построения алгоритмов, кластеризации, настройки коннекторов к базам) знание BI инструментов (Power BI, Tableau – оптимально, Fine BI – идеально). Будет плюсом: знание Jira, Confluence и умение работать с GIT. Что мы предлагаем: Работу в аккредитованной IT – компании Расширенный полис ДМС Доплаты по больничным листам до 30 дней в году Спортзал и душевые в офисе, компенсация части стоимости годового абонемента сети спортклубов Бесплатные завтраки и ужины, компенсацию обедов Релакс-зоны с массажными креслами Yamaguchi и топовыми кофемашинами Подарки и выплаты сотрудникам на значимые даты (первый день в компании, день рождения, свадьба, рождение детей) Мы тестируем наши продукты в игровых с мощным железом и приставками. Но если хотите размяться в офлайне, у нас есть настольный теннис, хоккей, баскетбол и кикер.","SQL,Oracle Pl/SQL,Business intelligence,Анализ данных,Power BI,Python,Tableau,FineBI",Lesta Games,"Санкт-Петербург, Ладожская, площадь Карла Фаберже, 8"
6709,79150358,Data Analyst,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Кто мы Мы — банк, который входит в тройку крупнейших банков России, и золотой работодатель по версии Forbes. Сейчас мы проходим этап технологической трансформации. Что это значит В департамент инженерной экспертизы и инструментов разработки мы ищем Аналитика данных по направлению — аналитика розничного бизнеса в сети офисов продаж. У нас много свободы, гибкие процессы, которые можно подстроить под себя, и передовые технологии. Чем предстоит заниматься: Разработка аналитических витрин и визуализация дашбордов в BI решении по направлению аналитика розничного бизнеса в сети офисов продаж Взаимодействие с заказчиком Анализ источников и данных (АС Банка / КХД) Настройка сбора данных из источников (ETL/ELT: Python скрипты, IBM DataStage) Разработка BI-отчетов миграции операций в удаленные каналы Разработка модели нормирования численности сети офисов продаж Разработка модели эффективности процессов сети офисов продаж Поддержка имеющегося портфеля BI-отчетов и витрин данных Как понять, что мы подходим друг другу: Опыт работы по аналогичному направлению деятельности не менее 1 года Хорошее знание SQL (оконные функции, подзапросы, оптимизация запросов, понимание работы индексов, партиций и т.д.) Понимание банковских бизнес-процессов Способность самостоятельно решать задачи Умение и желание работать с данными Аналитический склад ума Развитое логическое мышление Опыт аналитики и сбора статистики по розничным продуктам будет является преимуществом Почему мы? У нас круто! По-настоящему живая и увлечённая команда График работы удаленный/гибридный (по желанию) Официальное оформление по ТК РФ Достойный уровень вознаграждения ДМС со стоматологией с первого месяца работы Отпуск 33 дня + материальная помощь к отпуску Привлекательный соц.пакет, корпоративные программы Возможности для повышения уровня квалификации и личностного развития.","BI,SQL,ETL,Data Analysis",Газпромбанк,
6710,72682205,Data Analyst,з/п не указана,1–3 года,"Полная занятость,гибкий график","Vizor Games находится в поиске дата-аналитика, вместе с которым мы будем делать крутые и амбициозные вещи для наших казуальных проектов. Коллектив Vizor - это не просто коллеги, это большая (800+ человек) и весёлая (загляните на наши официальные странички, чтобы убедиться) команда. Задачи: Активное взаимодействие с командой разработки для понимания особенностей продукта и планируемых изменений. Анализ функциональности, изменений и поведения игроков в продукте на основе собранных данных. Проведение аналитических исследований с целью выявления слабых мест проекта и возможностей улучшения показателей. Предоставление рекомендаций по улучшению продукта. Анализ игрового баланса. Отслеживание ключевых метрик проекта. Обработка гипотез проектных команд. Подтверждение или опровержение гипотез на основе данных о действиях игроков. Проведение A/B тестов (от генерирования гипотезы до оценки результата теста). Написание аналитических отчетов. Постановка задач по сбору и отправке пользовательских данных в БД. Требования: Техническое или математическое высшее образование. Опыт работы с данными от года. Гибкое мышление, умение находить ответы на неочевидные вопросы, стремление находить суть проблемы. Знание основ статистики, теории вероятности, экономики. Уверенное знание SQL. Навыки визуализации данных. Умение предоставлять результаты своей работы в понятном виде. Опыт работы с аналитическими инструментами и сервисами. В качестве примера - Localytics, Dev2dev, Amplitude, MixPanel и т.п. Плюсом будет: гровой опыт (казуальные игры). Опыт работы на аналогичной позиции. Опыт работы с BI системами (PowerBI, Tableau). Навыки работы на Python или R. Уверенное знание Excel. Знание английского языка. Почему у нас приятно работать: Мы вдохновляемся друг другом! Делимся опытом, обмениваемся крутыми идеями, обсуждаем их и сразу же идем реализовывать.  результаты превосходят все наши ожидания. Наш департамент заботы усиленно работает, чтобы слово «забота» звучало в компании чаще, чем вы успеете о ней подумать. В стартовый набор входит медицинское страхование, компенсация больничного, отпуск, 4 Sick days в год, компенсация спорта. А с прошлого года мы добавили и психологическую поддержку для сотрудников. О наших офисах ходят легенды, про нас писали даже на страницах известного архитектурного онлайн-издания Yatzer. Наверное, упоминать удобное рабочее место и современную технику не стоит. Поэтому мы лишь намекнем, что у нас есть focus room, где можно вздремнуть после вкусного обеда (а это еще один бонус от компании).  чайный уголок в зимнем саду.  игровая с огромной плазмой и приставкой. Каждый наш офис продуман до мелочей, где дизайнерская мысль умело переплетается с корпоративной культурой. Для профессионального развития есть все необходимое: внутренние курсы английского языка, посещение профильных конференций, курсов, воркшопов и многое другое. Главное - ваше желание, а возможности роста у нас всегда найдутся. В копилке приятных бонусов также премии за рекомендации будущих коллег, ко дню рождения и важным событиям вашей жизни.  Присылайте ваше CV, давайте знакомиться!","SQL,PowerBI,Tableau,Python,R,Анализ данных,Data Analysis,MS Excel,Визуализация",Вайзор Геймз,"Минск, Восток, улица Франциска Скорины, 2"
6711,79173134,Аналитик Data Scientist,от 50 000 до 100 000 руб. на руки,1–3 года,"Полная занятость,полный день","Мы - амбициозная молодая команда Фаворит Фэшн Груп, которая за пару лет уверенно вышла в лидеры продаж на маркетплейсах! Одно из главных наших направлений – собственное производство и продажа одежды на всех известных маркетплейсах. Мы гордимся тем, что предоставляем нашим клиентам широкий выбор стильной и качественной одежды. В связи с быстрым ростом компании, мы предлагаем вам стать частью нашей команды и вместе двигаться к успеху! В связи с активным развитием нам нужен в нашу команду: Аналитик Data Scientist (jun+) Условия: Работа в растущей компании, занимающей лидирующие позиции в отрасли Заработная плата от 50 000 до 100 000 руб., обсуждается с финальным кандидатом в зависимости от компетенций и стеков Полный рабочий день в офисе Loft Ville (Павелецкая наб., 2) Полный рабочий день, 5/2, 9.00 - 18.00 нтересные практические задачи, над которыми предстоит работать Возможность получить глубокую техническую экспертизу Возможность профессионального развития и карьерного роста до Руководителя отдела аналитики Коллектив единомышленников - профессионалов своего дела Возможность обучения в элитной закрытой бизнес-школе управления. Требования: Профильное высшее образование (техническое, математическое) Опыт работы в роли Аналитика - от 1 года Знание Excel, Google Таблицы – на уровне эксперта / продвинутого пользователя Знание на практике основных бизнес-метрик, бизнес-процессов, KPI Умение ориентироваться в маркетинговых и финансовых показателях Личные качества: аналитический склад ума, внимательность, ответственность, умение доносить информацию в простом и понятном виде, критическое мышление. Обязанности: Сбор информации из разных источников, ее анализ и представление в наиболее удобном для восприятия виде Финансовый анализ спроса сбыта и ценообразования, разработка и осуществление мер по обеспечению финансовой устойчивости Формирование сводных отчетов из больших объемов и разрозненных данных, в т.ч. «с нуля» Анализ бизнес-процессов в компании и подготовка рекомендаций по их улучшению.","Аналитическое мышление,Анализ данных,Анализ бизнес показателей,MS SQL,Математическая статистика,Аналитические исследования,Анализ финансовых показателей,Математический анализ,Сбор и анализ информации,Системное мышление,Data Analysis,Data Scientist,Английский — B2 — Средне-продвинутый",ФАВОРТ ФЭШН ГРУП,"Москва, Павелецкая, Павелецкая набережная, 2с1"
6712,79090705,Data Analyst,з/п не указана,1–3 года,"Полная занятость,гибкий график","Команда профессионалов, за плечами которой участие в нескольких успешных FinTech проектах в странах Юго-Восточной Азии, развивает новый, еще более амбициозный проект. Мы решаем интересную и глобальную задачу – построение онлайн-банка в Азии. В Департамент рисков мы ищем Data Analyst для решения следующих задач: Сопровождение регулярной отчетности Разработка витрин данных, взаимодействие с Data Engineer Мониторинг и анализ качества кредитного портфеля Выполнение Ad-hoc аналитики Мы ждем от соискателя: Высшее техническое образование Аналитический склад ума Понимание принципов построения реляционных БД Владение SQL Знание инструментов визуализации (Tableau, Power Bi) Что предлагаем: Большой, светлый и комфортный офис в Москва-Сити Возможность частично удаленной работы Гибкий график для оптимального баланса работы и личной жизни Оформление по ТК, конкурентная зарплата Возможность расти совместно с командой","SQL,Tableau,Data Analysis,Аналитическое мышление,Power BI",Ок Софт,"Москва, Центральный административный округ, Пресненский район, Московский международный деловой центр Москва-Сити"
6713,79170279,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Наша команда разрабатывает и поддерживает более 20 моделей ценообразования (прогнозы CLTV и ФОТ, рекомендации индивидуальных тарифов, пакетов услуг). Модели уже используются для определения оптимального ценового и продуктового предложения для нескольких миллионов корпоративных клиентов – от микро- и до крупнейшего бизнеса, и существенно влияют на доход банка, эффект регулярно подтверждается А/Б экспериментами. В поиске Аналитика, готового предлагать и подтверждать гипотезы на основе огромных массивов данных желающего измерять эффект от своей работы в миллиардах рублей готового применять базовые методы машинного обучения. Обязанности Анализировать данные с целью построения и проверки гипотез исследовать зависимости и закономерности в данных визуализировать результаты Проводить A/B тестирование: готовить дизайн, участвовать в запуске, анализировать и представлять результаты Оказывать аналитическую поддержку DS для эффективного построения моделей Тесно коммуницировать с заказчиками и потребителями результатов модели Создавать методологию построения витрин и по ней строить ETL-пайплайны (PySpark) оценивать входные и результирующие данные. Требования уверенное знание SQL, Python (pandas, matplotlib/plotly/seaborn, будет плюсом - numpy, scipy, causalinference) Уверенное знание основных классических алгоритмов ML (linear models, random forest, gradient boosting) Умение проводить сложные агрегации данных Опыт анализа данных (от 1 года) Знание мат. статистики. Будет плюсом: Опыт работы с большими данными (Hadoop, Hive, Spark) нтерес к сфере финансов, большой плюс - опыт работы в ней Опыт проведения A/B тестов Умение понятно визуализировать данные Условия - Фиксированный оклад + годовой бонус - ДМС, страхование от несчастных случаев, социальные гарантии - Митапы DS Community банка и корпоративные мероприятия - Участие в различных конференциях для DS/DE - Корпоративное обучение - Комфортный офис в 5 минутах ходьбы от м.Нарвская - В офисе бесплатный фитнес-зал с душевыми кабинами, настольный теннис, кикер.",,Сбер для экспертов,
6715,79161633,Data Analyst (Удаленно),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Компания «АЙ-ТЕКО» — ведущий российский системный интегратор и поставщик информационных технологий для корпоративных заказчиков. Активно действует на рынке IT России с 1997 года, входит в ТОП-400 крупнейших российских компаний, ТОП-10 крупнейших IT-компаний России. В СВЯЗ С АКТВНЫМ РАЗВТЕМ ВНУТРЕННХ ПРОЕКТОВ В КОМПАН ОТКРЫТА ВАКАНСЯ - DATA ANALYST . ТРЕБОВАНЯ: Уверенное знание SQL и теории баз данныхОпыт работы в качестве аналитика данных, аналитика DWH  Понимание ООП Умение применять нотацию UML, знание REST архитектуры и формат JSON Понимание микросервисной архитектуры ПО. Умение четко формулировать мысли Внимательность к деталям БУДЕТ ПЛЮСОМ: Опыт работы с Greenplum или другой MPP СУБД Знание Python Опыт работы с Apache Airflow  Знание архитектурных особенностей разных СУБД Опыт работы в банке ЗАДАЧ: Системный анализ источников данных Проектирование модели данных и потоков данных Написание ТЗ разработчикам на основании требований бизнеса Поддержание проектной документации в актуальном состоянии. УСЛОВЯ: Работа в аккредитованной Т-компании Оформление в соответствии с ТК РФ с первого дня работы Возможность работать в удаленном формате Мы заботимся о здоровье наших сотрудников: предоставляем скидки на посещение фитнес-клубов, ДМС с первого месяца работы (включая стоматологию) Работа в команде, использующей гибкий подход к разработке Работа в развивающемся IT-проекте с командой специалистов высокого уровня, возможность развития и обмена опытом.","SQL,Python,Анализ данных,Apache Airflow,UML,REST,JSON API,Data Analysis,ООП",Ц АЙ-ТЕКО,
6716,78711842,Аналитик данных/Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Sape – это сервисы для рекламы и продвижения в интернете. Мы лидеры рынка digital - рекламы и за 15 лет прошли путь от монопродукта (биржа ссылок) до экосистемы, в которую сегодня входят более 10 сервисов. Один из наших продуктов RTB.Sape.ru - это 20 000 площадок для медийной рекламы, 10 млрд показов в месяц, свой стек технологий, собственный инвентарь и крупнейшие программатик каналы на любых устройствах. Для того, чтобы извлекать смысл из данных, находить зависимости, корреляцию, инсайты, и на основании этого формировать эксперименты, мы ищем коллегу Аналитика данных уровня middle+ в нашу действующую команду RTB.Sape. С чем предстоит работать: с логами RTB аукционов (ПБ данных) с A/B тестами с визуализацией данных Задачи: Анализировать массивы данных, находить инсайты и формулировать гипотезы, проводить эксперименты Проводить A/B тестирования Оценивать эффективность внедрения задач Создавать и поддерживать дашборды (grafana, power bi) Что мы ждем от тебя: Опыт работы с коммерческими проектами от 3-х лет Отличное знание Python, SQL, Spark Умение визуализировать данные в grafana, power bi Аналитические способности, логическое мышление и нелинейные вычисления Знание математической статистики и теории вероятности Умение объяснять и адаптировать сложные системы и технические термины к ясной лаконичной форме для нетехнических специалистов Умение работать в команде на результат Будет плюсом: Участие в соревнованиях по решению задач с помощью машинного обучения (Kaggle, RecSys пр.) Что мы готовы предложить: Возможность выбора удобного формата работы: офис/частичная удаленка/полная удаленка Оформляем в штат с первого дня работы Зарплата белая, начисляется 2 раза в месяц, на карту Заработная плата обсуждается на собеседовании и напрямую зависит от Ваших навыков и фактического опыта График работы: 5/2 с гибким началом рабочего дня с 09:00 до 12:00 ДМС после испытательного срока Уютный офис в шаговой доступности от м. Водный стадион и станции МЦК Балтийская (10-15 минут) Систему наставничества, планы развития, обучение за счет компании Работа среди профессионалов Стабильность - группа компаний на рынке с 2007 года и занимает лидирующие позиции Профессиональный и карьерный рост Возможность самореализации – мы ценим проактивных и инициативных людей","Grafana,Power BI,Дашборды,Spark,Python,SQL,Аналитическое мышление,Проведение тестирований,A/B тесты,Теория вероятностей,Математическая статистика",Sape,"Москва, Выборгская улица, 16с1"
6717,79209616,Аналитик / Data Analyst в Биллинг в Яндекс,з/п не указана,3–6 лет,"Полная занятость,полный день","Биллинг — один из внутренних сервисов Яндекса, который обслуживает финансовые задачи компании. В рамках этих задач сервис взаимодействует с множеством продуктов Яндекса и обменивается финансовыми данными. Одним из главных потребителей Биллинга являются Рекламные сервисы Яндекса. Перед командой стоят смелые цели: построить сквозную аналитику по всем основным разделам сервиса и настроить систему мониторинга критически важных процессов биллинга. Вам предстоит: Разбираться в бизнес-процессах платёжных систем и помогать анализировать проблемы Проводить исследования на основе большого количества данных, выдвигать и проверять гипотезы Визуализировать результаты исследований с дашбордами и элементами мониторинга. Вам будет комфортно с нами работать, если: У вас есть релевантный опыт от 3 лет Получили высшее математическое, техническое или экономическое образование Уверенно владеете Python и SQL для сбора и анализа данных Умеете извлекать ценное из «сырых» данных и превращать в ответы на бизнес-задачи. Будет плюсом, если вы: меете представление о маркетинге и о том, как работает реклама Работали с процессами сбора и обработки больших данных Понимаете, как устроены платёжные системы Умеете работать с Git. Компания предложит: Сильную команду, с которой можно расти Сложные задачи для сервисов с миллионами пользователей Возможность влиять на процесс и результат Зарплату на уровне рынка и выше Премии каждые полгода Расширенную программа ДМС с оплатой 80% стоимости ДМС для супругов и детей Гибкий график работы.","Анализ данных,Data Analysis,SQL,Python,Реклама,Big Data,Git",Remokate,
6718,78675069,Data аналитик,з/п не указана,1–3 года,"Полная занятость,полный день","ЛитРес — компания, о которой вы наверняка слышали! За годы усердной работы (мы появились в 2005 году) компания стала лидером на рынке лицензионных электронных и аудиокниг, а также крупнейшим книжным сервисом в России и СНГ. На нашем сайте уже больше 1 миллиона книг на русском и иностранном языках.  это не предел! Среди них около 48 000 книг, которые можно читать и слушать абсолютно бесплатно. Каждый месяц в нашем каталоге появляется более 5 000 новых книг. Мы сотрудничаем с 300 российскими и зарубежными издательствами и с 1000 авторов, среди которых звезды детективного, любовного, приключенческого, фантастического и других жанров. Каждый месяц нашими сервисами пользуются 12,5 миллиона человек, они скачивают более 1,5 миллиона книг.  приходят за новыми историями снова и снова. Сейчас мы в поисках Data Аналитика. Чем вы будете заниматься: Поддержка существующих и разработка новых отчетов Продуктовая аналитика (ab-тесты фичей, прогноз ключевых метрик продукта и тд) Аd-hoc запросы Мы ожидаем от вас: меете релевантный опыт работы от 1 года Работали с базами данных и хорошо знаете SQL/Python Знаете математику/мат. статистику и умеете делать выводы по данным Будет плюсом: Высшее техническое образование Знание алгоритмов/структур данных Опыт работы с BI системами Мы предлагаем: Комфортный офис в Москва-Сити башне «Меркурий» Стабильную белую заработную плату Гибридный формат работы (Москва) Стандартную рабочую неделю пн-пт с гибким временем прихода и без ненормированного графика После успешного прохождения испытательного срока: ДМС со стоматологией, фитнес, курсы английского языка и многое другое Частичную компенсацию парковки Неограниченный доступ ко всем электронным и аудиокнигам Оплату профильных курсов","Python,SQL",Литрес,"Москва, Выставочная, Деловой центр, 1-й Красногвардейский проезд, 15"
6719,76784959,Data Analyst / Аналитик данных,до 150 000 руб. до вычета налогов,1–3 года,"Полная занятость,полный день","Krediska - это современная FinTech компания на рынке онлайн кредитования, основанная профессионалами с более чем 10-ти летним опытом в этой сфере. Наш продукт - это онлайн платформа по выдаче денежных средств на карту. Мы - очень гибкая и молодая компания, наши главные цели - выйти в лидеры рынка, сделать наш продукт максимально удобным для людей, реализовывать самые современные решения и внедрять новейшие технологии. Развиваясь стремительными темпами, в 2021 году взяли премию ВЗО в номинации ""Открытие года"". В связи с активным ростов и расширением команды мы в поиске Аналитика Данных. Чем необходимо будет заниматься: Анализом данных кредитного конвейера Компании Мониторингом ключевых бизнес-метрик и формированием рекомендаций для бизнеса Построением и валидацией скоринговых моделей, мониторинг их работы Оптимизацией бизнес-процессов Участием в различных проектах продуктовых команд. Чего ожидаем мы: Опыт работы аналитиком от 1 года (желательно в fintech компаниях, банках, МФО) Знание SQL на уровне базовых запросов обязательно Опыт применения методов статистического анализа и моделирования Опыт работы с алгоритмами машинного обучения Умение выдвигать гипотезы, проверять их на практике и формировать рекомендации Уверенное знание языка Python для анализа больших данных Высшее образование в сфере математики и информатики. Будет плюсом: SPSS, Statistica, Stata, R Что мы предлагаем: Возможность делать крутые проекты, участвовать в качественном развитии Компании Рост ЗП согласно уровню выполняемых задач Ежегодная индексация заработной платы (10-15%) Продуманный, индивидуальный план развития сотрудника, посещение отраслевых конференций 2 раза в год Полная комплектация рабочего места по Вашему запросу Молодой, сплоченный коллектив, дружественный микроклимат в отделе Официальное трудоустройство по ТК РФ. Ждём твой отклик )","Python,SQL,Data Analysis,PostgreSQL,Machine Learning,Математическая статистика,R,Stata,Statistica,SPSS",Кредиска МКК,"Нижний Новгород, Горьковская, Ковровская улица"
6721,79262670,Data analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Привет, мы команда TYMY (ex.SalesChain) и мы ищем Data analyst! TYMY (tymy.io) – это B2B2С решение, помогающее компаниям автоматизировать агентские продажи Команда - у нас распределённая активно-растущая международная команда. Мы приветствуем открытое общение, при этом уважаем дисциплину и профессионально развиваемся. Клиенты и партнёры - мы работаем в партнерстве с крупнейшими банками и банковскими экосистемами: Сбер, Альфа, Газпром, Райффайзен, Росбанк, РСХБ, Уралсиб и другие. Успехи - на нашей платформе работают более 250 000 агентов, ежемесячно подключается более 10 000 новых пользователей. Через нашу платформу проходит более 30 000 сделок в месяц. Мы являемся резидентом кластера «нфотех», резидентами Сколково, а также активно выходим на рынки Турции, ндии и СНГ. Что важно знать о нас: • Сделали платформу для банков и крупного бизнеса. С её помощью наши клиенты продают свои продукты через сеть независимых агентов. • Работаем с крупнейшими банками и финансовыми экосистемами в РФ, у нас стабильный и растущий бизнес. • Финалисты международных акселераторов, умеем строить процессы в компании по лучшим практикам. Почему у нас классно: • Бесконечные возможности для роста в заряженной команде. Стартап находится на этапе быстрого роста – в процессе быстрого расширения на российском рынке в новых сегментах + выходим на международный рынок. • Можно и нужно напрямую влиять на создаваемый продукт и видеть результат своей работы, а не быть винтиком в гигантской машине. • Удалённая работа. • Официальная зарплата по рынку, которая зависит от твоих навыков и ожиданий. • Оформление по ТК РФ.  Чем предстоит заниматься: • Систематизировать и автоматизировать процесс сквозного сбора данных из различных внутренних и внешних источников • Разрабатывать и внедрять новые витрины данных для аналитики и построения предиктивных моделей на основе БД и множества источников • Визуализировать данные, создавать дашборды в Metabase • Создавать и поддерживать инструменты для обеспечения удобной работы с данными продуктовых команд и аналитиков • Участвовать в развитии инфраструктурных решений для работы с big data.  Что требуется: • Отличное знание SQL (У нас PostgreSQL) • Знание Python, умение писать читаемые вспомогательные скрипты • Базовые знания о работе Excel • Опыт работы с системами веб-аналитики Яндекс.Метрика, Гугл аналитика и др • Опыт работы с любым визуализаторов для аналитики (Power BI, Metabase и др) • Умение взаимодействовать с командой разработки по выставлению требований к источникам данных для дэшбордов • Английский язык - техническое чтение. Если ты можешь сказать, что все это про тебя, ждем твоего отклика на вакансию и будем рады видеть тебя в команде TYMY!","Python,SQL,Data Analysis",Платформа Сейлз Чейн,"Москва, Уланский переулок, 22с1"
6722,79255312,Intern Data Scientist,з/п не указана,1–3 года,"Стажировка,полный день","В команду Управления внутреннего аудита по Среднерусскому банку ПАО Сбербанк требуется специалист (стажер), который обеспечит реализацию алгоритмических и технологических задач, связанных с развитием и внедрением наших решений. Обязанности Обязанности обязанности - реализация digital-задач - подготовка и обработка данных для реализации digital-задач - участие в проектах в качестве DA/DE/DS - сопровождение действующих инструментов -аналитика данных Требования Требования Высшее образование (не оконченное): Техническое / Физико-математическое Опыт проведения / участия в Т-проектах Хорошее знание языков программирования Python, SQL Умение работать с большими объемами данных, навык их систематизации Компетенции в области Data Science Понимание базовых ML-алгоритмов Приветствуется опыт работы с Hadoop, знание Spark и Java Приветствуется знание инструментов BI аналитики Знание английского языка в объеме, необходимом для работы с технической документацией Развитые коммуникативные навыки Умение работать в режиме многозадачности Условия Офис м.Римская/Площадь льича (10 минут от метро) Работа только в офисе Официальное трудоустройство по ТК РФ с первого дня работы – срочный трудовой договор Корпоративный спортзал Постоянное развитие профессиональных навыков за счет использования современных технологий и внутренних тренингов.",,Сбер для экспертов,
6723,78674017,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Lesta Games ведёт разработку игровых проектов в различных жанрах, а также экспериментирует с инструментами и технологиями. Мы выпускаем легендарные игры «Мир танков», «Мир кораблей», Tanks Blitz и трудимся над новыми перспективными проектами. Наши продукты выходят на различных игровых платформах: PC, мобильные устройства. Мы не планируем останавливаться на достигнутом – впереди много работы, чтобы сделать наши проекты ещё более успешными. Офисы Lesta Games находятся в Минске, Санкт-Петербурге, Москве и Ташкенте. У нас работают более 1500 сотрудников. Сейчас мы в поиске талантливого Data Analyst в нашу команду Минского центра разработки для работы над проектом «Мир танков». Чем предстоит заниматься: работать с внутренними заказчиками, проверять продуктовые гипотезы и готовить Ad-hoc аналитику для поддержки принятия бизнес-решений консультировать внутренних заказчиков о возможности поддержки их бизнес-задач со стороны данных/аналитики собирать необходимую информацию из баз данных, преобразовывать и визуализировать её для представления заказчикам разрабатывать метрики и методологии, необходимые для подготовки аналитических отчётов по оценке эффективности маркетинговых кампаний, игровых режимов, ивентов и акций искать аномалии и инсайты, позволяющие увеличить эффективность продукта или его частей формализовывать требования, планировать и проводить исследования, проектировать эксперименты и оценивать их эффективность для продюсеров, продуктовых, проектных и маркетинговых менеджеров. Тебе понадобится: хорошее знание математики и статистики отличное знание SQL на уровне сложных запросов навыки визуализации данных в любой из BI-систем знание Python (Pandas, NumPy) и/или R опыт работы на подобной позиции от одного года. Будет плюсом: опыт работы в игровой компании. Что мы предлагаем: работу в IT-компании (резидент ПВТ) расширенный полис ДМС с первого месяца работы доплаты по больничным листам до 30 дней в году тренажёрный зал и душевые в офисе, компенсацию спорта компенсацию питания в корпоративной столовой или доставки еды в офисподарки и выплаты сотрудникам на значимые даты (первый день в компании, день рождения, свадьба, рождение детей) мы тестируем наши продукты в игровых с мощным железом и приставками. Но если хотите размяться в офлайне, у нас есть настольный теннис, хоккей и кикер, бильярд, а также релакс-зоны с массажными креслами доставку сотрудников корпоративными шаттлами метро <-> офис «Волна» (Минск, Партизанский проспект, 178/2).","Python,Data Analysis,SQL,Business Intelligence Systems,Математическая статистика,Анализ данных,Аналитика",Lesta Games,"Минск, Партизанский проспект, 178/2"
6725,77541047,Аналитик данных / Data analyst,з/п не указана,1–3 года,"Полная занятость,удаленная работа","СберМегаМаркет — это онлайн-площадка, на которой можно купить всё необходимое: от телевизора до свежих фруктов. Наши команды помогают людям приобретать товары, не выходя из дома, а партнёрам – развивать свой бизнес. У нас уже 15 млн уникальных посетителей, 8 тысяч продавцов и более 4 млн товаров.  мы не собираемся останавливаться. Наша большая цель — сделать лучший e-commerce сервис в России и собрать в одном месте всё лучшее, что может предложить онлайн-торговля. Мы развиваемся быстро: единицы на рынке запускают маркетплейсы за столь короткое время. Поэтому задачи будут сложные, нестандартные, но точно захватывающие. Задачи для тебя: Аналитическая поддержка коллег по показателям коммерции в направлении работы с продавцами и ассортиментной аналитики. Финансовый анализ продавцов. Взаимодействие с внутренними заказчиками по созданию новых аналитических инструментов – метрик, отчетов, моделей на базе Tableau/OLAP/Excel/MS SQL. Регулярный контроль ключевых показателей эффективности бизнес процессов. Моделирование, участие в планировании/прогнозировании и разработки KPI. Создание рекомендаций по методологии и последующему мониторингу показателей, согласование с бизнесом и создание отчетности, исследование бизнес-процессов. Взаимодействие с разработкой по организации забора и хранения данных в КДХ (DWH на MS SQL Server). Важно для нас: Релевантный опыт работы от 1-2 лет в сфере e-commerce/розничной торговли, опыт работы управления командой. Опыт взаимодействия с командой разработки по забору данных в КХД. Профессиональный пользователь Excel и SQL (join, группировки, оконные функции, чтение и проверка чужого кода). Навык построения отчетов/дашбордов в какой-либо из систем Tableau или аналогах Qlik/PowerBI. Умение решать бизнес кейсы/задачи – ""Как увеличить продажи?"", ""Как повысить эффективность ассортимента/контента на сайте?"" и тд. Бонусы: Официальное оформление и все социальные гарантии. Белая заработная плата и выгодные зарплатные проекты в нескольких банках. Полный пакет ДМС: предоставляется в течение 1 месяца с момента трудоустройства (стоматология, скорая помощь, полис для выезда за рубеж, а также возможно приобретение пакета ДМС по льготной цене для родственников и детей). Льготная ипотека или рефинансирование существующей для тех, кто с нами полгода и дольше. Бесплатная подписка СберПрайм+. Возможность приобретения товаров, размещенных на площадке СберМегаМаркет со скидкой. Проекты, которые развивают: всегда есть возможность прокачать свои навыки в работе и профессионально расти. Среда для обмена знаниями – высокая экспертиза внутри команды, которой мы щедро делимся. Нашу культуру создают сами сотрудники – мы их слышим и помогаем создавать и поддерживать корпоративные комьюнити по интересам. Удалённый формат работы с предоставлением техники от компании.","SQL,OLAP,Power BI,Аналитика",СберМегаМаркет,
6727,78934984,Data engineer (Стажер),з/п не указана,не требуется,"Стажировка,полный день","НЕ НУЖНО ОТКЛКАТЬСЯ НА ВАКАНСЮ! ЧТАЙТЕ НФОРМАЦЮ ВНМАТЕЛЬНО НЖЕ! Компания Sapiens solutions открывает двери для начинающих талантливых айтишников и айтишниц, которые хотят прокачиваться в направлениях хранилищ данных, бизнес-аналитики, систем планирования и прогнозирования. Для таких энтузиастов мы предлагаем стартовую площадку в этой сфере — короткую насыщенную учебную программу по работе с MPP СУБД Greenplum. Вы получите комплексные знания по программе в режиме онлайн, которая составлена нашими опытными инженерами и архитекторами, совершенно бесплатно! Это не сама стажировка, это только обучение! Стажировка начинается спустя месяц, после успешного прохождения обучения! Что такое СУБД Greenlum? Это аналитическая колоночная массивнопараллельная СУБД, разработанная для хранения и обработки больших объёмов информации. Она позволяет работать с терабайтами и даже петабайтами данных. Как поступить на программу обучения: Вы отправляете заявку через сайт (5 минут). Сайт стажерской программы можно найти на нашем официальном сайте.  За следующие 1–2 дня вы проходите короткий вступительный тест и выполняете задания на знание SQL. Также заполняете анкету ""Расскажи о себе"".  В течение 2-3 дней мы даём Вам обратную связь (Прошли ли вы на курсы или нет).  Для успешно прошедших тестирование мы проводим дистанционный welcome-тренинг и рассказываем подробности о нашей работе и о будущем обучении.  Вы учитесь на нашей платформе и выполняете учебные задания (6 недель). Весь процесс обучения вас будет сопровождать куратор из числа опытных инженеров данных Sapiens solutions, многие из них тоже когда-то пришли к нам стажерами.  По результатам обучения – обязательная защита итогового проекта (Проверка и оценка полученных знаний). Представляете проект и разбираете его нюансы с нашими тимлидами и архитекторами (2 часа). Получаете сертификат о прохождение учебной программы.  Congrats! После успешной защиты и пройденного собеседования, вы можете перейти на следующий уровень как полноценный начинающий инженер данных в составе команды Sapiens Solutions. СТАРТ ОБУЧЕНЯ - 10 МАЯ!!!! Подходит ли вам программа: меете высшее образование или заканчиваете учиться (в том числе студенты последних курсов!!!!!). Опыт в Т приветствуется. По завершении учёбы вы готовы работать по 40 часов в неделю (с понедельника по пятницу, с 10:00-19:00) в Sapiens solutions. Частичная занятость и удаленная работа не позволяет стажеру погрузиться в технологический стек полностью. Знаете основы SQL и не боитесь программирование. (При приеме это будет обязательно учитываться. Нам бы хотелось что-то большее, чем знание Select* и Inner Join) Готовы перебраться в столицу. Желание обучаться и развивать знания и навыки в области Т, в целом, и в области аналитических решений, в частности нацеленность на результат. После успешной защиты итогового проекта мы предлагаем: Оформление в соответствии с ТК РФ Работа в большом современном офисе на м.Бауманская/Красносельская Заработная плата - 40000 руб. на руки Работа на интересных проектах в крупных компаниях, где вы сможете развивать, как профессиональные, так и личностные навыки Перспективы карьерного роста внутри компании, через полгода Вы уже можете претендовать на уровень «младшего» инженера и далее ДМС, включая стоматологию, начиная с позиции «Младший консультант» Молодой и дружный коллектив профессионалов, комфортная рабочая атмосфера. Корпоративные, спортивные, образовательные мероприятия для наших сотрудников.","SQL,Greenplum,Big Data,DWH,СУБД,Базы данных,Планирование карьеры,Английский язык,Обучение и развитие,Анализ данных,Дистанционное обучение",Sapiens solutions,"Москва, Бауманская, Комсомольская, Красносельская, Нижняя Красносельская улица, 40/12к2"
6728,79108064,Data analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Сравни – финансовый супермаркет, мы создаем удобные сервисы и рекомендации для того чтобы помочь людям принимать правильные решения при выборе банковских и страховых продуктов - ОСАГО, страховок путешественника, страховния недвижимости, Каско, вкладов, кредитов, кредитных карт или подобрать лучший вариант ипотеки. Мы первыми в Рунете придумали и запустили сервисы оформления электронного ОСАГО и подбора кредита. Сейчас у нас: 14 млн уникальных пользователей в месяц 8 000 предложений от банков и страховых компании 140 000 отзывов о банках и страховых компаниях более 7000 оформленных страховок в день Кого ищем? Аналитика с хорошими навыками в Excel, SQL и опытом в продуктовой аналитике. Необходимо будет разобраться в аналитике продуктов (unit-экономике, P&L, специфике монетизации), наладить процесс сбора отчетности для инвесторов и повышать качество данных. В чем ценность данной вакансии: Работа над одной из важнейших частей аналитики в компании Работа с самыми современными инструментами и технологиями Возможность получить широкий опыт: задачи требуют взаимодействия со всеми направлениями аналитики Оптимизация текущих процессов и возможность пересмотреть подходы. Чем предстоит заниматься? Разобраться в устройстве аналитике, хранении данных, типах монетизации Поддерживать и развивать верхнеуровневую аналитику и отчетность для инвесторов Отвечать за своевременную подготовку и корректность P&L компании, участвовать в проработке моделей аллокации расходов Автоматизировать еженедельную и ежемесячную отчетность для инвесторов Взаимодействовать с продуктовыми аналитиками и финансовыми менеджерами. Будет плюсом: Опыт визуализации данных в Power BI. Опыт в финтехе или e-commerce. Мы предлагаем: Работу в аккредитованной IT компании ДМС, включая стоматологию, страхование жизни 2 day-off в год Каждые полгода проводим ревью всех сотрудников, составляем планы развития и даём возможность расти по карьерной лестнице Пицца/пироги/суши каждую пятницу Оплату посещения профильных конференций и курсов Реферальная программа для сотрудников Материальная помощь при рождении ребёнка +3 дня оплачиваемого отпуска Ремоут-френдли. Доставим всё, что нужно для комфортной работы, и организуем встречи с командой онлайн и офлайн. Поддержку в обмене знаниями и идеями: поощряем выступления на митапах и помогаем с подготовкой докладов. Корпоративные мероприятия и тимбилдинги Помощь с переездом для кандидатов из других городов (оплата билетов и первого месяц квартиры).","Python,SQL,MS Excel,Power BI",Сравни,"Москва, Площадь льича, Римская, бульвар Энтузиастов, 2"
6729,79122341,Data-аналитик,з/п не указана,1–3 года,"Полная занятость,полный день","Сбер — это более 60 компаний экосистемы, 14 тысяч подразделений, а масштабы компании и система поддержки сотрудников открывают возможности для карьеры в любом направлении. В аналитический центр Сбера требуется Data аналитик. Обязанности Проведение глубоких аналитических исследований по направлениям банковской деятельности, построение факторных моделей, выявление трендов, интерпретация результатов Защита исследовательских выводов и сформированных рекомендаций, взаимодействие с product owner Подготовка ad-hoc аналитики для территориальных руководителей Требования Высшее образование (финансовое, IT, математическое) Опыт работы с OLAP-кубами, SQL, TeraData, GreenPlum, Excel Знание Python будет вашим преимуществом Критическое мышление Условия Место работы ул.Костина,6 Трудоустройство согласно ТК РФ Льготная ипотека для сотрудников (ниже рынка на 4 %) Бесплатная подписка СберПрайм+, скидки на продукты компаний-партнеров Okko, Сбер Маркет, Delivery Club, Самокат, Ситимобил, Сбер Еаптека и другие ДМС для сотрудников/родственников (с первого дня трудоустройства). Обучение в СберУниверситете, доступ к виртуальной школе, профессиональные конкурсы.",,Сбер для экспертов,"Нижний Новгород, улица Костина, 6"
6730,79112858,Data Scientist R&D,от 150 000 до 300 000 руб. до вычета налогов,1–3 года,"Полная занятость,гибкий график","Мы в Rubbles занимаемся разработкой и внедрением DS-продуктов в крупные бизнесы. Например, системами предсказания спроса на товары в ритейле и fmcg, рекомендательными системами, системами предсказания поломок оборудования, поисковыми системами для онлайн-магазинов, системами оптимизации производства в промышленности, цифровые двойники и многим другим. Алгоритмы Rubbles ежедневно улучшают работу крупнейших банков, ритейл-сетей, нефтегазовых компаний и других предприятий. Мы ищем data scientist уровня middle для решения задач в промышленности: предсказание поломок оборудования, рекомендательные системы для минимизации остановок оборудования и самое разное детектирование неоптимальностей (например, простои грузовиков вне положенных мест, аномальное количество отходов производства на каком-то из тех. переделов). Существенной частью работы будет исследование проблем производства и формализация задач совместно с бизнес-аналитиками и коллегами-дсами Обязанности: Проверка и валидация бизнес-гипотез с существенным погружением в предметную область Решение ML-задач, к которым свелась бизнес-проблема, выбор лучшего решения (например, детектирование аномалий vs semi-supervised learning? Найти таргет для обучения с учителем vs найти глазами кластер с остановами?) Построение воспроизводимых пайплайнов ML-моделей: Получение - развернуть дамп базы, сходить на ftp-сервер Обработка - пайплайн выживает даже при битых данных Обучение - не бояться применять эвристики при необходимости Валидация - корректно выстраивать процесс в зависимости от решаемой задачи - мониторить не только технические но и бизнес-метрики не заглядывая в будущее, имитировать работу реальной системы Деплой - под присмотром ДЕ или же самостоятельно. Участие в пресейлах - решение реальной задачи в формате хакатона. Минимальные требования: Опыт работы с классическими ML-алгоритмами (Бустинг, логрег, леса. Знаете границы применимости, умеете генерировать подходящие под задачу фичи, а потом подобрать лучший алгоритм) Опыт решения задач с существенной исследовательской составляющей Опыт разработки на python (pandas, numpy, sklearn) от 1 года, знаете как писать эффективный код (векторизация, распараллеливание). Будет плюсом: Опыт работы на позиции, связанной с промышленной разработкой Опыт работы с глубоким обучением (pytorch) Опыт работы над задачами промышленности в одной из областей: нефтехимия, приборостроение, логистика Soft-skills и прошлый опыт работы в проектной команде Опыт проведения и/или анализа результатов АБ-тестов. У нас: Работа в одной из самых сильных ML команд в России Гибкий график работы, гибкое предоставление отгулов и отпусков Гибкий формат работы: полная удаленка/гибрид/офис в Мск. Поддержка в профессиональном и карьерном росте, оплата профильного обучения, конференций и книг, корпоративные скидки на курсы английского Совместная работа с опытными разработчиками, аналитиками данных, менеджерами, продуктологами ДМС со стоматологией после испытательного срока (3 месяца) по всей России При желании работать из офиса – уютный офис в центре Москвы (2 минуты от м. Сухаревская) со всем необходимым для комфортной работы. Особенно актуальное: Мы аккредитованная Т-компания со всеми вытекающими льготами.","Python,Pandas,Machine Learning,Numpy,Аналитические исследования,Задачи оптимизации,sklearn",Rubbles,"Москва, проспект Мира, 3с3"
6731,79075333,Data-инженер,з/п не указана,3–6 лет,"Полная занятость,полный день","Требование: Умение писать запросы в базах MS SQL, Oracle, Postgress, MySQL Опыт работы в построении отчетов и визуализации на базе Power BI Отличное знание SQL, Oracle DB, Power BI. Опыт работы с облачными платформами, в частности Amazon Web Services. Хорошее понимание NoSQL (моделирование данных, хранение данных). Опыт работы с Big Data и Data Warehouse Обязанности: Работа с Data Warehouse - Актуализация данных из различных баз Подготовка отчетности и выгрузок по запросам подразделений сследование данных, аналитика","SQL,Power BI,MS SQL,Ответственное хранение,Базы данных,Работа с базами данных,Data Mining: Statistica,MS Power BI,Oracle CRM",NOMAD insurance,
6732,78784729,Data analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","так, тебе предстоит: Написание SQL запросов для оценки емкости аудитории для потенциальной рекламной кампании Создание сегментов с помощью SQL запросов и передача их в рекламные кабинеты Оптимизация внутренних запросов Коммуникация с внутренним заказчиком Мы будем рады рассмотреть твою кандидатуру, если у тебя есть: Отличное знание SQL Умение видеть за числами смысл Желание развиваться в аналитике Знание postman и python будет плюсом",,"билайн: Т, Data, Digital",
6733,77586678,Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Какие задачи нужно будет выполнять: Подготовка требований для организации эко- системы и хранилища данных: анализ источников (онлайн продажи, веб аналитика, CRM данные пользователей, оффлайн продажи), анализ требований к дашбордам, коммуникация с интегратором. Предобработка сырых данных из маркетинговых платформ (сервисы рассылок, системы аналитики сайта и прочие). Объединение данных из разных источников для последующего анализа. Сегментация пользователей на основе данных, поиск инсайтов в их поведении. Сбора, поверка корректности и подготовка данных для анализа (ETL) Подключение рекомендательных моделей (next best offer / action/ up и cross-sell) для персонализации предложений в разных каналах Построение дашбордов в BI платоформе, поиск гипотез, аномалий Разработка предиктивных моделей поведения покупателей Ежемесячная и ad hoc аналитика промо-активностей и программы лояльности. Предоставление результатов в виде презентаций/дашбордов с выводами и рекомендациями. Атрибуционное моделирование Ведение коммуникации внутри и с клиентом (в том числе на английском языке письменно и устно) Наши ожидания от идеального кандидата: Знание основ мат. статистики и умение применять знания в работе, Умение работать с базами данных и наличие опыта написания сложных SQL запросов Уверенное владение Python (pandas/numpy/sklearn) Опыт работы с BI системами. Умение ясно и последовательно излагать логику исследования предоставлять результаты моделирования в виде презентаций Умение строить прогнозы на основе анализа исторических данных Опыт сбора, поверки корректности и подготовки данных для анализа (ETL) Понимание основ теории вероятностей и математической статистики Общее представление об основных алгоритмах машинного обучения и решаемых ими задачах Английский язык от intermediate и выше Опыт в дата аналитике от 2 лет Мы предлагаем: — Возможность работать удаленно два или более раз в неделю (после испытательного срока) — Классный офис в центре Москвы — нтересные проекты и работа с крупнейшим международным брендом — Уникальная возможность работать с экспатами, в международном агентстве — Творческая свобода, поощрение твоих идей и предложений — Компенсация питания — ДМС после 6 месяцев работы в компании.",,Чейл Рус,"Москва, Баррикадная, Новинский бульвар, 31"
6736,79130671,Data аналитик,з/п не указана,1–3 года,"Полная занятость,полный день","Компания KMF – лидер на рынке микрофинансирования с большими планами на будущее. Мы открыли более 116 офисов, получили множество наград и активно принимаем участие в важных для экономики Казахстана событиях. Поддерживаем «зеленые технологии», спорт, предпринимательство и т.д. Что делать? 1) Бизнес аналитика: Анализ и консолидирование требований (в т.ч. не функциональных) к составу и формату данных/отчетов от бизнеса Внесение изменений в бизнес-документацию хранилищ данных (бизнес-глоссарий и спецификации отчетов) Консультирование пользователей автоматизированных отчетов и хранилищ данных 2) BI аналитика: Анализ и профилирование данных на источниках Разработка модели витрины данных и мэппинг для BI решения Формирование технических спецификаций BI решений и участие в имплементации Контроль качества данных в хранилищах данных 3) Тестирование BI решения: Тестирование разработанных отчетов, витрин и кубов данных Разработка и внедрение тест-кейсов по каждому BI решению для автоматизации сверки данных Если у вас: Высшее образование Опыт работы в Т-сфере на аналогичной позиции не менее 1 года, желательно в банковской сфере Знание нотации PL SQL и опыт выгрузки данных из Oracle. Ориентирование в модулях CBS Colvir. Опыт выгрузки данных с CBS Colvir. Что мы предлагаем: 13-ую зарплату и повышения 2 дня дополнительного отдыха Отпуск длится дольше, чем в других компаниях – 26 дней Возмещение расходов на спорт, медицинское страхование, на свое развитие или развитие детей Деловые и корпоративные мероприятия, которые запомнятся на долгие годы Оформление по Трудовому Кодексу Казахстана.","Сбор и анализ информации,Написание технических заданий,SQL,База данных: Oracle,Oracle Pl/SQL,Colvir,Бизнес-анализ",Микрофинансовая организация KMF(КМФ),"Алматы, Жибек Жолы, проспект Назарбаева, 50"
6737,79219377,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Компания lifetech ищет в свою команду Data Scientist. Какие задачи Вас ждут у нас? Анализ ключевых метрик продуктов, поведения пользователей Участие в формировании KPI для бизнеса звлечение больших объемов данных из различных внутренних и внешних источников с последующим анализом Сбор и анализ данных, построение сегментаций, визуализация результатов в доступном читабельном виде Формирование и проверка гипотез, подготовка предложений для бизнеса на основании исследований Оценка эффективности рассылок, предложения по оптимизации Постоянное улучшение существующих предиктивных моделей и построение новых (отток, скоринг, фрод, CLV и т.п.) Участие в разработке проектов в областях CV(OCR, Object Detection) Ответственность за все стадии ML-проектов: от формализации задачи до внедрения в продакшен Взаимодействие со смежными командами аналитиков и разработчиков, активное участие в развитии сервисов. Наши ожидания: Высшее образование в области математики, статистики, информатики, инженерии или других связанных областях Опыт работы с данными от 2 лет Знание языков программирования Python, R, SQL, а также инструментов машинного обучения и анализа данных, такими как Pandas, Scikit-learn, TensorFlow, pyTorch , OpenCV и другими Практический опыт работы в сфере обработки изображений, в решениях задач детекции, распознавании машинописного текста Знание наиболее распространенных алгоритмов машинного обучения, понимание их теоретических основ Системное мышление, способность самостоятельно разбираться в особенностях продуктов и поведении пользователей Аналитический склад ума, умение анализировать данные, извлекать ценные инсайты и делать выводы Умение объяснять сложные технические концепции простым языком и работать в команде, включая нетехнических специалистов Умение работать с большими объёмами данных и уметь обрабатывать их с помощью соответствующих инструментов Навык визуализации и наглядного представления данных скренняя увлеченность данными, желание копать до получения ответа на свой вопрос. Что мы предлагаем Вам: Офис в БЦ Виктория Олимп, г. Минск, Победителей, 103 Подробнее о нашей социальной политике и бенефитах можно узнать в профиле компании","SQL,Python",Лайфтех,
6740,79032177,Data analyst,от 2 500 до 6 000 USD до вычета налогов,более 6 лет,"Полная занятость,удаленная работа","The team of experts providing analytical services to healthcare clients is looking for a great, long-term data analyst. You will join an international team of first-class professionals who are passionate about creating products that improve the quality of medical services. As a Senior Data Analyst you will have to: • build analytical pipelines and dashboards from idea to product • interact with business and explain results of your analysis • manage junior and middle data analysts • provide ad-hoc research • help with development of internal analytical platform • be proactive and propose new ideas of analytical services. Requirements: • At least 4 years of experience of working as a data analyst • Solid understanding of statistical analysis • Strong Python knowledge • Structured Query Language (SQL) expert • Good communication skills • Critical thinking • Excellent visualization and presentation skills • Experience with Google cloud/ AWS • Experience with deployment of micro services • Intermediate+ English (at least written communications). Benefits: • 2 weeks of paid vacation • flexible working hours • fully remote job • opportunity to work with international team of first-class professionals.","Data Analysis,Python,Analytical skills,SQL,Statistics,Google cloud,AWS,Elasticsearch,Английский — B2 — Средне-продвинутый",ТРТ,
6741,79084256,Data Engineer (lead),от 300 000 до 400 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Что нужно будет делать: Проектировать, разрабатывать и поддерживать пайплайны для сбора и обработки данных Обеспечивать SLA и качество данных Готовить данные для моделей машинного обучения и участвовать в их продукционализации совместно с data science командой • Работать в команде и развивать отдел DE. Будет классно, если у тебя: Хорошее знание технологий из стека: Python, SQL, Spark, Airflow Опыт работы на проектах с большими данными, понимание принципов распределенной обработки данных Опыт продуктовой разработки в технологических компаниях Опыт постановки задач Опыт наставничества Отличные коммуникативные навыки. Ты покоришь наши сердца и разум, если у тебя: Опыт работы с облаками, особенно, с Яндекс.Облаком Опыт разработки высоконагруженных бэкенд сервисов на Java, Scala или Python Опыт работы с моделями машинного обучения в продакшене Опыт работы с базами данных для аналитики, особенно, с ClickHouse. Мы предлагаем: Работу в аккредитованной IT компании с сильнейшей командой в разных масштабных проектах Гибридный график работы 5/2, с 10:00 - 19:00 ДМС со стоматологией В современном офисе в стиле Лофт с капсулой медитации, спортзалом, большой современной библиотекой и кабинетом для записи подкастов и треков Комфортную кухню с холодильником, кофемашиной, тостером, микроволновкой и Magic Bullet Холодильник с напитками (соки, энергетики, вода и т.д.) и едой (сыры, колбасы, сырки и м.ч.) Каждую пятницу совместные обеды с разными кухнями мира за счет компании.","SQL,Spark,Python",Predicto,
6743,76700906,Data Analyst/Аналитик отчётности,от 130 000 руб. на руки,1–3 года,"Полная занятость,полный день","Кто мы: BestDoctor — экосистема медицинских и страховых сервисов, созданная экспертами для удобного управления здоровьем. Мы меняем рынок медицинского страхования и отношение людей к своему здоровью с помощью качественного сервиса и принципиально нового клиентского опыта. Благодаря глубокой экспертизе в создании медицинских решений и любви к своему делу, нам удалось создать ту самую экосистему полезных, эффективных и, главное, простых медицинских сервисов для управления здоровьем компаний и людей. Чего мы достигли:  За семь лет мы вышли на второе место по числу клиентов среди insurtech компаний в Европе. Сегодня с нами уже 100 000+ застрахованных пользователей (40 000 из них мы подключили в 2021 году), а в списке клиентов — Aviasales, МТС Банк, Нетология, InDriver, Эвотор, Ivi.ru, Ostrovok.ru, VC.ru и еще 140 компаний.  Создали экосистему медицинских сервисов, которая включает в себя: сервис онлайн-поддержки 24/7, сервис онлайн записи в оффлайн клинику, свою виртуальную клинику, сервис второго мнения специалиста, чекапы, сервис психологической поддержки и др.  Запустили свою страховую BestInsure - на базе которой мы развиваем линейку страховых сервисов (страхование критических заболеваний, имущества, страхование от несчастного случая, страховки на время путешествия и др.). Один из наших успешных продуктов: страхование посуточной аренды с партнёрами sutochno.ru и Avito.ru. Подробнее о сервисе BestDoctor: https://bestdoctor.ru/ и https://hh.ru/article/29681 Кого мы ищем Мы ищем опытного аналитика данных, который поможет автоматизировать наши финансовые процессы и прийти к единству и корректности данных из разных источников. Это непростая и многоуровневая задача, решение которой напрямую влияет на P&L, а значит и на успех компании в целом. Тебе предстоит Проводить регулярную аналитику, строить дэшборды и предоставлять отчетность змерять ключевые показатели бизнес-процессов, строить понятные и удобные для принятия управленческих решений дашборды и отчеты Выстраивать системы метрик для отслеживания целевых показателей в рамках инициатив Делать оценку влияния инициатив на такие метрики, как средний чек и Loss Ratio. Проводить анализ финансовых показателей и выявлять причины отклонения от них Работать над автоматизацией финансовых процессов - превращать долгие ручные операции в удобные функциональные решения Заниматься сверкой данных: сейчас у нас есть много разных источников данных - админка, 1с, гугл-диски и прочее, важно с помощью SQL приводить всё это к единообразному и корректному виду для прозрачности финансовых результатов Повышать качество данных совместно с командой DWH Тесно взаимодействовать с другими аналитиками, отделом разработки, Data engineering, андеррайтинга и финансами. Мы ожидаем, что ты Отлично владеешь SQL: сложные запросы, cte, оконные функции. Круто, если умеешь понимать и оптимизировать план запроса Умеешь визуализировать данные в одном из BI-инструментов: Tableau / Power BI / Qlik Sense / Microstrategy (мы используем Tableau) Обладаешь аналитическим складом ума (логика, статистика и тд), высокой скоростью работы и проактивностью Сможешь отвечать за собственный стрим работы и самостоятельно предлагать решения Знаешь методы сбора, оценки и анализа информации У тебя есть желание «раскладывать все по полочкам» и оптимизировать процессы твоей работы. Nice to have! Знание Python будут преимуществом Разбираешься в финансовой сфере - опыт работы в банках/финтехе будет большим плюсом Опыт работы системным аналитиком будет преимуществом. Как мы нанимаем: Мы готовы оперативно выходить с оффером, если понимаем, что подходим друг другу. 1 этап - телефонное интервью с HR (15-20 минут) 2 этап - техническое интервью с тимлидом команды аналитики 3 этап - финальное интервью с CDO и HR. Почему с нами круто? Ты можешь подобрать формат работы под себя: офис (ст.м. Савёловская), микс, полная удаленка У нас гибкий график работы, который подойдет как жаворонку, так и сове Тебя будет окружать команда талантливых и мотивированных людей Мы предоставим тебе ноутбук и всю необходимую технику, которая позволит эффективно и комфортно работать ДМС от BestDoctor после испытательного срока.  Ты будешь частью большого социально значимого дела. Мы реализуем амбициозную задачу — меняем рынок страхования и здравоохранения, действительно помогаем людям, и у нас это отлично получается.  у тебя получится.","SQL,Python,Power BI,Tableau,Аналитическое мышление",BestDoctor,"Москва, Савёловская, Савёловская, Вятская улица, 27с15"
6744,79181984,Data-аналитик,з/п не указана,1–3 года,"Полная занятость,полный день","e2e4 — это крупный интернет-магазин компьютерной техники и цифровых решений! Более 19 лет мы работаем по всей России, открыли более 24 филиалов от Москвы до Южно-Сахалинска. Сейчас мы ищем Data-аналитика, который поможет сделать нашу команду ещё сильнее и эффективнее. Задачи: Выполнение задач трансформации данных, что подразумевает извлечение, преобразование и загрузку данных (с последующим хранением и обработкой) из различных информационных систем Создание конвейеров автоматизированной регулярной и непрерывной подготовки данных Поиск способов перепроверки результатов (контроль и повышение качества данных) Настройка подключения к данным из Power BI Участие в проектировании и разработке отдельной аналитической БД (корпоративного хранилища информации) по различным направлениям аналитики в компании Анализ данных, написание функций и построение запросов в SQL Будет преимуществом: Практический опыт работы с Power BI и автоматизации отчетности Требования: Высшее образование в области прикладной математики, экономики, статистики, Т Опыта работы от 1 года в области анализа данных или смежных областях Практический опыт работы с реляционными СУБД Отличное знание SQL (с упором на приёмы работы в Postgres) Опыт работы с продуктами Atlassian (Jira, Confluence, Bitbucket, Bamboo) Знание алгоритмов и структур данных Высокая степень самостоятельности Желание самостоятельно изучать новые методы и технологии анализа данных и ставить эксперименты на их основе. Условия: Полная занятость График работы 5/2 График работы, либо гибридный, либо удаленный.","Atlassian Jira,Анализ данных,Базы данных,Atlassian Confluence,Аналитическое мышление,Статистический анализ,СУБД,Power BI,Аналитика,Data Analysis",e2e4 Магазин компьютерной и цифровой техники,"Новосибирск, Площадь Ленина, Коммунистическая улица, 2"
6746,79114600,Data scientist (коллекшн),з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Осуществляет разработку, внедрение, мониторинг и обновление скоринговых моделей, которые используются во взыскании Осуществляет обеспечение ежедневного расчета всех моделей для их применения в процессе Осуществляет выделение однородных сегментов на основе моделей, с использованием подхода «риск-баланс» и с помощью других факторов для дальнейшей обработки различными инструментами Проводит оценку экономического эффекта от внедрения скоринговых моделей, уровней отсечения сследует возможности повышения эффективности прогнозных моделей Проводит А/Б тестирование новых моделей на части портфеля Проводит анализ эффективности взыскания на всех стадиях/процессах Осуществляет планирование/прогнозирование эффективности взыскания Осуществляет Ad-hock аналитику по направлению взыскания Разрабатывает бизнес-требования/технические задания в IT подразделения Банка (ДРТ, АБЦТ, ДТ и т.д.) и внешним вендорам на изменение стратегии работы по сформированным сегментам. Требования: Уверенное владение SQL, MS Office Навыки работы в одном или нескольких инструментах по анализу данных: R (RStudio), Python, SAS Guide/Miner Опыт разработки и/или мониторинга, валидации моделей по взысканию (Soft, Hard, Self Cure) опыт разработки и/или валидации скоринговых моделей в подразделениях розничных кредитных рисков/взыскание. Условия: Стабильная заработная плата Работа в уютном офисе ул. Люсиновская, д. 27 Корпоративная социальная программа ДМС (включая стоматологические услуги) по факту прохождения испытательного срока Льготные условия кредитования Реферальная программа с возможностью получить вознаграждение до 100 000 руб. за кандидата, трудоустроенного по Вашей рекомендации Внутреннее и внешнее обучение у лучших специалистов Электронная библиотека, включающую более 2000 книг бизнес-литературы Скидки на фитнес и участие в корпоративных спортивных активностях Скидки на посещение игр хоккейного клуба «Ак Барс», бесплатное посещение игр баскетбольного клуба «Уникс».",,Ак Барс Банк,
6748,79151678,Аналитик-менеджер по данным | Chief Data Officer,з/п не указана,более 6 лет,"Полная занятость,полный день","С чем предстоит работать: Data driven бизнес с 10+ млн клиентов. Построение и ведение карты данных. Управление качеством данных. Амбициозные планы по сохранению экспоненциального роста, динамичная команда профессионалов. Что мы ожидаем: Обширный опыт работы с данными и DWH: понимание что это такое, как хранятся, как используются. Сильные аналитические навыки (нужно систематизировать все данные организации). Управленческие и лидерские навыки (нужно выстроить и администрировать процессы работы с данными в масштабе организации). Сильные коммуникативные навыки (стейкхолдеры – вся организация). Мы предлагаем: График работы: 5/2, 10:00-19:00. Гибкая система карьерного роста. Комфортабельный эко-офис в центре города. Корпоративный Английский, тренинги, тимбилдинги. Конкурентная заработная плата.",,Payme (СП ООО Inspired),"Ташкент, улица Фидокор, 10"
6750,78432046,Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Команда Центра цифровой трансформации РТ в поисках Data-аналитика на проект ""Фабрика данных"".  Обязанности: анализ требований заказчика уточнение деталей бизнес-требования у заказчика перевод неформальных требований заказчика в измеримые метрики подбор метрик на основе понимания целей проекта разработка требований к качеству данных контроль качества данных, используя инструменты отладки, SQL и инструменты визуализации данных постановка задачи инженерам данных для разработки трактов поставки данных приемка результата разработки трактов поставки данных согласование результатов реализации требования с заказчиками гармонизация данных и преобразование в полезную информацию для последующего анализа предоставление аналитических выводов и предложений на основе полученной информации развитие периодической аналитической отчетности разработка отчетов по запросам  Работа будет связана с: инструментами самостоятельной аналитики (Yandex DataLens, Apache Superset) пакетом MS Office (Excel, PowerPoint, Word) реляционными СУБД (PostgreSQL, MySQL, MS SQL, Oracle) аналитическими СУБД (greenplum, clickhouse) экосистемой Hadoop (hdfs, hive, spark) apache zeppelin, python Требования: бизнес-ориентированный подход к данным хорошее знание языка SQL хорошее знание одного из инструментов визуализации данных (Yandex DataLens, PowerBI, Tableau, Qlik Sense и др.) продвинутый уровень владения Excel, Word владение русским языком (как письменным, так и устным) владение английским языком (чтение со словарём) опыт интерпретации данных способность презентовать результаты своей работы опыт работы с (большими) данными в одной из отраслей будет преимуществом: телеком, интернет-компании, банки, страхование, ритейл знание JS будет преимуществом опыт в сфере работы с данными от 3 лет аналитический склад ума, умение самостоятельно разбираться в новом материале, документации опыт работы с базами данных, большими объемами информации Мы предлагаем: работу в команде профессионалов, не лишённых юмора и душевности поддержку инициатив сотрудников и признание права на ошибку официальное трудоустройство в соответствии с ТК РФ стабильную «белую» заработную плату, выплаты два раза в месяц (10 и 25 число), уровень зарплаты обсуждается по итогам интервью комфортный офис в центре города (Т-парк) поддержку профессионального развития участие в конференциях и обучающих мероприятиях за счет компании индивидуальный подход во всех вопросах сложные, но очень интересные задачи, полное отсутствие скуки корпоративные мероприятия.","SQL,Python,Hadoop,Spark,Big Data",ГКУ «Центр цифровой трансформации РТ»,"Казань, Суконная слобода, Петербургская, 52"
6751,78761869,Financial data analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","inDrive — международный сервис пассажирских перевозок. Мы создаем глобальный высокотехнологичный продукт, который меняет жизнь миллионов людей к лучшему. Входим в TOP-2 мобильных сервисов для заказа поездок в мире по количеству скачиваний — 150 млн. установок. Мы работаем в 707 городах 47 стран мира. Команда финансового департамента в поисках опытного Финансового аналитика данных (Financial data analyst) в г. Алматы! Вам предстоит: комплексная проверка качества и целостности данных определение требований к отчетам, используемым финансовым дивизионом, составление техзаданий коммуникация с коллегами из технологических департаментов, работая с ними над оптимизацией и улучшением системы формирования данных для финансовой отчетности анализ расхождений между различными источниками данных, поиск технических проблем и методологических расхождений сообщать об источниках технических проблем и формулировать требования по их исправлению команде разработчиков подготовка данных по запросам контролирующих органов либо контроль за получением таких данных от дата аналитиков из других подразделений и проверка таких данных искать способы улучшения мониторинга, выявления проблем и повышения качества данных поддержка IT аудита показателей используемых в финансовой отчетности. Наши пожелания: опыт работы в области бизнес-/системного анализа или обеспечения качества данных знание английского языка не ниже уровня intermediate (В1) высшее образование в области информационных технологий желательны базовые знания и опыт в области экономики и финансов уверенное знание и опыт работы с SQL и Python базовые знания по созданию технологической документации сильные письменные и устные коммуникативные навыки, включая навыки технического письма. Мы предлагаем: стабильную заработную плату гибридный формат работы добровольное медицинское страхования с первого рабочего дня, включая членов семьи неограниченные возможности профессионального и карьерного роста, регулярное внешнее и внутреннее обучение от наших партнеров частично или полностью оплачиваемые дополнительные обучающие курсы программы личностного роста, в которых мы ставим цели и вместе к ним движемся возможность стать частью международной команды профессионалов и просто хороших людей, которые все вместе создают одну из самых крутых историй успеха в мировой IT-индустрии. Наши сотрудники - самое ценное, что у нас есть. Мы заботимся о том, чтобы офисное пространство было максимально комфортным для работы и отдыха. Мы любим различные корпоративные мероприятия и тематические дни, чтобы наша жизнь была еще более интересной и насыщенной.","Python,SQL,Анализ финансовых показателей,Data Analysis,Английский — B1 — Средний",inDrive,
6752,68822135,Data Analyst,з/п не указана,1–3 года,"Полная занятость,удаленная работа","В Росбанке возможен полностью дистанционный формат работы: откуда работать - решать только тебе! Приходи к нам, чтобы работать над амбициозными и интересными проектами и наслаждаться балансом между работой и личной жизнью! Росбанк – частный универсальный банк, работающий на российском рынке с 1993 года. Росбанк обслуживает порядка 1,5 млн активных розничных клиентов, около 83 тысяч активных клиентов малого бизнеса и около 10 тысяч активных клиентов корпоративного бизнеса более чем в 60 регионах России. Росбанк входит в ТОП 5 самых надежных российских банков по версии журнала Forbes и включен Банком России в число 13 системно-значимых кредитных организаций России. Наш банк имеет наивысшие кредитные рейтинги российских и международных рейтинговых агентств. ОБЯЗАННОСТ: Работа с базами данных Анализ данных в целях выявления трендов проведения банковских операций Подготовка аналитики и участие в создании скоринговых моделей Формирование гипотез для улучшения показателей Визуализация данных (приведение статистики в наглядные графики) Предложение решений для развития проектов. ТРЕБОВАНЯ: Знание и регулярное использование в работе SQL Опыт работы с большими объемами данных Опыт работы с СУБД GreenPlum/Postgre/Oracle/MS SQL Опыт работы с ETL инструментами. БУДЕТ ПЛЮСОМ (НО ЕСЛ НЕТ НАУЧМ): Опыт работы с BI инструментами Tableau/Power BI/Metabase Опыт использования Python для обработки данных Опыт работы с JIRA и Confluence Понимание цикла разработки ПО. УСЛОВЯ: Полностью дистанционный формат работы – это возможность работать из любой точки Стабильный и прозрачный доход: зарплата и премии по результатам работы График 5/2 31 календарный день оплачиваемого отпуска Забота о здоровье сотрудников: программа ДМС, включая стоматологию и страхование при выезде за рубеж, корпоративные спортивные команды и скидки на абонементы в фитнес-клубы Дополнительная оплата за больничный лист: доплата сверх пособия по болезни до оклада (до 5 рабочих дней в год) Личностное развитие и рост: корпоративная электронная библиотека Альпина, возможность прохождения бесплатного обучения и тренингов, участия в регулярных встречах корпоративных клубов и скидки на курсы он-лайн школ Скидки и привилегии по кредитам, ипотека на льготных условиях, льготные условия обслуживания и т.п. Программа корпоративных скидок и привилегий Primezone: развлечение, отдых, товары и услуги, обучение Программа волонтерства и благотворительности Сообщества по интересам сотрудников.","SQL,PowerBI,Базы данных,Работа с базами данных,Визуализация данных,Навыки составления отчетности",«РОСБАНК»,
6753,78778781,Senior Data scientist,от 4 000 USD на руки,3–6 лет,"Полная занятость,полный день","Приглашаем в нашу команду профессионального и амбициозного Senior Data scientist / Аналитика данных. Вам предстоит решать сложные, но очень интересные задачи. Мы - международная финтех компания AMarkets. С 2007 года предоставляем передовые решения для торговли на финансовых рынках для трейдеров и инвесторов во всем мире. Задачи, которые предстоит решать: Сбор, валидация и анализ данных из корпоративных информационных систем Анализ исторических данных Построение алгоритмических математических моделей Разработка и обучение нейронных сетей Анализ и прогноз временных рядов Кластеризация и сегментация клиентской базы Разработка моделей скоринга клиентов Разработка моделей прогнозирования и моделирования сальдо торговых счетов клиентов Разработка моделей прогнозирования и моделирования LT клиентов Разработка моделей прогнозирования и моделирования оттока клиентов Разработка моделей прогнозирования и моделирования LTV Прогнозирование кол-ва обращений в поддержку Прогнозирование и моделирование показателей эффективности клиентской поддержки Выдвижение и проверка гипотез для улучшения ключевых показателей эффективности бизнеса Разработка новых показателей (метрики, KPI). Наши ожидания: Опыт работы в финтех индустрии, брокерских, букмекерских компаниях или игорной индустрии от 3 - х лет Высшее образование (желательно наличие ученой степени) в таких предметных областях, как: математика, финансы или экономика, информатика, физика, инженерия или аналогичные сследовательский склад ума: быть глубоким мыслителем, творческим человеком, настойчивым, умным, инициативным, внимательным к деталям Критическое мышление и способность придумывать нестандартные подходы Сильная рабочая этика Уверенное пользование инструментами BI аналитики Tools: MySQL, Google BigQuery, Python, Hadoop, Git Английский язык: upper -intermediate (B2). Будет плюсом: Сильный послужной список академических достижений (докторская степень, научные публикации, презентации на конференциях, гранты или награды) Знание финансовых рынков. Мы предлагаем: Релокация в Черногорию , г. Подгорица В случае релокации - работа в комфортабельном офисе, переезд и легализация за счет компании Конкурентную заработную плату в зависимости от ваших компетенций и опыта ДМС, программа лояльности для сотрудников Сплоченная команда профессиональных единомышленников Амбициозные и интересные задачи.",,AMarkets,
6755,79052444,Product/ Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы Green Code, и мы не хотим завоевать весь мир или заработать все деньги лона Маска (пока что), но и у нас есть амбициозные планы. Один из них - наш проект iGaming игр, ключевое отличие которых skill-based games/PvP games - в них есть и элементы рандома, и моменты зависящие от решений и skill'ов пользователя. Другим отличием является возможность игрока проверить на честность результат любой своей или многопользовательской игры. Наша задача - делать уникальный продукт для нового поколения.  Сейчас мы расширяем команду и ищем дата аналитика со следующим небольшим списком требований: высшее математическое/техническое/экономическое образование опыт работы с анализом данных от 3-х лет уверенное знание UML, SQL опыт работы с ClickHouse опыт визуализации данных, метрик опыт работы с Metabase опыт автоматизации отчетности продукта. большим плюсом будет опыт в igaming или gamedev сфере. Задачи и обязанности: формирование и согласование требований к продуктовым метрикам и выборкам взаимодействие с лидами продуктовых отделов для поиска точек роста участие в дизайне экспериментов, анализ их результатов измерять пользу от внедренных фичей, других изменений продукта составление дашбордов по метрикам конструирование метрик используя SQL запросы к базам данных, другим источникам подготовка ТЗ на регулярную отчетность. Условия: любое удобное оформление, возможность привязки к валюте есть и офис (Москва, Казахстан), можешь сам выбирать комфортный вариант если есть идеи для проекта - круто! Каждый в нашей команде может влиять на продукт у нас можно реализоваться, как твоей душе угодно, главное любить то, что делаешь не нужно выпрашивать повышений или премий)","SQL,Анализ данных,Аналитика",Green Code,
6757,78006685,Data Analyst (Junior),от 70 000 руб. на руки,не требуется,"Полная занятость,полный день","Мы - аккредитованная Минцифры IT-компания DNS Технологии! У нас активно развивается аналитический отдел направления «Развитие сайта» и наша команда является центром бизнес-анализа данных нтернет направления. На сегодняшний день перед командой стоят задачи, связанные с веб-аналитикой, а также с разработкой и поддержанием собственного аналитического приложения. Сейчас, в связи с увеличением количества проектов, мы хотим расширить наш отдел, и готовы принять в команду еще одного аналитика данных. Основной используемый стек технологий: Python (pandas, plotly), SQL(postgresql, clickhouse) Чем предстоит заниматься: Поддержкой аналитических отчетов на Dash Созданием системы метрик интернет продаж Проектированием отчетов Проведением исследований и поиском точек роста Наш кандидат: меет высшее IT образование Знает наш технологический стек: Python (pandas, plotly), SQL(postgresql, clickhouse) Умеет и хочет работать в команде Готов к постоянному развитию Мы предлагаем: Развитую систему наставничества Прозрачную систему грейдов для роста и развития внутри компании Командный подход к разработке, где приветствуется атмосфера взаимопомощи и общения Разнообразные интересные задачи Обширную базу знаний Лояльное отношение к дресс-коду Возможность найти коллег по интересам для участия в различных внерабочих активностях А еще: Трудоустройство по ТК РФ в официально зарегистрированной Т-компании и полностью “белую” заработную плату Ежегодную премию по результатам работы Компании Возможность приобретать товары Компании по специальной цене Компенсацию внешнего обучения по профилю 70% Скидки на обучение английскому языку и скидки от партнёров (фитнес-клуб, мобильная связь) Участие в корпоративных мероприятиях Офис, оснащенный всей необходимой техникой для работы, а также местом для отдыха и кухней. Как дополнительный плюс – наличие парковки. Кандидатов оцениваем по знаниям и навыкам, финальную заработную плату обговариваем после собеседования. Если заинтересовала вакансия - ждём резюме откликом или по электронной почте! :)","Pandas,PostgreSQL,Python,SQL,ClickHouse,Dash,Статистика",DNS Технологии,"Владивосток, проспект 100-летия Владивостока, 155"
6758,79047478,Аналитик данных / Data Analyst,от 100 000 руб. на руки,1–3 года,"Проектная работа/разовое задание,полный день","В поисках датааналитика на разработку клиентских дашбордов в Microsoft Power BI и визуализацию данных внутри компании. Обязательные навыки: Опыт работы с Microsoft Power BI от года Python, SQL Умение делать презентации Уверенное владение MS PowerPoint, XLS Желательные навыки: VBA, EViews, Matlab, R и др. REST API Функционал: Разработка и развитие витрин данных, подготовка прототипов для промышленного слоя Структурирование большого объёма данных Повышение качества данных, исследование и корректировка существующих витрин и поставок данных Условия: Проектная занятость, с будущим оформлением в штат на полную ставку Работа по договору","Data Analysis,MS Power BI,SQL,Визуализация данных,PowerPoint,Python,MATLAB,MS Visual Basic,Подготовка презентаций,Логика",,
6759,79026713,Data Analyst,от 50 000 до 100 000 руб. на руки,1–3 года,"Полная занятость,полный день","Привет! Fabula – быстрорастущий проект с применением AI технологий. Целевой рынок – profile picture. У проекта уже 100 000 пользователей, но мы верим, что можем вырасти еще в 10 раз в ближайшие несколько месяцев. Наша задача – вывести проект на международный рынок, и для этого нам нужен аналитик данных, на основе отчетов которого будут приниматься важные управленческие и технические решения.  Чем нужно будет заниматься? Выстраивать дашборды и витрины данных с ориентиром на продуктовые метрики, валидировать гипотезы, искать инсайты и идеи для следующих проверок гипотез, оформлять результаты экспериментов и делать автоматизированный сбор статистики. Продукт растет очень быстро, поэтому мы ищем человека, который сможет помочь продукту развиваться еще быстрее и качественнее. Что мы ждем от кандидата: опыт работы от года опыт проведения A/B тестирования хорошее знание SQL, Python знание Pandas, Jupyter, NoSQL базовые навыки работы с docker опыт работы с приложениями и аналитикой сайтов опыт работы с 1-2 инструментами: AppMetrica, PowerBI, Superset, Amplitude, расширенная Google Аналитика. Условия: оформление по ТК РФ, 100% оплачиваемый отпуск и больничный официальная заработная плата два раза в месяц график 5/2, суббота и воскресенье выходной компания относится к аккредитованным IT-компаниям своя кухня с вкусными печеньками, чаем и кофемашиной. А теперь о том, как мы вкладываемся в наших сотрудников, чтобы всем работалось комфортно и эффективно: возможность совмещать офис и удаленку квартальное премирование, привязанное к эффективности работы возможность до 25% рабочего времени посвящать профессиональному развитию карьерные треки, зарплатные карты и тренинги личностного роста с учетом интересов сотрудника и компании оплата хобби, кастомизация рабочего места и мерчендайз-наборы с помощью внутренней валюты компании офисного фея, внимательно следящего за твоим комфортом на работе.  Присоединяйся к нашей команде! :)","Python,A/B тесты,Jupyter Notebook,SQL,Pandas,NoSQL,Amplitude,PowerBI,AppMetrica,Superset",Спутник,
6761,78845017,Data Analyst,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Приглашаем на позицию – Data Analist Проект в строительной сфере. Аналогов нашим продуктам нет, зато есть простор для технического творчества) Ваша зона ответственности: Общаться с продуктовыми командами, собирать, описывать и актуализировать информацию о логических сущностях в системах и их связях Описывать структуры БД продуктов (Таблицы, Поля), их логическое назначение Анализировать и описывать существующие процессы в системах, потоки и структуры данных Отслеживать пост-релизные изменения в БД продуктов и актуализировать информацию Создавать отчеты на основании собранных данных Наши пожелания: меете опыт работы системным/data-аналитиком от 3х лет меете уверенные знание SQL меете практический опыт работы с реляционными БД Большим плюсом будет: умение читать код на Python (например, посмотреть миграции в моделях Django) Опыт работы с PostgreSQL опыт работы с Jira, Confluence опыт работы с git опыт работ с NoSQL БД Мы предлагаем: Официальное трудоустройство и соблюдение ТК РФ График работы с 9:00 до 18:00, пятница – сокращенный день. Возможно гибкое начало дня Удаленный формат работы или в офисе БЦ Кунцево Плаза, м. Молодежная (кстати, наш офис получил премию «Трансформация года» в 2021г.) Расширенный пакет ДМС и страхование от несчастных случаев с первого месяца работы, льготное ДМС для близких родственников, страхование имущества и пр. Компенсация мобильной связи (корпоративная сим-карта) для тех, кому нужно всегда быть на связи Рост и развитие в компании: регулярная обратная связь каждому сотруднику, обучающие мероприятия и широкий доступ к материалам, в том числе ведущих образовательных платформ Скидки для сотрудников на недвижимость группы “Самолет”, индивидуальные условия по рассрочке",,Группа Самолет,
6762,78095991,Data analyst (Moscow),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы аккредитованная IT компания Servicepipe, которая работает на рынке Б более 6 лет. Мы разрабатываем решения, обеспечивающие доступность и безопасность онлайн-ресурсов и оказываем услуги на базе собственной распределённой инфраструктуры Про проект: мы разрабатываем свой сервис предотвращения DDoS-атак, защиты от ботов и интернет мошенничества. Процессинг трафика происходит в реальном времени, поэтому мы стараемся создать не только эффективное с точки зрения защиты, но и быстрое с точки зрения производительности решение. Сейчас в нашу команду мы ищем Аналитика данных. Обязанности: Анализировать сетевой трафик на предмет аномалий Писать правила эффективной фильтрации ботового трафика Разрабатывать новые методы борьбы с автоматизированной активностью. Требования: Уверенный SQL (аггрегация, оконные функции, вьюхи применяются на автомате). У нас - Clichouse Знание HTTP-протокола Базовые git, linux Мат. статистика. Условия: Свобода в выборе способов реализации задач, вы сами решаете какие инструменты лучше использовать для решения определенных задач Возможность работать в гибкой структуре и влиять на принятие решений по всему продукту Работа в команде профессионалов из разных сфер, которые всегда готовы поделиться опытом Гибридный формат работы Тренинги, курсы, конференции Корпоративный футбол и компенсация спорта laptop и необходимое оборудование на выбор ДМС после испытательного срока Корпоративная онлайн библиотека МФ.","SQL,Linux,Git,HTTP",Servicepipe,
6766,79169643,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Участие в оценке эффективности маркетинговых мероприятий, поиск фрода, построение моделей оттока клиентов, uplift моделирование, рекомендательных систем Выбор оптимального метода моделирования Дизайн и проведение А-Б тестов, проверка статистических гипотез, представление результатов бизнес-заказчику Визуализация данных по итогам проведения аналитики code review Требования: Опыт работы на позиции data scientist от 1-3 лет SQL, Python, Excel Опыт работы с (pandas, numpy, sklearn, optuna) Знание классических алгоритмов ml и что находится у них под капотом (catboost, xgboos, lgbm, als, lightfm и т.д) Методичность работы с информацией, выявление взаимосвязей Опыт использования на практике знаний в области прикладной математической статистики, теории вероятностей Способность быстро оценивать ситуацию и принимать решения Способность точно, аккуратно и педантично выполнять работу в установленные сроки, ответственность за результат Высшее образование (техническое, экономическое). Участие в хакатонах, Kaggle, как плюс Условия: Отпуск 28+3 дня ДМС, бонусы при выходе в отпуск, насыщенная социальная программа Уровень заработной платы обсуждается по итогам собеседования Работа в офисе (Большая Ордынка, 3) Оформление в ООО ""ЛКАРД"".",,ЛУКОЙЛ,"Москва, улица Большая Ордынка, 3"
6767,79098677,Data Analyst (Anti-fraud),з/п не указана,1–3 года,"Полная занятость,полный день","Наша команда занимается противодействием мошенничеству в розничных рисках. Мы работаем над сокращением времени от факта совершения события мошенничества до его обнаружения, над выявлением новых схем мошенничества и повышением эффективности работы по уже известным. Мы ищем того, кто принесет новые идеи и быстро подключится к решению амбициозных задач. Обязанности: Работа в Антифроде розничных рисков Развитие процессов противодействия мошенничеству Анализ различных источников информации с целью их использования в антифроде Мониторинг и улучшение текущих фрод-правил Подготовка выгрузок и анализ данных по запросам Создание и поддержка отчетности Написание аналитических заключений. Требования: Высшее математическое или техническое образование Знание математической статистики, теории вероятности, алгоритмов машинного обучения Хорошее знание языков программирования (PL\SQL, Python, R и проч.) Умение работать с большими объёмами данных Знание методологии по исследованию данных. Условия: потека выгоднее для каждого сотрудника и льготные условия кредитования Бесплатная подписка СберПрайм+ Скидки на продукты компаний-партнеров ДМС с первого дня и льготное страхование для близких Корпоративная пенсионная программа Обучение за счет Компании: онлайн курсы в Виртуальной школе Сбера и неограниченный доступ к библиотеке, обучение в Корпоративном университете, Тренинги, митапы и возможность получить новую квалификацию.","Python,SQL,Аналитическое мышление,Работа с большим объемом информации",Сбер для экспертов,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
6768,78985817,Data Analytics (Аналитик данных),от 150 000 руб. на руки,1–3 года,"Полная занятость,полный день","Наши направления работы: • Розничная торговля: сеть магазинов «Колхоз» - это 26 продуктовых магазина формата «у дома» в разных районах города. Мы – лидер на рынке в Санкт-Петербурге в сегменте традиционной торговли, и уже более 11 лет радуем наших покупателей свежими качественными продуктами и профессиональным обслуживанием. • Автомоечные комплексы: сеть из 5-ти автомоек высокого уровня (“Мойка под мостом»,«Зеленая мойка», «Мойка на Героев» + 2 мойки самообслуживания). «Мойка на Героев» - одна из самых больших в Санкт-Петербурге, более 8 лет на рынке. Условия работы: • Заработная плата и премии: высокая стабильная конкурентная заработная плата с возможностью влиять на ее увеличение с ростом новых задач и вашей личной пользы для компании. В период испытательного срока от 100.000 рублей. После испытательного срока обсуждается с успешным кандидатом индивидуально . Премии: годовая премия по итогам работы, премия от руководителя за успехи в работе, премии за инициативность и успешные идеи, премии на день рождения • График работы: в офисе -пятидневная рабочая неделя с 10-19. Выходные суббота и воскресенье. Гибридный график работы: офис и работа из дома, готовы обсудить на собеседовании. • Место работы: комфортный офис в 1 минуте от метро Чкаловская + выезды. • Оплата обучения: для улучшения ваших профессиональных навыков за счет компании. • Оформление: по ТК РФ, оплачиваемый больничный и отпуск 28 дней в году. • Карьерный рост: гарантирован при высоких результатах работы. У нас нет ограничений в плане карьерного роста – каждый сотрудник может достигать руководящих должностей, начиная с любой позиции в компании. • Команда: эксперты в своем деле. • Миссия: мы стремимся создать идеальный продукт для наших клиентов. • Компания: работайте в гибкой компании без шаблонов и бюрократии. • Дополнительно: участие в корпоративных мероприятиях возможность поработать из дома, если случился форс-мажор, подарки на праздники. Обязанности: Составление прогнозной модели по основным KPI в разных разрезах(категории, магазины) Стандартизация аналитики для нужд КС, визуализация в BI Подготовка аналитики в рамках процесса анализа категорий Расчет проектов. Отслеживание результатов Сбор, анализ, управление требованиями. Анализировать данные, строить воронки, проводить когортный анализ и делать выводы/строить гипотезы на основе полученных данных. Делать описание алгоритмов обработки данных. сследовать источники данных, изучать выгрузки данных. Формировать требования к выгрузкам данных из источников в хранилище. Писать ТЗ, прорабатывать сценарии, тестировать, запускать, поддерживать актуальность. Осуществлять построение отчетности и проведение исследований Формировать отчеты и информационные панели с помощью BI-системы. Формировать аналитические выгрузки данных, в соответствии с запросами профильных подразделений. Проводить оценку эффективности разработанных моделей. Анализ пользовательских метрик для поиска причин проблем или идей для развития бизнеса. Автоматизация аналитических инструментов. • Выстраивать краткосрочные и долгосрочные прогнозы для определение тактического и стратегического развития. Требования: У вас есть опыт работы в данной должности не менее 3 лет. У вас отличные знания Python/SQL и Язык R. Вы умеете работать с большим объемом информации. меете аналитическое и структурное мышление. Вы самостоятельны в принятии решении и знаете, что такое высокий уровень ответственности Умение анализировать большие объемы данных, видеть скрытые тенденции и закономерности. Знание Power BI (желательно). Если все это про Вас, то смело откликайтесь на нашу вакансию! После рассмотрения резюме и положительного ответа – мы обязательно свяжемся с Вами.","Python,SQL,Анализ данных,Аналитические исследования,Аналитическое мышление,язык программирования r,Работа с большим объемом информации,Power BI,Анализ бизнес показателей",КОЛХОЗ,"Санкт-Петербург, Большая Зеленина улица, 8"
6769,79275335,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Наша команда создает и развивает продукт для построения Data Lineage на различных технологических стеках хранения и преобразовании информации ( от традиционных РСУБД : Oracle, PostgreSQL, GreenPlum до Hadoop: Hive, Spark ). Перед командой стоит задача по созданию продукта не только в рамках платформы Фабрики, но и выхода в экосистему Сбербанка, а далее и на внешний рынок. Data lineage – информация, которая описывает движение данных от источника их происхождения по точкам обработки и применения, в виде ациклических графов. В мире Big Data, когда информации становится все больше, Data lineage позволяет управлять данными, реализуя следующие задачи: обеспечение качества данных за счет однозначной идентификации их источников повышение доверия к данным через прозрачность всех процессов работы с ними предоставление метаданных и сведений об их изменении в точках трансформации данных Чем предстоит заниматься: сследование данных и процессов различных систем источников Data Linage Участие в формирование требований по сбору, хранению и распространению фактического Data Lineage Участие в проектирование единой модели Синхронизация и устранение разрывов единой модели данных, моделей источников, модели приёмников Разработка процессов обработки, обогащения и трансформации Data Lineage (Spark 2,3, Hive) Участие в разработке/актуализации архитектуры Требования: Опыт работы аналитиком данных или Big Data аналитиком Знание современных инструментов описания процессов Высокий уровне знания SQL Знание REST/SOAP Понимание принципов и особенностей работы высоконагруженных систем Опыт использования экосистемы Hadoop (Spark, Hive, Spark ML), Scala или python Условия: гибкий график для оптимального баланса работы и личной жизни Офис: м. Нагатинская / мцк. Верхние Котлы профессиональный рост в команде дружных профессионалов ДМС, страхование жизни самые инновационные, амбициозные проекты и задачи. свободный дресс-код. льготные кредиты и корпоративные скидки профессиональное обучение, семинары, тренинги, конференции, корпоративная библиотека конкурентная компенсация (оклад и премии по результатам деятельности).",,Сбер. IT,Москва
6770,78386771,Middle+ Data Scientist,от 160 000 до 200 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","AgentApp — платформа для бизнеса, которая позволяет запустить продажи страховок со своего сайта или моб. приложения для клиентов со всей страны. Над продуктом работает единая команда разработчиков, аналитиков, маркетологов, а также экспертов в страховом бизнесе. 200 000 000р.+ — ежемесячный объем продаж через платформу. AgentApp — активно развивающийся стартап, позволяющий сотрудникам быстро развиваться профессионально и прокачивать скиллы. Наш продукт интегрирован в моб.приложения Сбербанк, OZON, ВТБ, МТС, Райффайзен, Газпром и имеет аудиторию свыше 70 млн пользователей. Мы находимся в поиске крутого специалиста, который поможет развивать наш Big Data проект! Что нужно будет делать: Разработка моделей скоринга Построение упрощенной модели по характеристикам авто и данным об убытках за пару лет Разработка моделей сегментации клиентов на основании их профилей и анализа их поведения. Мониторинг текущих показателей, обеспечением чистоты входящих данных, улучшением текущих моделей. Разработка инструментов мониторинга сследование тенденций и технологий в сфере Data Science, AI и Machine Learning с целью их последующего применения. Ждем от кандидата: Опыт подготовки неструктурированных данных для обучения модели (feature engineering) Прикладной опыт выведения моделей в продакшн Навык работы с базами данных: владение SQL / Hive / Hadoop / SQL Alchemy Опыт реализации классических ML-моделей: регрессия, классификация, кластеризация, понижение размерности данных Навыки Python-разработчика: работа с файлами - прочитать/записать, работа с АП http-сервисов через xml / json (SOAP/REST). Опыт работы с python-библиотеками (logging, yaml, xml, json, requests, threading) + ORM (sqlalchemy, ponyORM, tortoise) + навыки в ООП (работа через классы). Этапы интервью: 1. HR интервью (30 мин). Знакомство с вакансией. 2. Техническое интервью с CTO и тимлидом. (1-2 часа) 3. Знакомство с СЕО (30 мин) 4. Оффер. С нас: Работа над инновационном продуктом, который востребован на рынке Стабильная зарплата с потенциальными бонусами и регулярной индексацией Удаленная работа (при необходимости использование офиса в пешей доступности от ст.м. Василеостровская и ст.м. Спортивная (СПб)) Прокачка скиллов по запросу или по необходимости (курсы, книжки, семинары) Официальное трудоустройство.","SQL,Python,Базы данных,Big Data,ML",Remokate,
6771,76391927,Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Привет! Мы – Dodo Brands, международная компания, развивающая 3 бренда: Dodo Pizza, Drinkit и Doner 42. Dodo Pizza – самый крупный бренд и лидер в России по количеству открытых пиццерий. Всего у нас 880+ пиццерий в 17 странах, а ещё есть донерные и кофейни. Мы разрабатываем мобильное приложение и сайт для заказа пиццы. Кроме того – собственную информационную систему Dodo IS, которая помогает пиццамейкерам приготовить заказ, курьерам привозить горячую пиццу, а менеджерам на смене и управляющим видеть, насколько эффективны процессы в пиццериях и кофейнях. Наша компания основана на принципах радикальной открытости и доверия. В Dodo Brands каждый становится предпринимателем в рамках своей роли и может по-настоящему творить и менять. Открытость помогает нам развивать долгосрочные партнёрские отношения с клиентами, сотрудниками и франчайзи, основанные на взаимном доверии и принципе win-win. Мы укрепляем и расширяем команду, и ищем опытных дата-аналитиков. О команде и направлениях: Позиция дата-аналитика структурно находится в CVM&Analytics Global. Customer Value Management (CVM) - система персонализированного взаимодействия с клиентами, направленная на долгосрочный рост ценности взаимоотношений. Как следует из названия, у нашего направления 2 фокуса: всестороннее развитие CVM (с точки зрения проверки гипотез, моделей и технической реализации, а также масштабирование на другие страны/бизнесы внутри Dodo Brands) аналитические проекты и ad hoc задачи, напрямую не связанные с CVM, но влияющие на другие бизнес-юниты (b2b аналитика). Приоритетными направлениями для нас с точки зрения b2b аналитики являются: HR производственная эффективность контроллинг. Кого мы ищем: 1. Data Analyst (B2B) Аналитик будет заниматься преимущественно задачами b2b-аналитики. Миссия позиции: так как у перечисленных выше направлений нет своих аналитиков, человек, которого мы ищем, полностью возьмет на себя аналитическую поддержку направления: оптимизирует текущие процессы и инициирует новые. 2. Data Analyst (use-case Frequency) Аналитик будет 100% своего времени вовлечен в задачи CVM. При этом его фокусом будет use-case Frequency. Миссия позиции: совместно с DS и другими DA осуществлять поиск инсайтов и проверять гипотезы, которые позволят увеличить частоту клиентов. Чем предстоит заниматься: Оценивать A/B-тесты, а также заниматься генерацией и проверкой гипотез. Поиск инсайтов в данных Оценивать запускаемые акции и инициативы. Готовить предложения по улучшению методологии оценки нтерпретировать данные: поиск закономерностей, аномалий, декомпозиция Строить отчеты, дашборды Заниматься построением прогнозов различных метрик Драйвить data-driven культуру в компании через обучение коллег и поиск новых подходов и инструментов для решения задач. Что мы от вас ожидаем: Опыт работы Data Analyst не менее 2 лет (с решением схожих задач) Техническое образование Умение писать sql-запросы (в любом синтаксисе, на уровне получения и первичной обработки данных) Знание Python (обработка, визуализация, стат. пакеты) Понимание и практический навык, как решать базовые ML-задачи (регрессия, классификация, сегментация, обработка текстов и т.п.) Знание статистики (прежде всего, понимать, как теоретически и методологически оценивать A/B-тесты) Опыт работы с любым BI-инструментом визуализации (Tableau, Power BI, Superset и др) Аналитический склад ума (умение отвечать на конкретные потребности бизнеса используя данные, умение осуществлять drill-down анализ) Умение понятно доносить результаты своего анализа до аудитории. Почему у нас круто работать? Большие задачи. Сейчас мы лидеры на пицца-рынке России и только увеличиваем отрыв от конкурентов. Но мы хотим выиграть конкуренцию на международных рынках и активно развиваемся за рубежом. Мы собираемся стать первой глобальной розничной компанией родом из России Высокая скорость профессионального развития. Непрерывно появляются задачи, которые до нас ещё никто не делал.  мы не планируем останавливаться Команда профессионалов. У нас нет случайных людей. В нашей команде собрались люди с опытом работы в больших международных компаниях, которые понимают, как делать качественный продукт No-bullshit культура. Мы открыты и доверяем друг другу. Мы предлагаем корпоративную культуру, в которой люди сами принимают решения и несут за них ответственность, решая сложные задачи. Мы готовы вам предложить: Удаленку или работу в офисе в Москве, в Омега Плазе на метро Автозаводская Расширенная ДМС с первого рабочего дня Оплата профильных конференций, курсов, профессиональной литературы Партнерские программы (скидки на изучение английского языка Skyeng, компенсация психологической помощи на платформе Alter) Митапы, лекции, воркшопы и интенсивы Прокачка навыков публичных выступлений (сделаем из вас крутого спикера) Помощь в написании профессиональных статей и раскрутку вас, как автора, на профильных ресурсах (Хабр, VC).","Python,SQL,Tableau,Power BI,Английский язык","DODO BRANDS (Dodo Pizza, Drinkit, Doner 42)","Москва, Автозаводская, Автозаводская, улица Ленинская Слобода, 19с7"
6773,79275855,Marketing analyst / Data analyst in marketing / Web analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Lucy in the Sky - бренд молодежной женской одежды, наш головной офис, студия дизайна и производство находится в городе Лос Анджелес, США. Lucy in the Sky Tech - это наша команда аналитиков, дизайнеров, web/mobile разработчиков и тестировщиков. Мы занимаемся автоматизацией e-commerce. Нашей Tech командой мы работаем над следующими проектами компании: - внутренняя система компании, которая позволяет автоматизировать весь бизнес и производственный процесс, работу склада, клиентский сервис и другие - интернет-магазин - мобильное приложение. В данный момент мы в поисках кандидата на позицию Marketing analyst, основной задачей которого будет аналитика и повышение эффективности платных рекламных каналов. Анализ эффективности маркетинговых каналов, инструментов Анализ отклонений, поиск точек роста и инсайтов в данных Помощь команде маркетинга с гипотезами, метриками и экспериментами. Ожидания от кандидатов: Аналогичный опыт работы аналитиком данных в маркетинге от 3 лет Успешные кейсы по оптимизации и увеличению конверсии Владение инструментами обработки данных (SQL, Python) Опыт работы с системами визуализации данных (AWS QuickSight, Data Studio, Power BI, Tableau, Splunk либо аналоги) Умение анализировать цифры, работать с маркетинговой аналитикой и оценивать эффективность маркетинговых инвестиций Системный подход в работе, аналитическое мышление Знание английского B1 Intermediate и выше (поиск информации и свободный разговорный английский) Будет плюсом опыт работы с каналами Facebook, Google, Tik Tok, Snapchat. Мы предлагаем: Отсутствие бюрократии, решения принимаем быстро Полностью удаленная работа из любой точки мира Зарплата в долларах Перевод зарплаты в криптовалюте (USDT) или любой иностранный банк Контрактная работа с американской компанией Работаем по американскому календарю  Регулярный Performance Review и Salary Review Оплачиваемый отпуск Оплачиваемый больничный Оплата онлайн курсов Udemy.","Анализ данных,Data Analysis,SQL,Python,MS Excel,Системное мышление,Аналитическое мышление,Аналитика,Маркетинг,Английский — B1 — Средний",Lucy in the Sky Inc,
6774,79229664,Аналитик Google Data Studio проектно,з/п не указана,1–3 года,"Проектная работа/разовое задание,удаленная работа","Компания АКО с 2012 года лидер на рынке видео-контроля. Мы работаем с крупнейшими ритейлерами и fast-food сетями, с известными ресторанами и производственно-складскими помещениями. Наша цель: улучшать сервис и повышать эффективность магазинов и ресторанов через видео-контроль. Сейчас мы в поисках АНАЛТКА, кто проектно выполнит ряд задач по структурированию данных и разработает управленческие дашборды. Что уже есть: Мы используем дашборды в PowerBI, все данные, управленческие и операционные отчеты и сырые данные в Google таблицах. Что хотим: Собрать дашборды в Google Data Studio взамен PBI Автоматизировать ряд рутинных задач Структурировать справочники и прочую информацию из хаотичных гугл-таблиц в стройную систему, которая упростить работу пользователей Сроки: Приступить в апреле и реализовать несколько ТЗ за месяц (условно), при возможности занятости нашим проектом 1-3 часа в день Какой нужен опыт: Вы умеете создавать лаконичные и понятные дашборды Ваши дашборды работают устойчиво и надежно, без сбоев, не требуют ручных настроек внутри ПО Вы можете показать примеры своих работ, хотя бы в формате скриншотов У вас был опыт в бизнес-аналитике: вы можете задать вопросы руководителю, и предложить наилучшее решение под его запрос Условия сотрудничества: Готовы к обсуждению оплаты, ориентируемся к фикс стоимости за каждое ТЗ, Несколько встреч у нас в офисе в СПб, Частичная занятость, возможно в параллель к основной вашей работе, мы готовы к вечерним созвонам и встречам, В сопроводительном письме, укажите, пожалуйста, ориентир стоимости вашей работы.",,АКО,
6776,79115463,Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Кто нам нужен: Мы ищем Аналитика/ Дата инженера хранилищ данных, способного принять активное участие в развитии детального слоя хранилища, а также в построении витрин данных. Данная роль предусматривает: понимание как работает бизнес продукт, уточнение требований с заказчиками и постановку задач разработчикам, создание прототипов витрин, развитие модели хранения данных, контроль реализации функционала и его приемка, поддержка его эксплуатации в части обеспечения полноты и качества данных. Тебе предстоит: Участие в проекте по реализации базового слоя данных Блока Сеть Продаж – анализ и контроль процесса прототипирование витрин данных по продуктам Аналитическая и методологическая поддержка в части управления данными, анализе результатов A/B тестов и оценки финэффектов. Подготовка прототипов витрин данных для внутренней отчетности Активное участие в переходе на новую архитектуру хранения данных. Сбор, анализ, и согласование требований с заказчиками, разработчиками и архитекторами Контроль разработки документации к релизам, формирование спецификаций Разработка прототипов витрин и проработка алгоритмов расчета показателей, необходимых бизнес заказчикам Разработка и поддержка дэшборда по уровню качества данных и по метрикам индекса качества данных (T2M) Автоматизация расчетов ключевых целевых показателей подразделения Ad-hoc задачи, связанные с выгрузкой и анализом данных (расчет различных метрик по запросу) Наши ожидания: Must have: Уверенное знание SQL и Python, владение Git Опыт работы в Hadoop (Hive, Spark), PostgreSQL Nice to have: Опыт построения ETL пайпланов Понимание методов и подходов машинного обучения Опыт реализации контролей качества данных Мы готовы предложить: Deep diving в предметную область, много разработки по задачам имеющим прямой эффект на бизнес Возможность привносить новые идеи и нестандартные решения Сообщество D-people – поддержка, развитие и возможность учиться у профессионалов Достойную оплату труда Возможность расти в самой крупной DS-команде)) Возможности саморазвития: обучение за счет Компании: онлайн курсы в Виртуальной школе Сбера и неограниченный доступ к библиотеке, обучение в Корпоративном университете, тренинги, митапы и возможность получить новую квалификацию Скидки на услуги экосистемы Сбера и компаний-партнеров. потека выгоднее для каждого сотрудника и льготные условия кредитования Бесплатная подписка СберПрайм+ Скидки на продукты компаний-партнеров: Okko, Сбер Маркет, Delivery Club, Самокат, Сбер Еаптека и другие ДМС с первого дня и льготное страхование для близких Корпоративная пенсионная программа Курсы для будущих родителей, материальная поддержка и тематическое сообщество для молодых мам Детский отдых и подарки за счет Компании Реферальная программа для сотрудников: можно пригласить в команду знакомых профессионалов и получить вознаграждение до 100 тыс. рублей Скидки на отдых в лучшем в мире курортном комплексе «Mriya Resort & SPA» в Ялте.","Python,Hadoop,SQL",Сбер. Data Science,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
6778,78448054,"Специалист/нженер (AI, Data Scientist, Big Data, Machine learning, Нейронные сети, ChatGPT)",з/п не указана,3–6 лет,"Полная занятость,гибкий график","ПК ЛДЕРГРУПП – это успешная и динамичная команда профессионалов, реализующая проекты в области проектирования линейных объектов по всей территории России в качестве Генерального проектировщика. Условия: Персональный график работы (офис, удаленно, гибридный). Любая форма трудоустройства (Официально, ГПХ, Самозанятость). Уровень оплаты обсуждается индивидуально. Территориально: ст.м. Киевская офис класса А (в пешей доступности). Возможность участвовать в реализации новых уникальных проектов на базе . Профессиональный творческий коллектив. Задачи: Аналитика рынка AI-сервисов под бизнес-задачи кампании. Проведение тестирований на основе технологий искусственного интеллекта (-Сервисов). Подготовка протоколов и результатов исследований. Разработка и внедрение актуальных технологий AI для оптимизации бизнес-процессов Компании. Подбор и координация работы подрядчиков-разработчиков систем -Сервисов. Требования: Профильное высшее образование и навыки работы с разными языками программирования. Знание техник и алгоритмов AI (Data Scientist, Big Data, Machine learning, Нейронные сети, ChatGPT). Практический опыт разработки и внедрения программных продуктов. Опыт управления внутренними и внешними командами разработчиков.",,ПК ЛидерГрупп,
6780,79057856,Data Analyst (mobile games),з/п не указана,1–3 года,"Полная занятость,полный день","Мы расширяем команду и ищем талантливого Аналитика данных. Новый аналитик будет работать с продуктовыми и маркетинговыми метриками мобильных игр, развивать систему мониторинга этих метрик, проводить АБ-тесты и улучшать персональные офферы. Если мат.стат, Python и уверенные знания об игровой индустрии в наличии, как и желание вникать в суть вещей, то делайте тестовое и откликайтесь на вакансию! Основные направления работы сследовать аномалии в продуктах и искать их причины. Вести АБ-тесты, от формирования гипотезы до проверки результатов. Участвовать в разработке внутренних продуктов в роли продакт-оунера. Придумывать и прорабатывать LiveOps-акции и новые способы монетизации, не забывая оценить их результат. Ключевые требования Законченное высшее образование От 1 опыта работы аналитиком данных Опыт работы с играми или мобильными приложениями Уверенные знания математической статистики и теории вероятностей Владение Python для ежедневной работы Знание SQL, опыт с Clickhouse будет плюсом Знание методологии А/В-тестирования Понимание продуктовых метрик, опыт применения к играм будет плюсом Желание развиваться в аналитике игр Готовность много учиться и применять свои навыки на практике Широкий кругозор в мобильных играх: умение выделить плюсы\минусы решений в различных жанрах и аргументировать их. Мы предлагаем Профессиональное развитие в игровой аналитике данных Работа с проектами на разных стадиях разработки Результаты, которыми можно гордиться (и рассказать на конференциях) Достойная белая заработная плата Удаленный, офисный или гибридный формат работы Бюджет на профессиональное обучение и посещение конференций Частичная компенсация фитнеса и ДМС со стоматологией Онлайн-корпоративы и оффлайн-встречи отдела за настолками, стильный мерч и киберспортивные турниры. Процесс отбора на вакансию. Отклик с выполненным тестовым заданием (появится после нажатия кнопки ""откликнуться""). Общение с HR. Техническое собеседование с руководителем отдела. Принятие решения со стороны компании и кандидата. В случае отказа на любом этапе HR свяжется с вами по указанным контактам и сообщит о решении.","Python,SQL,Pandas,A/B тесты",Crazy Panda,
6782,79050201,Портфельный риск-аналитик/Data analyst,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Приглашаем ПОРТФЕЛЬНОГО РСК-АНАЛТКА присоединиться к команде. Росбанк – частный универсальный банк, работающий на российском рынке с 1993 года. Росбанк обслуживает порядка 1,5 млн активных розничных клиентов, около 83 тысяч активных клиентов малого бизнеса и около 10 тысяч активных клиентов корпоративного бизнеса более чем в 60 регионах России. Росбанк входит в ТОП 5 самых надежных российских банков по версии журнала Forbes и включен Банком России в число 13 системно-значимых кредитных организаций России. Наш банк имеет наивысшие кредитные рейтинги российских и международных рейтинговых агентств. Мы команда по управлению риском в портфеле розничных кредитов в Росбанке. Занимаемся множеством интересных задач, от оценки новых источников данных, прогнозирования поведения клиентов и до постановки требования на доработку кредитного конвейера. ОБЯЗАННОСТ: Анализ качества кредитного портфеля в направлении автокредитования Анализ качества системы принятия решений и предложения по повышению ее эффективности Участие в разработке новых продуктов, включая анализ рисков и формирование предложений, снижающих кредитный риск Автоматизация существующих отчетов Подготовка мониторингов, презентаций Выполнение ad-hoc задач. ТРЕБОВАНЯ: Хорошие знания SQL Python Опыт работы с математическими анализами и прогнозами Аналитический склад ума, поиск закономерностей, обучаемость, ответственность. УСЛОВЯ: Полностью дистанционный формат работы – это возможность работать из любой точки Стабильный и прозрачный доход: зарплата и премии по результатам работы График 5/2 31 календарный день оплачиваемого отпуска Забота о здоровье сотрудников: программа ДМС, включая стоматологию и консультации психолога, страхование при выезде за рубеж, скидки на абонементы в фитнес-клубы, страхование жизни Дополнительная оплата за больничный лист: доплата сверх пособия по болезни до оклада (до 5 рабочих дней в год) Кадровый электронный документооборот, который позволяет подписывать кадровые документы (дополнительные соглашения к трудовому договору, приказы и т.п.) в электронном виде Личностное развитие и рост: корпоративная электронная библиотека Альпина с книгами, курсами, тестами по бизнесу и саморазвитию, возможность прохождения бесплатного обучения и тренингов, участия в регулярных встречах корпоративных клубов и скидки на курсы он-лайн школ Скидки и привилегии по кредитам, ипотека на льготных условиях, льготные условия обслуживания и т.п. Программа корпоративных скидок и привилегий Primezone: развлечение, отдых, товары для взрослых и детей, услуги (авиакомпании, рестораны, магазины электроники и т.п.), обучение Программа волонтерства и благотворительности Сообщества по интересам сотрудников.","SQL,Python",«РОСБАНК»,
6784,78186921,Data-analyst (WEB),от 110 000 руб. на руки,1–3 года,"Полная занятость,удаленная работа","Обязанности: Аудит текущей системы аналитики и предложения по модернизации Построение сквозной аналитики Построение дешбордов, позволяющих влиять на бизнес на основе данных Внедрение системы АБ тестирования (на выбор) и проведение экспериментов Требования: Знание SQL Яндекс.Метрика Google Tag Manager нструменты проведения экспериментов (Optimizely, Convertize, Google Optimize, Метрика итд) Job Description 2 Опыт построения дешбордов (Tableau, Power BI, DataLens, Qlik) Технический склад ума Базовые знания статистики Условия: График работы — удаленно, 5/2 с 8:00 до 17:00 или с 9:00 до 18:00  Заработная плата — от 110 000 р (в зависимости от Вашего уровня) Отсутствие дресс-кода Весёлая дружелюбная атмосфера",,Бизнес Продвижение,
6785,78987552,Data-analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем талантливого специалиста, который будет отвечать за сбор, анализ и интерпретацию данных о неголосовом трафике. Ваша задача - помочь нашей компании понимать, как люди используют наш продукт, и как мы можем улучшить его для удовлетворения потребностей наших пользователей. Если Вы имеете опыт работы с Excel, SQL, Python или другими инструментами для анализа данных, то эта вакансия для Вас! Обязанности: - осуществлять обработку статистических данных по трафику - осуществлять мониторинг и контроль безубыточности абонентского трафика - обеспечивать взаимодействие внутри и за пределами компании по вопросам неголосового трафика( в том числе осуществлять сверку трафика) - обеспечивать выполнение плановых показателей при предоставлении неголосовых услуг. Требования: - высшее техническое, математическое или экономическое образование - не менее 1 года опыта в области аналитики - опытный пользователь ПК - опыт проведения сверки данных и анализа массивов данных приветствуется. Условия работы: - нетривиальные задачи и профессиональный рост - корпоративная мобильная связь - график работы 5/2, 9:00-18:00 ч. - заработная плата оговаривается по итогам собеседования.","MS Excel,Python,Базы данных,Аналитика,Математический склад ума,Английский — B1 — Средний",НУР Телеком,
6787,77502305,Аналитик данных / Data analyst,з/п не указана,1–3 года,"Полная занятость,удаленная работа","ПРГЛАШАЕМ В КОМАНДУ АНАЛТКА ДАННЫХ Самокат — это онлайн-магазин, который есть в более чем 60 городах России. Мы привозим продукты, товары для дома и косметику и дарим нашим клиентам то, чего всегда не хватает — время. Чтобы сделать заказ в Самокате, нужно собрать товары в корзину в приложении, оплатить их, и уже через 15-30 минут курьер принесёт всё самое нужное. Наши главные ценности — это команда, время и устойчивость. Мы ценим каждого, кто работает и сотрудничает с нами, быстро адаптируемся к изменениям и относимся друг к другу уважительно и на равных. Сейчас в нашем штате более 8 000 сотрудников, а заказы по всей стране доставляют более 30 000 курьеров-партнёров. Обязанности: Выполнение Ad-Hock запросов Статистический анализ и подготовка аналитической отчётности и предложений Унификация и формализация метрик между разными подразделениями, согласование с заинтересованными пользователями Взаимодействие с подразделениями компаний по вопросам разработки/доработки необходимой отчетности Прямое обращение к источникам данных всех подразделений (OLAP, BI системы, SQL, 1С и другой необходимый технический инструментарий) мплементация данных в текущую отчетность и инструмент работы с данными. Требования: Знание SQL, Excel - обязательно Опыт работы от 1 года в направлении логистики или онлайн-ритейла обязателен Опыт написания аналитических отчетов, умение выявлять причинно-следственные связи между показателями, грамотно и полно формулировать выводы Умение работать с большими объемами информации и модернизировать процессы. Условия: Пятидневная рабочая неделя, восьмичасовой рабочий день Удалённый формат работы, предоставляем необходимое техническое оснащение Оформление по ТК РФ с первого дня и все социальные гарантии Белая заработная плата и выгодные зарплатные проекты в нескольких банках ДМС со стоматологией после трёх месяцев работы. Ещё в полис входят онлайн-консультации врачей, страховка для путешественников и другие услуги Льготная ипотека (или рефинансирование существующей) для тех, кто с нами полгода и дольше Возможность проходить обучение за счёт компании Условия для профессионального развития и карьерного роста Комфортные офисы в городах присутствия — с тихой зоной для работы и переговорными для совещаний и мозговых штурмов Бонусы для сотрудников: корпоративные скидки у партнёров, внутрисамокатовские конкурсы и квизы с призами, подарки для детей и многое другое.  *В сопроводительном письме укажите Ваши зарплатные ожидания.","SQL,Tableau,BI,Работа с большим объемом информации,MS Excel",Самокат (ООО Умный ритейл),
6790,79085508,Аналитик/Middle data analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Группа Компаний Hobby World и Мосигра — крупнейшее российское издательство, дистрибьюторы и производители настольных игр ищем в свою дружную команду Аналитика. Обязанности: Выстраивание процесса по получению и обработке данных Знание инструментария по обработке и визуализации данных Подготовка отчетов и презентация выявленных тенденций и решений. Требования: Базовые знания Python Опыт работы с BI-аналитикой от 3-х лет Опыт в стандартизации данных меть отличную математическую базу Высшее образование (техническое, экономическое, математическое) Понимать базовую теорию вероятности и математическую статистику Обладать продуктовым мышлением. Уметь оцифровывать пользовательский опыт в метриках, а также видеть за метриками пользователей, пытающихся решить определенную задачу. Условия: Уровень заработной платы по результатам собеседования Официальное оформление по ТК с первого дня работы График 5/2, обязательно присутствие в офисе, возможно обсуждение гибридного графика.","Python,Аналитик,Power BI,BI - аналитика",Мир Хобби,"Москва, Бауманская, Бауманская улица, 11с8"
6792,79002008,Аналитик/Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Взаимодействие с пользователями и контрагентами Агентства, разработчиками систем в части сбора бизнес требований. Анализ и оптимизация процессов взаимодействия Оказание консультационных услуг в области бухгалтерского, управленческого учета и отчетности Разработка конечных решений, формирование технических спецификаций на модернизацию существующей, разработку дополнительной функциональности Разработка технических заданий и постановка задач разработчикам Разработка и ведение пользовательской и проектной документации Взаимодействие с пользователями и контрагентами Агентства, разработчиками систем в части сбора бизнес требований. Разработка конечных решений, формирование технических спецификаций на модернизацию существующей, разработку дополнительной функциональности Требования: Понимание терминологии, понятийного аппарата и бизнес-процессов, связанных c бухгалтерским учетом, кредитным конвейером, управлением кредитными рисками и кредитным портфелем, а также процессов обслуживания физических лиц, связанных формированием продуктов и услуг для физических лиц (кредитование, пластиковые карты, депозиты) Знания нормативных документов ЦБ, регламентирующих деятельность Банков в части корпоративного и розничного бизнеса Знание типов межсистемных коммуникаций, понимание принципов построения баз данных Знание теории языков программирования/навыки программирования Профильное техническое образование в сфере Т (или подтвержденный опыт работы в Т) Опыт составления технической документации Знанием ER нотаций Уверенные знания SQL Условия: оформление в соответствии с ТК РФ, наличие ДМС, возможность участия в корпоративных образовательных программах по различным направлениям деятельности график работы: 5/2 с 9.00 до 18.00 офис в центре Москвы (м.Белорусская) заработная плата по результатам собеседования",,Государственная корпорация Агентство по страхованию вкладов,"Москва, Белорусская, 5-я улица Ямского Поля, 5с1"
6794,78107782,Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","MAIN RESPONSIBILITIES: Working in Data Science team Leads the roll out of new or enhanced statistical sample based services. Ensures following best practices in sample based measurements. Consults with internal and external clients and helps provide expert consultation to solve complex data quality related issues. Ability to turn numbers into stories our clients can understand and respond to. Compiling and delivering documentation material such as power point slides for methodology questions and/or frequently asked questions. Works cross team to provide a professional, clear response to all clients. REQUIREMENTS: Master (or equivalent) in Statistics, Math, Economics, Computer Science or a related field Excellent knowledge of statistics and mathematics English - from Intermediate level Exceptional aptitude for data analysis and creative problem-solving R, Python, SQL or similar skills as a plus Proficiency in Excel, PowerPoint and Word A high degree of accuracy and attention to detail A strong communicator who is able to explain technical issues in a non-technical way Broad industry knowledge and methodologies is a benefit Excited by challenges, pro-actively interacting with others WE OFFER: Competitive salary Life and health insurance Corporate laptop and sim-card Work in an international, multicultural environment Access to learning platforms, mentorship programms and educational support to keep developing your skills Peer-to-peer recognition program to enable feedback sharing and reward your achievements Employees are provided access to PrimeZone Corporate Benefits Program (fitness, travel, restaurants, entertainment, etc.) Social and corporate events Office is near Tretyakovskaya metro station (Hybrid working module). ABOUT NIELSENIQ We are the most trusted source for complete consumer intelligence as we have for nearly 100 years. Our ability to provide global retailers, manufacturers and partners with the most comprehensive data, analysis and insights will remain unmatched. We deliver the complete truth. That’s why we are unrelenting in our pursuit of the most comprehensive data sets, measuring all transactions equally to deliver the knowledge people need. Our best-in-class data scientists and analysts simplify the complexity of this information, illuminating powerful insights through clear, compelling stories. We capture the world as it truly is to enable leaders to look forward and empower businesses to make decisions with confidence. Check our current job openings now to begin your NielsenIQ journey.",,NielsenIQ,
6796,70985788,Аналитик данных/Data analyst,з/п не указана,1–3 года,"Полная занятость,полный день","АО ""КОМТА"" - российская IT- компания, вот уже более 30 лет объединяющая профессионалов, высококвалифицированных специалистов в области IT- технологий. Основным направлением деятельности компании является разработка программного обеспечения в области систем защищенного электронного документооборота. В настоящий момент мы ищем к себе в команду в наш офис в Вологде Аналитика данных/Data Analyst. Мы ожидаем, что Вы: меете опыт работы на аналогичной должности от 1 года меете оконченное среднее-профессиональное или высшее образование (техническое/IT) Участвовали в проектах в области внедрения и развития информационных систем меете опыт описания бизнес-процессов Обладаете аналитическим мышлением и умеете систематизировать информацию Умеете выстраивать диалог с заказчиком, не являющимся техническим специалистом Умеете собирать и анализировать информацию, грамотно интерпретировать её и создавать отчетную документацию. Будет плюсом: Умение отличать проект от продукта Знание основ MVP Знание основ баз данных и управления данными (формирование sql-запросов) Знание средств криптографической защиты информации (КриптоПро, Сигнатура и др.) Знание базовых навыков программирования будет преимуществом Знание систем контроля версий (SVN, GitLab и др.) будет преимуществом Знание Google Analytics, Яндекс. Метрики и других хранилищ данных будет преимуществом. Чем предстоит заниматься: Анализировать большие объемы информации, работать с нормативными документами, форматами, в частности анализ информации, относящейся к изменению форматов предоставления данных Заниматься формализацией, визуализацией и документированием требований (постановка задач, написание технических заданий), контролем соблюдения требований Взаимодействовать с проектной командой, а также смежными подразделениями (программистами, тестировщиками, технической поддержкой) Разрабатывать и актуализировать регламентирующую документацию Выявлять и анализировать изменения бизнес-процессов Заниматься подготовкой аналитики и отчетов на регулярной основе. Мы предлагаем: Стать частью команды увлеченных, целеустремленных людей Трудоустройство в соответствии с ТК РФ, оформление с первого рабочего дня Добровольное медицинское страхование Квартальные премии после успешного окончания испытательного срока Денежные выплаты к семейным событиям Рабочий график – полный рабочий день, пятидневка с 8 до 17 часов, выходные- суббота и воскресенье Офис в пешей доступности от стадиона Динамо Возможность работать как в офисе, так и дистанционно(гибридный вариант) Возможность профессионального развития и карьерного роста Если вас заинтересовала вакансия, и вы подходите по указанным требованиям, присылайте свой отклик. Мы обязательно его рассмотрим!","SQL,Разработка технических заданий,Базы данных,SVN,MVP,менеджер проекта,Постановка задач разработчикам,Аналитическое мышление,Отчетность,Критическое мышление,XML,MS SQL,Atlassian Jira,нормативно-техническая документация,Atlassian Confluence","Комита, АО (Санкт-Петербург)","Вологда, улица Мальцева, 52"
6797,77846831,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","12 лет компания Apptimizm создает удобные и полезные веб и мобильные сервисы. За нашими плечами огромный опыт и множество успешных реализаций бизнес идей. Каждый новый проект для нас — не только работа, но и любимое занятие. Мы сотрудничаем с такими компаниями как Канал RuTV, радио DFM, радио Монте-Карло, Icult.ru, BoomMarket, МТТ, Renault, Lada, Русское радио и многие другие. Мы с оптимизмом превращаем идеи клиентов в полноценные инструменты для ведения бизнеса. Предстоящие задачи: Сбор и анализ требований для создания дата продуктов (включая ad-hoc запросы) Подготовка ТЗ для разработки витрин данных, Source-to-Target mapping, взаимодействие с Data-инженерами Создание концептуальной, логической и физической моделей данных Документация требований и решений (Confluence, BRD and FS, business process diagrams, data diagrams) Взаимодействие с бизнесом и IT командами. Мы ожидаем от тебя: Опыт работы 2+ лет с BI системами, DWH, кубами Продвинутый уровень SQL (window functions, CTEs, subqueries, опыт MS SQL и PostgreSQL) Опыт работы с документацией Опыт работы с концептуальной, логической и физической моделями данных. Понимание принципов построения DWH и подходов data Понимание процессов внутри FMCG компаний: HR, finance, sales, marketing, supply Аналитический склад ума, внимание к деталям Английский (Intermediate, written and spoken). Будет плюсом: Опыт работы с Python Знание ETL инструментов Опыт работы с Dremio/Presto Опыт работы в Yandex Cloud Platform.","Python,SQL,PostgreSQL,Английский язык,Анализ данных,DWH,ETL,BI,MS SQL",Апптимизм,
6798,78937901,Junior Data scientist (Аналитик),от 60 000 руб. на руки,не требуется,"Полная занятость,полный день","Zaymigo – это современная FinTech компания на рынке онлайн кредитования. Работаем с 2013 года. У нас более 2 000 000 клиентов. В команде больше 130 человек. Мы создаем сервис, дающий людям простой доступ к деньгам в любой стране. Наша компания имеет гибкий подход к решению задач, реализуем лучшие предложения наших сотрудников, поощряем нестандартный подход к делу. Сейчас находимся в поиске аналитика данных (data scientist). Над какими задачами будем работать: Построение рисковых скоринговых моделей Мониторинг работы моделей и их валидация Анализ рисковой отчетности работы компании и подготовка рекомендаций Участие в проектах внутри команды риск-аналитиков. Мы ждем от Вас: Серьезную математическую подготовку Опыт применения методов статистического анализа и моделирования Опыт работы с алгоритмами машинного обучения Уверенное знание языка Python для анализа больших данных Будут плюсом: навыки владения любым программным обеспечением для статистического анализа данных: SPSS, Statistica, Stata, R и т.п. Опыт работы от полугода в fintech компаниях, банках. Что мы предлагаем: Возможность делать крутые проекты, участвовать во всех этапах деятельности аналитического отдела 8-часовой график работы Проработанный план профессионального развития Посещение отраслевых конференций за счет компании Официальное трудоустройство по ТК РФ Комплектация рабочего места по Вашим запросам Рост ЗП согласно уровню выполняемых задач Молодой, сплоченный коллектив, дружественный микроклимат в отделе Офисный формат работы","Python,Статистический анализ,Прогнозирование,Математическая статистика",Займиго МФК,"Нижний Новгород, Горьковская, Ковровская улица, 21А"
6799,76936797,Middle Data Analyst (Retail Risk),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы команда управления риском дочерней компании Хоум Кредита, активно развивающейся в онлайн кредитовании на площадках/маркетплейсах партнеров Банка и пользующейся преимуществами упрощенной идентификации клиента. Мы ищем человека, который будет развивать процедуру принятия решения, проводить аналитику, генерировать идеи по развитию и доводить их до команды разработки. Твоими главными партнерами в этом будут команды моделирования и разработки, вместе с которыми вы будете двигать наш бизнес вперед. ЧЕМ ВЫ БУДЕТЕ ЗАНМАТЬСЯ: скать инсайты анализируя данные воронки продаж, действующего кредитного портфеля и др. спользовать продвинутые инструменты анализа для формирования и оценки эффекта инициатив Генерировать инициативы по подключению новых источников данных и новым вариантам использования уже имеющихся Разрабатывать новые ветки риск-стратегии для новых кредитных продуктов Участвовать в развитии процессов формирования витрин данных Участвовать в функциональном тестировании внедрения новых проектов ЧТО ВАМ ДЛЯ ЭТОГО НЕОБХОДМО: Высшее математическое, техническое или экономическое образование Продвинутые знания любой SQL БД Навыки анализа данных, знания основных алгоритмов (catbost, PCA, k-means и т.д.) Знание Python на прикладном уровне БУДЕТ ПЛЮСОМ: Знание основ администрирования Баз Данных Опыт работы в проектах в роли заказчика/лида МЫ ПРЕДЛАГАЕМ: Фиксированный оклад + система премирования Социальный пакет Офис: м. Белорусская Гибридный формат работы Команда, открытая самым смелым идеям Внутренние программы обучения и развития Высокий уровень ответственности и возможность самостоятельно принимать решения Атмосфера, где легко оставаться собой: минимум формализма, открытые коммуникации и отсутствие дресс-кода.","Анализ данных,Data Analysis,SQL,Python,Анализ рисков,Big Data,Работа с базами данных,Оценка рисков,BI,catbost,PCA,k-means",Банк Хоум Кредит,"Москва, Белорусская, Правды, 8 к.1"
6800,77196140,Data Analyst / Аналитик данных / BI-аналитик,з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Подготовка и оптимизация витрин данных. Разработка и совершенствование аналитического продукта . Обработка массива данных и подготовка информации для расчетов, автоматизация расчетов, работа с базами данных. нтерпретация данных, построение дашбордов. Работа с базами данных, формирование логики наполнения и хранения данных. Разработка и оптимизация SQL запросов. Требования: Умение формировать логичные аналитические материалы и экспертные заключения Опыт работы с большими массивами данных Знания PostgreSQL, Python, vba excel Опыт работы Apache Superset, Hadoop, Jupiter, Опыт создания дашбордов, умение наглядно представлять важную информацию и делать выводы, основываясь на цифрах. Опыт работы с BI системами, в том числе визуализация данных Условия: Официальное трудоустройство согласно ТК РФ, своевременная выплата заработной платы, без ""конвертов"" Для эффективной работы создана вся необходимая инфраструктура Обучение Корпоративная мобильная связь Компенсация стоимости фитнеса Медицинское страхование Чай/кофе всегда под рукой, за счет компании График работы: пн-пт: 09.00-18.00 Бонусы по результатам работы.","Работа с большим объемом информации,Python,Визуализация данных",ЭНКО ГРУПП,"Тюмень, Перекопская улица, 19"
6803,78961029,Data Scientist,от 160 000 до 180 000 руб. на руки,1–3 года,"Полная занятость,полный день","О компании: Компания Сайберфизикс занимается разработкой системы предиктивной аналитики оборудования и оптимизации технологических процессов на основе комбинации машинного обучения и численного моделирования. Основным продуктом компании является платформа создания моделей, обеспечивающая для пользователя полный цикл no-code разработки - от загрузки данных до production. Кого мы ищем? Талантливого DS вычислительного ядра основного продукта. Вы будет заниматься исследованиями и разработками передовых моделей и алгоритмов в области промышленной диагностики и оптимизации. Что предстоит делать: спользовать методы machine learning для улучшения существующих подходов системы предиктивной аналитики оборудования и оптимизации технологических процессов Анализировать эффективность существующих вычислительных алгоритмов, оценивать внедрения новых Разрабатывать программно-вычислительные модули в составе основного продукта Требования: Хорошая математическая подготовка: теория вероятностей, статистика, методы и алгоритмы machine learning Опыт разработки библиотек на Python Продвинутый уровень владения tensorflow, pandas, numpy, scikit-learn Уметь генерировать гипотезы и проверять их Будет преимуществом: Опыт разработки вычислительных модулей и их взаимодействия между собой Продвинутый уровень знаний ООП Знание принципов многопоточности и многопроцессорности Python Условия: Возможность работать по СЗ и ГПХ Гибкий график, отсутствие обязательного расписания Возможность работать удаленно (либо офис в БЦ Савеловский Сити м. Дмитровская) Предоставление ДМС после испытательного срока Бесплатный чай/кофе/шоколадки/печенье в офисе","Machine Learning,Python,Tensorflow,Pandas,ООП,Numpy",CyberPhysics,"Москва, Дмитровская, Дмитровская, Савёловская, Новодмитровская улица, 2к2"
6804,78142687,Лид Дата Аналитики / Data Analyst Lead,з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Проводить глубокие исследований данных по системам-источникам Анализировать потребности, составлять ТЗ на разработку \ доработку интеграционных потоков данных или витрин для анализа данных Управлять распределённой командой (4+ аналитика) Развивать модель данных компании совместно с архитектором, бизнес-аналитиками Выявлять проблем качества данных, оценивать их влияние на отчетность и аналитику Участвовать в процессах развития и изменения IT систем (систем-источников) Общаться с бизнес-аналитиками, архитектором, командой разработки для реализации системных требований к загрузке и обработке данных Участвовать в развитии дата-платформы: - сбор и анализ требований к платформе - проектирование и сопровождение интеграционных потоков - участие в определении архитектуры и физического дизайна платформы - написание ТЗ на внесение изменений в платформу. Требования: Опыт лидирования проектов развития аналитики данных Опыт анализа и спецификации системных требований, составления ТЗ Опыт управления командой data аналитиков. Опыт работы в направлении data-анализа от 3х лет Опыт работы с хранилищами данных, BI инструментами, инструментами продвинутой аналитики Понимание методологий моделирования (DWH, Data Vault, Star Schema) Уверенное знание SQL на продвинутом уровне, знание Python Опыт взаимодействия с бизнес-экспертами, архитекторами, разработчиками, специалистами технической поддержки при решении задач Опыт работы с инструментами Jira, Confluence, инструментами анализа данных.","Python,SQL,Системный анализ,Atlassian Jira,Управление проектами,Data Analysis",Офисная вакансия Yum! Brands,"Москва, Старопетровский проезд, 11к1"
6805,79092853,Data analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Кто мы? Группа компаний Урбантех – крупнейший в России поставщик технологичных решений в сфере транспорта и безопасности дорожного движения. Мы осуществляем: Фотовидеофиксацию на дорогах Московской области и Москвы Разработку интеллектуальных решений и технологий «умного города» в регионах РФ Повышение эффективности общественного транспорта Сейчас наша команда находится в поиске аналитика данных, который готов вместе с нами решать интересные и сложные задачи, а взамен мы гарантируем быстрый рост знаний и навыков. Что нужно будет делать: анализ имеющихся больших данных с целью прогнозирования показателей работы комплексов выявление статистических закономерностей, разработка математических моделей подготовка данных для прогнозирования показателей, в т.ч. аварийности с целью автоматизации принятия решения о необходимых мероприятиях для снижения аварийности и т.п. подготовка аналитических отчетов в различных разрезах, подготовка выводов участие в проектах и выполнение запросов. Что мы ждем от тебя: опыт работы в роли аналитика не менее 3-х лет уверенное знание SQL, построение запросов (MySQL, Postgre, Clickhouse) знание теории вероятностей, математической статистики и базовых методов оптимизации знание стандартных алгоритмов и структур данных поиска и хранения информации продвинутый пользователь Excel, power pivot, Jira, confluence. Что мы предлагаем: работу в аккредитованной Т компании классную команду профессионалов достойную зарплату отдельное рабочее пространство заботу о людях: возможность обучения на внешних курсах за счет компании, расширенная программа ДМС со стоматологией, программа корпоративных скидок «BestBenefits», совместные тренировки по двум направлениям: футбол и волейбол, внутрикорпоративные мероприятия офис в шаговой доступности от м. Аэропорт (гибридный график работы).","Статистический анализ,Аналитическое мышление,SQL,Математическая статистика,Анализ данных,Английский — A2 — Элементарный",МВС ГРУП,
6812,77480809,Data Scientist/ML,з/п не указана,1–3 года,"Полная занятость,полный день","Работа в Agile команде по методологии SAFE занимающейся системой принятия решения по конкретному виду страхования. Команда занимается разработкой и внедрением ML моделей, сложной аналитикой и внедрением на её основе бизнес правил, а так же тарификацией. КЛЮЧЕВЫЕ ЗАДАЧ: Полный цикл построение ML моделей: Сбор и подготовка данных Первичный анализ Обсуждение потенциальных фичей с экспертами предметной области Анализ фичей и фича-инжиниринг Построение различных типов моделей их сравнение Подбор гиппер параметров Презентация результатов заказчику Подготовка к внедрению. Типовые задачи: Построение моделей прогнозирования убытка (Частота/Тяжесть) Построение моделей противодействия мошенничеству Модели динамического ценообразования. Основные используемые типы моделей: GLM Градиентный бустинг (XGBoost, CatBoost) Любые другие типы моделей которые покажут свою эффективность на ретро данных. ДЛЯ НАС ВАЖНО: Стек: MS SQL, Oracle Python (jupyter notebook: Pandas, Statsmodels, Scikit Learn, SciPy) GitLab Apache Airflow Grafana ML Flow. У НАС ЕСТЬ: Работа в крупной и стабильной компании Официальное трудоустройство по ТК РФ Скидки на страховые продукты Гибридный график работы 2/3 (офис + удаленный формат) Офис расположен: г. Москва, ул. Островная д.4 (рядом с офисом собственная, большая, бесплатная парковка) Корпоративный транспорт от ст. м. «Октябрьское поле» и «Кунцевская».","Data Science,Machine Learning,ML","ВСК, САО","Москва, Островная улица, 4"
6813,78371688,Junior Data Engineer/ BI Аналитик (Дашборды),з/п не указана,3–6 лет,"Полная занятость,полный день","НПКЦ диагностики и телемедицины («Радиология Москвы»), – государственная компания с более чем 20-летним опытом работы в здравоохранении. Наш Центр - ведущая экспертная организация по развитию и повышению эффективности службы лучевой и инструментальной диагностики в России. Обязанности: Обязанности: Построение и оптимизация ETL скриптов, получающих данные от источников (базы данных, файлы, облако). Получение выгрузок при помощи запросов при помощи SQL Формирование выгрузок в Excel из ЕРС, ЕМАС и других информационных систем Обработка выгрузок на Python (или с использованием других программных приложений) Формирование и ведение баз данных Статистическая обработка и анализ данных Подготовка аналитических отчетов и справок Подготовка презентаций Оптимизация отчетных форм Анализ показателей работы оборудования для лучевой и инструментальной диагностики Выявление требования и подготовка Dashboard Описание и анализ бизнес-процессов Визуализация результатов статистической обработки данных в Yandex DataLens (построение графиков, диаграмм) Разработка методик прогнозирования Поддержка НР в части сбора, статистической обработки и анализа данных Постановка вычислительных экспериментов Требования: Высшее образование: техническое, физико-математическое Опыт работы с современным программным обеспечением для статистического анализа данных Знание современных методов статистического анализа Работа с данными: знание SQL Опыт разработки на Python, умение читать и анализировать чужой код (code review) Знание MS Excel - продвинутый пользователь Опыт анализа и структурирования информации Опыт работы с большим объемом информации (Big data), в условиях многозадачности Аналитическое мышление Английский язык не ниже В1. Мы ценим: Стремление достигать результата Желание постоянно развиваться Готовность к динамичным изменениям скренность и открытость Готовность к высокой нагрузке стартапов Умение работать в команде Навыки самоорганизации. Мы предлагаем: Оформление по ТК РФ График 5/2 с 9.00 до 17.30, выходные и праздничные соответственно государственным Выплаты 2 раза в месяц Участие в амбициозных проектах в масштабах отрасли и страны Сопричастность к решению «сверхзадач» в системе здравоохранения Наставничество и поддержка в развитии на международном уровне Возможность развиваться опережающими темпами, участвуя в программах обучения Высокий «белый» доход Стать частью яркой профессиональной команды.","Английский язык,Научные исследования,Базы данных,Python,Анализ данных,Аналитические исследования,Аналитическое мышление,Английский — B1 — Средний",ГБУЗ «Научно-практический клинический центр диагностики и телемедицинских технологий ДЗМ»,"Москва, улица Петровка, 24"
6816,71331696,Data analyst/ Data Engineer (удаленно),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Приглашаем DATA ANALYST/ DATA ENGINEER присоединиться к нашей команде.  Мы работаем в направлении Розничного бизнеса (кредитные карты), занимаемся созданием регулярной и разовой отчетности для продуктового направления.  В Росбанке возможен полностью дистанционный формат работы: откуда работать - решать только тебе! Приходи к нам, чтобы работать над амбициозными и интересными проектами и наслаждаться балансом между работой и личной жизнью! Росбанк – частный универсальный банк, работающий на российском рынке с 1993 года. Росбанк обслуживает порядка 1,5 млн активных розничных клиентов, около 83 тысяч активных клиентов малого бизнеса и около 10 тысяч активных клиентов корпоративного бизнеса более чем в 60 регионах России. Росбанк входит в ТОП 5 самых надежных российских банков по версии журнала Forbes и включен Банком России в число 13 системно-значимых кредитных организаций России. Наш банк имеет наивысшие кредитные рейтинги российских и международных рейтинговых агентств. ОБЯЗАННОСТ: Сбор и подготовка данных Разработка регулярной и разовой отчетности для продуктового направления розничного бизнеса (кредитные карты) Разработка процедур на SQL, создание конечных витрин, разработка кубов, визуализация (Power BI) и Reporting Service. ТРЕБОВАНЯ: Опыт разработки GreenPlum, PostgreSQL (от 2 лет), возможно T-SQL или PL/SQL Уверенное владение SQL Знание Python будет преимуществом Знание PowerBI, OLAP (tabular), SSRS, MDS, MDX, DAX будет преимуществом. УСЛОВЯ: Полностью дистанционный формат работы – это возможность работать из любой точки РФ Стабильный и прозрачный доход: зарплата и премии по результатам работы График 5/2 31 календарный день оплачиваемого отпуска Забота о здоровье сотрудников: программа ДМС, включая стоматологию и страхование при выезде за рубеж, корпоративные спортивные команды и скидки на абонементы в фитнес-клубы Дополнительная оплата за больничный лист: доплата сверх пособия по болезни до оклада (до 5 рабочих дней в год) Личностное развитие и рост: корпоративная электронная библиотека Альпина, возможность прохождения бесплатного обучения и тренингов, участия в регулярных встречах корпоративных клубов и скидки на курсы он-лайн школ Скидки и привилегии по кредитам, ипотека на льготных условиях, льготные условия обслуживания и т.п. Программа корпоративных скидок и привилегий Primezone: развлечение, отдых, товары и услуги, обучение Программа волонтерства и благотворительности Сообщества по интересам сотрудников.","SQL,Базы данных,Power BI,PostgreSQL,Oracle Pl/SQL,Transact-SQL,Python,Data Analysis",«РОСБАНК»,
6819,79035705,Data Analyst в команду Боты / Knowledge Assistant,з/п не указана,1–3 года,"Полная занятость,полный день","В команду, разрабатывающую современную базу знаний для операторов и ботов требуется аналитик данных Обязанности Анализ воронок клиентских путей в продуктах Генерация гипотез, поиск точек роста продукта на основе истории взаимодействия пользователей Проведение и анализ продуктовых пилотов Прототипирование дашбордов и написание аналитических отчетов Взаимодействие с командами Big Data в Банке в части обмена опытом Требования Владение SQL, PySpark, Python для обработки и анализа данных Знания статистики для работы с гипотезами и доверительными интервалами Опыт проведения а/б тестов Умение работать с большими массивами данных Навыки презентации и визуализации Будет плюсом: Опыт работы с NLP библиотеками (nltk/gensim), т.к. иногда придется работать с текстовыми данными Опыт работы с QlikView/QlikSense Опыт работы с Колл-Центрами и автоматизацией обслуживания обращений Условия комфортный офис на Кутузовском проспекте с тренажерным залом, коворкинг-пространствами и кафе полный рабочий день, но гибкий график работы (можно выбрать режим начала работы в промежутке 7:00 - 10:30) ДМС, программы лояльности для сотрудников (льготное кредитование, предложения экосистемы Сбера) комьюнити data-people, множество программ профессионального обучения (курсы, тренинги, конференции, семинары).",,Сбер для экспертов,
6821,78888265,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Чем предстоит заниматься: Анализировать экономический потенциал новых сервисов и продуктов Продумывать структуру метрик для оценки различных инициатив и проектов Разрабатывать сложные или быстрые аналитические модели скать причинно-следственные связи в данных Ставить гипотезы, проводить АБ тесты Предлагать свои любые самые смелые инициативы, направленные на развитие всего бизнеса Требования: Опыт в аналитике от 1 года SQL и Python - уверенное владение A/B тесты: знание статистики, лежащей в основе(методы увеличения чувствительности, расчет необходимых и достаточных условий) Опыт визуализации результатов в любом инструменте Будет плюсом: - Опыт построения ML моделей - Tableau Что мы можем предложить: Сильную экспертизу в аналитике. По-настоящему интересные задачи, которые каждый раз будут бросать вам вызов и заставлять придумывать новые методы и подходы. Классную команду с приятной атмосферой и обсуждением задач. Возможность удаленной работы. Возможность принимать решения, влияющие на всю компанию. Условия: Медицинское страхование Внутреннее и внешнее обучение Служебная мобильная связь Участие в программе годовых бонусов Корпоративное предложение фитнес услуг Ежегодный отпуск 28 календарных дней Бесплатная подписка MyBook Новый современный офис в центре города Гибридный формат работы.",,Мобайл Телеком-Сервис (Объединенная Компания Tele2/ALTEL),
6822,78886611,Senior Data Analyst / Старший маркетинговый аналитик (GameDev),от 200 000 до 300 000 руб. до вычета налогов,3–6 лет,"Полная занятость,полный день","AppQuantum — паблишер мобильных игр. Мы — это успешная команда из 150 человек, которая занимается performance-маркетингом, паблишингом и разработкой мобильных игр. Мы строим технологичную платформу для разработчиков, в которой разработчик с первого дня работы с нами получает всю необходимую аналитику, репортинг и сервисы. Наша глобальная цель — стать топ-1 геймдев паблишером в Европе. Это сложная и амбициозная задача, и вы можете стать частью этой истории! Мы ищем сильного маркетингового аналитика, который станет проводником маркетинга в мир данных, эффективности и точек роста. Вы будете работать рука-об-руку с CMO и лидами направлений. Мы ожидаем, что вы будете выступать двигателем изменений, поэтому круто, если у вас есть опыт построения маркетинговой аналитики, ее автоматизации. Задачи: Поддерживать команду user acquisition в вопросах масштабирования / изменения качества закупки трафика / заливки на новые проекты Приоритизировать точки роста: изучать влияние внешних (рынок итп) и внутренних (продукт) факторов, влияющих на закупку, исследовать новые рынки и каналы Совершенствовать существующие подходы к анализу эффективности закупки (продумывать новые метрики, кластеризовать рынки/аудитории) Дорабатывать модель LTV игрока Выстраивать аналитику новых направлений (креативов, ретаргетинга, influencer marketing) Менторить младших аналитиков Участвовать в развитии аналитической инфраструктуры компании. Требования: Опыт работы аналитиком от 3 лет Желание работать в геймдеве и строить аналитику топ-уровня Уметь приоритизировать задачи и держать фокус Разбираться в Unit-экономике проектов и основных метриках Уметь писать SQL запросы Крайне желательны знания Python и опыт реализации алгоритмов ML Понимание мат.стат / тер.вер чтобы уметь в выборки, A/B тестирование и стат.значимость. Плюсом будет: Опыт настройки маркетинговых интеграций Наличие успешных завершенных проектов в маркетинге/аналитике/бизнесе в целом. Для тебя: Работа в просторном офисе Ереван, Кипр или удалённо Конкурентная заработная плата по результатам собеседования, выплачивается 2 раза в месяц Необходимое и комфортное оборудование для работы Возможность профессионального и карьерного роста Команда из 150 человек, занимающаяся разработкой, паблишингом и маркетингом, готовая сделать продукт успешным после его готовности Менторы и инвесторы из игровой индустрии и интернет-маркетинга, создавшие большое количество успешных IT компаний.","Python,SQL,Git,Linux,ROI,дико плюсить,Google Analytics,analyst,gamedev,attribution,adjust,appsflyer,ML,clickhouse,tableau",AppQuantum,
6825,79177117,Middle Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Наша команда занимается созданием аналитических платформ и продуктов для разных направлений корпоративно-инвестиционного бизнеса. Команда платформы консолидирует данные из различных внешних и внутренних источников, запускает пилотные проекты и обогащает данными в соответствии с требованиями бизнес-заказчиков. Обязанности · Обеспечение сбора и организация процесса загрузки данных в аналитические системы, · включая получение структурированных и не структурированных данных из различных источников, подготовку, очистку и предобработку данных из внешних источников, построение агрегатов · сследование источников данных · Настройка первичной обработки данных от источников (очистка, обогащение и т.д.) · Общение с заказчиком, пользователями и выявление требований · Подготовка прототипов решений · Написание технической и проектной документации · Работа с большими объемами данных · Участие в автоматизации процессов. · Создание дашбордов для пользователей · Взаимодействие со смежными командами Требования · Высшее техническое/экономическое образование · Знание SQL, Python, навыки оптимизации запросов · Знание Excel · Опыт в банковской, страховой, консалтинговой или Т сфере не менее 2 лет · Опыт работы с Hadoop или Teradata или Oracle · Опыт разработки инструментов для автоматизации процессов обработки данных Автоматизации типовых задач с помощью скриптов · Умение аргументированно обосновывать свое мнение и решения · Аналитическое мышление Будет плюсом: · Работа с большими объемами данных · Умение работать с Confluence, Jira, Nexus, Bitbucket · Опыт работы с ETL-инструментами (Informatica BDM, ODI, Pentaho) и BI-средствами · Опыт работы с Hadoop (Hive, Impala, sqoop, oozie, HDFS, YARN) Опыт работы с Spark · Навыки программирования на Java/Python · Опыт работы с Unix shell · Знания предметной области «Банки и финансы» Условия · Офис «Sbergile Home» рядом с м. Кутузовская. https://vc.ru/sberbank/38179-agile-na-11-000-sotrudnikov · Бесплатный фитнес-зал, настольные игры на этажах · Бесплатная подземная парковка · нтересные, сложные, амбициозные задачи · Создание продуктов для многомиллионной аудитории пользователей · Профессиональный рост в молодой и сильной команде",,Сбер для экспертов,
6826,78815196,Data Analyst,до 300 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Продуктовая IT компания, которая занимается созданием SaaS решения для бизнеса (разработкой B2B платформ развлекательной, игровой и спортивной тематики), находится в поисках Data Analyst. В команде уже есть более 50 специалистов, и большинство из них уровня Senior c многолетним опытом работы на высоконагруженных проектах. Круто, если Вы не против выполнить тестовое задание или поделиться примерами кода. Стек проекта: микросервисы на Go и PHP (8+) на бэкенде, фронтенд на React + Vite SSR, MySQL, Kafka, ClickHouse, MongoDB, Redis, ElasticSearch, Riak KV. Документация ведётся в Confluence. В качестве таск-трекера используется решение от JetBrains - YouTrack.  Чем предстоит заниматься: Создание структур данных, выбор подходящих движков в ClickHouse и других СУБД в соответствии с бизнес требованиями Написание / оптимизация / профилирование SQL/NoSQL запросов ETL процесс получения raw data из KAFKA (KSQLDB) Совместная работа с бизнес аналитиком над новыми отчетами Совместная работа с разработчиками сервиса отчетов в рамках имплементации Настройка ClickHouse (шардинг, репликация) в т.ч. взаимодействия с Kafka (попадание сырых данных, решение возможных проблем с очередностью сообщений, валидностью данных) Решение возможных проблем с нарушением целостности данных Дальнейшая работа с данными в компании (BI, warehouse, ETL). Какие навыки необходимы: Опыт работы Data Analyst/Engineer от 2-х лет Высокий уровень экспертизы работы с ClickHouse обязателен Опыт построения сложных составных SQL запросов и оценка их производительности Экспертиза в выборе типа хранилища данных и понимание различий SQL/NOSQL/Column-oriented/OLAP/Time Series Желателен опыт работы с данными в KAFKA (KSQLDB) и коннекторы к ClickHouse. Будет плюсом: Знание и опыт Cassandra, Apache Spark и BI решений Tableau, Apache Superset Желателен опыт работы с graph-oriented базами данных (neo4j, graphDB, RedisGraph) Уровень английского языка достаточный для чтения технической документации. Что компания может предложить Вам: Достойный уровень полностью белой заработной платы Ежегодная индексация, новогодняя премия, и 100% оплата больничных и отпусков Поездки на Т-конференции, митапы, учебные курсы за счет компании, частичная компенсация английского со SkyEng Гибкое начала рабочего дня, возможность работать удаленно или в офисе: Москва, Прага, Кипр Подарки сотрудникам и их детям на Новый год.","ClickHouse,SQL,NoSQL,Kafka",Employcity,
6827,78273747,Data Engineer (Big Data),до 280 000 руб. до вычета налогов,1–3 года,"Полная занятость,гибкий график","Платформа ОФД - продуктовая IT-компания, крупнейший в России оператор фискальных данных. Мы создаем полезные и удобные сервисы для предпринимателей. Делаем рыночную аналитику на основе данных из магазинных чеков. Компания резидент Сколково, входит в Экосистему Сбера. Что у нас есть: Много данных: каждый 3-й чек, пробиваемый в России, находится на наших серверах. Мы принимаем до 50 млн чеков в день, имеем 2 млрд уникальных названий товаров в базе. Развитая инфраструктура: есть несколько кластеров Hadoop, у DS есть несколько мощных машин, GPU делают бр-бр Команда из 4 DE и сильная экспертиза 80% кода мы пишем на Scala Оформление по ТК РФ, белая зп ДМС с госпитализацией, скорой и стоматологией Офис близко от м. Спортивная/Лужники. Можно работать из дома Удобная кухня, релакс-зона с тренажером, массажным креслом, приставкой и караоке Пицца-пати раз в месяц и корпоративные праздники Наш стек: Hadoop, Spark, Hive, SCALA, Python, Java, PostgreSQL, ClickHouse, Zeppelin/IntelliJ, AirFlow, ElasticSearch, Apache Superset GitLab, k8s, Docker, Jira, Confluence Чем предстоит заниматься: Разрабатывать ETL-процессы с использованием библиотеки Apache Spark на Scala Анализировать, проектировать и создавать витрины данных в соответствии с требованиями конкретного проекта Развивать инфраструктуру для обработки больших данных и кодовой базы Scala Работать с DS для внедрения математических алгоритмов и ML-моделей в промышленные процессы Откликайся, если ты: Живешь в Москве или МО Не менее 2-х лет решаешь задачи в области сбора, хранения и анализа данных Пишешь код на Scala Отлично знаешь SQL Применяешь в работе инструменты BigData: Airflow, Hadoop, Spark, Hive, Zeppelin Будет плюсом опыт работы с Docker и k8s Выбор кандидата проходит по итогам выполненного тестового задания","Python,Java,SCALA,SQL,Big Data,Hadoop",Платформа ОФД,
6828,78656467,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Наша команда каждый день работает над повышением качества связи и отвечает за стабильный сервис для тебя. Профессионалы билайн уверенно создают надежную связь по всей территории нашей страны: в небольших поселках и крупных городах, на вершинах гор и под землей. Если ты готов решать сложные и масштабные задачи в команде экспертов — мы ждем твое резюме!  Обязанности: Построение процесса контроля качества данных и настройка системы мониторинга ключевых риск-индикаторов (КР) на доменной платформе Взаимодействие с владельцами источников и потребителями данных, формирование функциональных требований Проведение анализа данных: сбор и загрузка данных, преобразование данных в удобный для исследования вид, проверка их качества и полноты, аналитические выводы Разработка проектной документации Разработка новых метрик, ad-hoc аналитика Участие в текущих и будущих продуктах/проектах в виде эксперта по домену данных функционального блока Требования: Понимание принципов анализа и контроля качества данных, умение делать выводы и представлять их в наглядном виде Уверенный уровень SQL (сложные запросы, оконные функции и другие) Опыт работы хотя бы с одной СУБД (PostgreSQL, Oracle, Teradata или другие) Опыт работы с экосистемами Hadoop/Cloudera (Hive, Spark) Опыт визуализации данных в QlikSense/Tableau/Superset/Redash Опыт работы с проектной документацией Навыки профилирования источников данных Отличные коммуникативные навыки и навыки кросс-функционального взаимодействия Уверенный уровень работы с Python (знание основных библиотек для анализа данных и визуализации, написание сложных функций и тд) Желательно: опыт работы в телеком/digital отраслях Английский язык – intermediate Условия: ДМС + стоматология после испытательного. Корпоративная мобильная связь. Оплата обучения по квалификации. Билайн академия.","SQL,PostgreSQL,Hadoop,Spark,Python,QlikSense,Английский — B1 — Средний",билайн: Контактные центры,
6829,79255894,"Senior Data Analyst (""Рекомендации"")",з/п не указана,3–6 лет,"Полная занятость,полный день","Мы создаём рекомендательную систему, которая является одним из ключевых ML–сервисов в Okko. Простые задачи мы уже решили, остались интересные. Поэтому мы ищем специалиста с обширным опытом работы. Обязанности: исследование применимости различных алгоритмов в рекомендательной системе моделирование входных данных, участие в EDA и генерации фичей участие в оценке и интерпретации экспериментов в направлении ""Рекомендации"" аналитическая проработка алгоритма внутренней системы мотивации активных пользователей построение мониторинговых дашбордов. Что мы используем: Python (sklearn, seaborn, numpy, scipy, statsmodels) ClickHouse, PostgreSQL, Redis, etc. Airflow, FlaskAPI/FastAPI Bitbucket, Jira, Confluence. Требования: опыт работы аналитиком данных/продуктовым аналитиком от 3-х лет уверенное владение SQL знание основ машинного обучения знание математической статистики и основ A/B тестирования владение Python на уровне использования аналитических инструментов и базового синтаксиса опыт самостоятельного общения с бизнес-заказчиками бизнес-ориентированное мышление. Будет плюсом: опыт проведения onboarding новых членов команды успешный опыт работы в “большой тройке” консалтинговых компаний. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","SQL,Python,A/B тесты",Okko,"Москва, Баррикадная, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с13"
6831,79115520,Senior Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Команда Сеть Продаж Сбера ищет Руководителя направления по аналитике данных в команду по повышению эффективности филиальной сети отделений и банкоматов Сбербанка Задачи: Участие в проектах по анализу эффективности работы филиальной сети банка Создание алгоритмов и процедур трансформации данных с целью дальнейшего построения управленческой отчетности сследование показателей сети и данных по операциям клиентов, проверка гипотез, проведение А/В тестирования Создание аналитических витрин и дэшбордов, подготовка регулярных и разовых аналитических заключений, автоматизация этого процесса Проведение ad-hock анализа по запросам руководителей Работа в команде, контроль выполнения задач в зоне ответственности Наши ожидания: Опыт работы по направлению аналитики не менее 3х лет Опыт создания инструментов принятия решений Опыт работы с большими объёмами данных Уверенное знание SQL Мы готовы предложить: Deep diving в предметную область, много разработки по задачам имеющим прямой эффект на бизнес Возможность привносить новые идеи и нестандартные решения Сообщество D-people – поддержка, развитие и возможность учиться у профессионалов Достойную оплату труда Возможность расти в самой крупной DS-команде)) Возможности саморазвития: обучение за счет Компании: онлайн курсы в Виртуальной школе Сбера и неограниченный доступ к библиотеке, обучение в Корпоративном университете, тренинги, митапы и возможность получить новую квалификацию Скидки на услуги экосистемы Сбера и компаний-партнеров. потека выгоднее для каждого сотрудника и льготные условия кредитования Бесплатная подписка СберПрайм+ Скидки на продукты компаний-партнеров: Okko, Сбер Маркет, Delivery Club, Самокат, Сбер Еаптека и другие ДМС с первого дня и льготное страхование для близких Корпоративная пенсионная программа Курсы для будущих родителей, материальная поддержка и тематическое сообщество для молодых мам Детский отдых и подарки за счет Компании Реферальная программа для сотрудников: можно пригласить в команду знакомых профессионалов и получить вознаграждение до 100 тыс. рублей Скидки на отдых в лучшем в мире курортном комплексе «Mriya Resort & SPA» в Ялте.",,Сбер. Data Science,
6832,79047659,BI analyst / Data Analyst,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Приглашаем BI АНАЛТКА/ АНАЛТКА ДАННЫХ присоединиться к нашей команде.  Мы работаем в направлении Розничного бизнеса (кредитные карты), занимаемся созданием регулярной и разовой отчетности для продуктового направления. В Росбанке возможен полностью дистанционный формат работы: откуда работать - решать только тебе! Ты можешь работать из любой точки! Приходи к нам, чтобы работать над амбициозными и интересными проектами и наслаждаться балансом между работой и личной жизнью! Росбанк – частный универсальный банк, работающий на российском рынке с 1993 года. Росбанк обслуживает порядка 1,5 млн активных розничных клиентов, около 83 тысяч активных клиентов малого бизнеса и около 10 тысяч активных клиентов корпоративного бизнеса более чем в 60 регионах России. Росбанк входит в ТОП 5 самых надежных российских банков по версии журнала Forbes и включен Банком России в число 13 системно-значимых кредитных организаций России. Наш банк имеет наивысшие кредитные рейтинги российских и международных рейтинговых агентств. ОБЯЗАННОСТ: Разработка регулярной и разовой отчетности/аналитики для продуктовых направлений розничного бизнеса Разработка витрин уровня dm (Data Marts): Разработка процедур на SQL, создание конечных витрин, разработка кубов Визуализация (Power BI) и Reporting Service Аналитические исследования, анализ гипотез и ML. ТРЕБОВАНЯ: Отличное знание SQL Опыт работы с GreenPlum/PostgreSQL Знание инструментов визуализации витрин данных (Power BI, Qlick View, Tableau) Знание и понимание принципов работы Hadoop, Hive Опыт работы с GIT + Bitbucket (Pull Request), JIRA, Confluence Будет плюсом банковский опыт, желательно в продуктовой розничной аналитике Дополнительное преимущество: опыт работы с Python, SSRS, MDS, MDX, DAX, Figma. УСЛОВЯ: Полностью дистанционный формат работы – это возможность работать из любой точки Стабильный и прозрачный доход: зарплата и премии по результатам работы График 5/2 31 календарный день оплачиваемого отпуска Забота о здоровье сотрудников: программа ДМС, включая стоматологию и консультации психолога, страхование при выезде за рубеж, скидки на абонементы в фитнес-клубы, страхование жизни Дополнительная оплата за больничный лист: доплата сверх пособия по болезни до оклада (до 5 рабочих дней в год) Кадровый электронный документооборот, который позволяет подписывать кадровые документы (дополнительные соглашения к трудовому договору, приказы и т.п.) в электронном виде Личностное развитие и рост: корпоративная электронная библиотека Альпина с книгами, курсами, тестами по бизнесу и саморазвитию, возможность прохождения бесплатного обучения и тренингов, участия в регулярных встречах корпоративных клубов и скидки на курсы он-лайн школ Скидки и привилегии по кредитам, ипотека на льготных условиях, льготные условия обслуживания и т.п. Программа корпоративных скидок и привилегий Primezone: развлечение, отдых, товары для взрослых и детей, услуги (авиакомпании, рестораны, магазины электроники и т.п.), обучение Программа волонтерства и благотворительности Сообщества по интересам сотрудников.","Power BI,Визуализация данных,SQL,Tableau,Qlick View,Hadoop,Hive,Python,PowerBI",«РОСБАНК»,
6833,77774476,Data analyst/ Data Scientist  (удаленно),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Приглашаем DATA ANALYST/ DATA SCIENTIST присоединиться к нашей команде.  Мы занимаемся разработкой Centralized Data Platform (CDP) для домена Риски, создаем и развиваем скоринговые модели по клиентам. В Росбанке возможен полностью дистанционный формат работы: откуда работать - решать только тебе! Приходи к нам, чтобы работать над амбициозными и интересными проектами и наслаждаться балансом между работой и личной жизнью! Росбанк – частный универсальный банк, работающий на российском рынке с 1993 года. Росбанк обслуживает порядка 1,5 млн активных розничных клиентов, около 83 тысяч активных клиентов малого бизнеса и около 10 тысяч активных клиентов корпоративного бизнеса более чем в 60 регионах России. Росбанк входит в ТОП 5 самых надежных российских банков по версии журнала Forbes и включен Банком России в число 13 системно-значимых кредитных организаций России. Наш банк имеет наивысшие кредитные рейтинги российских и международных рейтинговых агентств. ОБЯЗАННОСТ: Проверка гипотез Построение ML моделей Сбор и анализ данных по клиентам Подготовка AD-hoc аналитики для принятия бизнес-решений. ТРЕБОВАНЯ: Опыт анализа данных от 2 лет Уверенное владение SQL Опыт построения моделей кластеризации и классификации с помощью ML Опыт работы с Python (анализ данных) Опыт работы с Hadoop, Spark Знание математической статистики и теории вероятности Опыт работы в банковской сфере будет преимуществом. УСЛОВЯ: Полностью дистанционный формат работы – это возможность работать из любой точки Стабильный и прозрачный доход: зарплата и премии по результатам работы График 5/2 31 календарный день оплачиваемого отпуска Забота о здоровье сотрудников: программа ДМС, включая стоматологию и консультации психолога, страхование при выезде за рубеж, скидки на абонементы в фитнес-клубы, страхование жизни Дополнительная оплата за больничный лист: доплата сверх пособия по болезни до оклада (до 5 рабочих дней в год) Личностное развитие и рост: корпоративная электронная библиотека Альпина с книгами, курсами, тестами по бизнесу и саморазвитию, возможность прохождения бесплатного обучения и тренингов, участия в регулярных встречах корпоративных клубов и скидки на курсы он-лайн школ Скидки и привилегии по кредитам, ипотека на льготных условиях, льготные условия обслуживания и т.п. Программа корпоративных скидок и привилегий Primezone: развлечение, отдых, товары для взрослых и детей, услуги (авиакомпании, рестораны, магазины электроники и т.п.), обучение Программа волонтерства и благотворительности Сообщества по интересам сотрудников.","SQL,Python,Hadoop,Spark,Анализ данных,Data Analysis,Data Science,Machine Learning,ML,Numpy,Pandas",«РОСБАНК»,
6839,76222353,Аналитик (Domain Data Warehouse),з/п не указана,1–3 года,"Полная занятость,полный день","ЗАО «Группа компаний С7» (S7 Group) — управляющая компания холдинга S7. Мы занимаемся стратегическим и коммерческим планированием, юридическим сопровождением, управляем финансами, маркетингом, пиаром и развиваем продажи. Корпоративный офис по управлению данными S7 Group занимается разработкой внутренних продуктов для сбора и хранения данных, аналитических систем, корпоративной отчётности, data governance. В нашем арсенале такие решения как: DWH, BI, доменные хранилища данных (Data Mesh), Data Lake, шина данных, каталог данных, виртуализация данных. С какими технологиями и концепциями мы работаем: Vertica, Airflow, Informatica, Oracle, Anchor Modelling, Data Centricity. Мы ищем аналитика в команду DDW на поддержку и развитие текущего хранилища. Вам предстоит погрузиться в несколько бизнес-доменов одной из самых интересных отраслей - авиации. Предполагаемый круг задач: Сбор и анализ требований от заказчика. Анализ источников данных. Постановка задач на разработку DDW. Ведение документации по проекту. Консультирование пользователей витрин данных. Разбор инцидентов. Формирование AD HOC выгрузок. Консультации внутри команды и DEMO результатов. Что для нас важно: Высшее техническое или математическое образование. Знание SQL среднего уровня. Знание теории баз данных и принципов их построения. Опыт формирования ТЗ на разработку. Опыт составления ER-диаграмм. Будет плюсом: Опыт работы в команды с гибкой методологией разработки. Знание BI-систем. Опыт работы с базами знаний и трекерами задач.",,Группа компаний С7,"Москва, Кузнецкий мост, Охотный ряд, Театральная, улица Петровка, 7"
6840,78769816,Ведущий специалист отдела математического моделирования / Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы тебе: работу над актуальными финтех-продуктами продуктивную и вдохновляющую атмосферу понятные задачи: полный цикл анализа данных и моделирования для повышения доходности портфеля просроченных займов (предсказание доходности клиента при различных методах взыскания, сегментация клиента для оптимизации работы моделей, выбор оптимального действия при взыскании в т.ч. с помощью машинного обучения и углубленной аналитики, участие в выработке и оптимизации стратегии взыскания на основании моделей) анализ эффективности и участие во внедрении новых источников данных (анкеты клиента внутренняя и внешняя кредитная история, мобильное приложение и др.) создание мониторинговой отчетности по математическим моделям стабильную, официальную зарплату комьюнити крутых профессионалов и наставников, где ценят усилия и результаты каждого сотрудника, честны, открыты и уважительны друг к другу удаленный или гибридный формат работы (офис или коворкинг) прокачку знаний и программы развития (внутреннее/внешнее обучение) профессиональный и карьерный рост дружелюбную атмосферу и развитую корпоративную культуру, где инициируем изменения и всегда готовы к любым вызовам ежегодные конференции, тимбилдинги, митапы и другие мероприятия Ты нам: опыт работы в data science от 2х лет высшее математическое/техническое образование знание и навыки работы с SQL высокий уровень владения python опыт работы с основными ML пакетами опыт разработки и мониторинга качества скоринговых и других математических моделей проактивность и включенность в работу понимание основных бизнес-процессов финансовой организации нестандартные решения и желание экспериментировать, развиваться Ты нам – отклик и желание работать, Мы тебе – приглашение присоединиться к нашей крутой команде!",,Eqvanta,
6841,78860693,Data-аналитик,з/п не указана,3–6 лет,"Полная занятость,полный день","Наша команда каждый день работает над повышением качества связи, обеспечивая бесперебойность сервиса для клиента. Мы – это уверенность, надежность, профессионализм и внимание к деталям. Если ты готов решать сложные и масштабные задачи в команде экспертов – мы ждем твое резюме!  сейчас у тебя есть возможность присоединиться к лучшей команде в качестве Data-аналитика. так, тебе предстоит: Анализ данных по показателям бизнеса розничной сети Поиск инсайтов, разработка алгоритмов системного выявления отклонений в деятельности сотрудников и партнеров компании сследование источников данных Взаимодействие с разработчиками для реализации промышленных алгоритмов анализа данных и разработки инструментов управления и взаимодействия с клиентами. Ключевой проект: Центр Управления Продажами – это создание систем управления физической розничной сетью (приложения для сотрудников и партнеров компании, модели прогнозирования и оптимизации, алгоритмы выявления отклонений, dashboards). Мы будем рады рассмотреть твою кандидатуру, если у тебя есть: Опыт работы аналитиком данных от 2 лет Уверенное использование SQL и Python.","Power BI,SQL,Анализ данных,MS PowerPoint,Python,Базы данных,Алгоритмы,Прогнозирование,Аналитическое мышление,Аналитика,Qlik Sense","билайн: Т, Data, Digital","Москва, Новослободская, Краснопролетарская улица"
6842,79134476,Системный аналитик Big Data,з/п не указана,3–6 лет,"Полная занятость,полный день","Команда Big Data занимается развитием внутренней экосистемы для работы с данными, которые генерирует беспилотник во время движения. У нас уже есть: Data Lake на базе S3 и Hadoop (Spark, Hive) > 30 Пб данных Форк Dagster для оркестрации конвейера обработки данных, который мы сами дорабатываем Аналитическое хранилище на ClickHouse. Для BI используем Metabase Приложения и сервисы для работы с данными (поиск и разметка данных, визуализации геоданных). Это собственные разработки с использованием open source решений Сейчас мы ищем человека, который вместе с нами обеспечит аналитическую поддержу команды Big Data по следующим трекам: Разработка data-пайплайнов, ETL/ELT процессов нтеграция с различными источниками данных сследование данных Развитие аналитического хранилища, построение витрин данных и дашбордов Ведение базы знаний и развитие data lineage. Для этого тебе потребуется: Понимание принципов проектирования хранилищ данных, ETL/ELT процессов Опыт сбора и разработки требований к подобным системам. Нужно будет общаться как с бизнесом, так и с разработкой Понимание структур и моделей данных Уверенный SQL (использовал для анализа и проверки данных, применял оконные функции). Будет плюсом, если: Был опыт анализа данных с использованием Python (Pandas/Numpy) Есть опыт работы с оркестраторами (Airflow, Dagster) Есть опыт ведения базы знаний Применял на практике UML, BPMN.",,SberAutoTech,"Москва, Автозаводская, ЗЛ, Технопарк, проспект Андропова, 10А"
6843,77181469,Data scientist / Аналитик риск-моделей,от 120 000 до 300 000 руб. на руки,1–3 года,"Полная занятость,полный день","Webbankir - российская финтех компания, маркетплейс финансовых продуктов и услуг в сегментах B2B и B2C. Мы ищем кандидата на должность Data scientist / Аналитик риск-моделей. Обязанности: Построение вероятностных скоринговых моделей Анализ имеющихся и новых источников данных и эффективное использование их для процесса принятия решений Мониторинг и калибровка имеющихся моделей, их обновление и развитие Анализ эффективности моделей и оперативное управление их применением Построение моделей текущей и будущей доходности, моделей взаимодействия с клиентом Участие в разработке и управлении лимитной и тарифной политиками Компании Анализ рисков по кредитным продуктам Подготовка, проведение и анализ результатов тестов Развитие процессов принятия кредитного решения и не только. Требования: Высшее математическое или техническое образование (предпочтительно: МГУ, МФТ, МФТ, МГТУ им. Баумана) Опыт построения моделей от 2-х лет Аналитический склад ума и умение концентрироваться на одной задаче и доводить дело до конца Хорошее знания теории вероятностей и математической статистики Опыт работы с SQL, SAS, Python, Zeppelin, другими системами/языками создания моделей Опыт взаимодействия с бизнесом и построение моделей решающих бизнес задачи Условия: Современный, просторный офис в Бизнес-парке ""GreenWood"" (ст. м. ""Сходненская"") Удобная транспортная доступность (на территории бизнес-центра есть большой паркинг) График работы: 5/2, гибрид (удалёнка/офис) Оформление на работу по Трудовому законодательству РФ (оплачиваемые отпуск, больничный) Достойная белая заработная плата Возможность карьерного роста Дружный коллектив, лояльное руководство Традиционные корпоративные мероприятия, ежемесячные денежные конкурсы, дни рождения сотрудников в приятной компании.","Python,SQL,Sas,Анализ данных,Математическая статистика",МФК ВЭББАНКР,"Москва, Сходненская, МКАД, 69-й километр, внешняя сторона, к1"
6844,78122011,Data Analyst,от 80 000 до 90 000 руб. до вычета налогов,1–3 года,"Полная занятость,полный день","Мы команда, которая занимается разработкой внутрикорпоративных инструментов по: · выявлению противоправных действий сотрудников при совершении банковских операций · риск-ориентированному профилированию сотрудников для предупреждения противоправных действий с их стороны Мы ищем опытного data-аналитика, которому предстоит проектировать и разрабатывать решения на платформе MPP СУБД Greenplum/Hadoop. Если у тебя хорошие инженерные навыки, имеешь опыт работы с большими объемами данных и ты готов к интересной работе – мы ждем тебя! Обязанности Анализ, загрузка, очистка и трансформация больших объемов данных из различных автоматизированных систем банка (оценка структуры, качества, полноты и применимости данных) в рабочую область на платформе MPP СУБД Greenplum/Hadoop Проектирование и разработка аналитических витрин данных Проверка витрин данных, разработанных по вашим спецификациям Реализация CTL-процессов Разработка и поддержка сопроводительной документации и спецификаций данных, развитие и поддержка базы знаний по вопросам работы с данными(Confluence/Jira) Участие в подготовке внедрения релизов в промышленную среду Требования Опыт работы с большими объемами данных на платформах MPP СУБД Greenplum/Hadoop. Знание SQL(PostgreSQL/Hive QL/Transact SQL) на продвинутом уровне (аналитические функции, подзапросы, хранимые процедуры/функции, оптимизация производительности) Умение оптимизировать программный код в соответствии с особенностями архитектур хранения данных. Опыт работы в роли аналитика данных в проектах по построению Data Warehouse. Ориентация на достижение результата, внимательность к деталям, коммуникабельность. Готовность к работе в офисе Будет здорово, если вы: меете опыт работы с Scala, Spark. меете опыт работы по Agile (SCRUM, Kanban, и т.д.). Условия Работа в Сбере – это: стабильный оклад и социальная поддержка сотрудников официальное оформление с первого дня ДМС с первого дня и льготное страхование для близких обучение за счет компании: онлайн курсы в Виртуальной школе Сбера, возможность получить новую квалификацию бесплатная подписка СберПрайм+, скидки на продукты компаний-партнеров корпоративная пенсионная программа ипотека выгоднее на 4% для каждого сотрудника.",,Сбер для экспертов,
6845,79005656,Data analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы команда Digital Apps, и мы занимаемся развитием маркетинговых технологий для Сбербанка. Мы создаем инструменты сквозной аналитики, позволяющие отследить весь пользовательский путь от просмотра баннера до первой транзакции, автоматизировать запуск рекламы в Digital и эффективнее управлять ей. Наша основная цель – быть #1 в привлечение клиентов в цифровом пространстве. Обязанности: проведение анализа и оцифровка предметной области (CJM клиента) описание процесса оформления продукта с точки зрения взаимодействия систем, передачи данных, оценка их структуры, полноты и применимости описание логики выстраивания Data-pipelines, проектирование аналитических витрин данных общение с внутренними и внешними заказчиками с последующей декомпозицией задач поиск, получение доступов к существующим и новым источникам данных предоставление экспертной поддержки внутренним потребителям (data analysts, data scientists) по вопросам, связанным с использованием данных поиск и внедрение новых Martech-инструментов для роста эффективности кампаний. Требования: не менее 3-х лет работы в качестве аналитика опыт анализа/изменения бизнес-процессов знание методов и стандартов обмена данными между информационными системами, умение раскладывать use кейсы на системы и их взаимодействия знание SQL на продвинутом уровне и уверенный Python отличное знание мат статистики и теории вероятности опыт работы с данными веб-аналитических систем, кликстримами, понимание маркетинговых метрик опыт в проектировании DWH, построении модели данных в проектах big data, составления требований знание английского языка на уровне понимания технической литературы. Тех стек: Hadoop, GreenPlum, ClickHouse, Airflow & Spark, BI-инструменты (Superset, Qlik). Условия: работа в офисе класса А на 26 этаже в формате open space: быстрое развитие и level-up в профессии поддержка/ментерство коллег и руководителя в решении задач и в коммуникации регулярное корпоративное обучение гибкое начало дня (с 8 до 10) дружный коллектив и адекватные руководители работа в крупнейшей компании России трудоустройство согласно ТК РФ ДМС.",,Сбер. IT,
6846,73591237,Data analyst / Аналитик данных,з/п не указана,3–6 лет,"Полная занятость,полный день","За последние 2 года мы (IQnergy) выросли в 5 раз. Мы помогаем O’KEY, Додо Пицца, Hoff, Ташир (ТЦ РО), X-Fit и еще 10-и сетями магазинов и ресторанов следить за климатом в помещениях, автоматически управлять оборудованием и экономить энергию (умный дом для коммерческих зданий). щем пополнение в наш команду разработки – аналитика, который поможет автоматизировать диагностику и поиск аномалий работы оборудования. Как мы работаем: Быстрые итерации (релизы раз в 2 недели) Обсуждение и тестирование гипотез совместно с клиентом Проверка качества кода (code review). Чем придется заниматься: Менять привычки инженеров эксплуатации зданий Придумывать алгоритмы поиска поломок оборудования Строить аналитические отчеты по работе оборудования и энергосбережению. Ты идеальный кандидат(ка) если: меешь опыт разработки python в большой Т компании или стартапе на стадии роста Знаешь современные методы анализа данных, в т.ч. анализа и прогнозирование временных рядов, методы классификации У тебя техническое образование: МФТ, МГУ (ВМК, МехМат, Физфак), МГТУ им. Баумана и подобное Знаешь Python и будет плюсом если знаешь библиотеки анализа данных: Pandas, NumPy, SciPy, scikit-learn Условия: Достойная компенсация, которая позволит вам сосредоточиться на развитии проекта и своем профессиональном росте Сильная и мотивированная команда – у вас будет возможность обмениваться опытом и расти профессионально Сложные и интересные задачи, в том числе реальная практика в построении разработки и реализации алгоритмов анализа данных Комфортные условия работы – офис в 5-и минутах от метро Нагатинская Возможности для быстрого роста вместе с компанией.",Анализ данных,IQnergy,"Москва, Верхние Котлы, Московское центральное кольцо, станция Верхние Котлы"
6847,78585391,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем специалиста по анализу данных на задачи, связанные с оптимизацией ассортимента, динамическим ценообразованием и прочими розничными направлениями. Ждём от кандидата готовности погружаться в особенности бизнес-процессов, желания крутить-вертеть таблички, копаться в данных, искать в них инсайты. Нестрашно, если ты раньше не сталкивался с задачами розницы или не знаешь каких-то алгоритмов, главное – уметь думать, иметь аналитическое мышление, а также быть заинтересованным в саморазвитии. Не оставляем с задачами наедине: коллеги всегда готовы подсказать и помочь. У нас довольно разнообразные задачи: где-то потребуется поискать причинно-следственные связи в данных, где-то – создать новый аналитический инструмент или улучшить качество старого, а потом мониторить его работу и при необходимости вносить доработки. Характер работы разнородный: предполагается как решение маленьких бизнесовых задач, так и участие в крупных проектах. Мы верим, что никакая математика не спасёт без глубокого понимания данных, что инструмент должен подбираться под задачу, а не задача под инструмент, что анализ и моделирование проводятся ради конечного результата, а не ради самих себя. Если тебе близки наши принципы работы, будем рады видеть тебя частью нашей команды. Обязанности: Подготовка и очистка данных Анализ данных на предмет выявления закономерностей Автоматизация существующих бизнес-процессов, связанных с аналитикой данных, расчётом ключевых показателей и принятием решений на основе изменений в их динамике Разработка и внедрение собственных аналитических инструментов, доработка существующих алгоритмов нтерпретация полученных результатов и их представление бизнес-пользователям Требования: Опыт работы от 1 года Владение SQL, Python (numpy, pandas, sklearn)/R (работа с таблицами – ключевой навык) Знание статистики (в частности методов анализа временных рядов) Владение математической статистикой и алгоритмами машинного обучения (с учителем и без учителя) будет преимуществом Опыт решения задач в области анализа данных спользуемые технологии: SQL (MSSQL, Oracle) R (RStudio) Python (Jupyter Notebook) OLAP-кубы с подключением через Microsoft Excel (вспомогательный инструмент, обучение на месте) Условия: Гибкое начало рабочего дня (с 8, 9 или 10) Гибридный график работы (офис + удалёнка) Участие в конференциях Оформление по ТК РФ Заработная плата обсуждается индивидуально с успешным кандидатом Работа в современном БЦ в пешей доступности от ст.м. Электросила Бесплатные курсы английского языка Корпоративная VIP-карта на продукцию","SQL,MS SQL,ORACLE,R,Python,OLAP,Анализ данных,Анализ временных рядов,Статистический анализ,Кластерный анализ",Улыбка Радуги.IT,"Санкт-Петербург, Московский проспект, 158Б"
6848,78996156,Data analyst (Middle),з/п не указана,1–3 года,"Полная занятость,полный день","Привет, к себе в команду ищем аналитика данных, формат работы: гибридный или удаленный только по РФ О чем проект Проект направлен на выделение интересов, соцдема и активности абонентов для улучшения таргетингов, а также для использования этих знаний в ML-моделировании Чем предстоит заниматься зучать большой объем данных с помощью инструментов BigData и искать в них инсайты Выдвигать гипотезы для тестирования и разрабатывать дизайны A/B тестов Строить клиентскую аналитику и сегментацию, разрабатывать отчетность и дэшборды Что для этого нужно Высшее образование Умение работать с реляционными (SQL) базами данных Понимать инструменты анализа данных Python, уметь визуализировать инсайты Уверенно знать статистический анализ Опыт работы в data science от 2 лет Плюсом будет умение работать с инструментами Hadoop (pyspark, hive)","Python,SQL,Hadoop,A/B тесты","МегаФон, IT","Москва, Маяковская, Новослободская, Чеховская, Оружейный переулок, 41"
6849,76969784,Data analyst (middle/senior),з/п не указана,1–3 года,"Полная занятость,полный день","Команда SmartNLP разрабатывает “мозг” виртуального ассистента. Наши сервисы отвечают за то, чтобы понять намерение (интент) пользователя и предложить на этот интент самые релевантные результаты (фильмы, песни, товары итд.). Сейчас мы умеем предсказывать 600+ интентов и искать по 10+ вертикалям. Делаем пайплайн от предобработки текста до классификации и учета контекста для принятия решения. Напрямую влияем на клиентский опыт и поведение ассистента в целом. Основные задачи: — Работа с результатами работы NLP моделей(анализ классификации, выдвижение гипотез, разбор ошибок) — Проведение А/Б экспериментов — Разработка инструментов аналитики и визуализации данных — Поиск точек роста качества классификации — Разработка дизайна экспериментов и тестирование гипотез для улучшения клиентского опыта Требования: Опыт работы с различными источниками данных, в том числе с базами данных (sql) — Уверенное знание python для задач DA — Уверенное знание статистики и продуктовой аналитики — Умение генерировать гипотезы и определять критерии их успешности Будет плюсом: — Опыт анализа работы NLP моделей — Опыт работы со стеком ELK (Elasticsearch, Logstash и Kibana) — Опыт работы с Толокой Условия: Конкурентную компенсацию (оклад и премии по результатам деятельности) Свободный дресс-код Гибкий график для оптимального баланса работы и личной жизни Профессиональное обучение, семинары, тренинги, конференции, корпоративная библиотека ДМС, страхование жизни Самые инновационные, амбициозные проекты и задачи Льготные кредиты и корпоративные скидки","Python,NLP,Data Analysis,Data Science,Алгоритмы",Сбер. IT,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
6850,76934468,Data scientist / Аналитик данных,з/п не указана,1–3 года,"Полная занятость,полный день","Мы – Цифровая платформа КАМАЗ, продуктовая IT компания. Наш профиль – это грузовые и пассажирские перевозки. Обеспечиваем телеметрию и развиваем умную логистику. Мы ищем: Data scientist на проект Микротранзит – общественный транспорт с умной моделью построения маршрута, персонализированные перевозки по требованию в крупных городах России.  У нас вам предстоит работать над нашим собственным сервисом «Челнок» по улучшению городской инфраструктуры. Это абсолютно новый способ в России передвижения по городу, гибрид общественного транспорта и такси. У нас динамические маршруты: развозим пассажиров, которым «по пути» уже в трёх городах (Москва, Набережные Челны, Красногорск) и нновационном центре «Сколково». Наш сервис обрабатывает запросы от мобильных приложений пассажира и водителя, строит маршруты, связывает пассажиров и автобусы, а также позволяет диспетчерам мониторить состояние автопарка. Нашей команде приходится справляться с высокой нагрузкой, а также решать по-настоящему нестандартные задачи. Ссылка на мобильное приложение «Челнок»: https://app.mt.dpkapp.ru/go Вам предстоит: 80 % времени работать с данными из разных источников Отрабатывать гипотезы Обучать ML модели Решать оптимизационные задачи в транспорте и не только Реализовывать продакшн решения на базе ваших обученных моделей Наш стек: ClickHouse, PostgreSQL, HDFS MlFlow, AirFlow GitLab, Kubernetes, Docker Python Необходимые скиллы: SQL на уровне среднего запроса сложности (выгрузки, агрегации) Знать принципы работы алгоритмов машинного обучения (линейные модели, деревянные модели и ансамбли основанные на деревянных, нейронные сети и др.) Любить теорию вероятности и математическую статистику Писать понятный и воспроизводимый код Представлять данные в виде понятных сводных таблиц/графиков (гистограммы, тепловые карты, зависимости) Формулировать и проверять на данных статистические гипотезы Быть внимательным к физике данных, чтобы делать правильные Sanity Check результаты и выводить корректные выводы У нас: Официальное трудоустройство Работа в центре Санкт-Петербурга, Малая Конюшенная улица дом 1-3 Гибридный формат работы, гибкое начало и конец рабочего дня Выдаем ноутбуки: MacBook, Lenovo ThinkPad Компенсации спорта и курсов иностранного языка, обучение за счет компании Атмосфера той самой идеальной команды!","ClickHouse,SQL,Python,Статистика",KAMAZ DIGITAL,"Санкт-Петербург, Малая Конюшенная улица, 1-3"
6852,77998800,"SRE Data Analyst, Группа проектного управления",з/п не указана,3–6 лет,"Полная занятость,полный день","Мы ищем профессионала в области SRE аналитики в Департамент разработки платформы и инфраструктуры Озон.  Твоими стейкхолдерами будут IT директора и сам CTO, импакт твоего анализа будут чувствовать более 4000 разработчиков внутри Озона и миллионы наших юзеров Нам особо важно с глубокое понимание устройства IT-инфраструктуры на физическом и логическом уровнях, и при этом опыт взаимодействия с бизнесом и со стейкхолдерами уровня CEO, CTО В Платформе мы поддерживаем стабильность и масштабируемость бизнеса на всех уровнях инфраструктуры: Смотрим на метрики и прогнозы бизнеса и делаем выводы, какую нагрузку будут испытывать наши сервисы и оборудование Делаем прогнозы потребления и на основе их формируем бюджет на закупку оборудования Даем рекомендации разработчикам по оптимальному использованию ресурсов для успешного прохождения сезона распродаж Работаем с собственными облачными решениями, что позволяет централизованно управлять метриками и прогнозами.  С чем нужно будет работать: Новая и необычная предметная область, востребованность которой растёт вместе с рынком облачных технологий, SaaS и low-code решений Заказчики – инженеры: не заваливают адхоками, глубоко погружаются в аналитику и хорошо в ней понимают Работа с передним краем облачных технологий Возможность разобраться в том, как внутри устроен большой высоконагруженный продукт, не утонув в деталях. Вам предстоит: Разработка и реализация стратегии работы с данными для аналитики Платформы Озон. Сбор данных, валидация, использование Разработка прогнозов для закупок оборудования на основании исторических данных потребления ресурсов и прогнозов бизнес-показателей Разработка рекомендаций для разработчиков и аналитиков по эффективному использованию ресурсов. Мы ожидаем: Опыт работы Data Analyst в Senior/Lead позиции, аналитика бизнес показателей или SRE Умение брать задачу в работу с простыми бизнес формилировками, самостоятельно формировать скоуп работ, находить заинтересованных лиц и экспертов для консультации, презентовать результат и отвечать за него Хороший python, умение кодить – можешь правильно придумать несложную архитектуру, знаком с инструментами деплоя, умение проводить code-review Опыт менторства, управленческие навыки, умение сформировать и защитить стратегию работы с данными. Стек: Никакого легаси, всё самое удобное и современное gitlab + jupyter + nbdev для разработки Метрики в Prometheus, аггрегации в postges/clickhouse, бизнес-данные в vertica/clickhouse airflow для запуска джоб (у нашей команды своя отдельная инсталяция, никакой “коммуналки” с переполнеными очередями) superset для вывода дашбордов с текущим потреблением, метриками, прогнозами. Мы предлагаем: Динамичный и быстроразвивающийся бизнес, ресурсы, возможность сделать вместе лучший продукт на рынке e-commerce Свободу действий в принятии решений Достойный уровень заработной платы Профессиональную команду, которой мы гордимся Возможность развиваться вместе с нашим бизнесом.","Python,IT,Платформа",Ozon нформационные технологии,
6853,78258371,Analytics and data engineer,з/п не указана,1–3 года,"Полная занятость,полный день","АНО ""Аналитический центр города Нижнего Новгорода"" - первый в России муниципальный аналитический центр. Организация занимается разработкой информационных систем для Администрации города Нижнего Новгорода и имеет статус аккредитованной IT компании. Наша основная задача - сбор данных из информационных систем Нижнего Новгорода, их систематизация, хранение, и предоставление администрации города для анализа и принятия управленческих решений. Всвязи с расширением, мы открываем набор на позицию ""нженер по аналитике и работе с большими данными"". Обязанности: Сбор и обработка данных из различных источников Разработка автоматизированных решений для получения данных Проектирование и разработка интеграций между информационными системами Подготовка BI отчетности с использованием Yandex.DataLens Работа с базой даных PostgreSQL Поддержка и доработка REST API. Требования: Наличие высшего технического/экономического образования будет плюсом Знание Python с библиотеками для обработки данных Понимание архитектуры REST API Навыки работы с PostgreSQL. Навыки работы с ClickHouse будут преимуществом. Умение строить визуализацию данных с использованием BI систем. Понимание концепции DDDM. Опыт работы с Yandex.DataLens будет преимуществом Опыт работы с большими данными. Условия: Официальное трудоустройство Льготы и бонусы аккредитованной IT компании Заработная плата: оклад и надбавки стимулирующего характера График работы: пн-чт 9:00 - 18:00, пт 9:00 - 17:00 Работа в офисе АНО ""АЦГ"", расположенном в историческом центре города Дружная команда и широкие возможности карьерного роста Профессиональное личностное развитие: тренинги личностного роста, возможны профессиональные курсы Корпоративные мероприятия.","Python,PostgreSQL,SQL,Аналитика,Базы данных,Аналитическое мышление,Yandex.DataLens",АНО АЦГ,"Нижний Новгород, Горьковская, Рождественская улица, 6"
6858,79021402,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","By joining KAZ Minerals as a Data scientists, you will: Solve the most complex and practical tasks of the Metals and Mining industry, the key economy sector of Kazakhstan, with immediate impact on operations. The industry has been accumulating enormous operational data, but lagging behind using these data for an educated decision making based on the power of advanced analytics and artificial intelligence Take part in building a Digital and Analytics arm of the most advanced M&M company in Kazakhstan, creating impact-oriented culture without bureaucracy. KAZ Minerals is aiming to become the most innovative and digitally driven mining companies in Kazakhstan, and have started the development of artificial intelligence solution to optimize its production. The company plans to build the team of best data scientists, who would like to lead this direction Implement advanced analytics solution might require some business trips to the Operations sites in Eastern and Northern parts of Kazakhstan, where you will be working with the experienced international and local miners and metallurgists Job duties: Develop complex models and algorithms that drive innovation throughout the organization. This may include improving on-time performance, network planning, etc. Conduct advanced statistical and other analysis to provide actionable insights, identify trends, and measure performance Provide coaching and insight on analytic approaches and can objectively weigh trade-offs of different analytic methods Guide data engineering efforts to ensure alignment with future data science needs Provide guidance to business leaders and data engineering function highlighting data integrity risks Collaborate with analytics engineers to implement and deploy scalable solutions Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders Skills and qualification requirements: BS/MS in computer science, statistics, economics, mathematics, ops research or related technical discipline 2+ year of experience as a data analyst and/or data scientist Knowledge of machine learning, statistics, optimization, or related field Experience with Python is required Experience with SQL, Pandas, Numpy, SciPy, Scikit-learn, xgboost Experience with BI and visualization tools is a plus Experience in the Metals and Mining industry is a plus Professional attitude and service orientation superb team player Good written and verbal communication skills along with strong desire to work in cross-functional teams","Python,Data Mining,SQL,Machine Learning,Data Science,Numpy",KAZ Minerals Management,
6861,79255397,"Senior Data Analyst (""Рекомендации"")",з/п не указана,3–6 лет,"Полная занятость,полный день","Мы создаём рекомендательную систему, которая является одним из ключевых ML–сервисов в Okko. Простые задачи мы уже решили, остались интересные. Поэтому мы ищем специалиста с обширным опытом работы. Обязанности: исследование применимости различных алгоритмов в рекомендательной системе моделирование входных данных, участие в EDA и генерации фичей участие в оценке и интерпретации экспериментов в направлении ""Рекомендации"" аналитическая проработка алгоритма внутренней системы мотивации активных пользователей построение мониторинговых дашбордов. Что мы используем: Python (sklearn, seaborn, numpy, scipy, statsmodels) ClickHouse, PostgreSQL, Redis, etc. Airflow, FlaskAPI/FastAPI Bitbucket, Jira, Confluence. Требования: опыт работы аналитиком данных/продуктовым аналитиком от 3-х лет уверенное владение SQL знание основ машинного обучения знание математической статистики и основ A/B тестирования владение Python на уровне использования аналитических инструментов и базового синтаксиса опыт самостоятельного общения с бизнес-заказчиками бизнес-ориентированное мышление. Будет плюсом: опыт проведения onboarding новых членов команды успешный опыт работы в “большой тройке” консалтинговых компаний. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","SQL,Python,A/B тесты",Okko,"Санкт-Петербург, Беговая, улица Савушкина, 126Б"
6862,77606083,ESG/Sustainability Data Analyst (Senior),з/п не указана,3–6 лет,"Полная занятость,полный день","inDrive — международная технологическая платформа транспортных и бытовых услуг. Мы входим в топ-2 мобильных сервисов для заказа поездок в мире: более 150 миллионов установок, более 2 миллиардов поездок, 700+ городов в 40+ странах мира. inDrive — продукт, которым ежемесячно пользуются десятки миллионов людей. Они совершают городские или междугородние поездки, заказывают грузоперевозки или курьерскую доставку, ищут работу и вызывают мастеров для оказания бытовых услуг. В inDrive работает более 2 000 сотрудников, из которых 450+ — разработчики, поделенные на 50+ кросс-функциональных команд. Следуя своей миссии борьбы с несправедливостью inDrive развивает повестку устойчивого развития и управления вопросами социального, экологического и корпоративного управления. Поэтому мы ищем ESG data-аналитика, который используя данные, аналитический аппарат и знание IT процессов совместно с командой Sustainable Development, выстроит систему мониторинга экологических, социальных и корпоративных показателей компании. Сотрудника должны отличать сильные навыки анализа данных, межличностного общения и менеджмента. Чем предстоит заниматься: Проведение экспертного анализа предметной области ESG / Sustainability Сбор и формализация требований к смежным системам, поиск данных и организация потоков данных Поиск, обработка и анализ данных для формирования отчетов проекта Расчет бизнес метрик и автоматизация отчетности совместно с командой BI, создание системы отчетности для отдела ESG / Sustainability Подготовка аналитических отчетных материалов в понятном для бизнес-заказчика формате Построение процессов и систем сбора, обработки и анализа данных, связанных с тематикой ESG внутри компании Участие в комплексном тестировании функционала и настроек систем Подготовка рекомендаций по улучшению ESG повестки на основе анализа данных из внутренних и внешних источников Организация кросс-командного взаимодействия (бизнес-заказчики, стейкхолдеры, дата инженеры и т.п.). Ты подойдешь нам, если у тебя есть: Высшее техническое/экономическое образование Отличное понимание IT-процессов Знание нотаций моделирования бизнес-процессов и опыт визуализации схем (UML, BPMN и др.) Опыт в анализе инициатив бизнес-заказчика на этапе их возникновения и определение видения Т-реализации, активное участие в наполнении бэклога Практический опыт формирования отчета и презентации, используя SQL Практический опыт сбора и формализации требований Способность быстро обучаться и адаптироваться к меняющемуся IT-ландшафту Умение работать в сжатые сроки и режиме многозадачности Развитые коммуникационные навыки Английский язык не ниже B2. Для тебя мы предоставим: Работа по гибкому графику, оформление по ТК. Для сотрудников от года работы доступна программа «Офис без границ» — возможен временный переезд в любую точку мира и работа из этой локации (по согласованию с руководителем)  Релокация на Кипр или в Казахстан с помощью компании, релокационный пакет, оплата отеля на время поиска квартиры, дотации на аренду жилья, помощь в устройстве детей в школы и детские сады, страхование жизни и ДМС Регулярное внешнее и внутреннее обучение. У сотрудников есть возможность посещать профессиональные конференции в качестве участника или спикера Частично или полностью оплачиваемые дополнительные образовательные курсы Программа личностного роста Sinet Challenge, в которой мы ставим цели и вместе движемся к ним: Sinet Run для вовлечения в культуру бега, Sinet Challenge — частичная компенсация активного отдыха в период отпусков Ежемесячные мероприятия формата FunDay — корпоративы в различных форматах: от стендапов до походов в горы Приятное к важным датам — подарки от компании на свадьбу, при рождении ребенка и на день рождения. inDrive — команда тех, кто во благо постоянного роста умеет экспериментировать и учиться на ошибках. Здесь работают люди, которым не страшно брать на себя ответственность и создавать свои собственные правила, когда привычные не работают. Присоединяйся!","BPMN,SQL,UML,Бизнес-анализ,Английский язык,Python,Ad Hoc Analysis,Data Analysis,Big Data,Pandas,BiqQuery,Apache Hive,Tableau,ESG,Sustainability,Agile Project Management",inDrive,
6864,77148399,Data Science/Data Analyst,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","MY.GAMES is a leading European publisher and developer headquartered in Amsterdam, with over one billion registered users worldwide. War Robots, Hustle Castle, Rush Royale, Left to Survive, Tacticool, and many other games were developed and produced by MY.GAMES. The company creates and publishes games for PC, consoles, and mobile devices. We have more than a dozen game development studios united under MY.GAMES, as well as MGVC, a global game investment company. The global MY.GAMES and MGVC partner network comprises over 40 studios. Our studios are professional teams with their own unique atmosphere. We’re united by a common passion: transforming our enthusiasm and talent into fabulous games. We create engaging products which captivate millions of people all over the world. What you’ll do: Design and develop predictive algorithms Automate marketing analytics based on your own models, create dashboards for end users Test and research various relevant hypotheses What you need to succeed: Commercial experience designing (or developing) your own predictive models Confident Python skills A math background sufficient for using common ML-algorithm libraries (you’ll need to understand their work principles and possess practical skills with some of them) A basic understanding of statistics results Good command of SQL Nice to have: Marketing or gamedev background Spark framework experience (or a readiness to learn) What we offer: Work remotely from all around the world Collaborative working atmosphere in an internal game dev community that unites more than 40 in-house and partner studios A strong team of specialists across different areas — access unique expertise and professional knowledge Possibility to experiment and work on interesting tasks with ambitious goals — we have all resources to implement new ideas Create great games and win the hearts of players Push the boundaries of the game industry and lead the way forward","Python,ML,SQL",MY.GAMES,
6867,78634621,Руководитель отдела анализа данных/Lead Data Analyst,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы – команда Гринмани, современный FinTech проект и один из крупных сервисов онлайн-кредитования в стране. Гринмани работает на рынке с 2015 года, уверенно растет и развивается. Сейчас в компании более 350 человек - распределенная команда и сотрудники офисов в Новосибирске и Кемерово. Мы работаем с российским рынком, с гражданами РФ. Продукты - PDL, IL, только онлайн формат. меем амбициозные планы развития бизнеса. Открываем позицию Руководителя отдела анализа данных. Данная роль у нас выделяется впервые, основная цель - обеспечить все бизнес-подразделения качественной регулярной и ad- hoc аналитикой. Обязанности: Создание и управление отделом анализа данных в кредитном бизнесе Поддержка всех бизнес-подразделений компании в части регулярной отчетности и ad hoc аналитики (автоматизированные отчеты, дэшборды, выгрузки, BI) Реализация исследовательских задач для разных подразделений - тестирование гипотез, построение моделей Регулярная поставка продуктовой, маркетинговой, веб-аналитики Ведение R&D проектов - исследование аномалий в данных, поиск точек роста доходности бизнеса, продуктов Развитие инструментов и экcпертизы в отделе, модернизация стека технологий Регулярное самостоятельное выполнение аналитических задач Данная команда не будет заниматься инженерными задачами (развитие DWH, ETL и т.д.). Требования: Актуальные навыки анализа данных на уровне ведущего аналитика - SQL, Python, BI, Excel, математическое моделирование, статистика, управление качеством данных Опыт лидирования процессов, проектов Опыт управления командой Готовность развивать команду и продолжать работать руками 60-70% рабочего времени Очень желателен опыт работы с digital b2c продуктами, опыт работы с продуктовыми метриками, веб-аналитикой. Условия: У вас будет возможность создать подразделение с нуля, организовать работу, применить свой опыт и видение У нас распределенная команда, мы готовы к удаленному сотрудничеству, в том числе, если вы сейчас заграницей. В Новосибирске и Кемерово возможна работа а офисе/гибрид Условия оффера гибко обсуждаются Мы чтим ТК Мы адаптивные, увлеченные и дружелюбные, с нами интересно работать, у нас амбициозные цели.","Python,Big Data,SQL,Business Intelligence Systems,Математическое моделирование,Математический анализ,Бизнес-моделирование",ГРНМАН,
6868,79091569,Data Engineer в направление Core Data Lake (Big Data),з/п не указана,1–3 года,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Data Engineer в направление Core Data Lake Описание продукта: Core Data Lake обеспечивает централизованное подключение коммунальных источников в Data Lake Big Data и создание коммунальных витрин для всех продуктов Big Data и аналитиков всех вертикалей МТС. Обязательно: коммерческий опыт работы Data Engineer (разработчик ETL) от 1 года знание Python (работа с большими объемами данных) знание SQL (аналитические функции, оптимизация) знание Spark (работа с большими объемами данных) знание любой реляционной СУБД (Orcle, Mysql, postgres) Что предстоит делать? загружать данные с реляционных источников в Data Lake, размещать их в соответствии с подходами команды, обвешивать мониторингами и DQ проверками дорабатывать программный код оповещать пользователей о планируемых работах и их результатах собирать сущности и витрины в хранилище Hadoop Стек технологий: Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные и международные конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","ETL,Python,SQL,Spark,Big Data,PostgreSQL,MySQL,Hive",МТС,
6870,79273001,Data scientist (Middle),з/п не указана,1–3 года,"Полная занятость,полный день","Привет, ищем в нашу команду Middle Data scientist, формат работы: удаленный, гибридный/офисный по Москве О проекте: Персонализация офферов для клиентской базы в рамках CVM (Customer Value Management) Предсказание потребления, конверсии, выручки, построение look-alike по целевым сегментам Участие в дизайне, подготовке и анализе АБ тестов для прилотирования моделей Какие задачи необходимо решать: Разработка моделей машинного обучения на больших данных Feature-engineering, аналитика данных для поиска инсайтов по профилю клиента Настройка Data Quality и Model Quality для ML моделей нтерпретация и презентация результатов работы разработанных моделей Для решения этих задач требуется: Высшее образование Знания в области математики, теории вероятности, мат. статистики (высшее образование, наличие ученой степени будет дополнительным плюсом) Знание алгоритмов машинного обучения, принципов их работы, ключевых особенностей и ограничений Знание инструментов анализа данных, библиотек машинного обучения Python, PySpark. Опыт работы с Airflow, MLflow будет плюсом Опыт работы в области Data Science от 2х лет",,"МегаФон, IT","Москва, Маяковская, Новослободская, Чеховская, Оружейный переулок, 41"
6871,71322369,Data Scientist Middle/Senior,з/п не указана,3–6 лет,"Полная занятость,полный день","Responsibilities: Collaborate with business partners to develop novel ways to meet objectives utilizing cutting edge techniques and tools Effectively communicate the analytics approach and how it will meet and address objectives to business partners Advocate and educate on the value of data driven decision making focusing on the “how and why” of solving problems Lead analytic approaches, integrating work into applications and tools with data engineers, business leads, analysts and developers Create repeatable, interpretable, dynamic and scalable models that are seamlessly incorporated into analytic data products Engineer features by using their business acumen to find new ways to combine disparate internal and external data sources Share their passion for Data Science with broader enterprise community identify and develop long-term processes, frameworks, tools, methods and standards Collaborate, coach, and learn with a growing team of experienced Data Scientists Stay connected with external sources of ideas through conferences and community engagements Domain Expertise: Bachelor’s degree required Graduate degree in quantitative discipline and demonstrated Data Science skill set, plus 3+ years work experience Must have Python or R proficiency working with DataFrames Must have proficiency writing complex SQL queries Must have proficiency with Machine Learning to solve clustering, classification, regression, anomaly detection, simulation and optimization problems on large scale data sets Must have proven ability to merge and transform disparate internal & external data sets together to create new features Advanced time series forecasting understanding – from classical linear approaches to ML ones Understanding the key business metrics and its application to ML models Experience with sophisticated data cleansing approaches & robust models Proficiency validating the current approaches and understanding the improvement area Experience with Big Data technologies preferred — Hadoop, Spark, H20.ai, Cloud AI platforms, containerization Experience with supporting deployment, monitoring, maintenance and enhancement of models desired Experience with data visualization tools preferred — Power BI, Tableau, R Shiny, Plotly, etc. Experience with AB testing preferred We offer: Competitive salary Advanced benefits package (annual bonus, health insurance, mobile compensation, partial fitness compensation, 3-year saving plan) Professional development and career growth Ability to take part in digital transformation in a large company","Python,Machine Learning,SQL,Big Data,Data science",Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
6873,78959836,Data-аналитик (стрим еСпортс),з/п не указана,3–6 лет,"Полная занятость,полный день","MTS Digital — это инновационное подразделение МТС, которое работает над созданием экосистемы цифровых сервисов, мобильными приложениями, продуктами в финтехе, стриминге, гейминге, «облаках», AI и других направлениях.  Мы расширяем команду, которая занимается разработкой универсальной UGC платформы для развития инструментов стриминга и новых видео-форматов для блогеров, и ищем Data аналитика.  Что предстоит делать: формировать отчеты, аналитические справки и презентации для продуктовой аналитики составлять дашборды, отчеты, выборки в рамках продуктовых задач формировать требования к источникам данных в рамках продуктовых задач. Наши ожидания: опыт работы с базами данных, умение писать сложные запросы, опыт создания дашбордов опыт обработки и структурирования данных умение работать с Grafana, Сlickhouse, Redash умение получать прямой доступ к данным умение описывать структуры данных, документирование данных. Что мы предлагаем: собственную платформу MTS Ocean для получения Т-ресурсов, а это значит, что деплой, мониторинг, observability - не будут для вас проблемой, вы сможете сосредоточиться на фичах профессиональные гильдии инженеров по направлениям, чтобы поддерживать друг друга и обмениваться опытом внутреннюю площадку TechTalks для обмена опытом, дискуссий, развития навыков самопрезентации участие во внешних IT конференциях. Мы выступаем на HighLoad++, DataFest, Mobius, Test Driven Conf, Joker, DevOps, Матемаркетинг и даже проводим собственную конференцию по архитектуре Hello, conference! полезные курсы и вебинары в корпоративном университете и электронные библиотеки. А еще: медицинскую страховку с 1 месяца со 100% покрытием расходов, включая стоматологию, страхование жизни и здоровья в поездках за рубеж. Можно застраховать родственников с корпоративной скидкой доступ к сервису «Понимаю»: онлайн-консультации с психологом, юристом, экспертом по финансам или ЗОЖ корпоративный и командный психолог в офисе и массажный кабинет единую подписку МТС Premium — KION light в онлайн-кинотеатре KION, сервис МТС Music, 30 дней бесплатного пользования подпиской OZON Premium скидки и предложения от партнеров на фитнес, занятия английским и прочее.","ClickHouse,Базы данных,PostgreSQL,Grafana,Redash,Анализ данных,SQL",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
6874,78608518,Trainee data analyst,з/п не указана,не требуется,"Стажировка,полный день","WHAT WE NEED YOU TO DO: Building weekly/monthly reports that contain main commercial KPIs Data steward function: data quality monitoring Preparing documentation for current reports/BI tools Instructional manuals for End-users Development and support of Qlik dashboards. Working on their optimizations Project management: providing technical tasks and controlling of working process of internal and external developers Providing technical trainings for End-users. REQUIREMENTS: Python – basic level SQL – basic database queries MS Excel - Advanced level English - Intermediate Analytical skills, ability to define the reasons and consequences, build logical sequences Communication skills - Advanced level Critical thinking and analysis, ability to work independently Proactivity, initiative Experience of dashboard development using any tool – PowerBI, Tableau, Qlik, etc will be a plus CONDITIONS: We care about you: paid internship, flexible start and end of the work day, hybrid format (3 days offline/ 2 days online), fruit days and fresh orange juice in the kitchen, corporate food card (more than 100 restaurants and food delivery at home). We are glad to see you from the first day: buddy to support for new employee, individual employee introduction plan, mentor for the whole internship program. We like to develop and grow: free English lessons with our partner Education First, online/offline trainings and workshops all year round, free access to the library resources MyBook, workshops on presentation skills SEB Talks, communication with colleagues from other countries and international opportunities. We like to rest together: 14 days annual leave for 6 months, club of interests (support of employees’ hobbies), running club, hatha yoga twice a week, corporate events, breakfast with general manager. We like to delight our employees: gifts for the holidays, discount on our products and partner’s products, moreover we take part in charity projects and support our volunteer employees.","Python,SQL,Analytical skills,PowerBI,Time management,Business English,English,Leadership Skills,Communication skills",Tefal,"Москва, Балтийская, Войковская, Стрешнево, Ленинградское шоссе, 16Ас3"
6875,78149683,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","В отдел по работе с данными ритейла требуется Data Scientist. Мы ищем не просто коллегу, который будет заниматься реализацией проектов, но и единомышленника! Вакансия открыта в г. Нижний Новгород, полностью удаленного формата работы нет.  Что нужно будет делать? Планировать и проводить исследования данных Распределять задачи в группе Визуализировать и презентовать результаты исследований Строить пайплайны обработки данных Оценивать корректность ML моделей Составлять и реализовывать алгоритмы. Что для этого нужно? Высшее высшее математическое/техническое образование Уверенное знание Python Знание библиотек NumPy, pandas, matplotlib, sklearn Хорошее знание алгоритмов и структур данных Понимание принципов обучения ML-моделей Знание SQL, GIT Умение реализовывать переиспользуемые решения. Что предлагаем? Возможность развить свои навыки анализа и обработки данных на реальных проектах в команде опытных аналитиков и датасаентистов Возможность освоить методы data science Гибридный формат работы (офис Нижнего Новгорода).","Python,SQL,MS PowerPoint,Статистический анализ,ML,Data Science",Моризо Диджитал,"Нижний Новгород, Горьковская, Алексеевская улица, 6/16"
6876,76536709,Data Scientist (LTV),з/п не указана,3–6 лет,"Полная занятость,полный день","Продуктовая команда департамента клиентской аналитики в поисках опытного Data Scientist для решения задач моделирования LTV абонентов и внедрение данной концепции в бизнес-процессы компании. Основные задачи: Решение бизнес-задач с помощью анализа данных и машинного обучения Статистический анализ и обработка данных Построение и валидация моделей машинного обучения Дизайн и проведение А/B-экспериментов Написание отказоустойчивого production-кода. Мы будем рады рассмотреть твою кандидатуру, если у тебя есть: Уверенное владение Python (нужно будет писать код, который пойдет в продакшн) и основными ML-библиотеками (numpy, pandas, sklearn, lightgbm и т.п.) Понимание классических методов и алгоритмов машинного обучения, опыт их применения на практике Хорошее знание SQL и умение копаться в источниках, опыт работы с инструментами экосистемы Hadoop (hive, spark) или готовность их быстро освоить Умение переложить бизнес-задачу на язык анализа данных, подобрать соответствующий алгоритм с учетом требований и ограничений, интерпретировать результат Хорошее знание теории вероятностей и математической статистики Будет плюсом: Опыт выведения моделей в продакшн Опыт с инструментами нашего стека (чем больше, тем лучше) Участие в хакатонах и соревнованиях по машинному обучению (например, Kaggle). Наш стек: Python, Spark, Hadoop, Hive, Airflow, Docker, k8s, MLFlow Git, Jira, Confluence.","Python,Linux,SQL,Математическая статистика,Hadoop,Git,Atlassian Jira,Spark,Data sciense,Анализ данных,Analysis,Статистика,Big Data,Статистический анализ","билайн: Т, Data, Digital",
6881,71220088,Middle/Senior Data Engineer,от 200 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Мы специализируемся на разработке программного обеспечения больших, высоконагруженных и производительных систем, созданием сервисов и клиентских приложений для букмекерских компаний.  В настойщий момент в команду Data Science ищем опытного Data Engineer для решения вопросов с данными для построения моделей оттока, антифрода, рекомендаций, разработки дашбородов для мониторинга ключевых клиентских метрик. Вас ждут миллионы клиентов и миллиарды транзакций, возможность раскрыть свой потенциал и получить удовлетворение от того, как результаты вашего труда дают эффект в реальном бизнесе.  Чем предстоит заниматься: звлечение, преобразование, загрузка данных и их обработка Построение датасетов для data science моделей и аналитики Построение надежных и оптимальных пайплайнов обработки данных нтеграции с новыми источниками данных Оптимизация вычислений и затрат на хранение данных Что мы ожидаем от кандидата: Уверенные знания SQL и опыт работы с базами данных Опыт написания процессов загрузки данных ETL Уверенное знание Python (Pandas, Numpy), опыт разработки, желание писать аккуратный и красивый код Желателен опыт работы с командной строкой Linux (Bash) и GitHub Опыт работы с Hadoop, Pyspark будет преимуществом Желательно понимание терминов Data Sciencе при работе с данными (обучающая и валидационная выборки, Data Leak) Что мы предлагаем: Оформление в штат компании, полное соблюдение ТК РФ (отпуск, больничный), официальная заработная плата Персональный гибкий график После испытательного срока мы подключаем ДМС и еженедельное посещение спорт зала А еще: Лучшая техника (Apple) и софт нтересная предметная область и сложные технические задачи, возможность развития и роста Просторный и современный офис в 10 минутах пешком от м. Домодедовская, в котором комфортно работать и приятно общаться с коллегами Бизнес-ланчи в нескольких ресторанах рядом с офисом Компании Уютные кухни-столовые с чаем, кофе и конфетами  Для того, чтобы мы быстрее связались с Вами, просим ответить на простой вопрос при отклике.","SQL,ETL,MS SQL,Apache AirFlow,Python,Pandas,Numpy,Bash,GitHub,Git",24Н Софт,"Москва, Домодедовская, Шипиловская улица, 28А"
6883,79221567,Data Engineer,от 80 000 руб. на руки,1–3 года,"Полная занятость,полный день","Компания, специализирующаяся на бизнес-аналитике (BI), расширенной аналитике данных (Advanced Analytics) и архитектуре данных для бизнес-аналитики, приглашает Data Engineer Мы предлагаем: Заработная плата от 80 000 рублей оклад+бонусы полностью удаленно график 5/2, ненормированный рабочий день дружная профессиональная команда официальной трудоустройство, гарантии и компенсации в соответствии с ТК РФ внутренние и внешние конференции, форумы, курсы повышения квалификации возможность быстрого профессионального и карьерного роста. Обязанности: Участие в полном цикле разработки Data engineering проектирование и разработка архитектуры баз данных, структур данных, таблиц, словарей разработка процессов с использованием средств ETL Informatica Power Center, SQL Server Integration, IICS, AzureDataFactory(ADF), Databricks. . Требования: Опыт работы от года высшее техническое профильное образование (Прикладная математика, Прикладная информатика, Бизнес информатика…) разговорный английский. Отличное знание: IICS, AzureDataFactory (ADF), Databricks, SQL, Excel",,Кадровое Агентство Уникальных Специалистов,
6884,74377863,Бизнес-аналитик (Big Data),з/п не указана,1–3 года,"Полная занятость,удаленная работа","В центральном офисе федеральной розничной сети ""Лента"" открыта вакансия Бизнес-аналитика в Департаменте BigData. Задачи: выявление, управление и поддержка бизнес и функциональных требований написание функциональных спецификаций ПО, включая use cases и диаграммы поддержание актуальности документации взаимодействие с заказчиками, DS, DA Требования: опыт работы Бизнес-аналитиком от 2-х лет владение основами теории алгоритмов, баз данных, систем и системного анализа, защиты информации опыт моделирования рабочих процессов и данных, проектирования систем и написания спецификаций владение основными нотациями моделирования (BPMN, UML) базовые знания SQL высшее образование Мы предлагаем: возможность работать над технически сложными задачи удаленная работа годовое премирование по результатам годовой оценки ДМС, включающий стоматологию оформление по ТК РФ, полный спектр социальных льгот","UML,BPMN,SQL,Бизнес-анализ","Лента, федеральная розничная сеть, IT",
6885,78052551,Data Engineer (аналитик больших данных),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Обязанности: Разработка и поддержка инфраструктуры для хранения и обработки данных Создание ETL-процессов, используя внутренние и внешние источники данных Обеспечение полноты и доступности данных для решения задач в области статистического анализа и машинного обучения Наш технологический стек: CDH, Hadoop, Spark, Kafka, Hive, Impala, Kudu, Hue, Zeppelin, Jupyter, StreamSets. Требования: Опыт работы с распределенными системами хранения и обработки данных: Cloudera, Hadoop, Spark, Hive, Impala, Kudu Опыт работы с распределенными системами построения потоков данных: Kafka, Oozie, Airflow, StreamSets Опыт проектирования схем хранения данных Владение языком программирования Python Уверенные знания SQL Опыт администрирования OC Linux Желателен опыт администрирования Tableau Желателен опыт сбора информации о действиях пользователей с UI (web, mobile app). Условия: У нас нет бессмысленного формализма и дресс-кода, мы не занимаемся микро-менеджментом и осмотрительно относимся к KPI Удаленный режим работы Амбициозные и интересные задачи Конкурентная заработная плата в полном соответствии с ТК РФ Соцпакет с первого дня работы (ДМС, скидки на корпоративные продукты Сбера) Стабильная Компания","Python,SQL,Linux",Деловая среда,
6886,76863778,Senior Data Analyst (Marketing),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы в Space307 разрабатываем международную торговую платформу. Каждый день у нас в онлайне 255 тысяч уникальных пользователей из 100+ стран. У нас плоская структура и нет просто исполнителей. Каждый из нас — спец в своей области, и принцип работы простой: к нам приходят с проблемой, а мы отвечаем решением. Наш проект с большим количеством фич и вся разработка ведется в кросс-функциональных командах.  Сейчас команда Marketing Analytics находится в поисках опытного маркетингового аналитика.  ЧЕМ ПРЕДСТОТ ЗАНМАТЬСЯ: Оценивать эффективности UA и Reengagement/Retargeting кампаний. Формировать дизайн метрик популярности контента и успешности брендовых рекламных кампаний, составлять рекомендаций по контенту на основе анализа пользовательских предпочтений. Проводить A/B тесты. Определять необходимое количество наблюдений для получения статистически значимых результатов. Проводить инкременталити тесты ретаргетинговых активностей. Заниматься сегментацией пользователей. Анализировать аномалии, искать точки роста и инсайты в данных. Помогать команде маркетинга с гипотезами, метриками и экспериментами. Собирать и поддерживать отчетность для команды. В будущем внедрять ML-модели, строить скоринг системы, сегментировать пользователей Прогнозировать жизненный цикл пользователей (LTV, LT, ROI etc). Анализировать медиа показатели контента в диджитал среде. КЛЮЧЕВЫЕ ТЕГ ПРОЕКТА: SQL, Python / R, Google Analytics, AppsFlyer, DataStudio, Qlik, Excel/Google Sheets МЫ ЖДЁМ, ЧТО ТЫ: меешь опыт запуска A/B тестов, сетап тестов, анализа эффективности полученных результатов. Знаешь как анализировать поведение аудитории на платформе, проводить сегментацию аудитории. Владеешь SQL на уверенном уровне (оконные функции, оптимизация запросов). меешь опыт работы с аналитическими базами данных (Vertica, Clickhouse, Redshift, Snowflake, Google BigQuery, etc.). Владеешь скриптовым языком (Python/R) на хорошем уровне. меешь опыт создания простых дата-пайплайнов (DBT, Airflow, Luigi и т.д.). БУДЕТ ПЛЮСОМ: Опыт работы с инструментами анализа: Google Analytics, Firebase и т.д. Опыт работы в проектах Retention/Retargeting со стороны маркетинга или продукта. Опыт построения моделей атрибуции. Опыт работы с BI-платформами (Google DataStudio, QlikView, MS PowerBI и т.д.). Знание математической статистики и теории вероятности. Понимание app/web трекинга (как настраивается, для чего нужен в закупке трафика, опыт работы с системами трекинга – Appsflyer/Adjust/Firebase, GoogleAnalytics/Amplitude и пр.). Понимание принципов работы SKAN атрибуции. Опыт работы с MMP и анализом CJM. Знание метрик для оценки успешности рекламного контента. ЧТО ТЕБЯ ЖДЕТ В SPACE307: Комфорт и достойные условия: гибкий график, удалённая работа ворлдвайд и, конечно же, конкурентный уровень заработной платы. Честность, прозрачность и отсутствие бюрократии. Структура, в которой нет «СЕО минус четыре» — мы все равны и каждый отвечает за результат. Мероприятия на любой вкус: тренинги, семинары, конференции, лекции, мастер-классы. А также тимбилдинги и корпоративы, впечатляющие своим масштабом. Хакатоны, марафоны, квесты и турниры: коллеги объединяются в команды, создают крутые идеи и проекты и получают за это не менее крутые призы. Настоящая команда: здесь дают честный фидбэк, приходят на помощь и болеют за результат.","SQL,Python,Маркетинговые исследования",Space307,"Санкт-Петербург, Горьковская, Чкаловская, улица Кропоткина, 1"
6887,78731177,Data analyst (Sales),от 150 000 руб. на руки,1–3 года,"Полная занятость,полный день","Кто мы: BestDoctor — экосистема медицинских и страховых сервисов, созданная экспертами для удобного управления здоровьем. Мы меняем рынок медицинского страхования и отношение людей к своему здоровью с помощью качественного сервиса и принципиально нового клиентского опыта. Благодаря глубокой экспертизе в создании медицинских решений и любви к своему делу, нам удалось создать ту самую экосистему полезных, эффективных и, главное, простых медицинских сервисов для управления здоровьем компаний и людей. Чего мы достигли:  За семь лет мы вышли на второе место по числу клиентов среди insurtech компаний в Европе. Сегодня с нами уже 100 000+ застрахованных пользователей (40 000 из них мы подключили в 2021 году), а в списке клиентов — Aviasales, МТС Банк, Нетология, InDriver, Эвотор, Ivi.ru, Ostrovok.ru, VC.ru и еще 140 компаний.  Создали экосистему медицинских сервисов, которая включает в себя: сервис онлайн-поддержки 24/7, сервис онлайн записи в оффлайн клинику, свою виртуальную клинику, сервис второго мнения специалиста, чекапы, сервис психологической поддержки и др.  Запустили свою страховую BestInsure - на базе которой мы развиваем линейку страховых сервисов (страхование критических заболеваний, имущества, страхование от несчастного случая, страховки на время путешествия и др.). Кого мы ищем: Мы ищем опытного data-аналитика в команду ДМС, который будет формировать дерево метрик в воронке продаж и строить дэшборды на основании этого дерева, а также сегментировать базу клиентов в CRM и разрабатывать её приоритизацию. Тебе предстоит: Совместно с бизнесом глубоко погружаться в воронку продаж ДМС, искать узкие места и предлагать решения Создавать дэшборды, собирать аналитических отчеты и делать выводы на основе этих данных Оценивать эффективности реализуемых проектов Выполнять ad-hoc запросы, проверять гипотезы на данных Взаимодействовать с командой разработки (постановка задач по доработке аналитики) Контролировать корректность поступающих данных из различных источников данных. Мы ожидаем, что ты: меешь опыт работы на аналогичной должности от 2-х лет Отлично владеешь SQL: сложные запросы, cte, оконные функции. Круто, если умеешь понимать и оптимизировать план запроса Умеешь визуализировать данные в одном из BI-инструментов: Tableau / Power BI / Qlik Sense / Microstrategy (мы используем Tableau) Можешь общаться с разработчиками на одном языке и можешь самостоятельно взаимодействовать с заказчиками Знаешь Python и библиотеки для анализа данных (Pandas, Numpy) Умеешь реализовывать поставленные бизнес-запросы меешь опыт в самостоятельном проведении A/B-тестов. Nice to have! Опыт работы бизнес/системным аналитиком будет преимуществом. Как мы нанимаем: Мы готовы оперативно выходить с оффером, если понимаем, что подходим друг другу. 1 этап - телефонное интервью с HR (15-20 минут) 2 этап - техническое интервью с экспертами команды аналитики 3 этап - финальное интервью с CDO и HR. Почему с нами круто? Ты можешь подобрать формат работы под себя: офис (ст.м. Савёловская), микс, полная удаленка У нас гибкий график работы, который подойдет как жаворонку, так и сове Тебя будет окружать команда талантливых и мотивированных людей Мы предоставим тебе ноутбук и всю необходимую технику, которая позволит эффективно и комфортно работать ДМС от BestDoctor после испытательного срока.  Ты будешь частью большого социально значимого дела. Мы реализуем амбициозную задачу — меняем рынок страхования и здравоохранения, действительно помогаем людям, и у нас это отлично получается.  у тебя получится!","SQL,Python,Tableau,Power BI,A/B тесты,Анализ данных",BestDoctor,"Москва, Савёловская, Савёловская, Вятская улица, 27с15"
6889,79093164,Middle Data Scientist в продукт МТС Маркетолог (Big Data),з/п не указана,1–3 года,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Middle Data Scientist в ad-hoc команду продукта МТС Маркетолог Описание продукта: В продукте мы помогаем внешним и внутренним клиентам запускать таргетированные рекламные кампании на основе данных Big Data МТС: формируем гипотезы, проводим AB тесты, ищем новые и необычные сегменты для клиентов, проводим Post аналитику рекламных кампаний, постоянно подключаем новые источники данных и работаем с ними. Обязательно: Знание python на продвинутом уровне (ds, ml библиотеки – sklearn/catboost, lgbtm) Опыт работы с Hadoop, Apache Spark, SQL Сильные теоретические знания ML Умение переложить бизнес задачу на язык анализа данных, умение простым языком объяснять сложные вещи, интерпретировать результат (придется работать, как с внешними, так и с внутренними заказчиками) Что предстоит делать? Строить модели предсказания поведения пользователя Работать с базами данных (проводить проверку и приемку витрин для дальнейшей работы по части ML) Документировать процессы и процедуры, связанные с разработкой моделей Проводить А/В тесты, дизайнить эксперименты, вводить культуру проведения A/B тестов в продукте Писать ТЗ для инженеров  Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Python,SQL,Apache Spark,Hadoop,ML,A/B тесты",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
6890,77435759,Data-аналитик,от 700 000 до 950 000 KZT на руки,1–3 года,"Полная занятость,полный день","Kolesa Group — международная IT-компания, строим классифайды для 12,5 миллионов пользователей. Наши продукты — kolesa.kz | krisha.kz | avtoelon.uz — помогают людям и бизнесам продавать, покупать и владеть авто, недвижимостью, товарами и услугами. Культура экспериментов, командный дух, технологии, постоянное развитие и желание достичь крутых результатов — отличительные черты Kolesa Team. В наш отдел Аналитики, который занимается крутыми проектами: находит точки роста продуктов, строит модели монетизации, визуализирует бизнес-показатели и конверсии, находит в данных инсайты и предлагает бизнесу решения требуется Data-аналитик. Команда состоит из крутых профессионалов, собранных из разных точек мира и ставит перед собой амбициозную задачу – построить Data Driven Company.  главное, мы делаем полезные для миллионов людей проекты! Присоединяйтесь! Тебе предстоит: Анализировать показатели сайтов и приложений для принятия продуктовых решений Визуализировать данные, создавать отчеты и делать выводы Контролировать внедрение новых продуктовых событий и метрик скать инсайты в большом объеме данных для формирования продуктовой стратегии Работать с менеджерами продуктов, дизайнерами и командой разработки Формулировать гипотезы, запускать A/B тесты, causal inference эксперименты и подводить итоги Обеспечивать качество сбора данных активно работать с DWH-инженерами спользовать инструментарий ML для более глубокого понимания и решения бизнес проблем Разрабатывать и изучать новые методики анализа данных в продукте. Мы стараемся следовать за state-of-the-art решениями в анализе данных. Мы ждем от тебя: Опыт работы с SQL Опыт работы с Python (знание R будет плюсом) Навыки применения аналитики для решения бизнес проблем. Будет преимуществом: Опыт работы со стеком Google Cloud (наша DWH построена на Google Big Query) или другими облачными хранилищами Знание и опыт работы в BI системах (мы используем Microsoft Power BI) Знание и навыки проведение экспериментов. АБ-тесты, Causal Inference методики, бутстрап и прочее Большим плюсом будет релевантный опыт в диджитал-компаниях (продуктовые/бизнес аналитики) Опыт работы с ETL и системами оркестрации (предпочтительно Airflow). Что приятного предлагаем: Возможность использования современных технологий Профессиональный рост all inclusive (система грейдов, индивидуальные планы развития, менторство) Клевые тематические мероприятия (квизы, киновечера, Family Day, тимбилдинги) Обучение английскому языку Посещение зарубежных конференций, участие в митапах, тренингах и мастер-классах, доступ к огромной tech-библиотеке Социальный пакет на выбор: медицинская страховка по VIP-пакету, оплата фитнеса, услуги стоматологии, обучения, курс массажа, услуги психолога, авиабилетов, талоны на бензин, компенсация дет.сада или частных школ Скидки на оплату фитнеса, lamoda, skillbox, skyeng, geekbrains Современные и уютные офисы, открытые для сотрудников 24/7 (возможен гибридный формат работы) Программа релокации для иногородних сотрудников","Microsoft Power BI,Python,SQL,A/B тесты",Колеса,"Алматы, улица Шевченко, 157Б"
6892,78821598,Data analyst,з/п не указана,1–3 года,"Полная занятость,полный день","В нашу команду требуется Data Analyst. Наша команда отвечает за работу системы автоматизированного подбора персональных предложений Клиентам Сбера. обязанности · Развитие и поддержка системы выбора лучших предложений для Клиентов · Организация процессов сбора и обмена данными с другими бизнес-командами · Анализ бизнес-процессов и разработка автоматизированной отчетности · Мониторинг и аудит работы системы (процесс, качество и сбои) · Формирование и проверка гипотез по улучшению работы системы требования · Опыт работы в роли DA/DS/BA от 2 лет · Опыт разработки на Python от 1 года · Знания SQL, PL/SQL · Знание основ мат. статистики и теории вероятностей · (будет плюсом) Опыт работы с экосистемой Hadoop (PySpark, HIVE) · (будет плюсом) Знания в области Machine Learning · (будет плюсом) Опыт работы в банковской сфере условия • стабильный оклад и социальная поддержка сотрудников • расширенный ДМС с первого дня работы для сотрудников и льготная медицинская страховка для близких • бесплатная подписка СберПрайм+, скидки на продукты компаний-партнеров • корпоративная пенсионная программа • корпоративное обучение за счет компании • реферальная программа для сотрудников: можно пригласить в команду знакомых профессионалов и получить вознаграждение до 100 тыс. рублей • официальное оформление с первого дня • корпоративный спортзал и скидки в спортзалы-партнеры • мощное железо, дополнительные мониторы и всё, что нужно для продуктивной работы • современный офис с системой «умный дом», зонами отдыха и balance-бордами",,Сбер. IT,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
6893,78715073,Аналитик данных / Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем коллегу на роль: Аналитика данных. Основные направления бизнеса: Аналитический консалтинг - предоставляем услуги, позволяющие организациям принимать оптимальные решения на основе существующих данных и продвинутой аналитики Разработка продуктов - разрабатываем собственные решения по анализу и визуализации данных Обязанности: Разработка дашбордов Подготовка регулярных и AD HOC аналитических отчетов Описание потоков данных Взаимодействие с продуктовыми командами, сбор и актуализация информации о логических сущностях, системах и связях Проектировка системы показателей, разработка алгоритмов расчета. Мы ожидаем: Опыт работы SA/DA от 2 лет Опыт работы с BI платформами Уверенное владение SQL (в том числе оконных функций, CTE и т.д.) Понимание архитектуры аналитических хранилищ данных. Будет плюсом: Владение Python Навыки презентаций и выступлений Техническое высшее образование. Мы предлагаем: Гибкий график работы Комфортный офис с современной техникой и панорамным видом на город в 8 минутах пешком от м. «Дмитровская» или удаленная работа на территории РФ ндивидуальный план развития с ежегодным пересмотром заработной платы Оплата обучения и участие в профессиональных мероприятиях Система наставничества для новых сотрудников ДМС со стоматологией и ОНКОзащитой после испытательного срока Подарки сотрудникам и их детям к праздникам Меры поддержки для аккредитованных Т-компании от государства (запись в реестре № 14564 от 30.07.2021)","SQL,BI",Квиллис,"Москва, Дмитровская, Новодмитровская улица, 2к1"
6897,78855362,Аналитик данных / Data Analyst / Data Scientist,от 80 000 руб. до вычета налогов,3–6 лет,"Полная занятость,полный день","НАПРАВЛЕНЕ: Анализ речевых и текстовых коммуникаций Уважаемые соискатели, обратите внимание, сотрудник требуется в офис, удаленная работа на постоянной основе невозможна. ОБЯЗАННОСТ: настройка платформы речевой и текстовой аналитики DEERAY под задачи клиента формирование отчетности с учетом потребности Заказчика проектирование, анализ, оптимизация и формирование отчетности (включая дашборды), в том числе в BI-системах формирование и проверка гипотез в рамках анализа клиентских коммуникаций построение глубокой аналитики на основе смысловой и эмоциональной составляющей клиентских коммуникаций (поиск ошибок операторов и кейсов для оптимизации, инициация изменений для сценариев продаж и обслуживания, составление рейтингов / анти-рейтингов, аналитика повторных обращений, аналитика по результатам CSI и NPS и др.) формирование аналитических отчетов к построенной аналитике, отчетности и дашбордам участие в коммуникациях с внешними и внутренними заказчиками участие в развитии продукта по своему направлению помогать в очистке данных и прочих «внутренних» задачах. ТРЕБОВАНЯ К КАНДДАТУ: высокая проактивность, нацеленность на результат и профессиональный рост продвинутый пользователь Excel, Query знание SQL, Phyton не ниже среднего уровня английский не ниже pre-intermediate (A2) высшее образование (желательно по направлению информационных технологий, экономики) умение работать с большими массивами данных практический опыт применения математических и статистических методов анализа грамотная речь (письменная и устная), коммуникационные навыки. БУДЕТ ПРЕМУЩЕСТВОМ, ЕСЛ КАНДДАТ ОБЛАДАЕТ: умением работать в тайминге, знание методологий Agile, Scrum опытом проектирования витрин данных в Yandex DataLens и/или работа с BI-системами опытом работы на аналогичной позиции опытом работы с платформами текстовой и/или речевой аналитики опытом работы с AI/ML-решениями английским upper-intermediate (B2). ЧТО МЫ ПРЕДЛАГАЕМ: оформление согласно ТК РФ, выплаты 10 и 25 числа каждого месяца работа в аккредитованной Т-компании пятидневка, по согласованию с руководителем возможен гибкий график работы или дистанционная работа культура открытости, наставничества и взаимопомощи сложные и интересные задачи возможность предлагать идеи и развивать экспертизу в сфере AI и Big Data влияние на развитие и качество продуктов корпоративное обучение ДМС карьерные перспективы в рамках компании современное оборудование и любовь к инновационным технологиям уютный офис в верхней части города (г. Нижний Новгород) с доступной парковкой, кофемашиной, корпоративной профессиональной библиотекой и многое другое. УСПЕЙТЕ ПРСОЕДНТЬСЯ К КОМАНДЕ DEERAY!","Python,Jupyter Notebook,Business Intelligence Systems,Data Analysis,Анализ данных,Аналитическое мышление,Big Data,ML,MS Excel,ETL,A/B тесты,Mathematical Statistics,SQL,Power Query,Работа в команде,Data Science,Математическая статистика,Регрессионный анализ,Статистический анализ,Git,Английский — B1 — Средний",DEERAY,
6898,78960197,Data Engineer/Data Analyst в команду CSI/NPS,з/п не указана,1–3 года,"Полная занятость,полный день","Мы команда исследования и аналитики клиентской удовлетворенности, находимся в управлении клиентским опытом B2C. Занимаемся организацией опросов удовлетворенности и лояльности (CSI/NPS), сборкой отчетности и аналитикой по этим показателям. На текущий момент проводим опросы более чем по 200 направлениям и количество опросов продолжает расти. Нам необходимо выстроить процесс мониторинга, траблшутинга и восстановления работоспособности опросов/отчетности. менно для это задачи мы ищем человека. Обязанности Работа в основном в роле DE, меньше DA. Сбор витрин данных для мониторинга (с выводом статистики на экран с помощью BI инструментов), Восстановление и сопровождение инцидентов по неработоспособности опросов/отчетности, Автоматизация и улучшение процессов Требования Продвинутый уровень SQL. (БД: GreenPlum, Hadoop) Python. Базовые навыки. Excel. Продвинутый уровень. Опыт в автоматизации как плюс (airflow, cron и др) Условия комфортный офис на Кутузовском проспекте с тренажерным залом, коворкинг-пространствами и кафе полный рабочий день, но гибкий график работы (можно выбрать режим начала работы в промежутке 7:00 - 10:30) ДМС, программы лояльности для сотрудников (льготное кредитование, предложения экосистемы Сбера) комьюнити data-people, множество программ профессионального обучения (курсы, тренинги, конференции, семинары).",,Сбер для экспертов,
6899,76826976,Lead/Senior Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","R1 — это новый взгляд на пространство, в котором живет человек. Наша команда убеждена, что технологии способны сделать дом многофункциональным, удобным и универсальным как для семейных вечеров, так и для работы днем. Наша миссия — делать технологии понятными и доступными, чтобы каждый человек мог качественно улучшить свою жизнь, сделать собственный дом своим местом силы. Среди наших проектов развлекательная smart-платформа Movix, устройства и приложения для «умного дома», e-commerce и др. Мы также уделяем большое внимание развитию и обслуживанию наших проектов, создавая и тестируя новые продукты в технической лаборатории Movix Lab, и вместе с командой CTO Office, которая занимается разработкой инфраструктурных сервисов всей компании. Мы запускаем уникальный проект по рестарту функции клиентоцентричных продаж в базу и максимизации ценности клиента (CVM). Цель проекта - создание системы для предложения клиентам нужных продуктов в правильное время с удобным клиентским опытом. Мы хотим: Предвосхищать потребности конкретного клиента Предлагать только, нужные клиенту продукты сейчас Обеспечить персонализированные омниканальные клиентские пути Внедрять постоянные улучшения на основе обратной связи от клиентов Обеспечить гибкую операционная модель и Т архитектура. Обязанности кандидата: Управление группой аналитиков из 4 человек Участие в разработке и поддержке data driven решений в продуктовых командах Поиск инсайтов и паттернов в поведении пользователей Построение и поддержка регулярных отчетов и ad-hoc запросов Подготовка, анализ и ускорение процесса А/Б-тестирования (CUPED, Линеаризация) Участие в проектировании целевой архитектуры совместно с технической командой. Требования к кандидату: Глубокое понимание продуктовых и бизнес-метрик Владение Python и соответствующими библиотеками для анализа данных Уверенное знание SQL, умение строить сложные запросы и оптимизировать производительность Базовое понимание распределенных вычислений на кластере. Будет плюсом: Опыт разработки data pipelines на Spark с применением Luigi/Airflow/Oozie. Мы предлагаем: Оформление по ТК РФ, полностью белая з/п ДМС со стоматологией после испытательного срока, 100% компенсация больничного Скидки от компаний-партнеров Удаленка, гибрид или работа в офисе - на ваш выбор Кроме того, R1 аккредитована как IT компания.","Python,SQL,A/B тесты,Ad Hoc Analysis",Эр-1,
6902,77186103,Senior Data Analyst,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Чем предстоит заниматься: Проверять гипотезы, проводить разведывательный анализ данных и искать точки роста в маркетинговых и продуктовых взаимодействиях с пользователем Строить BI-отчетность по различным процессам компании Улучшать текущий процесс А/Б-тестирования Автоматизировать аналитические процессы совместно с другими аналитиками Активно участвовать и развивать data-driven подход в компании Работать над улучшением механизмов маркетинговой атрибуции доходов компании Наш стек: СУБД: PostgreSQL, ClickHouse, BigQuery ETL, enrichment, research: Airflow + Python BI: Redash + Superset Для успешного выполнения задач тебе потребуется: Опыт работы аналитиком от трех лет Уверенное знание математического аппарата для разведывательного анализа, проверки гипотез и проведения экспериментов Владение SQL на уровне решения любых задач выборки и обработки данных Владение Python или другими ЯП для анализа данных Понимание принципов и метрик e-commerce и продуктовой аналитики Навыки разработки отчетности в BI-системах Знание английского языка Работа в Movavi – это: Быть частью продуктовой софтверной компании: все – от концепции до дистрибуции – делаем сами Работать с трендовым рынком мультимедиа Делать 20 приложений и программ, переведенных на 18 языков Получать отзывы от пользователей по всему миру. Нашими приложениями пользуются журналисты BBC из Англии, фотографы из США, видеооператоры из Бразилии, блогеры из России, мы сами, наши друзья, ваши друзья. Может быть, вы? :) Находиться в команде профи, готовых делиться экспертизой Работать удаленно из любой точки мира Если ты не получил ответ на отклик в течение трех рабочих дней: 1. Проверь папку «Спам» в электронной почте. Возможно, письмо с ответом оказалось там. 2. Позвони или напиши нам.","SQL,Python,Английский язык,PostgreSQL,Анализ данных,Английский — B2 — Средне-продвинутый",Movavi,
6903,78617195,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Rubius – IT-компания со смелым характером. Мы разрабатываем софт для клиентов из различных отраслей – от промышленности и нефтегаза до ритейла и медицины. Обосновались в Томске, работаем по всему миру: наше программное обеспечение используют в США, Европе и Азии. Наши решения используют Apple, Tesla, Kaspersky, Amazon, IBM, Uber, Netflix, Газпром, РЖД и другие. В группу компаний входят представительства в США (Нью-Йорк), Казахстане (Алматы, резиденты Astana hub), ОАЭ (Дубай). В нашем профиле на hh.ru мы постарались подробно рассказать о нас, обязательно загляните:) Одна из наших команд, которая занимается искусственным интеллектом, приглашает Data Engineer, так как команда расширяется. Вам предстоит работать с большими данными совместно с аналитиками и командой ML. Мы ищем человека, который умеет собирать витрины, джойнить данные и проверять полученный результат. У нас есть экспертиза по синтезу аудио и видео, анализу изображений и видео, компьютерному зрению, предиктивной аналитике, обработке текстовых данных и тд. Мы исследуем разные сферы от логистики до медицины, погружаемся в сферы наших крупных заказчиков с головой, чтобы помочь оптимизировать процессы. Также команда разработала свой продукт для видео аналитики Visius. Чем предстоит заниматься: проектировать и собирать витрины данных по разработанному ТЗ проектировать, разрабатывать и поддерживать ETL-процессы для загрузки данных из/в Data Lake тестировать результаты преобразования данных и проверять их целостность писать документацию - комментировать код работать с data-аналитиками для создания новых и оптимизации существующих витрин Добро пожаловать к нам в команду, если есть: понимание основных операций ДБ и DWH опыт работы с Hadoop технологиями (Spark, Hive и тд) хорошее знание SQL, Python опыт работы с Azure/Yandex облачными платформами опыт работы с Airflow, Kafka будем плюсом Что мы предлагаем: Сотрудники компании – главная ценность Rubius. Мы поддерживаем свободу творчества и полёт инженерной мысли. Стремимся, чтобы каждый участник нашей команды раскрыл свой потенциал. Мы стараемся максимально заботиться о наших сотрудниках. Здесь удалённые и офисные команды чувствуют себя максимально комфортно. Про работу и оплату белая и своевременная заработная плата в зависимости от компетенций и уровня официальное трудоустройство до 10% ежемесячной премии за хорошие результаты помощь с home office возможно трудоустройство в нашей компании в Казахстане (для желающих получить заветную карту Visa) Про рост и развитие индивидуальный трек развития по желанию бесплатное обучение английскому языку бонус за профессиональное развитие (курсы, подкасты, литература по хард и софт скиллам) компенсация 50% за профессиональную сертификацию внутренние митапы на разные темы Про офис, плюшки и атмосферу оплачиваемые занятия спортом (даже в домашних условиях) программа ДМС после испытательного срока скидка для вас и родственников в Rubius Academy бонусы к рождению детей и свадьбе классные корпоративы и активности развитая и комфортная корпоративная культура, без иерархии и бюрократии А ещё у нас есть лучший офис в Томске, где тебя всегда ждут, сообщества по интересам (футбол, теннис, своя музыкальная группа, шахматный клуб...) и коллектив, где прислушиваются к мнению каждого. Подробнее о нашей компании можно почитать в нашем профиле на hh.ru. Там же есть ссылочки на наши сайты и соцсети. Откликайтесь!",,Rubius,"Томск, улица Нахимова, 13/1"
6904,70163749,Data Scientist (middle/senior),до 400 000 руб. до вычета налогов,3–6 лет,"Полная занятость,полный день","Мы в Rubbles занимаемся созданием Data Science-продуктов и разработкой аналитических решений для различных индустрий: системы предсказания спроса на товары для оффлайн-ритейлов, рекомендательные системы в банках, поисковые системы по товарам для онлайн-ритейлеров и многое другое. Среди наших клиентов: Сбербанк, Пятёрочка, KFC, Перекрёсток, Альфа-Банк, МВидео и др. Мы ищем data scientist'ов уровня middle/senior для усиления нашего направления, которое занимается разработкой систем прогнозирования спроса на товары, ценообразования, автоматического подбора оптимальных промо-акций и др. Обязанности: Моделирование и обработка данных на Python для извлечения бизнес-ценности из данных Построение воспроизводимых и переиспользуемых решений для работы с данными и моделями Детальное обсуждение поставленных перед командой задач и методов их решения совместно с коллегами и бизнес-заказчиками. На что смотрим: Опыт использования ml библиотек на Python (бустинг, нейронные сети и др.) и понимание особенностей реализации различных аспектов алгоритмов в коде Опыт работы на позиции, связанной с промышленной разработкой Понимание методов машинного обучения с точки зрения математики и умение адаптировать их под конкретные задачи Опыт работы с Spark, Pyspark, Pandas, SQL, Hive и др. Опыт проработки задачи от бизнес-постановки до математической формулировки и реализации в коде Опыт автоматизации пайплайнов работы с данными (Airflow и др.) и навыки devops (Docker, Kubernetes и др.). У нас: Работа в одной из самых сильных ML команд в России Гибкий график работы, гибкое предоставление отгулов и отпусков Поддержка в профессиональном и карьерном росте, оплата профильного обучения, конференций и книг, корпоративные скидки на курсы английского Совместная работа с опытными разработчиками, аналитиками данных, менеджерами, продуктологами ДМС со стоматологией после испытательного срока (3 месяца) по всей России При желании работать из офиса – уютный офис в центре Москвы (2 минуты от м. Сухаревская) со всем необходимым для комфортной работы. Особенно актуальное: Мы аккредитованная Т-компания со всеми вытекающими льготами.","Python,Spark,SQL,Machine Learning,Pandas,Машинное обучение,Data Science,Big Data",Rubbles,
6907,78578025,Аналитик Data,от 250 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","В крупный проект ан удалёнку требуется Аналитик DATA Обязанности: Аналитическая часть - Согласование и уточнение требований к системе копирования - Согласование и уточнение требований к системе трансформации OLAP кубов SAS  Разработка - Участие в разработке архитектуры системы копирования данных SAS - Участие в разработке модуля трансформации OLAP кубов SAS в плоские таблицы - Участие в реализация ETL-процесса c копированием таблиц SAS  Документация - Разработка приемо-сдаточной документации - Согласование результатов на тестовом стенде - Участие в приемо-сдаточных испытаниях Требования: - Опыт работы с базами данных в качестве аналитика от трех лет - Опыт участия в проектах по созданию и развитию DWH - Понимание принципов разработки с помощью ETL инструментария - Опыт написания технических заданий на разработку ETL-инструментов - Опыт разработки приемо-сдаточной документации - Понимание предметной области Телеком Понимание нюансов работы платформ Teradata, SAS (особенности DDL,DML,PL/SQL) Уровень: Middle+",,АБП,
6913,77504201,Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Чем предстоит заниматься: Мониторинг и контроль качества данных Сбор/Формирование/Разработка витрин Поиск и анализ несоответствий в данных. Обоснование найденных несоответствий Формирование предложений по улучшению качества данных Анализ и расследования спорных ситуаций начисления процентов Формирование бизнес требований, технических заданий, тестирование доработок, методологическая поддержка Работа в связке с владельцем продукта. Наши пожелания к кандидатам: Высшее образование Опыт работы с крупными массивами данных, умение их анализировать, выявлять закономерности и несоответствия Обладание системным, критическим мышлением, проактивность, инициативность Понимание принципов гибких методологий создания и модификации продуктов (JTBD, Agile, Scrum) Разработка и оптимизация sql-скриптов, хранимых процедур , ETL процессов формирования витрин данных Хорошее понимание баз данных SQL и NoSQL Опыт работы с большими данными: Hadoop, Spark, Kafka Знание алгоритмов и структур данных Понимание основ распределенных систем Продвинутый пользователь SQL. Наши условия: Стабильный и прозрачный доход: размер заработной платы обсуждается по итогам собеседования Среда для твоего неизбежного развития: тебя ждут сложные и интересные задачи с использованием большого массива данных, у нас регулярно проходят тренинги, вебинары, у тебя будет доступ к бесплатным корпоративным библиотекам Альпины, МФа и бизнес - изданий, скидки на курсы иностранных языков Чувство локтя: у нас дружелюбная атмосфера и команда лучших профессионалов, которые готовы делиться с тобой экспертизой Забота о твоем здоровье: программа ДМС, куда входит стоматология и обслуживание в лучших клиниках города, бесплатный фитнес-клуб на территории Банка, неформальные спортивные сообщества Возможности для разнообразного досуга: скидки на услуги туристических агентств, продукты питания, в рестораны и бары, в магазины и салоны красоты.","SQL,Scrum,Анализ данных,MS PowerPoint",Альфа-Банк,
6914,77413250,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","В отдел по работе с фискальными данными требуется Data Analyst. Мы ищем не просто коллегу, который будет заниматься реализацией проектов, но и единомышленника! Вакансия открыта в г. Нижний Новгород, полностью удаленного формата работы нет.  Что нужно будет делать? Формировать SQL-запросы в соответствии с аналитическими задачами Заниматься подготовкой данных для дальнейшей аналитики (чистка данных, аудит данных, реструктуризация и группировка и т.п.) Анализировать и визуализировать структуры данных Визуализировать средствами Python и MS Excel Формировать простые отчеты, в соответствии с техническим заданием Анализировать распределения, выбросы, коренные причины, формировать предложения по модификации исследовательской задачи на основе данных Разрабатывать и тестировать аналитические модели, проверка гипотез Анализировать и обрабатывать массивы данных, в соответствии с аналитическими задачами Формировать отчеты по результатам анализа данных, в соответствии с техническим заданием. Что для этого нужно? Опыт работы от 1 года Владение базовыми методами статистического анализа Практический опыт работы с SQL: подзапросы, объединения, агрегации, фильтрация Практический опыт работы с Python: re, pandas, numpy, matplotlib Уверенное владение Excel (построение таблиц, отрисовка графиков, работа с функциями ВПР и т.п.). Будет плюсом: Знание методов статистического тестирования и анализа Опыт построения прогнозных моделей Знание методов машинного обучения Понимание структуры данных торговых сетей Опыт формирования презентаций в MS PowerPoint Умение обработки больших объемов данных. Что предлагаем? Возможность развить свои навыки анализа и обработки данных на реальных проектах в команде опытных аналитиков и датасаентистов Возможность освоить методы data science.","Python,Анализ данных,SQL,MS PowerPoint,Статистический анализ",Моризо Диджитал,"Нижний Новгород, Горьковская, Алексеевская улица, 6/16"
6915,78898370,AntiFraud Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","AntiFraud — дружная команда, которая противодействует мошенничеству в банке. Наш продукт — это новая система фрод-мониторинга с автоматизированным выявлением подозрительных событий и пользовательским интерфейсом с информацией для расследований. Система поможет минимизировать ущерб клиентов и банка от действий мошенников. Мы собираем, обрабатываем и анализируем Big Data, создаем и оптимизируем алгоритмы выявления подозрительных событий, планируем внедрить машинное обучение. Нам нужен настоящий Шерлок Холмс, который на основе источников данных сможет найти самых неуловимых мошенников, сформировать правила для их выявления и поможет команде автоматизировать этот процесс. Мы постоянно растем, не боимся экспериментировать и будем рады сделать все для того, чтобы тебе было с нами интересно. При желании ты сможешь развиваться в Data Engineering/Data Science, а команда будет готова помогать в процессе обучения.  Чем предстоит заниматься анализировать данные из различных систем банка строить витрины искать закономерности в данных и подозрительные цепочки действий реализовывать алгоритмы поиска мошеннических действий (PySpark, Python) визуализировать результаты выстраивать коммуникации с другими командами в части получения/анализа данных и оптимизации мониторинга. Наши ожидания опыт работы в антифроде хорошее владение SQL хорошее владение Python для анализа данных и умение писать эффективный код желание глубокого погружаться в задачи готовность общаться с бизнесом умение визуализировать данные желание изучать новое и искать лучшие решения для задач команды желание расти и развиваться. Будет плюсом знакомство с экосистемой Hadoop опыт работы со Spark опыт работы с Git. Мы предлагаем возможность работать из офиса или удаленно, главное — договориться с командой профессиональное развитие в области Big Data возможность присоединиться к Data Science, Python, Data Engineering-комьюнити в банке, где коллеги обмениваются опытом и помогают друг другу комфортную атмосферу для развития и возможность активно участвовать в принятии важных решений внутреннее и внешнее обучение за счет банка страховку со стоматологией, которая работает как в Москве, так и в регионах льготные условия по продуктам банка тысячи скидок на покупки и услуги от наших партнеров — можно дешевле ходить в рестораны, летать на самолетах и жить в отелях стандартные 28 дней отпуска, возможность брать дей-офф по личным причинам, оплачиваемый больничный современный офис с собственным фитнес-залом в трех минутах от станции метро «Технопарк».",,Райффайзен Банк,
6917,54513152,Financial Data Analyst,з/п не указана,не требуется,"Полная занятость,полный день","Claro is seeking a Financial Data Specialist to join our growing team in Minsk, Belarus. The role is focused on curating and validating financial data and content relating to companies, industry sectors and jobs for publication on the website. Claro uses advanced data aggregation technology including machine learning and natural language processing techniques, and the role of the content team is to validate and curate the data that is collected, as well as continually improve and streamline the collection and validation process. Responsibilities Create company profiles for publication on public-facing website and gather financial data of companies for publication on public-facing website, using proprietary admin interface and data aggregation technology Monitor and improve data quality throughout the platform Research and complete topical analyses on companies and sectors, e.g. team composition, financial and operational metrics analysis on selected sector groups Identify and recommend improvements to content creation profile throughout the team, for development and implementation by the technology team Must have Very good/Excellent written and spoken English Ability to understand financial statements of companies  General Requirements Strong computer skills, e.g. experience with spreadsheets (e.g. Excel or Google Sheets) Basic knowledge of HTML/CSS and other web technologies is valued Energetic and entrepreneurial mindset - able to overcome challenges and constraints, go above and beyond, raise the bar Strong execution, communication and organization, comfortable executing with little oversight to drive results, highly adaptable and strong ability to think ahead Excellent attention to detail and system thinking","MS Excel,Business English,Analytical skills,Financial Analysis",Кларо Дата Солюшнс,
6919,77659634,Аналитик Данных / Data Analyst (Ценообразование),з/п не указана,1–3 года,"Полная занятость,удаленная работа","В Департамент анализа данных и машинного обучения ищем специалиста на позицию Аналитик Данных. Команда создает аналитические продукты с целью оптимизации процессов управления ценами и скидками по товару. Чем предстоит заниматься: сследованиями для получения новых знаний, полезных для принятия продуктовых решений Анализом влияния доработок алгоритмов на продуктовые и технические метрики, искать проблемные места и предлагать решения по улучшению Проектированием продуктовых и технических метрик продукта, создавать дэшборды для их отслеживания. Стек наших технологий: В разработке используем: Python, Spark, Oracle SQL, Hadoop, AirFlow Для организации работы: Jira, Confluence, Miro, Git. Мы ждём от наших будущих коллег: Высшее образование Аналитический подход к решению задач, желание самостоятельно генерировать идеи Уверенное владение SQL (опыт работы с большими данными, оптимизации запросов, уверенное знание оконных функций) Базовые знания Python Опыт работы аналитиком от 2-х лет Знание базовых алгоритмов ML и опыт работы в agile командах будет преимуществом.",,"Компания «СПОРТМАСТЕР», Sportmaster Lab","Москва, Аэропорт, Кочновский пр., 4К3"
6922,78908230,Data Analyst/Data engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы – сплоченная команда единомышленников, которая разрабатывает автоматизированную систему управления биометрией, через которую проходят все запросы на регистрацию, аутентификацию, идентификацию (и др.) по биометрии пользователей. Уже сейчас мы умеем работать с биометрией по лицу, голосу, пальцам, в будущем планируем расширять свои возможности. Вам предстоит принять непосредственное участие в развитии биометрических технологий, которые активно используются внутри подразделений Сбера и внедряются у партнеров банка. Наша команда расширяется, в связи с чем мы ищем уверенного Data Analyst / Data Engineer для участия в разработке новых и совершенствовании существующих биометрических алгоритмов. Задачи Выявление аномалий в данных, построение гипотез для поиска слабых мест в новых и существующих процессах Обогащение, структурирование, версионирование данных Проведение валидации и оценка показателей новых и существующих моделей Разработка, документирование и версионирование протоколов тестирования биометрических моделей Структурирование и реализация методологий тестирования биометрических моделей (ISO/IEC, NIST, ГОСТ). Наши ожидания Знание подходов к тестированию моделей машинного обучения Умеете объективно оценить качество работы модели Достаточный математический бэкграунд для решения перечисленных задач, отличное знание теории вероятностей и математической статистики Владение Python стеком: multiprocessing, numpy, scipy, pandas, matplotlib, bokeh, opencv, flask Владение Linux shell на уровне, достаточном написания утилит для работы с данными Опыт работы с реляционными базами данных, знание SQL меете достаточный уровень владения английским языком для быстрого чтения статей Вы можете писать чистый код, в котором другие исследователи/разработчики смогут быстро разобраться. Будет плюсом: Вы знакомы с алгоритмами цифровой обработки сигналов, активно пользуетесь инструментами sox, librosa, ffmpeg, opencv Опыт написания краулеров, размещения заданий разметки и сбора данных на краудсорсинговых площадках Опыт web разработки. Мы предлагаем: Крутая команда с интересными задачами Конференции и обучение Возможность выступать на внутренних и внешних мероприятиях Современный и удобный офис Возможность увидеть результаты своей работы внедрёнными в продукт ДМС, сниженные ставки по кредитованию, программы лояльности для сотрудников Бесплатный фитнес-зал и парковку.",Python,Сбер. IT,
6923,78632870,Data analyst,з/п не указана,1–3 года,"Полная занятость,полный день","В региональный центр компетенций по аналитике ищем Data analyst'а на направление расчет мотивации Проект AI мотивация – проведение исследований с помощью ML модели для предсказания доходности продаж (высокодоходные продажи и доплата за них), долгосрочное прогнозирование доходности базы клиентских менеджеров (высокодоходных клиентов) Обязанности анализ эффективности сотрудников блока Корпортативный инвестиционный бизнес формулирование и проверка гипотез подготовка несистемной аналитики ML моделирование Требования PL/SQL (вложенные запросы, подзапросы, UNION, JOIN, мат. функции, и.т.д ). Python (pandas, numpy и т.д.), умения применять ML в задачах регрессии, классификации, кластеризации, построение прогнозных моделей EXCEL на уровне продвинутого пользователя (сводные таблицы, формулы и.т.д.) знания основ статистики и теории вероятности аналитический склад ума, умение интерпретировать полученный результат, умение формулировать и проверять гипотезы Условия гибкое начало рабочего дня структуру дохода: оклад + годовой бонус обучение и возможность развиваться профессионально заботу о здоровье: ДМС с первого дня и бесплатный фитнес льготные ставки по потребительским кредитам и ипотеке «ДомКлик» бесплатная подписка СберПрайм+",,Сбер для экспертов,
6926,78928573,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Pudov – производитель продуктов питания и товаров повседневного спроса, лидер российского рынка в категории «Всё для выпечки». Мы трансормируемся из классической в цифровую компанию, внедряем и используем в работе передовые инструменты и современный стек технологий. Приглашаем в команду активного, внимательного и ответственного сотрудника на должность "" Data Scientist"". Готовы рассмотреть кандидатов без опыта работы, но с большим желанием развиваться в сфере Big Data. Обязанности: Анализ имеющихся данных в разных направлениях деятельности компании Оценка качества данных, валидация данных, построении правильной архитектуры данных Организация сбора данных (проработка необходимых параметров отчета, ТЗ на составление кастомизированного отчета для выгрузки данных из системы учета) Построение, обучение, тестирование моделей и алгоритмов для исследования данных с целью получения новых признаков клиентов, зависимостей, гипотез, прогнозов и т.д. нтерпретации данных в отчетах (выводы, графики, зависимости) Участие в подборе и внедрении ML-решений сследование новых алгоритмов и подходов, развитие экспертизы в области data science и machine learning. Требования: Высшее образование Опыт работы с большими массивами данных Активность, инициативность, аналитический склад ума Знание библиотек: Pandas, NumPy, Scikit-learn, TensorFlow, Keras, SciPy, Plotly, Seaborn, PyTorch Знание (линейной алгебры теории вероятности и математической статистики математический анализ и методы оптимизации временные ряды). Мы предлагаем: Мы предлагаем работу в проектах с реальными данными (производство, логистика, продажи, закупки, электронная коммерция, розница), возможность стать частью нашей команды Data Science Обучение от Сбера (нашего партнёра и лидера в области обработки и исследования данных) нтересные задачи, качественный продукт и амбициозные цели Карьерный рост и профессиональное развитие (каждый второй руководитель вырос внутри компании) Всё по ТК РФ: трудоустройство в штат компании, полностью «белая» ЗП, выплаты строго в срок Корпоративные скидки на продукцию компании (для сотрудников), корпоративные праздники, тренинги и обучение Возможность гибридного графика работы (возможность совмещать с учёбой или военной кафедрой) Возможность пройти практику и трудоустроится в Компанию. Добро пожаловать в команду!","Data Scientist,Аналитик,Pandas,NumPy,Scikit-learn,TensorFlow,Keras,SciPy,Plotly,Seaborn,PyTorch",Pudov,"Таганрог, улица Менделеева, 117/6"
6930,72312345,Data Engineer,до 400 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Мы в Rubbles создаем решения на базе анализа данных и искусственного интеллекта для оптимизации технологических и бизнес-процессов такие как: системы предсказания спроса на товары в ритейле, рекомендательные системы в банках, цифровые двойники, cистемы поддержки принятия решений на производстве и многое другое. Алгоритмы Rubbles ежедневно улучшают работу крупнейших банков, ритейл-сетей, нефтегазовых компаний и других предприятий. Мы ищем data engineer'ов разного уровня для усиления нашего направления, которое занимается разработкой систем прогнозирования спроса на товары, ценообразования, автоматического подбора оптимальных промо-акций и др. Задачи: Разработка и развитие платформы прогнозирования – архитектура и реализация инструментов для построения ML-пайплайнов (подготовка данных, сбор фичей, обучение моделей, применение моделей, ведение ML-экспериментов и т.п.) Помощь коллегам DS в оптимизации их работающих пайплайнов. Проактивность с предложениями оптимизации Взаимодействие с коллегами Devops по настройке окружений, деплоя кода, работы с инфраструктурой компании Общение с коллегами DQ, выяснение деталей наполенения данных, участие в составлении БТ к данным Решение неожиданных проблем с данными, задержками их доставки. Минимальные требования: Уверенные знания Python 3.7 + Spark 2.4 / Spark 3.0 (структуры данных, алгоритмы, концепции языка) Уверенные знания SQL: агрегации, джойны, вложенные запросы, индексы, оптимизации запросов Глубокие теоретические знания стека технологий и практический опыт (Spark, Hadoop, Hive Kubernetes (K8S)) Linux Опыт проектирование БД, понимание концепций OLAP и OLTP Опыт оптимизаций sql-запросов и понимание оптимизаций на уровне spark catalyst. На что ещё смотрим: Опыт работы с Airflow и другими подобными инструментами для запуска регулярных задач Опыт Devops (Docker, Gitlab-CI, настройка окружения на серверах и др.) Опыт разработки сервисов (Flask, Django, Asyncio и др.) Опыт проектирования высоконагруженных приложений и/или приложений работы с большими данными Опыт использования машинного обучения Опыт разворачивания, настройки мониторинга и передача на поддержку разработанных решений Pytest/Unitest Опыт работы с такими базами данных как PostgresQL, Greenplum, Clickhouse, SQLAlchemy. У нас: Работа в одной из самых сильных ML команд в России Гибкий график работы, гибкое предоставление отгулов и отпусков Поддержка в профессиональном и карьерном росте, оплата профильного обучения, конференций и книг, корпоративные скидки на курсы английского Совместная работа с опытными разработчиками, аналитиками данных, менеджерами, продуктологами ДМС со стоматологией после испытательного срока (3 месяца) по всей России При желании работать из офиса – уютный офис в центре Москвы (2 минуты от м. Сухаревская) со всем необходимым для комфортной работы. Особенно актуальное: Мы аккредитованная Т-компания со всеми вытекающими льготами.","Python,Spark,Hadoop,SQL,Big Data,Hive,Kubernetes,Linux",Rubbles,
6931,76826977,Lead/Senior Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","R1 — это новый взгляд на пространство, в котором живет человек. Наша команда убеждена, что технологии способны сделать дом многофункциональным, удобным и универсальным как для семейных вечеров, так и для работы днем. Наша миссия — делать технологии понятными и доступными, чтобы каждый человек мог качественно улучшить свою жизнь, сделать собственный дом своим местом силы. Среди наших проектов развлекательная smart-платформа Movix, устройства и приложения для «умного дома», e-commerce и др. Мы также уделяем большое внимание развитию и обслуживанию наших проектов, создавая и тестируя новые продукты в технической лаборатории Movix Lab, и вместе с командой CTO Office, которая занимается разработкой инфраструктурных сервисов всей компании. Мы запускаем уникальный проект по рестарту функции клиентоцентричных продаж в базу и максимизации ценности клиента (CVM). Цель проекта - создание системы для предложения клиентам нужных продуктов в правильное время с удобным клиентским опытом. Мы хотим: Предвосхищать потребности конкретного клиента Предлагать только нужные клиенту продукты сейчас Обеспечить персонализированные омниканальные клиентские пути Внедрять постоянные улучшения на основе обратной связи от клиентов Обеспечить гибкую операционная модель и Т архитектура. Обязанности кандидата: Управление группой аналитиков из 4 человек Участие в разработке и поддержке data driven решений в продуктовых командах Поиск инсайтов и паттернов в поведении пользователей Построение и поддержка регулярных отчетов и ad-hoc запросов Подготовка, анализ и ускорение процесса А/Б-тестирования (CUPED, Линеаризация) Участие в проектировании целевой архитектуры совместно с технической командой. Требования к кандидату: Глубокое понимание продуктовых и бизнес-метрик Владение Python и соответствующими библиотеками для анализа данных Уверенное знание SQL, умение строить сложные запросы и оптимизировать производительность Базовое понимание распределенных вычислений на кластере. Будет плюсом: Опыт разработки data pipelines на Spark с применением Luigi/Airflow/Oozie. Мы предлагаем: Оформление по ТК РФ, полностью белая з/п ДМС со стоматологией после испытательного срока, 100% компенсация больничного Скидки от компаний-партнеров Удаленка, гибрид или работа в офисе - на ваш выбор Кроме того, R1 аккредитована как IT компания.","Python,SQL,A/B тесты,Ad Hoc Analysis",Эр-1,
6932,72748493,Автор курсов по Data Analytics,з/п не указана,3–6 лет,"Проектная работа/разовое задание,полный день","Хекслет - это образовательная платформа для подготовки программистов. На нашей платформе обучаются десятки тысяч пользователей по всему миру.  Основные направления: администрирование, программирование, тестирование и аналитика. Мы растём и развиваемся, поэтому нам нужны руки и головы. Сейчас мы ищем автора для разработки текстовых курсов по Data Analytics. Автор — это эксперт в своей теме, который умеет и любит объяснять ее новичкам. Мы научим вас проектировать учебные курсы и доносить информацию до аудитории так, чтобы ваши студенты были вам благодарны. У нас есть Школа Авторов, если у вас совсем не было опыта в шаринге знаний. Автор вместе с командой продакшена создает контент для наших пользователей: текстовые уроки видео уроки практические задания, квизы и упражнения Что нужно делать: Помогать разрабатывать программы курсов При запуске нового направления мы вместе с автором обсуждаем программу обучения, по которой наши студенты смогут пройти путь от самых основ до определенного уровня Разрабатывать учебные материалы в формате видеоуроков или текста Команда редакторов и технических специалистов помогает продумывать планы уроков, писать тексты, записывать видеоуроки и создавать практику. Мы рассказываем общие рекомендации, которые вам помогут на каждом этапе Какие курсы нужно разработать (на выбор): Курс Введение в Дата аналитику Курс Направления в аналитике Курс Математика для аналитиков Курс Статистическая значимость Курс Сквозная аналитика Курс по Looker Studio Надо писать тексты по готовым программам :) Что мы ожидаем от вас: Сильную экспертизу в вашем стеке Опыт в сфере от 2 лет Опыт создания образовательного текстового контента Гибкость и умение слышать чужое мнение Условия работы: Неполная занятость: можно легко совмещать с работой Доступ к материалам Хекслета: вы можете учиться программированию сами, мы это только приветствуем Поурочная оплата по готовности материала Поддержим на всех этапах. У нас есть команда продюсеров и редакторов технических текстов Обучение в Школе авторов, где мы рассказываем как создается образовательный контент, на что важно обращать внимание при объяснении материалов и как учатся новички  Перед разработкой курсов мы предложим вам написать короткую текстовую статью на заданную тему. На примере статьи мы помогаем авторам учиться работать с текстом и обратной связью :)","Data Analysis,SQL,Математическая статистика,Работа с базами данных,PostgreSQL,Numpy,NoSQL,MongoDB",Hexlet,"Москва, Волгоградский проспект, Волгоградский проспект, 32к5"
6934,78579078,Аналитик качества данных/Data Quality Analyst,до 240 000 руб. до вычета налогов,1–3 года,"Полная занятость,полный день","Мы ожидаем: Глубокое знание SQL, опыт оптимизации запросов для обработки больших объёмов данных Понимание принципов построения реляционных СУБД, опыт работы с ETL-инструментами Опыт в разработке моделей данных, умение понять чужие модели Высокие коммуникативные навыки: готовность много общаться со специалистами технической поддержки, разработчиками, аналитиками, специалистами по тестированию. Ваши задачи: Обеспечение управления качеством поступающих в витрины данных Проверка баз данных и ELT-процессов на всех этапах обработки данных Постоянное совершенствование существующих методов проверок и разработка новых Консультирование разработчиков и тестировщиков продукта по вопросам качества генерируемых данных и методов их проверки Разрабатывать и актуализировать инструкции по методикам проверок Data Quality Утверждение данных перед отправкой бизнес-заказчикам Расследования инцидентов, вызванных проблемами в качестве сбора и трансформации данных. Мы предлагаем: официальное трудоустройство с первого дня работы график работы — 5/2 и гибкое начало дня и гибридный режим современный офис рядом с метро Звёздная: кухни, вкусный кофе, места для отдыха ДМС с момента трудоустройства программа адаптации и welcome-тренинг бонусы для сотрудников: реферальные программы, корпоративные мероприятия, мерч, подарки для детей корпоративные скидки: английский, спорт, кафе и рестораны в ТРЦ разделяем принципы устойчивого развития: раздельный сбор отходов, контейнеры для батареек и своп-вечеринки в офисе.  Компания входит в список аккредитованных Т компаний, на сотрудников распространяются все социальные льготы для профильных специалистов, в том числе льготная ипотека и освобождение от призыва на военную службу.","СУБД,SQL,Grafana,PowerBI",Монополия,"Санкт-Петербург, Звёздная, Звёздная улица, 1"
6935,77567000,Senior\Middle Data Scientist (Big Data),от 250 000 до 400 000 руб. до вычета налогов,1–3 года,"Полная занятость,полный день","Кто мы: Отдел занимается сбором, анализом и структурированием внешних и внутренних данных, построением, валидацией, внедрением как в real time так и в offline процессы построенных моделей для различных департаментов банка. Мы уже разработали и внедрили в систему принятия решений Банка ряд моделей. В частности, модели с использованием ML/DL/CV для кредитного скоринга (RNN-ки на транзакциях / социальный граф по окружению клиента), выявления мошенников по фотографиям (face detection + face matching), выявление агентского фрода, махинаций с персональными данными, речевая аналитика для автоматизации коммуникации с клиентами, рекомендательные системы и др. Кого мы ищем: В команду Big Data ищем Middle Data Scientist. Что тебя ждет: Проведение Proof-of-Concept по возможности построения моделей, решающих конкретные бизнес-задачи (например, подтвердить возможность выделение из разговора с клиентом конкретной причины недовольства для повторной коммуникации). Оценка ценности новых источников данных для принятия решений об их подключении. Разработка и построение моделей по успешным PoC или новым источникам данных. Продукционализация и поддержка моделей (документирование, мониторинг, контейнеризация, установка на шедулер airflow). Мы ждем от тебя: Уверенное знание математики, алгоритмов машинного обучения, статистики, алгоритмов и структур данных. Уверенное владение sql (Oracle/PostgreSQL). Классический стек на python (pandas, numpy, sklearn, xgboost, etc.) и хотя бы один DL-framework (tensorflow / keras / pytorch). Владение английским на уровне чтения и написания технической документации. Плюсом будет опыт вывода разработанных решений в prod (luigi/airflow для jobов и async/await фреймворков flask, sanic, etc.), а также знание docker, git, bash. Особенно мы ценим наличие опыта и завершенных проектов в computer vision / natural language processing / time series analysis. Мы предлагаем: Возможность создавать новые на банковском рынке решения Новый офис на метро Войковская (БЦ Метрополис) Стандартный график работы 5/2, 8-часовой рабочий день Гибридный формат работы, гибкое начало рабочего дня Оклад + годовой бонус 20% Отсутствие строгого дресс-кода (мы лояльны к любому проявлению личного стиля) Программы поощрения ОТП Мания (когда ты за внутреннюю валюту можешь купить себе как толстовку, так и day-off, например) Welcome pack ДМС (а также возможность его замены на фитнес) Льготные условия по кредитам и депозитам BestBenefits – сервис скидок и привилегий (техника и электроника, рестораны и доставка, обучение, отдых, спорт, красота и здоровье, товары, развлечения, услуги, детские товары и развлечения) Управленческое обучение, развитие навыков личной эффективности, профессиональное развитие Участие в корпоративных и спортивных мероприятиях (он-лайн и офф-лайн) Корпоративная библиотека МФ и Bookcrossing Детские подарки к Новому Году.","Python,SQL,Git","ОТП Банк, АО (OTP bank)","Москва, Балтийская, Войковская, Ленинградское шоссе, 16Ас2"
6937,78426679,Data Analyst junior / Аналитик данных,з/п не указана,не требуется,"Полная занятость,полный день","Мы ЛУЧШАЯ СЕТЬ СТУДЙ ЛАЗЕРНОЙ ЭПЛЯЦ по версии AURORA AWARDS Beauty&Health 2019. Лазерная эпиляция - это самый эффективный и безболезненный способ удаления волос навсегда. У нас одни из самый мощных диодных аппаратов лазерной эпиляции в Москве. Эффект виден с первого раза. Клиенты приходят к нам снова и рекомендуют своим друзьям. Миссия #IZUM: збавить людей от проблем связанных с удалением нежелательных волос повышая их чувство уверенности в себе. #IZUM ищет аналитика данных. Вместе с Вами мы будем: Участвовать в разработке новых систем метрик и показателей продаж и бизнеса в целом. Собирать данные и анализировать показатели продаж и бизнеса в целом. Формировать требования к настройке crm и участвовать в настройке. Мы ждем от тебя: Высшее техническое или экономическое образование. Обладаете навыками обработки данных. Обладаете опытом построения аналитики в компании, или большим желанием его получить. Что у нас есть для Вас: Возможность карьерного роста до Руководителя направления или бизнес-единицы и выхода на уровень дохода 250 тыс. и более. Мы всегда в движении, с нами не бывает скучно. Бесплатные процедуры лазерной эпиляции для себя и членов семьи. Условия: График работы: 5/2 Офис в 5 минутах от метро Преображенская площадь. Оформление по договору с самозанятым (позднее по трудовому договору или ГПХ). Этапы отбора: Телефонное интервью. Собеседование с руководителем. Тестовый период (обсуждается индивидуально). С кем мы не будем работать: ""Удалёнщики"". Не готовыми брать ответственность на себя. Не готовыми развиваться, чтобы вести проекты ""под ключ"". Нам нужен единомышленник, который ГОТОВ РАСТ каждый год Х5-Х10. Если все что выше про Вас, то смело отправляйте резюме и можете быть уверенным, мы точно сработаемся! Хорошего дня и до встречи в офисе) Станьте прямым участником развития бизнеса! С уважением, команда #IZUM","Экономический анализ,Аналитика продаж,Бюджетирование,Ценообразование,Аналитика,roistat,Экономическое моделирование",#IZUM,"Москва, Преображенская площадь, Электрозаводская, Электрозаводская улица, 29с1"
6940,78769342,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Команда создает платформу данных для розничного бизнеса, обеспечивающую сбор и обработку данных о клиентах-физических лицах для запуска AI-решений, комплексной аналитики и формирования максимально персонализированных предложений по продуктам экосистемы Сбера. Обязанности · Поиск корневых причин некорректной работы витрин данных · Проверка качества данных в источниках и витринах · Разработка и применение методов по восстановлению консистентности и актуальности витрин данных · Формирование требований к командам разработки для оптимизации/улучшения сервиса сопровождения витрин данных · Предоставление экспертной поддержки внутренним потребителям (data analysts, data scientists) по вопросам, связанным с использованием данных Требования · Не менее 1 года работы в качестве Data Engineer / Data Analyst / ETL Developer · Знание SQL на продвинутом уровне (аналитические функции, подзапросы, хранимые процедуры, оптимизация производительности), · Умение разбираться в чужом коде · Навыки работы с БД Hadoop или Greenplum. · Опыт подготовки документации: функциональных и бизнес требований, модели данных, сопроводительной документации при прохождении тестовых и приемо-сдаточных испытаний, спецификаций на загрузку данных, расчет сайзингов · Навыки декомпозиции бизнес-требований, формирования ТЗ для разработчиков · Опыт работы с инструментами Atlassian Confluence, Jira, Nexus Приветствуем, но не ожидаем от кандидата: · Знание банковского бизнеса · Apache Flink, HBase, Scala, Python, Apache Airflow, Java · Опыт работы по Agile (SCRUM, Kanban, и т.д.) Условия · Профессиональное обучение, семинары, тренинги, конференции · Годовые премии · ДМС, сниженные ставки по кредитованию, программы лояльности для сотрудников · Самые инновационные, амбициозные проекты и задачи · Комфортный офис с просторными оупенспейсами, лаунж зонами, кафе на Кутузовском. · Дисконт-программа от множества компаний партнеров.",,Сбер для экспертов,
6941,78769543,Аналитик данных / Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Привет! Мы — ООО «Датаномика», решаем проблемы структурирования разнородных данных, которые сложно поддаются анализу, помогаем среднему и малому бизнесу, банкам, ритейлу использовать данные чеков для оценки конъюнктуры спроса и экономических показателей, помогаем банкам повысить качество сервиса финансового планирования и аналитики для клиентов. Сейчас у нас открыта вакансия ""Аналитик данных / Data Analyst"" на проект в крупный российский Банк. Задачи проекта: Аналитика данных банка (транзакции, переводы, платежи, проводки) и экосистемы (история покупок в приложениях) с целью: Построения бизнес интерпретируемых атрибутов на клиента (спортсмен, автомобилист и т.д.) Формирования полезных фичей для моделей Построения клиентской аналитики. Команда проекта: 9 человек ( 3 DS, 4 DA, 2 DE). Чем предстоит заниматься: Анализом клиентской базы Банка и выделением паттернов клиентского поведения, например: необходимо выделить в клиентской базе Банка потенциальных ВПов (клиентов, с высоким доходом) Анализом текущих випов (используем Greenplum(postgres), Hadoop (spark)) Формированием атрибуты, которые хорошо разделяют випов от других клиентов (используем Greenplum(postgres), Hadoop (spark)) Построением модели (python, pyspark) Выводом результатов модели в пром (scala) Ключевые показатели эффективности: Рост количества атрибутов на клиента Прирост качества моделей склонностей к продуктам Банка и Экосистемы Доп. эффект в пилотах. Необходимые знания и навыки: Опыт работы в аналогичной должности от 2х лет Навыки работы с неструктурированными данными Знание SQL Python Spark/Pyspark Основы машинного обучения Математическая статистика, А/Б, проверка гипотез Будет преимуществом опыт работы с: Нейронными сетями Большими данными. Мы предлагаем: Работа в Т-аккредитованной компании Работа в офисе full time (без удаленного доступа) по адресу: Кутузовский проспект, 32 График работы 5/2, гибкое начало рабочего дня Официальная «белая» зарплата Оформление с первого рабочего дня, полное соблюдение ТК РФ нтересные, амбициозные задачи с достижимым результатом, понятным заказчиком и продуктом Достаточную свободу действий, инструментарий и необходимые ресурсы Регулярное обучение и профильные конференции, современное оборудование для работы.","SQL,Python,Математическая статистика,Machine Learning,Big Data,Pyspark,Spark",Datanomica,"Москва, Кутузовская, Кутузовский проспект, 32"
6943,77643478,Media Data Analyst / Аналитик медиа-данных,з/п не указана,1–3 года,"Полная занятость,полный день","Аналитическое подразделение Accelerate коммуникационной группы ""Group4Media"" ищет ""Media Data Analyst / Аналитика медиа-данных"" Обязанности: Работа с данными проектов Mediascope (TV Index, Brand Pulse, Radio Index, CrossWeb, мониторингом рекламы), Digital Budget, Admetrix итд работа с «сырыми» данными Создание и поддержка медийных баз клиентов в рамках текущих проектов и в новом бизнесе (в т.ч. создание шаблонов для выгрузки, создание ETL-процессов и / или формирование SQL-скриптов, работа с таблицами и витринами в SQL) Участие в разработке аналитических продуктов группы (вместе с другими отделами Accelerate: Business Science, Consumer Insights, Devs), развитие и апдейт текущих инструментов Консультирование и аналитическая поддержка коллег группы по индустриальным данным Участие в обновлении регулярного обзора рынка рекламы на уровне группы Развитие экспертизы и репутации агентства, за счет проведения внутренних тренингов Требования: Высшее образование Знание SQL на уровне базовых запросов Знание специализированного программного обеспечения и индустриальных медиа-проектов Mediascope будет являться дополнительным преимуществом Владение Python будет являться дополнительным преимуществом. Условия: Оформление согласно ТК РФ (оплата отпуска, больничного) Гибридный режим работы ДМС (с расширенной стоматологией, ВЗР, телемедициной, выделенная линия психологической поддержки) Классный офис в 3-х минутах ходьбы от ст. м. Трубная/Цветной Бульвар – рядом «Цветной», Брикет-маркет, Центральный рынок и многое другое Обучение: Еженедельные внутренние тренинги и воркшопы в агентстве Внешние тренинги и конференции Wellbeing Program – корпоративная скидка в World Class, X-Fit, душ в офисе Поддержка Mental Health - корпоративное сотрудничество с платформой ""Ясно"" Возможность поработать в команде профессионалов с крупнейшими международными клиентами Уровень заработной платы обсуждается с успешным кандидатом.","SQL,Internet,Аналитика,Cистемы управления базами данных,Бизнес-анализ,Аналитическое мышление,Аналитические исследования,Работа со СМ,Анализ данных","Группа компаний «Group4Media», Управляющая компания","Москва, Трубная, Цветной бульвар, Цветной бульвар, 2"
6945,78632808,Аналитик данных в Data Office,з/п не указана,1–3 года,"Полная занятость,полный день","Data Office появился пару лет назад. Наша команда: • строит хранилище данных для VK • запустила Data Portal как отдельный сервис для удобного взаимодействия с данными основные наши пользователи — маркетологи, менеджеры продуктов, аналитики, дата-сайентисты • провела десятки обучающих мероприятий для менеджеров и аналитиков • организовала сообщества DS/ML и Analytics и объединила дата-сайентистов и аналитиков всех продуктов VK • провела сотни продуктовых исследований.  Каждый день мы работаем с огромными объёмами данных (50 петабайт), используем современный стек технологий (Spark, Airflow, Presto, Vertica, ClickHouse) и разрабатываем современные дата-сервисы, которые помогают развиваться каждому продукту в компании.  Основные функциональные направления нашей работы: • Data Analytics, • Data Engineering, • Data Science, • Product and Service Development. щем специалиста, который поможет нам формировать регулярную аналитическую отчётность и проводить исследования различной сложности. Вам предстоит: • создавать и регулярно обновлять аналитическую отчётность • находить причины аномалий, ошибки в данных и курировать их исправление • исследовать данные источников, искать зависимости, выстраивать процессы с нуля • формировать growth-hacking идеи • выполнять ad-hoc задачи. У нас интересно, потому что: • мы анализируем данные, выдвигаем, разрабатываем и тестируем гипотезы по улучшению продуктовых метрик • вы сможете узнать, как устроены все продукты VK, поработать с их данными и реализовать с нуля новые проекты. Мы ожидаем, что вы: • получили высшее техническое образование • работали аналитиком данных не менее 2 лет • уверенно владеете SQL — знаете про сложные запросы и оконные функции • знаете Python на уровне обработки и анализа данных — Pandas, SciPy, NumPy, библиотеки matplotlib, plotly, seaborn • умеете интерпретировать результаты аналитики и превращать их в понятную форму для бизнеса — продакт-менеджеров и маркетологов • знаете основы статистики, математики, комбинаторики, эконометрики • умеете самостоятельно разбираться в бизнес-процессе, искать слабые стороны и придумывать решения. Приглашаем специалиста, который сможет работать в комбинированном режиме в офисе в Москве или Санкт-Петербурге. Ждём ваших откликов. Удачи!","MS SQL,Python,Анализ данных,ClickHouse,Hadoop","VK, ВКонтакте",
6947,78905646,Data Analyst (middle/middle+) Core-analytics,з/п не указана,3–6 лет,"Полная занятость,полный день","В связи с расширением ищем аналитика данных уровня middle/midle+ в отдел аналитики бизнеса. Обязанности: исследования аудитории по основным метрикам (MAW, MAU, Active Base, WT, AWTPW) построение автоматизированных инструментов аналитики совершенствование системы метрик, по которой живет бизнес ad-hoc-запросы и рисерчи предиктивная аналитика. Требования: структурное, аналитическое мышление инструменты обработки данных (SQL, Python/R) понимание бизнес-метрик и взаимосвязей между ними опыт работы в аналитике данных от 2 лет опыт работы с системами визуализации данных (Data Studio, Power BI, Tableau, Splunk либо аналоги) высшее техническое образование Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","SQL,Python,Data Analysis,Reporting",Okko,"Санкт-Петербург, Беговая, улица Савушкина, 126Б"
6948,78609928,Senior Data Analyst,от 200 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Мы — PARI, технологичная букмекерская компания. Мы создаем все условия для того, чтобы любители спорта могли наслаждаться просмотром спортивных событий и заключать пари. PARI обладает внушительным спонсорским портфолио в самых популярных видах спорта и сотрудничает с ведущими российскими федерациями — Союз биатлонистов России, Всероссийская федерация волейбола футбольными клубами: «ПАР НН», «Торпедо», «Ахмат», любительский футбольный клуб «Амкал» хоккейными клубами: «Торпедо», «Северсталь», «Нефтехимик», «Адмирал» и «Витязь». В нашей команде амбассадоров — известные телеведущие Дмитрий Губерниев, Ольга Петрикова, популярные российские ММА-бойцы Петр Ян и Арман Царукян, а также легенда российского футбола Андрей Тихонов и главный регбист страны Василий Артемьев. СТЕК: Python SQL PowerBI, DataLens, Tableau. ЧЕМ ПРЕДСТОТ ЗАНМАТЬСЯ: Участвовать в разработке, внедрении и поддержке data-driven процессов в всех командах Разрабатывать и поддерживать дашборды и системы метрик Собирать требования и оформлять в задачи для доработок системы хранения данных Проводить Ad hoc анализ данных по запросу от всех команд (искать инсайты, формировать и проверять гипотезы). ДЛЯ НАС ВАЖНЫ: Опыт работы Data Analyst от 3-х лет Аналитические способности Хорошо развитое критическое мышление Уверенные знания математической статистики и теории вероятностей Опыт визуализации данных (PowerBI, DataLens, Tableau, FineBI, Plotly и тд) Уверенное знание SQL и Python.","Python,PowerBI,Tableau,Power BI,Аналитическое мышление,Data Analysis",PARI,
6953,77697328,Аналитик данных / Data engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","На амбициозный проект запуска онлайна ищем компетенцию сильного Data analyst. Наша компания - розничная федеральная сеть финансовых отделений. Мы работаем на рынке массовых финансовых услуг для населения с 2009 года в более чем 50 городах страны (в Москве, Московской области, Санкт-Петербурге, Южном федеральном округе и других). Мы гибкие к формату работы и ценим в первую очередь ваш опыт и компетентность. Готовы рассмотреть удаленный график и проектную занятость. Обязанности: Анализ исходных данных в системах-источниках (оценка структуры, полноты и качества данных) Проектирование и разработка аналитических витрин, выстраивание системы нормативно-справочной информации Настройка процедур обновления витрин данных и мониторинга их качества Постановка задач по обогащению хранилища данных Построение и администрирование моделей данных Подготовка аналитики по кредитному портфелю – оценка эффективности, выявление закономерностей, прогнозирование рисков, подготовка решений и предложений по итогам анализа Автоматизация операционных отчетов и их администрирование Проектирование архитектуры хранилища данных Настройка ETL-процессов для работы с множеством источников данных Нормализация данных из 1С источников Формирование модели метаданных \построение многомерных массивов (кубы данных) Подбор и настройка инструментов визуализации данных Построение и визуализация аналитических витрин Создание регламента формирования операционных отчетов Статистическая обработка исторических данных кредитного портфеля с целью оптимизации системы принятия решений . Требования: Отличная математическая база и математическая культура Знание базовой теории вероятности и математической статистика Умение переложить бизнес-задачу на язык анализа данных, подобрать соответствующий алгоритм с учетом требований и ограничений, интерпретировать результат Опыт написания сложных запросов SQL и их оптимизация Опыт построения моделей данных в Tabular и знание ключевых принципов моделирования данных Знание DAX, M Code будет плюсом Знание Python или R будет плюсом Знание Power BI будет плюсом Законченное высшее образование по одному из направлений: Математика, Компьютерные науки, Экономика, Финансы Знание английского языка будет плюсом. Условия: Работа в стабильной розничной федеральной сети Официальное трудоустройство по ТК РФ График работы обсуждается с кандидатом (офис, удаленная работа, гибридный график), возможна проектная занятость Дружный коллектив и сплоченная команда профессионалов. Уважаемые кандидаты, мы ценим Ваше время, уделенное изучению вакансии в Компании «Благо Кредит», и рады, что Вы рассматриваете нашу Компанию как потенциального работодателя. При положительном рассмотрении вашего резюме мы свяжемся с Вами в течение трёх рабочих дней. В ином случае Ваше резюме будет зачислено в резерв, мы вернемся к нему при появлении вакансии, соответствующей вашим компетенциям и ожиданиям. Желаем Вам успехов!","Python,SQL,Математическая статистика,Математическое моделирование,Power BI,Data Analysis,Математический анализ,Навыки работы с большим объемом информации,1C: Финансы,Профессиональный пользователь ПК,Аналитические навыки,Коммуникабельность, ответственность,Работа в условиях многозадачности,Ответственность и пунктуальность,Высокая ответственность",Благо Кредит,
6954,78506716,Аналитик Data engeneer (удаленно),от 200 000 до 270 000 руб. на руки,более 6 лет,"Полная занятость,полный день","Outlines Tech – это аккредитованная IT-компания. Мы разрабатываем ПО и проекты для корпораций, а также подбираем сотрудников высокого класса. Среди клиентов – банки из ТОП-5 России, ритейл, строительные и логистические компании.  У нас десятки проектов и сотни вакансий. Официально трудоустраиваем в штат IT-специалистов для работы на долгосрочных проектах. Сейчас мы находимся в поиске одной из части нашей команды – Data engineer аналитика в финансовый сектор. Формат работы: удаленно из РФ. Почему мы: Outlines Tech — аккредитованная IT-компания. Это значит, что мы подлежим всем вытекающим льготам. С нами ты можешь работать максимально комфортно: без жесткого графика и микроменеджмента. Люди на первом месте не на словах, а на деле: отдел заботы курирует тебя 24/7.Помимо «белого» трудоустройства: ежегодная индексация зарплаты, 28 дней отпуска и 5 days off (бесплатные отгулы). Все для саморазвития: помогаем выступить на конференции, написать статью в технический блог, выучить английский, пройти обучение, сменить стек. Техническая команда состоит из прокаченных специалистов, многие из которых хорошо известны в мире финтеха. Мы обязательно поможем тебе вырасти профессионально внутренними митингами, а если ты круче — поможешь нам. , конечно, все остальные «плюшки»: медстраховка со стоматологией, оплата техники, музыки, книг, кино. А вот печенек нет. Чем предстоит заниматься: Оновная задача - вместе с командой разработки превратить внутреннюю систему продуктовой аналитики Альфа Метрика в сквозную. Для этого нужно объединить данные внутреннего хранилища, системы маркетинговой и системы продуктовой аналитики. Также нужно будет формировать и поддерживать витрины данных для получения сквозных воронок и отчетов по мобильным кампаниям. Для оптимизации времени загрузки отчетов необходимо будет переработать структуру хранимых данных. Необходимые навыки: Опыт Data/маркетинг/продуктовым аналитиком от 3х лет, желательно финтех. Глубокое понимание принципов и ограничений в сборе и обмене данными в системах мобильной, веб-аналитики, а также рекламных систем. Опыт применения best practices по интеграции данных в интернет-маркетинге и умение аргументировать принимаемые решения. Понимание ETL-процессов в интернет-маркетинге и продуктовой аналитике. Опыт работы с одной или несколькими системами аналитики: Appsflyer, myTracker, Firebase, Amplitude, Mixpanel, Google Analytics, Яндекс.Метрика, AppMetrica или аналогами Облачные хранилища: Google Cloud Storage, Yandex.Cloud или аналоги.рекламные системы: Google Marketing Platform, рекламные продукты Яндекса. Опыт работы с API систем аналитики и рекламных систем. Опыт построения автоматизированной отчетности: от сбора, хранения, подготовки данных до построения отчетов/дашбордов и проведения анализа данных. Уверенное владение SQL и опыт работы с базами данных (Oracle, Vertica, Hadoop). Знание инструментов для автоматизации сбора, статистической обработки сырых данных (R/Python). Откликайся скорее – порадуй наших рекрутеров!","Hadoop,Data Analysis,Анализ данных,SQL,Python,R,ORACLE,Google Analytics,Appsflyer,Amplitude,ETL",Outlines Technologies,
6956,78266507,Junior Data Analyst,з/п не указана,не требуется,"Полная занятость,полный день","О нас. Компания РЕСО-гарантия – один из лидеров страхования в России, услугами которой ежегодно пользуются более 15 млн. человек. Мы - команда высококлассных аналитиков и в нашем распоряжении находится одно из крупнейших хранилищ данных на рынке страхования. щем аналитиков с опытом и без него. Объём задач, связанных с обработкой и анализом информации растет, поэтому мы расширяем нашу команду. Нам интересно работать как с опытными, так и с начинающими аналитиками, поэтому нужны и те, и другие. Конечно, уровень заработной платы и функционал будут разниться в зависимости от опыта и квалификации, но мы готовы учить, делиться опытом и помогать в работе. Чем предстоит заниматься - построением математических моделей страхового портфеля - исследованием спроса и эластичности - управленческой аналитикой - тарификацией - анализом рентабельности страховых продуктов - анализом бизнес-процессов. Кого ищем - человека с высшим математическим или техническим образованием, но готовы рассматривать также студентов последнего курса, с возможностью работать от 4-х дней в неделю - организованного, ответственного, с аналитическим складом ума - способного работать с большими массивами новой информации - внимательного к деталям и изучению данных - ориентированного на результат. Что будет плюсом - диплом МГУ (Мехмат/ВМК/Физфак), МГТУ им. Баумана, МФТ, ВШЭ - знание SQL и PL/SQL - знание R или Python, пакетов статистического анализа - знание теории вероятности и математической статистики - понимание задач актуария - знание методов машинного обучения. Мы предлагаем - возможность попробовать и реализовать себя в разных ролях и направлениях аналитики - работу в кроссфункциональной команде экспертов с многолетним опытом - возможность освоить и применять передовые технологии в области анализа данных - офис в пешей доступности от ст.м Нагатинская и МЦК Верхние Котлы - социальный пакет (ДМС, скидки на страхование и прочее) - официальное трудоустройство.",,"РЕСО-Гарантия, САО","Москва, Нагорный проезд, 6"
6958,78375082,Аналитик данных / Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","КЛЮЧЕВЫЕ ЗАДАЧ: Сбор и анализ требований бизнеса Проверка гипотез для улучшения показателей бизнеса Подготовка данных для анализа, создание витрин данных Визуализация данных в Power BI ДЛЯ НАС ВАЖНО: Опыт работы Data Analyst от 2 лет Уверенное знание SQL Опыт создания дашбордов в MS Power BI Знание ETL процессов. Знание Python приветствуется. Высшее образование (техническое – как преимущество) Коммуникативные навыки, гибкость при принятии решений, умение рассмотреть задачу с разных точек зрения (бизнес-заказчик – пользователь – разработчик) Проактивность, умение задавать вопросы и искать ответы Организаторские компетенции, готовность к работе в режиме многозадачности МЫ ПРЕДЛАГАЕМ: Фиксированный оклад Оформление по ТК РФ Расширенный социальный пакет: страхование жизни, ДМС, компенсация питания, корпоративная мобильная связь График работы 5/2 Реализацию своего потенциала - интересные, амбициозные задачи Профессиональное обучение, индивидуальный план развития Главный офис в шаговой доступности от МЦК ЗЛ (200 м), г. Москва, пр-кт Лихачёва, д. 15.",,Леруа Мерлен. Центральный офис,
6959,78914227,Middle Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем специалиста по работе с данными в Корпоративный блок Сбера для аналитической поддержки лидеров бизнес-подразделений и топ-менеджмента. Нужно искать инсайты в данных и выстраивать систему показателей, чтобы ответить на вопросы: в чем сильные и слабые стороны конкурентов что происходит с компаниями и как это сказывается на бизнесе Сбера что мотивирует клиентов переходить в Сбер и другие, предполагающие креативную аналитическую работу Обязанности Проводить анализ корпоративных клиентов в Сбере и на рынке Диагностировать сильные и слабые места, вырабатывать рекомендации Визуализировать результаты анализа и переводить на бизнес-язык Предлагать направления дальнейшего исследования Требования Уверенное знание SQL Опыт работы аналитиком в крупном банке/аналогичной компании Понимание банковского бизнеса Хорошее знание математической статистики и теории вероятностей Как преимущество Знание бизнес-метрик, финансовой и управленческой отчетности банков Опыт работы с GreenPlum, Hadoop, Knime, Power BI Знание ml-стека на python: numpy, pandas, sklearn Знание Spark, PySpark, использование UDF Мы гарантируем нтересные и масштабные задачи, интеллектуальный вызов и возможность выбрать карьеру по интересам Работу в быстро развивающейся команде Офис в центре Москвы, классную столовую, отсутствие дресс-кода Тренажерный зал премиум-класса в офисе Конкурентоспособную зарплату + годовой бонус + ДМС",,Сбер для экспертов,
6960,78423651,Data Analyst,до 150 000 руб. на руки,1–3 года,"Полная занятость,полный день","The position is open with our client, of a large Chinese company. Responsibility: Data analysis specialist, responsible for Internet operation data analysis and report development. Analyze operation data and monitor operation indicators together with operation manager. Plan data requirements with operation manager, and develop data reports. Previous experience and Abilities Requested: Good skill of Microsoft office software, especially excel, macro skill will be a plus. Have experience in data analysis of Internet operation platforms. Be sensitive to data and have strong data analysis capabilities. Be proficient in SQL language. Proficient in using FineBI data processing tools would be a plus. Fluent in English and native local language. Chinese language would be a plus. Excellent communication skill in internal and external. Ability to handle multiple tasks concurrently, prioritizing and accurately completing them in a potentially stressful environment. Conditions: Working time: 5/2 since 9.30 a.m. to 18.00 p.m. Opportunity for professional growth and career development Mobile phone allowance.","MS Excel,SQL,Fine BI,Power BI,Английский язык,Английский — B2 — Средне-продвинутый",Manpower,
6961,77886099,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Проводит систематический анализ рынка и действий конкурентов по вопросам целевых кампаний Проводит систематический анализ рынка и действий конкурентов по проводимым кампаниям на и оборудованию (модемы, рoутеры, телефоны, смартфоны, планшеты и т.д.) Проводит соответствующий анализ и проверку на каждом этапе разработки предполагаемой для выхода на рынок кампании Разрабатывает и внедряет новые модели сегментации для публичных и непубличных кампании направленные на удержании и продвижение услуг компании Выдвигает гипотезы для тестирования, изучать данные и искать в них инсайты Разрабатывает дизайн A/B теста Построение аналитических отчетов и дэшбордов Принимает участие в процессе разработки и поддержания развития услуг Участвует в разработке стратегии ценообразования на разрабатываемые услуги Готовит бизнес анализ запускаемого продукта Систематически готовит отчетность по запушенным продуктам. Требования: Высшее образование Работа в офисе Умение работать с реляционными (SQL) базами данных Отличное владение инструментами анализа данных Python Уверенное знание статистического анализа. Условия: Культуру Компании нацеленную на достижения результата Рабочую среду в команде профессионалов, где вы будете чувствовать себя, как член команды единомышленников Добровольное медицинское страхование (ДМС) Корпоративная сотовая связь Профессиональный рост и развитие.","Бизнес-анализ,MS PowerPoint,SQL,Аналитическое мышление,Английский язык",COSCOM ТМ Ucell,
6963,78405363,Аналитик данных / Data Scientist,от 150 000 руб. на руки,1–3 года,"Полная занятость,полный день","Обязанности: Проверять продуктовые гипотезы и готовить Ad-hoc аналитику для поддержки принятия бизнес-решений. зучать поведение пользователей, формулировать гипотезы по улучшению их опыта. Планировать эксперименты вместе с командами маркетинга и продаж, проводить их и подводить итоги. Подготовка презентаций, ведение регулярных отчетных таблиц, загрузка и контроль входных - выходных данных. Анализ, оформление, подготовка аналитических записок. Разработка формул для расчетов. Мы ожидаем от вас: Высшее образование (обязательно с математическим или техническим уклоном). Опыт работы с OLAP-кубами, большими массивами данных. Опыт работы с неструктурированными данными. Продвинутое использование Microsoft Excel, Microsoft PowerBI. Продвинутое использование Python, Jupiter notebook, Scikit-learn, Pandas, Keras, Catboost. Опыт предобработки данных. Опыт исследовательского анализа данных. Опыт статистического анализа данных. Опыт применения машинного обучения в бизнесе. Вы знакомы с продуктовыми метриками и представляете, как их используют. Знаете SQL и применяли его для решения практических задач (желательно, по возможности). Умеете автоматизировать рутинные задачи с помощью программирования (желательно, по возможности). Грамотно излагаете свои мысли. Условия: Оклад обсуждается после финального собеседования с успешным кандидатом. График работы 5/2 10:00 - 19:00 (формат работы обсуждается). нтересные задачи в Компании с известным брендом на рынке элитной недвижимости. Дружный коллектив профессионалов.","Ad Hoc Analysis,Python,Olap (online analytical processing),База данных: Olap,Аналитическое мышление,Анализ данных,Jupiter,Pandas,PowerBI,Английский — B1 — Средний",Kalinka - Realty,"Москва, 1-й Казачий переулок, 7"
6964,78150043,Junior Data Analyst,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Мы открываем позицию junior data analyst в консалтинговую аналитическую компанию Valiotti Analytics. Компания работает с 2019 года с молодыми, интересными и технологичными стартапами из Европы и России. Позиция предполагает удаленную работу в области анализа данных и построения отчетности. У нас гибкий график и проекты из разных индустрий. Вы сможете эффективно применить Ваши знания в области data analytics и получить новый ценный опыт. Обязанности: Построение ad-hoc отчетности с использованием языка SQL Построение выборок из баз данных c использованием SQL Разработка дашбордов на фреймворке dash / plotly Разработка отчетов в BI-системах: Tableau, Redash, Superset, PowerBI Построение дашбордов и систем мониторинга Построение отчетов с использованием Python (pandas, numpy, matplotlib, plotly) Обязательные навыки: Владение SQL (проверяем на тестах) Способность анализировать. Внимательность к деталям Мягкие навыки Внимание к деталям и аккуратность Самоорганизация и эффективное планирование Владение английским языком на уровне чтения и анализа технической документации Поведенческая гибкость. Корпоративные навыки Клиентоориентированность Нацеленность на результат Умение декомпозировать задачи на этапы Работа в сложных ситуациях Настойчивость в достижении цели Соблюдение сроков Адекватное распоряжение ресурсами змерение и презентация результатов Эффективная коммуникация Прочие требования Высшее техническое образование, отличные знания мат.статистики опыт работы с SQL опыт работы с Python Условия: Удаленная работа Если Вы прочитали описание позиции, в сопроводительном письме напишите, пожалуйста, чем Вас заинтересовала наша вакансия.","SQL,Python,Английский язык,Английский — B1 — Средний",Valiotti Analytics,
6965,78301838,Digital Data Analyst,от 150 000 до 249 000 руб. на руки,более 6 лет,"Полная занятость,полный день","Responsibilities: Generate and test hypotheses for conversion growth together with our agencies Predict the cost and likelihood of conversion: CPO, CPL, etc. Building an unified Brand database from various sources (Data of e-commerce, registrations on the site, Smart TV Users, mobile app, data from media campaigns, etc.), development of a long-term communication strategy with different segments of the Brand database Develop data-driven proposals for business process optimization and work them through with internal stakeholders. Communicate and Collaborate with internal business stakeholders, data science peers from Agencies and the Colleagues responsible for data storage. Regular A/B testing, hypotheses, test setup, analysis of results, debriefing, performance reporting Making forecasts of site performance indicators (traffic, revenue, conversion, average check, bounce rate and deliverability). Audit existing data processes to ensure they are functioning correctly. Work with performance team to help architect solutions when problems exist Track the implementation of KPIs, conduct a deep factor analysis of deviations, prepare proposals based on the results of the analysis and contribute to their implementation Determination and prediction of the unsubscription rate, fraud search, analysis of appeals to the Brand through various channels (website, social networks, instant messengers, customer service, etc.) Development of a strategy for managing communication channels with Subscribers, setting up personalized communication processes (e-mail, messengers, push notifications, calls, etc.) Evaluate demand and calculate unit economics, calculate payback and break-even point Requirements: 5+ years experience in data science or analytics, data marketing with data management responsibilities The ability to find data insights and a willingness to understand the essence of the processes that this data shows MS Excel, SQL – advanced user, able to quickly work with big data sets. Strong analysis skills, experience with searching insights in data and developing recommendations based on analytics. Intermediate+ English. Excellent communication skills, willing and readiness to communicate with internal customers. Ability to balance multiple, competing directions and manage multiple projects successfully Possess knowledge of methods and metrics of statistical analysis and machine learning, understanding of their applicability, and ability to explain them to the Colleagues Experience in implementing projects in the field of data analysis Experienced in the use of statistical analysis/modeling - correspondence analysis, time series analysis and other regression, clustering, factor analysis etcюб Proficient in use statistical software (Python, SQL) Knowledge of the principles of Google Marketing Platform tools and ability to work with Google Tag Manager Understanding attribution models for each digital channel Conditions: Registration according to the Labor Code of the Russian Federation Working hours at office 9:00 – 18:00 Trial period of 3 months Medical insurance (VMI), Life insurance after the trial period Lunch allowance Incentive pay according to corporate policy. Place of work: Business office building near M. Belorusskaya Salary is negotiable","Data Science,SQL,MS PowerPoint,Big Data,Анализ данных,Marketing Strategy Development,Analytical skills,MySQL,Статистический анализ,Английский — C1 — Продвинутый",HS Ad,"Москва, 4-й Лесной переулок, 4"
6966,78685969,Data Analyst (Customer Experience Analytics Team),от 3 000 USD на руки,1–3 года,"Полная занятость,удаленная работа","Tabby creates financial freedom in the way people shop, earn and save by reshaping their relationship with money. Over 3,000,000 active users choose Tabby to stay in control of their spending and make the most out of their money. Over 10,000 global brands and small businesses, including H&M, Adidas, IKEA, SHEIN, noon, and Bloomingdale's use Tabby's technology to accelerate growth and gain loyal customers by offering flexible payments online and in stores. Tabby is active in Saudi Arabia, UAE, Egypt and Kuwait and backed by leading investors including Sequoia Capital India, STV, PayPal Ventures, Mubadala Investment Capital, Arbor Ventures and others.  About the role We are looking for the Data Analyst to the Customer Experience Analytics Team to own the data universe of CX function. CX aims to create a frictionless customer journey, analyzing root causes for the customer contacts, trying to measure friction along the journey, and identify internal opportunities for improvement across all functions. That requires a CX Data analyst to get familiar with how the company works, what are the KPIs and measures existing across customer-relevant functions, starting from the Customer Service through Partner Service, Risk and so on. You will be successful in the role, if you combine natural curiosity, passion for self-development and business literacy. Your reporting line is to the Head of CX analytics, and you will have colleagues in your team as well as bigger analytical function to collaborate with and to learn from. You'll be working in a dynamic, rapidly evolving environment with the following responsibilities: Be a key player of CX team in the field of data analytics Connect data from internal and external sources and organize it for business analysis Perform a deep statistical analysis to connect internal execution, Voice of the Customer data layer and company profitability Perform data visualization Identify business issues and opportunities.  You should apply if you have experience in CX Analytics Retention analysis Data visualization SQL Clustering Connecting data from rigorous sources Creating custom API connectors Regression analysis Statistics (great understanding).  Nice to have experience in Business analysis Setting up AI or using 3rd party AI tools.  Relocation We offer remote work from anywhere in the world and are happy to work out an individual relocation plan for you. Our employees have the opportunity to choose a country for registration: at the moment those are Armenia/Georgia. We will help you open a legal entity and a bank account. In Armenia and Georgia the taxes are compensated by Tabby. For our employees we cover the following: Flight to Armenia/Georgia Accommodation during the paperwork completion period Opening a bank account and getting a residence permit in one of the mentioned countries Family relocation (dependants). New employees can also choose an alternative method of relocation to another country of their choice. In this case, Tabby will reimburse up to $5,000 of verified costs upon opening a legal entity and a bank account.  What you can expect A competitive salary dependent on your experience Excellent health benefits Flexible working hours and freedom to manage your own time to do your job well, while also remaining in touch with your team A working environment that gives you autonomy and responsibility from day one. We are open to insights and new ideas, and we are ready to experiment An equitable, high-performing workplace that gives people from all backgrounds the support they need to thrive, grow and meet their goals (whatever they may be).","SQL,Business Analysis,Data Analysis,Английский — B2 — Средне-продвинутый",Tabby,
6967,78672191,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","В команду «Гео и графы» кластера «Data Science и клиентская аналитика» корпоративного блока Сбербанка мы ищем специалистов по работе с данными. Вам предстоит работать с графами связей, строить витрины данных, использующиеся для построения моделей и автоматизации, применять алгоритмы машинного обучения для построения моделей. Функциональные обязанности: Построение графовых и LM нейронных сетей Построение и поддержка аналитических моделей (Python + Spark + Sklearn + LGBM) Feature Engineering: методы оценки значимости и отбора признаков, методы уменьшения размерности Построение аналитических отчетов по результатам проведенной работы Обеспечение документирования результатов моделирования для передачи на валидацию Получение структурированных и неструктурированных данных из различных источников, сследование источников данных, обеспечение сбора данных Составление требований для Data Engineer по разработке новых витрин/объектов Построение и проверка гипотез по запросу Заказчика Построение моделей машинного обучения исходя из потребностей Заказчика Навыки и опыт работы: Опыт работы в области Data Science от 2 лет Хорошее знание алгоритмов машинного обучения, нейронных сетей Python, библиотеки для работы с ML Графовые библиотеки (torch_geometric, dgl и др.) Базовые знания Spark, опыт работы со стеком Hadoop Знание SQL Понимание процессов ETL, ELT Как преимущество Знание SOTA технологий, применение трансформеров, нейронных сетей Знание Spark, PySpark, использование UDF, особенности написания кода для стека Hadoop Знание особенностей программирования в распределённых системах Опыт работы с noSql базами Обучение моделей на ресурсах GPU(А100/V100)/DGX","SQL,Python,ETL,Spark",Сбер. IT,
6969,77758898,Web/Data-аналитик,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы — Эксперо. Разрабатываем IT-продукты в области pharmtech и medtech для пользования участников фармацевтического рынка. Наши продукты нацелены на улучшение сотрудничества между пациентом, фармацевтом и производителем лекарственных средств. Работа у нас – это: Свобода действий. Предлагай, что и как делать.  делай! Сильная команда: учим, выращиваем и развиваем Ресурсы для осуществления идей, даже странных :) Проект в сфере E-commerce. Чем предстоит заниматься: Участие в процессе автоматизации отчетов (хранение, обработка и консолидация данных) Визуализацией данных в Power BI/Tableau Построением системы отчетности для команды и руководства, поддержка и доработка Построением моделей атрибуции Глубокая аналитика медийных, продуктовых и бизнес-показателей по всем каналам коммуникации Формированием гипотез по оптимизации показателей, тестированием и масштабированием UI/UX-анализ посадочных страниц, a/b тесты, рекомендации по улучшению пользовательского опыта Что ждем от кандидата: Опыт автоматизации и визуализации отчетов Построение моделей атрибуции Сквозная аналитика SQL R/Python Анализ данных до бизнес-показателей Обязательное знание ПО: Google Ananlytics, Google Sheets и т.д. С нас: Светлый, уютный, современный офис по линии метро Красный проспект Возможность работать гибридно (офис/удаленка) Официальное трудоустройство, полный соц. пакет Стабильная и «белая» зарплата Корпоративные скидки на фитнес Милые корпоративные подарочки ДМС English speaking club Бесконечный гематоген    У нас крутая команда, которой необходим сильный специалист. Мы заинтересованы в поиске и привлечении крутых специалистов, а также желающих таковыми стать :)","Python,MS SQL,Анализ данных,A/B тесты,Анализ бизнес показателей,Power BI",EXPERO,"Новосибирск, Советская улица, 36"
6970,75628514,Data analyst,з/п не указана,1–3 года,"Полная занятость,полный день","SberDevices - инновационное направление компании, которое создает умные устройства, виртуальных ассистентов и другие продукты в области Speech Recognition, NLP, Computer Vision. Команда речевых технологий ищет Аналитика данных. У нас сильная и активная команда (ex-Yandex, выпускники МФТ, МГУ, ВШЭ, ШАД). Мы создаем технологическую платформу: занимаемся созданием и развитием голосовых технологий (ASR, TTS, Keyword Spotting, Emotion Recognition). В последние годы эта область развивается быстрыми темпами, и мы активно следим и внедряем лучшие решения в наши продукты. Помимо всего этого, девайсы активно опенсорсят в комьюнити (датасет Golos, GPT-3, SBERT - крутые эмбеддинги текстов), пишут статьи (https://arxiv.org/pdf/2106.10161.pdf, https://www.mdpi.com/1424-8220/21/20/6744), двигают рынок. Кстати говоря, разметка и human in the loop очень горячая тема сейчас, так что потенциально можно сделать крутую работу. Основные задачи: Keyword Spotting (Wake-word detection) - важный компонент речевых технологий, через который проходит любое взаимодействие пользователя с устройством. Цель алгоритма keyword spotting - выявить ключевое слово в условиях шума и не допустить ложных активаций. Сейчас у нас делают много ML экспериментов, но не хватает человека, который очень хорошо разберется в данных, найдет косяки разметки, проверит качество разметки, придумает новые полезные сценарии для записи звука, придумает вместе с нами, как улучшить тест сеты, чтобы они лучше отображали реальность ASR - распознавание речи, automatic speech recognition. Краеугольная задача нашего отдела - сделать качественный, быстрый и стабильный ASR. Дата аналитик в этой команде должен будет работать бок о бок с нашими DL инженерами и ресечерами, предлагать сценарии экспериментов в части данных, разбираться, где наши слабые и сильные стороны. Строить дата-пайплайны, улучшать разметку. Требования: Уверенное владение Python, Git, Linux Хорошо писать код Драйв. Дата аналитики могут стать центром ML движухи, мы ищем очень активных людей Базовое знание статистики Хорошее верхнеуровневое понимание ML систем, отличное знание метрик (будем спрашивать, что такое precision, recall!). Будет плюсом: Обучение в ШАД Опыт с краудсорсингом Опыт работы с моделями распознавания речи Базовое понимание цифровой обработки сигналов. Условия: Мощные сервера, терабайты данных Свой сервис разметки, прямое влияние на данные и соответственно весь ML Конференции и обучение, возможность выступать на внутренних и внешних мероприятиях Офис м.Кутузовская(смешанный формат работы удаленка-офис) ДМС, сниженные ставки по кредитованию, программы лояльности для сотрудников.","Python,Computer Vision,Tensorflow,NLP,PyTorch,Data Analysis,Linux,Data Science,Алгоритмы,ML",Сбер. IT,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
6971,78769739,Data Scientist / Дата-сайентист,з/п не указана,1–3 года,"Полная занятость,полный день","Привет! Мы — ООО «Датаномика», решаем проблемы структурирования разнородных данных, которые сложно поддаются анализу, помогаем среднему и малому бизнесу, банкам, ритейлу использовать данные чеков для оценки конъюнктуры спроса и экономических показателей, помогаем банкам повысить качество сервиса финансового планирования и аналитики для клиентов. Сейчас у нас открыта вакансия ""Data Scientist"" на проект в крупный российский Банк. Задачи проекта: Аналитика данных банка (транзакции, переводы, платежи, проводки) и экосистемы (история покупок в приложениях) с целью: Построения бизнес интерпретируемых атрибутов на клиента (спортсмен, автомобилист и т.д.) Формирования полезных фичей для моделей Построения клиентской аналитики. Команда проекта: 9 человек ( 3 DS, 4 DA, 2 DE). Чем предстоит заниматься: Анализом клиентской базы Банка и выделением паттернов клиентского поведения, например: необходимо выделить в клиентской базе Банка потенциальных ВПов (клиентов, с высоким доходом) Анализом текущих випов (используем Greenplum(postgres), Hadoop (spark)) Формированием атрибуты, которые хорошо разделяют випов от других клиентов (используем Greenplum(postgres), Hadoop (spark)) Построением модели (python, pyspark) Выводом результатов модели в пром (scala) Ключевые показатели эффективности: Рост количества атрибутов на клиента Прирост качества моделей склонностей к продуктам Банка и Экосистемы Доп. эффект в пилотах. Необходимые знания и навыки: Опыт работы в аналогичной должности от 2х лет Навыки работы с неструктурированными данными Python Spark/Pyspark Основы машинного обучения Математическая статистика, А/Б, проверка гипотез Будет преимуществом опыт работы с: Нейронными сетями Большими данными. Мы предлагаем: Работа в Т-аккредитованной компании Работа в офисе full time (без удаленного доступа) по адресу: Кутузовский проспект, 32 График работы 5/2, гибкое начало рабочего дня Официальная «белая» зарплата Оформление с первого рабочего дня, полное соблюдение ТК РФ нтересные, амбициозные задачи с достижимым результатом, понятным заказчиком и продуктом Достаточную свободу действий, инструментарий и необходимые ресурсы Регулярное обучение и профильные конференции, современное оборудование для работы.","Python,Математическая статистика,Machine Learning,Big Data,Pyspark,Spark",Datanomica,"Москва, Кутузовская, Кутузовский проспект, 32"
6972,77847286,Data analyst middle,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Проект отвечающий за все виды удаленного обслуживания юридических лиц. Мы объединяем несколько контактных центров по всей стране, общей численностью более 5000 человек. Перед командой стоит задача обеспечить бесшовный переход с Siebel CRM на собственную платформу Банка с микросервисной архитектурой в части предоставления управленческой и бизнес-отчетности Трайба. Твои задачи: Создание общей модели данных из различных автоматизированных систем Участие в проекте миграции на целевую АС Банка Активное взаимодействие со смежными командами в части сбора требований для разрабатываемых решений Проектирование функциональных требований Разработка витрин данных Консультации по наличию данных в витринах, по качеству и категоризации данных Обеспечение коммуникаций внутри команды и с заказчиками Мы ждем от тебя: Опыт работы аналитиком не менее 2-х лет Опыт в сфере анализа бизнес-процессами Навыки создания аналитической и технической документации Опыт проектирования моделей данных от физических (сырых) к логическим (преобразованным) Знание SQL (сложные запросы, создание процедур, умение читать и оптимизировать чужой код) Понимание процесса разработки и командного взаимодействия Умение искать и предлагать варианты решений в условиях высокой неопределенности и брать ответственность за результат задачи Мы предлагаем: Профессиональная сессия развития персонала дважды в год, по итогу которой составляется план индивидуального развития каждого сотрудника Тренинги за счет компании, внутренние семинары, внутренние митапы, мы очень любим учиться новому Корпоративная культура со своими ценностями и традициями, в которой каждый чувствует себя частью команды","SQL,Аналитическое мышление,Аналитика,Витрины данных",Лига Цифровой Экономики,
6973,78254193,DATA-аналитик,з/п не указана,1–3 года,"Полная занятость,полный день","НАШ ПРЕМУЩЕСТВА: аккредитованная Т-компания сильная команда, в которой можно расти режим занятости: полная занятость, работа в офисе во Владимире совместно с разработчиками (иногда возможен удаленный формат работы из дома) график: 5/2, с 9.00 до 18.00 регулярные сложные технологические задачи трудоустройство по ТК РФ, социальные гарантии комфортный офис в центре города корпоративная культура открытости и взаимопомощи условия оплаты труда обсуждаются индивидуально на собеседовании. ЧТО ПРЕДСТОТ ДЕЛАТЬ: Вызовы, которые Вас ждут: обучать многослойные нейронные сети и строить модели машинного обучения проверять гипотезы, строить систему предсказаний на основе нейронных сетей, выявлять скрытые аномалии в данных с поиском причин, автоматическое переобучение моделей. Базовые функции: Анализировать поступающие от бизнеса задачи. Прояснить требования к бизнес-задачам, перевести их в математическую плоскость. На основе анализа и структурирования огромных массивов данных построить понятную систему инструментов/ модель машинного обучения, которая будет решать задачу. Проверить правильность работы модели: внедрить на наборе пользователей или провести A/B-тестирование. Находить зоны роста в текущих моделях и предлагать улучшения, в том числе очень смелые, которые предполагают полную переделку системы. Реализовывать прототипы и проверять гипотезы. НАШ КАНДДАТ: имеет высшее профессиональное образование (в сфере IT или техническое предпочтительно) занимался аналитикой или Data Science не менее 1 года фанатеет от математики, теории вероятности, статистики, машинного обучения умеет работать с базами данных владеет инструментами обработки больших объемов данных (напр., Apache Spark и Hadoop Mapreduce) владеет навыками программирования на Python, имеет базовые знания SQL обладает системным мышлением, внимателен к деталям.","Python,Математическая статистика,SQL,Spark,Hadoop,Анализ данных,Теория вероятностей,Базы данных,Data Analysis,Математический анализ,Машинное обучение,Математическое моделирование,Работа с большим объемом информации,Machine Learning,Data Science",ЭлРос,"Владимир, улица Сакко и Ванцетти, 50"
6974,77800691,Data Entry Specialist and Analyst,от 140 000 до 160 000 KZT на руки,не требуется,"Полная занятость,полный день",,,Maxinum Consulting Ltd,"Алматы, Алатау, улица Айманова, 124"
6975,78608877,Business Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Автоматизация различных задач, связанных со сбором и обработкой данных (постоянные задачи и Ad-hoc) Подготовка и очистка данных с использованием SQL. (Самостоятельная работа с базой) Разработка и реализация эффективных алгоритмов для работы с большими массивами данных. Разработка дашбордов (в одном из: Tableau BI, Power BI, Plotly Dash) Контроль качества данных, поиск и устранение аномалий, тестирование, подготовка результатов. сследование бизнес-процессов компании. Коммуникация с внутренними заказчиками. Основные заказчики Маркетинговый, продуктовый и коммерческий отдел. Взаимодействие с командой разработчиков по подготовке данных для процесса аналитики. Построение отчетности. Требования: Понимание многомерных моделей данных Знание SQL (базовый) Знание Python (базовый) Высокий уровень навыков работы с MS Excel Знание и умение применять основы статистики и теории вероятностей Ответственность, аккуратность, внимательность, усидчивость, высокая работоспособность, готовность к рутинной работе. Желание расти и развиваться Плюсом будут: Высшее образование в технической отрасли. Навыки в написании сложных запросов SQL (оконные функции и процедуры) Опыт работы с одним из следующих BI систем: Tableau BI (Creator), Power BI или Plotly Dash Навыки MLOps Условия: Выход на зарубежный рынок (Дубай) и работа с сильной командой прекрасные карьерные перспективы успешный стартап с мощной динамикой современный менеджмент.","MS PowerPoint,SQL,Python,Tableau,Power BI,Работа с базами данных,Статистика,Бизнес-анализ,Data Analysis,BI,Анализ данных,Статистический анализ,Визуализация данных,Business Intelligence Systems,Аналитическое мышление,Бизнес-аналитика,Базы данных,Русский — C1 — Продвинутый,Английский — C1 — Продвинутый",INSANE GROUP CO,
6977,76957610,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Компания является глобальным технологическим лидером и сегодня входит в десятку ведущих мировых брендов. Обязанности: Загрузка данных в корпоративные IT-системы Выгрузка данных из в корпоративных IT-систем Контроль качества и анализ предоставляемых данных в корпоративные IT- системы Контроль и анализ нарушений, связанных с загрузкой данных, со стороны партнеров Еженедельная/ежемесячная сверка предоставляемых данных с дистрибьюторами Ведение проекта по проверке загружаемых данных (полное сопровождение процесса, еженедельная отправка данных на проверку, контроль выполненных звонков, корректировка данных во внутренних IT системах, исполнитель – внешний колл-центр) Ведение проекта по автоматизации получения данных по продажам и остаткам (EDI) с ключевыми бизнес-партнерами по серийным номерам Предоставление аналитической отчетности Сбор бизнес-требований, составление технических заданий в IT подразделение, контроль выполнения, тестирование, обучение пользователей Коммуникация с бизнес и IT подразделениями Коммуникация с партнерами Участие в остальных проектах BI департамента. Требования: Высшее образование (экономическое или техническое) 0,5-2 года в качестве помощника аналитика, работа с необработанными данными Навыки работы с Excel (продвинутый уровень), умение использовать сложные формулы Умение работать с большими объемами данных Аналитические навыки, высокий уровень точности в деталях Английский язык: upper - intermediate Знание VBA, R, Python, SQL, BI систем как плюс Внимательность Отличные коммуникативные навыки Ориентированность на результат Готовность работать с большим объемом информации и документов Стрессоустойчивость Условия: График работы 5/2 (пн-пт) Формат работы: полностью офисный, начало и окончание рабочего дня гибкое Заработная плата: обсуждается индивидуально Полугодовой бонус (плюс оклад) при выполнении KPI, ДМС, скидка на продукцию компании и корпоративная мобильная связь Бесплатный обед и ужин Оформление по ТК РФ м. Баррикадная",,Avanta Россия,
6978,78838644,Data Engineer,от 600 000 до 800 000 KZT на руки,1–3 года,"Полная занятость,полный день","Обязанности: Разработка, тестирование и оптимизация баз данных Работа с большим объемом данных, их анализ и обработка Проектирование и разработка ETL процессов Разработка и поддержка инфраструктуры для обработки данных Работа с командой разработчиков, аналитиков и продуктовых менеджеров для определения требований к проектам. Требования: Умение разрабатывать и оптимизировать базы данных Навыки программирования на SQL, Python, Java, Scala и/или других языках Знание инструментов и технологий для работы с большими объемами данных Опыт работы с ETL процессами и инструментами Опыт проектирования хранилищ данных Опыт работы с системами класса ERP (1C) и CRM (Bitrix24) Навыки работы с Linux и системами контроля версий Будет преимуществом Опыт работы с Modern Data Stack Знание и понимание архитектуры Big Data систем Опыт работы с NoSQL базами данных Знание основных алгоритмов машинного обучения и статистики. Условия: Официальное трудоустройство по ТК РК Работа в крупной автомобильной компании Стабильный доход Возможность работать удаленно График работы 5/2 с 09:00 до 19:00 (обеденный перерыв 13:00-15:00).","Big Data,Java,Data Analysis,SQL,Jira,Английский — B1 — Средний",ALLUR AUTO,"Астана, проспект Туран, 53А"
6979,78683099,Аналитик данных ML - Data Science,з/п не указана,1–3 года,"Полная занятость,полный день","Наша компания занимается разработкой собственной cloud-native платформы потоковой обработки данных. На её основе мы выполняем различные проекты: от сбора национального сегмента сети до ML аналитики с собственными SoTA алгоритмами в области текстового и сетевого анализа. Всё это обрабатывает порядка 10 млн. событий или около 10 ТБ данных в сутки. В связи с увеличением количества проектов ищем в команду второго специалиста по Data Science. Обязанности: Разработка моделей для решения задач с использованием методов машинного обучения Подготовка датафреймов для обучения Встраивание моделей в существующие операционные процессы Подготовка автоматизированных отчетов, дашбордов, алертов по результатам работы моделей Участие в обсуждении задач и верификации результатов по проектам Требования: Уверенное владение Python и SQL Знание стека работы с данными (numpy, pandas, scipy, matplotlib) Знание ML-стека Python (XGBoost, Scikit-learn, Torch, Tensorflow, Keras) Знание архитектуры нейронных сетей, их слоев и модулей – от RNN, CNN и FC до FastText, Transformer, BERT, GCNN – на уровне понимания и объяснения их принципов Знание математической статистики, линейной алгебры и базовой математики Условия: Работа в офисе рядом со станцией метро Марьина роща Молодой дружный коллектив Белая заработная плата График работы: 5/2 с гибким рабочим днем Оформление по ТК РФ Компания с 2017 года в реестре аккредитованных Т-организаций. Есть все льготы для IT специалистов, включая отсрочку от мобилизации З/п по результатам собеседования","Python,Математическая статистика,Data Mining,C++,Data Science",Аналитические программные решения,"Москва, Марьина Роща, 3-й проезд Марьиной Рощи"
6983,78438562,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","RESPONSIBILITIES: Analyze data from various sources to identify process inefficiencies and areas for improvement. Utilize Six Sigma tools and techniques to track performance metrics, identify bottlenecks and inefficiencies, and implement process improvement initiatives. Develop and release effective and automated instruments for static, dynamic, and predictive analysis. Contribute to the data mining program aimed at identifying critical few Xs from large amounts of sales data to propose solutions that will prevent customer loss or revenue reduction. Work closely with the data governance, reporting, and communication teams to deliver data-driven insights that can be used to make more informed decisions. Improve forecasting accuracy, identify potential issues early, operate in an agile and responsive manner, and develop more complex and comprehensive analysis methods incrementally. REQUIREMENTS: Bachelor's degree in statistics, mathematics, computer science, or a related field. Experience in data analysis, statistical modeling, and data visualization. Experience in Machine Learning is preferred. Understanding of Six Sigma methodologies, including the DMAIC approach. Strong analytical and problem-solving skills. Excellent communication and collaboration skills. Knowledge of SQL and data mining techniques. Experience with statistical process control, value stream mapping, and process flow diagrams. BENEFITS Convenient work tools Latest Mac workplaces + additional hardware to make you more effective at work Google Chat, Gmail, Google Drive, Confluence, Jira, GitLab PROFESSIONAL GROWTH Free trainings and participation in specialized conferences Rich knowledge exchange within the company MORE PERKS Relocation in Malaysia Health insurance (Medical, dental and optical)- Employee and dependants Flexible hours: organize your day according to your needs and sprint & teamwork demands No dress code Comfortable and new office environment Wellness perks ABOUT XSOLLA Xsolla is a global video game commerce company with a robust and powerful set of tools and services designed specifically for the video game industry. Since its founding in 2005, Xsolla has helped thousands of game developers and publishers of all sizes fund, market, launch and monetize their games globally and across multiple platforms. As an innovative leader in game commerce, Xsolla’s mission is to solve the inherent complexities of global distribution, marketing, and monetization to help our partners reach more geographies, generate more revenue and create relationships with gamers worldwide. Headquartered and incorporated in Los Angeles, California, with offices in Berlin, Seoul, Beijing, Kuala Lumpur, and cities around the world, Xsolla supports major gaming titles like Valve, Twitch, Roblox, Ubisoft, Epic Games, KRAFTON, Nexters, NetEase, Playstudios, Playrix, miHoYo, Pearl Abyss, NCSoft, and more. For additional information and to learn more, please visit: xsolla.com",Английский — B2 — Средне-продвинутый,Xsolla,
6984,78365368,Data Analyst,з/п не указана,3–6 лет,"Проектная работа/разовое задание,полный день","Мы в компании «INSITECH Development» работаем над различными IT проектами, как собственными, так и для наших клиентов - лидеров российского рынка. Мы активно осваиваем новые направления и аудитории. «INSITECH Development» — команда единомышленников, которая создает инновационные продукты и ценит своих сотрудников. Мы растем и расширяемся. Работа над проектами происходит с использованиями гибкого фреймворка SCRUM Для нас очень важно что бы у Вас было: Уверенное знание математической статистики и умение использовать ее в работе Уверенное знание Python на уровне стандартных библиотек для анализа данных (numpy, pandas, scikit-learn, statsmodels) Хорошее знание Pyspark Знание ML Хорошее владение SQL (join, фильтрация, агрегирование, группировка) Работа у нас — это: команда профессионалов, готовых поддержать ваши инициативы возможность работы с новыми технологиями гибкий график возможность удаленной работы достойная зарплата — размер обсудим на собеседовании Будем благодарны если Вы коротко расскажете о себе в сопроводительном письме. С нетерпением ждем Ваших откликов!","Data Mining,Python,SQL,Pyspark,ML,Big Data,Математическая статистика,Pandas,Анализ данных,Статистический анализ,Data Science,Spark,Tableau",INSITECH Development,
6985,78686565,Middle data analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Сравни.ру – финансовый маркетплейс, мы создаем удобные сервисы для того, чтобы помочь людям принимать правильные решения при выборе банковских и страховых продуктов. Сейчас у нас: 14 млн уникальных пользователей в месяц 8 000 предложений от банков и страховых компании 140 000 отзывов о банках и страховых компаниях более 7000 оформленных страховок в день  Что предстоит делать: Сегментация существующего клиентского портфеля в разрезе продуктовых и маркетинговых активностей. Формирование клиентского профиля. Анализ эффективности и развитие существующих каналов коммуникации развитие и оценка новых. Разработка методологии и механизмов персонализации предложений для клиентов Разработка методологии и механизмов удержании клиентов на сервисе. Требования: Умение работать с данными, написание запросов SQL Умение работать с данными MS Office Базовые навыки программирования на Python (pandas, numpy, scikit-learn) Базовые навыки визуализации на Python (matplotlib, plotly) Знание ML (опыт построения предсказательных моделей, эконометрических моделей, регрессионный анализ) Будет плюсом: Опыт работы в CRM Мы предлагаем: Работу в аккредитованной IT компании ДМС, включая стоматологию, страхование жизни 2 day-off в год Каждые полгода проводим ревью всех сотрудников, составляем планы развития и даём возможность расти по карьерной лестнице Пицца/пироги/суши каждую пятницу Оплату посещения профильных конференций и курсов Реферальная программа для сотрудников Материальная помощь при рождении ребёнка +3 дня оплачиваемого отпуска Ремоут-френдли. Доставим всё, что нужно для комфортной работы, и организуем встречи с командой онлайн и офлайн. Поддержку в обмене знаниями и идеями: поощряем выступления на митапах и помогаем с подготовкой докладов. Корпоративные мероприятия и тимбилдинги Помощь с переездом для кандидатов из других городов (оплата билетов и первого месяц квартиры).","Python,SQL",Сравни,"Москва, Площадь льича, Римская, бульвар Энтузиастов, 2"
6986,78768854,Data аналитик/Аналитик BI,з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем аналитика, который будет определять целевые метрики для достижения стратегических целей, анализировать причины их отклонений, выявлять ключевые факторы влияния, тестировать гипотезы по их улучшению и предлагать возможные пути автоматической оптимизации этих метрик. Вам предстоит: строить модели поведения пользователей Авито, сегментировать их и выявлять потребности продумывать структуру метрик для оценки различных инициатив и проектов, проектировать модель данных и соответствующую отчетность прогнозировать и отслеживать поведение этих метрик, выявлять ключевые факторы влияния и возможности их изменения обнаруживать с помощью анализа данных различные неэффективности в существующих процессах и их исправлять. Мы ожидаем, что вы: имеете опыт работы аналитиком BI / данных от 1 года в совершенстве знаете математическую статистику знаете Python или R получили высшее образование в области вычислительной математики, статистики, анализа данных и т.п. владеете методиками анализа данных, используя различные инструменты любознательны, умеете договариваться. Мы предлагаем: конкурентную заработную плату (оклад и годовой бонус) компенсацию питания расширенный полис ДМС со стоматологией, страхование жизни, страхование выезжающих за рубеж постоянное развитие: обратная связь руководителя, коллег, личный кошелек на обучение вне компании сильная команда амбициозных коллег с высокой профессиональной экспертизой в различных областях индивидуальный план адаптации и наставник помогут пройти испытательный срок в Авито самые передовые IT инструменты для эффективного выполнения задач уверенность в качестве предлагаемых продуктов, которые мы постоянно совершенствуем для наших пользователей масштабные корпоративы, онлайн-вечеринки, командные тимбилдинги, вечерние посиделки и игры в PlayStation 5 здоровый образ жизни: свой тренажерный зал, занимаемся йогой и делаем функциональные тренировки, а также скидки у партнеров 5-тидневка, гибридный или удаленный формат работы. Мы предоставляем все необходимое для удаленной работы: технику, софт, онлайн-обучение.","Scrum,SQL,Аналитическое мышление,Аналитические исследования,Аналитика продаж,Business Intelligence Systems",Авито: аналитика,
6987,78257276,Data Analyst / Аналитик данных,з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем в команду Аналитика, который будет вести аналитическую работу по финансовой/операционной части отдела партнерских продаж.  Вам предстоит: просчитывать вывод партнеров на прибыльность (понизить комиссию, просчитать ивент и т.д.) разрабатывать KPI для эффективной оценки вклада сотрудников в общий результат бюджетировать департамент создавать аналитические инструменты для менеджеров отдела с целью минимизации ad hoc запросов просчитывать финансовую эффективность активностей сотрудников (командировки, встречи с партнерами и т.д.) участвовать в брейнстормах и проектах аналитического комьюнити. Мы ожидаем: 3+ лет опыта на аналогичной должности Знание английского на уровне B2 Upper- intermediate и выше Опыт разработки системы KPI для сотрудников Умение писать запросы с помощью SQL Опыт использования инструментов визуализации (Power BI, Tableau, Qlik). Мы предлагаем: Работа на международные рынки Поддержка и содействие в профессиональном росте (семинары, курсы, тренинги, внутреннее обучение) Полностью белая заработная плата и официальное оформление Гибкое время начала и окончания рабочего дня Оплачиваемые вкусные обеды в офисе Обучение английскому языку с корпоративным преподавателем Подключение к ДМС со стоматологией после прохождения испытательного срока (включая полис для детей) Частичная компенсация спортивно-оздоровительных мероприятий (спорт, йога, бассейн и тд.) и занятий с психологом после прохождения испытательного срока Транспортный бенефит.","Data Analysis,Визуализация данных,Анализ текущих финансовых показателей,SQL,Tableau,Анализ бизнес показателей,Аналитика продаж,Английский — B2 — Средне-продвинутый",Колл Солюшенс,"Санкт-Петербург, Московская, площадь Конституции, 3к2"
6988,78260367,Data Scientist,от 250 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Renue — IT-компания из Екатеринбурга. Мы специализируемся на разработке масштабных проектов для государственных и крупных IT-компаний в России и СНГ. Каждый наш новый проект - уникальный, потому что мы занимаемся заказной разработкой (B2G), работаем с highload системами, сервис-ориентированной архитектурой и используем современные фреймворки и технологии. Сейчас мы формируем команду и ищем Data Scientist. Пишем пилотную версию чат-бота для ФНС (Федеральная налоговая служба). Это платформа поставки данных. В текущей версии нас ничего не ограничивает для выбора технологий. Для ускорения разработки мы выбрали готовую платформу для построения чат-бота Rasa. О проекте: ВПД (Внешняя поставка данных) - это пилот и некоторая оптимизация работы пользователей: помощь выполнения сценариев чат-бота для неавторизованных пользователей поиск некоторой информации внутри системы для авторизованных пользователей (распознавание намерений, поиск сущностей). Ближайшие планы: в июне 2023г выпустить пилот, далее развивать проект (выстраивать систему аналитики, обучения и переобучения и т.д.). Перспективы. В следующем году планируется большой контракт на создание публичного чат-бота для одной из федеральных инстанций. У него будет два интерфейса: web и Telegram. Поскольку проект масштабный, пользователей и сценариев будет много. Тебе предстоит: сбор, очистка, обработка и систематизация структурированных и неструктурированных производственных данных из различных источников формирование и проверка гипотез для оптимизации производственных процессов разработка математических моделей и алгоритмов машинного обучения для решения задач прогнозирования числовых рядов, обнаружения аномалий в данных, моделирования и оптимизации производственных процессов формирование и проверка гипотез для улучшения моделей разработка программных средств для взаимодействия математических моделей и моделей машинного обучения с остальными модулями программной системы предоставление аналитических выводов и предложений на основе полученной информации описание исследований, формирование отчетов по их итогам. Ты отлично справишься с задачами nlp, если: имеешь промышленный опыт работы (от постановки задачи до внедрения) в области DS/ML от 3-х лет умеешь решать nlp задачи классификации и кластеризации отлично владеешь Python (DS/ML библиотеки). Мы предлагаем: трудоустройство с первого дня, зарплата белая формат работы на твой выбор: удаленная работа или работа в офисе в центре Екатеринбурга, или гибрид работа в команде с прямыми короткими коммуникации. Мы против формализма и бесконечных совещаний гибкий рабочий график. Мы начинаем во сколько удобно и не считаем часы за работой, готовы к сдвигам в графике, если это не мешает взаимодействию и результату расширенная программа ДМС (с стоматологией, вызовом врача на дом, массажем и телемедициной) развивающая среда: ты сможешь проходить курсы за счёт компании, ездить на IT-конференции, чтобы послушать других или выступить самому помним о праздниках, дарим подарки сотрудникам, веселимся вместе на корпоративах.","Machine Learning,Python,Data Analysis,NLP",Ренью,"Екатеринбург, Площадь 1905 года, улица Хохрякова, 3А"
6989,78178051,ESG – аналитик / Data-Miner,от 60 000 до 80 000 руб. на руки,1–3 года,"Полная занятость,гибкий график","Обязанности: Сбор информации из открытых источников Обработка информации, полученной от клиентов Сравнение и систематизация собранных данных Первичный анализ и оценка информации Ведение документации. Дополнительно: Участие в подготовке вебинаров и мероприятий Анализ тематических новостей. Требования: Умение находить информацию в интернете, построение сложных поисковых запросов Способность ориентироваться в единицах измерения, не путать тонны с литрами и т.п., а также переводить их друг в друга. Excel на уровне простых формул, Word с умением форматировать без лишних пробелов Английский – intermediate (B1). Желательные навыки: Элементарные навыки пользования финансовой отчетностью, поиска или вычисления выручки, EBITDA и т.п. Опыт в ESG – огромный плюс. Условия: Гибридный режим работы после периода обучения Гибкий график ДМС после испытательного срока Официальное оформление и белая зарплата.","Internet,Пользователь ПК,Excel,Поисковые системы,Английский язык (Intermediate),Систематизация информации,Работа с большим объемом информации,Английский — B1 — Средний",РАЭКС-Аналитика,"Москва, Весковский переулок, 3"
6991,78725471,Data Analyst в команду Боты.KnowledgeAssistant,з/п не указана,1–3 года,"Полная занятость,полный день","В команду, разрабатывающую современную базу знаний для операторов и ботов требуется аналитик данных Обязанности Анализ воронок клиентских путей в продуктах Генерация гипотез, поиск точек роста продукта на основе истории взаимодействия пользователей Проведение и анализ продуктовых пилотов Прототипирование дашбордов и написание аналитических отчетов Взаимодействие с командами Big Data в Банке в части обмена опытом Требования Владение SQL, PySpark, Python для обработки и анализа данных Знания статистики для работы с гипотезами и доверительными интервалами Опыт проведения а/б тестов Умение работать с большими массивами данных Навыки презентации и визуализации Будет плюсом: Опыт работы с NLP библиотеками (nltk/gensim), т.к. иногда придется работать с текстовыми данными Опыт работы с QlikView/QlikSense Опыт работы с Колл-Центрами и автоматизацией обслуживания обращений Условия комфортный офис на Кутузовском проспекте с тренажерным залом, коворкинг-пространствами и кафе полный рабочий день, но гибкий график работы (можно выбрать режим начала работы в промежутке 7:00 - 10:30) ДМС, программы лояльности для сотрудников (льготное кредитование, предложения экосистемы Сбера) комьюнити data-people, множество программ профессионального обучения (курсы, тренинги, конференции, семинары).",,Сбер для экспертов,
6994,78815500,Middle Data Analyst CVM,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Чем ты будешь заниматься: Поддерживать и контролировать метрики CVM и моделей машинного обучения, консультировать пользователей по работе с метриками CVM Развивать систему аналитики Customer Value Management и участвовать в развитии продукта скать продуктовые проблемы (Продуктовый ресерч - например, находить и выявлять закономерности и изменении метрик) Поддерживать DataDriven подход Развивать отчетность в ClickHouse/Yandex.Lens. Мы ожидаем: Знание основ статистики и теории вероятности (стат.значимость, доверительный интервал, стат.тесты и т.д.) Понимание основных показателей деятельности CVM и ритейла, портфельная/продуктовая аналитика, операционная аналитика, PL Опыт построения систем отчётности на базе Oracle/Terradata/ Greenplum (или в облачных решениях) Опыт проведения A/B и A/A/B тестов Желание развиваться в области разработки алгоритмов машинного обучения для решения актуальных бизнес-задач. Стек: Стек: Python, SQL, Yandex.Lens Мы предлагаем: трудоустройство в аккредитованную Т-компанию график работы 5/2 с гибким началом возможность работать удаленно/гибридно/в офисном режиме, у нас есть офисы в Москве, Краснодаре, ннополисе ДМС со стоматологией и льготными условиями для членов семьи Корпоративные скидки от компаний-партнеров Развитие – мы оплачиваем обучение на курсах и участие в конференциях.","SQL,Data Analyst,A/B тесты","МАГНТ, Розничная сеть",
6996,77316163,Data Scientist (DMAG),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","О проекте: Мы разрабатываем методы детектирования от составления обучающей выборки и выявление признаков, до реализации и контроля качества на production системах. Разработанные методы далее используются во многих продуктах Лаборатории Касперского непосредственно защищая наших пользователей. С примерами задач команды можно ознакомиться по ссылкам: How to improve SOC analyst efficiency using ML - DataFest. ML & Security track - https://www.youtube.com/watch?v=DPzdb9Uivwc&feature=youtu.be Краткий ликбез по ML метрикам и их связи с бизнес-метриками - LeadDS meetup - https://www.youtube.com/watch?v=pDMgvhsUPJM&feature=youtu.be Monotonic models for real-time dynamic malware detection - whitepaper - https://openreview.net/pdf?id=rkjatuyvM Чем предстоит заниматься: Классификация исполняемых файлов как по статическим признакам, так и по их поведению Анализ android/mac файлов Распознавание вредоносных интернет ресурсов основываясь на статистических данных, графах связей IP адресов Кластеризация, быстрый поиск похожих вредоносных объектов.  Мы используем xgboost, различные варианты нейросетей, графовые подходы и locality sensitive hashing. Объемы данных варьируются до сотен миллионов объектов, сотен терабайт данных. Для хранения больших данных мы используем HDFS, для обработки pyspark. Для обучения нейросетей у нас есть свой GPU кластер на базе kubeflow. Что требуется от вас: Ведение DS проектов от начальных до заключительных стадий Участие в генерации и проверке гипотез по улучшению качества текущих алгоритмов и экспериментов с новыми подходами Хорошее знание моделей машинного обучения и понимания их внутренностей (например, зачем нужен градиент в градиентном бустинге) Уверенные навыки в python Желательно знание pyspark, pytorch или tensorflow. А еще мы предоставляем возможность: Регулярного участия профильных ML конференциях Внутренние семинары по ML раз в 2е недели Возможна частично удаленная или полностью удаленная работа.","Machine Learning,Spark,docker,Python",Лаборатория Касперского,
6997,78896261,Data scientist (Middle),з/п не указана,1–3 года,"Полная занятость,полный день","В команду «Гео и Графы» кластера «Data Science и клиентская аналитика» корпоративного блока Сбербанка мы ищем специалистов по работе с данными. Вам предстоит работать с графами связей, строить витрины данных, использующиеся для построения моделей и автоматизации, применять алгоритмы машинного обучения для построения моделей. Обязанности · Построение и поддержка аналитических моделей (Python + Spark + Sklearn + LGBM), скоринговых моделей · Feature Engineering: методы оценки значимости и отбора признаков, методы уменьшения размерности · Построение аналитических отчетов по результатам проведенной работы · Обеспечение документирования результатов моделирования для передачи на валидацию · Получение структурированных и неструктурированных данных из различных источников, · сследование источников данных, обеспечение сбора данных · Составление требований для Data Engineer по разработке новых витрин/объектов · Построение и проверка гипотез по запросу Заказчика · Построение моделей машинного обучения исходя из потребностей Заказчика - Умение переводить требования Бизнеса на язык ML Требования · Опыт работы в области Data Science от 2 лет · Хорошее знание алгоритмов машинного обучения, нейронных сетей · Python, библиотеки для работы с ML · Знание банковской предметной области, банковских продуктов · Понимание основ финансовых инструментов · Базовые знания Spark, опыт работы со стеком Hadoop · Знание SQL · Понимание процессов ETL, ELT Как преимущество · Знание Spark, PySpark, использование UDF, особенности написания кода для стека Hadoop · Знание особенностей программирования в распределённых системах · Опыт работы с noSql базами · Обучение моделей на ресурсах GPU(А100/V100)/DGX · Знание SOTA технологий, применение трансформеров, нейронных сетей Условия \- Фиксированный оклад + годовой бонус - ДМС, страхование от несчастных случаев, социальные гарантии - Митапы DS Community банка и корпоративные мероприятия - Участие в различных конференциях для DS/DE - Корпоративное обучение - Комфортный офис в 5 минутах ходьбы от м.Нарвская - В офисе бесплатный фитнес-зал с душевыми кабинами, настольный теннис, кикер",,Сбер для экспертов,
6998,78365379,Data Analyst,з/п не указана,3–6 лет,"Проектная работа/разовое задание,полный день","Мы в компании «INSITECH Development» работаем над различными IT проектами, как собственными, так и для наших клиентов - лидеров российского рынка. Мы активно осваиваем новые направления и аудитории. «INSITECH Development» — команда единомышленников, которая создает инновационные продукты и ценит своих сотрудников. Мы растем и расширяемся. Работа над проектами происходит с использованиями гибкого фреймворка SCRUM Для нас очень важно что бы у Вас было: Уверенное знание математической статистики и умение использовать ее в работе Уверенное знание Python на уровне стандартных библиотек для анализа данных (numpy, pandas, scikit-learn, statsmodels) Хорошее знание Pyspark Знание ML Хорошее владение SQL (join, фильтрация, агрегирование, группировка) Работа у нас — это: Команда профессионалов, готовых поддержать ваши инициативы Возможность работы с новыми технологиями Гибкий график Возможность удаленной работы Достойная зарплата — размер обсудим на собеседовании Будем благодарны если Вы коротко расскажете о себе в сопроводительном письме. С нетерпением ждем Ваших откликов!","Data Mining,Python,SQL,Pyspark,ML,Big Data,Математическая статистика,Pandas,Анализ данных,Статистический анализ,Data Science,Spark,Tableau",INSITECH Development,
6999,76939405,Data scientist (Middle+\Senior),з/п не указана,3–6 лет,"Полная занятость,полный день","Привет, к себе в команду ищем аналитика данных, формат работы: гибридный или удаленный только по РФ. Сейчас открыто несколько ставок на следующие проекты: продвижение кредитно-платежных продуктов (кредитные продукты, рисковые скоринги, автоплатежи и т.д.) персонализация тарифного плана: формирование наполнения тарифа по профилю абонента Чем предстоит заниматься Разработка моделей, углубленная аналитика, генерирование и проверка гипотез с целью формирования персонализированных предложений абонентам, прогноза спроса, трафика, выручки, удовлетворенности абонентов и других ключевых событий, влияющих на успешность нашей Компании Написание production-ready кода для быстрого деплоя пайплайна через MLOps Настройка мониторинга моделей и логики регулярного дообучения Оценка эффективности реализованных проектов (как технической, так и экономической), оценка потенциала проектов в процессе разработки Постановка задач на junior и middle дата-сайнтистов, обеспечение качества разработанных ML продуктов (версионирование, документация, code review, мониторинг и т.д. в соответствии с принятыми в подразделении регламентами и SLA) Что для этого нужно Знания в области математики, теории вероятности, мат. статистики (высшее образование, наличие ученой степени будет дополнительным плюсом) Наличие успешно завершенных проектов с использованием технологий анализа данных и машинного обучения Знание алгоритмов машинного обучения, принципов их работы, ключевых особенностей и ограничений Отличное владение инструментами анализа данных, библиотеками машинного обучения Необходимый стэк: Python, PySpark, Hadoop, SQL, Airflow, MLFlow Опыт работы в области Data Science от 3х лет","SQL,Hadoop,Python,Pyspark,Airflow","МегаФон, IT","Москва, Маяковская, Новослободская, Чеховская, Оружейный переулок, 41"
7001,77697283,Аналитик данных / Data engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","На амбициозный проект запуска онлайна ищем компетенцию сильного Data analyst. Наша компания - розничная федеральная сеть финансовых отделений. Мы работаем на рынке массовых финансовых услуг для населения с 2009 года в более чем 50 городах страны (в Москве, Московской области, Санкт-Петербурге, Южном федеральном округе и других). Мы гибкие к формату работы и ценим в первую очередь ваш опыт и компетентность. Готовы рассмотреть удаленный график и проектную занятость. Обязанности: Анализ исходных данных в системах-источниках (оценка структуры, полноты и качества данных) Проектирование и разработка аналитических витрин, выстраивание системы нормативно-справочной информации Настройка процедур обновления витрин данных и мониторинга их качества Постановка задач по обогащению хранилища данных Построение и администрирование моделей данных Подготовка аналитики по кредитному портфелю – оценка эффективности, выявление закономерностей, прогнозирование рисков, подготовка решений и предложений по итогам анализа Автоматизация операционных отчетов и их администрирование Проектирование архитектуры хранилища данных Настройка ETL-процессов для работы с множеством источников данных Нормализация данных из 1С источников Формирование модели метаданных \построение многомерных массивов (кубы данных) Подбор и настройка инструментов визуализации данных Построение и визуализация аналитических витрин Создание регламента формирования операционных отчетов Статистическая обработка исторических данных кредитного портфеля с целью оптимизации системы принятия решений . Требования: Отличная математическая база и математическая культура Знание базовой теории вероятности и математической статистика Умение переложить бизнес-задачу на язык анализа данных, подобрать соответствующий алгоритм с учетом требований и ограничений, интерпретировать результат Опыт написания сложных запросов SQL и их оптимизация Опыт построения моделей данных в Tabular и знание ключевых принципов моделирования данных Знание DAX, M Code будет плюсом Знание Python или R будет плюсом Знание Power BI будет плюсом Законченное высшее образование по одному из направлений: Математика, Компьютерные науки, Экономика, Финансы Знание английского языка будет плюсом. Условия: Работа в стабильной розничной федеральной сети Официальное трудоустройство по ТК РФ График работы обсуждается с кандидатом (офис, удаленная работа, гибридный график), возможна проектная занятость Дружный коллектив и сплоченная команда профессионалов. Уважаемые кандидаты, мы ценим Ваше время, уделенное изучению вакансии в Компании «Благо Кредит», и рады, что Вы рассматриваете нашу Компанию как потенциального работодателя. При положительном рассмотрении вашего резюме мы свяжемся с Вами в течение трёх рабочих дней. В ином случае Ваше резюме будет зачислено в резерв, мы вернемся к нему при появлении вакансии, соответствующей вашим компетенциям и ожиданиям. Желаем Вам успехов!","Python,SQL,Математическая статистика,Математическое моделирование,Power BI,Data Analysis,Математический анализ,Навыки работы с большим объемом информации,1C: Финансы,Профессиональный пользователь ПК,Аналитические навыки,Коммуникабельность, ответственность,Работа в условиях многозадачности,Ответственность и пунктуальность,Высокая ответственность",Благо Кредит,
7002,78668714,Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Команда УралАйТех (аккредитованная Т-компания) в поиске Аналитика данных в Дирекцию цифровых инноваций Какие задачи предстоит решать: Анализ бизнес и технологических процессов, определение новых инициатив, реализуемых методами машинного обучения (ML) Сбор и обработка данных Предварительная разработка математических моделей для машинного обучения Оценка экономического и технического эффектов от реализации ML-инициатив Административное обеспечение проектов Подготовка технических требований и отчётности Управление отношениями с заинтересованными лицами Скаутинг и акселерация (стартапы, инженерные чемпионаты, студенческие практики) Что для этого требуется Опыт участия в качестве аналитика данных в проектах цифровой трансформации производственной функции Знание ключевых цифровых технологий ндустрии 4.0 и архитектуры, хороший технологический кругозор Хороший навык подготовки презентаций Опыт работы в консалтинге (Big 4, Accenture) будет преимуществом Стек: Python/Jupyter, Kafka/Rabbitmq, Power BI Git, Kubernetes Корпоративная платформа данных со стандартным набором сервисов как DS/ML так и CI/CD Что мы предлагаем: нтересная работа в крупной промышленной компании Полное соответствие ТК РФ Добровольное медицинское страхование для сотрудника и его детей с первого дня работы (включая стоматологию) Годовые бонусы Льготы и преференции сотрудника Т-компании Корпоративная мобильная связь Корпоративное обучение, постоянное развитие Ежемесячные спортивные тимбилдинги","Power BI,Машинное обучение,Python,Управление проектами,ML,Подготовка презентаций",УРАЛХМ,"Москва, Выставочная, Пресненская набережная, 6с2"
7003,78768855,Data аналитик/Аналитик BI,з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем аналитика, который будет определять целевые метрики для достижения стратегических целей, анализировать причины их отклонений, выявлять ключевые факторы влияния, тестировать гипотезы по их улучшению и предлагать возможные пути автоматической оптимизации этих метрик. Вам предстоит: строить модели поведения пользователей Авито, сегментировать их и выявлять потребности продумывать структуру метрик для оценки различных инициатив и проектов, проектировать модель данных и соответствующую отчетность прогнозировать и отслеживать поведение этих метрик, выявлять ключевые факторы влияния и возможности их изменения обнаруживать с помощью анализа данных различные неэффективности в существующих процессах и их исправлять. Мы ожидаем, что вы: имеете опыт работы аналитиком BI / данных от 1 года в совершенстве знаете математическую статистику знаете Python или R получили высшее образование в области вычислительной математики, статистики, анализа данных и т.п. владеете методиками анализа данных, используя различные инструменты любознательны, умеете договариваться. Мы предлагаем: конкурентную заработную плату (оклад и годовой бонус) компенсацию питания расширенный полис ДМС со стоматологией, страхование жизни, страхование выезжающих за рубеж постоянное развитие: обратная связь руководителя, коллег, личный кошелек на обучение вне компании сильная команда амбициозных коллег с высокой профессиональной экспертизой в различных областях индивидуальный план адаптации и наставник помогут пройти испытательный срок в Авито самые передовые IT инструменты для эффективного выполнения задач уверенность в качестве предлагаемых продуктов, которые мы постоянно совершенствуем для наших пользователей масштабные корпоративы, онлайн-вечеринки, командные тимбилдинги, вечерние посиделки и игры в PlayStation 5 здоровый образ жизни: свой тренажерный зал, занимаемся йогой и делаем функциональные тренировки, а также скидки у партнеров 5-тидневка, гибридный или удаленный формат работы. Мы предоставляем все необходимое для удаленной работы: технику, софт, онлайн-обучение.","Scrum,SQL,Аналитическое мышление,Аналитические исследования,Аналитика продаж,Business Intelligence Systems",Авито: аналитика,
7004,78825971,Data scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","СберМобайл - MVNO мобильный оператор связи от Сбербанка ищет Аналитика больших данных Задачи: сследовать паттерны поведения клиентов, находить точки роста, изучать ретеншен Совместно с продуктовой командой искать новые направления развития продукта Формировать кластеризацию клиентской базы Формулировать и проверять гипотезы улучшающие ключевые метрики, оценивать бизнес-эффект от вносимых изменений Проектировать, сопровождать и оптимизировать систему аналитики для различных продуктов Участвовать в аналитических исследованиях, необходимых для запуска и внедерения новых продуктов Разрабатывать и поддерживать дашборды и системы метрик Строить модели клиентского поведения. Требования: Высшее образование (математика, статистика, аналитика данных) Знание продуктовых метрик телеком рынка Опыт работы в области анализа данных (воронки, когортный анализ, A/B-тесты) Знание мат. статистики, понимание основ теории вероятности Опыт понятной визуализации статистических данных и подготовки презентаций Эксперт SQL, Python Понимание основ data science и машинного обучения Умение работать в режиме многозадачности, внимательность к деталям, умение работать в тесной связке с бизнес заказчиком (продукт), способность находить зависимости, уметь объяснять отклонения.  Условия: Данная вакансия не предполагает сотрудников в подчинении График работы 5/2 с 9.00, 9.30 или 10.00, в пятницу сокращенный рабочий день на 1 час 15 минут Официальная заработная плата обсуждается с успешными кандидатами на собеседовании (оклад + ежеквартальные и годовые премии) спытательный срок 3 месяца ДМС после испытательного срока (поликлиническое обслуживание, обследование со сдачей анализов, страховка за рубежом, возможность прикрепления родственников, психологические консультации, +1 день к отпуску за прохождение чек-апа) Компенсация 50% фитнеса и английского языка после испытательного срока Частичная компенсация парковки Дисконт-программы от компаний-партнеров (фитнес, страхование, туризм) Льготное кредитные и ипотечные программы Социальные льготы Оплата участия в спортивных мероприятиях Возможность обучение за счет Компании Офис 5-7 минут пешком от м. Кутузовская, парк Победы , 10 минут .","Бюджетирование,Подготовка презентаций,MS Excel,Финансовый анализ",Сбербанк-Телеком,"Москва, Поклонная улица, 3к2"
7005,76924176,Аналитик Данных / Data Analyst,до 150 000 руб. на руки,1–3 года,"Полная занятость,полный день","Обязанности: Поддержание и масштабирование операционной инфраструктуры компании. Разработка отчётов, дашбордов на Airtable / Tableau / Power Bl. Проектирование, разработка и развитие No-code CRM-систем (для внутренних нужд компании). Автоматизация интеграционных процессов и комплексной бизнес-логики с использованием low-code методов. Требования: Опыт работы с реляционными БД, базовое понимание их проектирования (+ SQL). Понимание общих принципов работы веб-приложений. Опыт работы с Excel / Google Sheets / Airtable / Coda (хотя бы один из инструментов на мидл+-уровне). Опыт работы с Low-code / No-code инструментами + базовое знание одного из ЯП: Python, JS (node.js). Базовые навыки работы с серверами / доменами. Умение описывать и оптимизировать бизнес-процессы. Аналитический склад ума, способность структурировать большие потоки информации. Условия: Офис в центре города (оплачиваем парковочное место). Гибкое начало рабочего дня. Возможность профессионального развития в узкой сфере.","SQL,Организация рабочего процесса,Python,Node.js,Google Docs,Аналитические навыки,Excel,Google таблицы,MS PowerPoint,Автоматизация процессов,Умение работать в условиях многозадачности,Работа в MS Office,JS,Системность",Marlerino Group,
7006,78260411,Data Scientist,от 250 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Renue — IT-компания из Екатеринбурга. Мы специализируемся на разработке масштабных проектов для государственных и крупных IT-компаний в России и СНГ. Каждый наш новый проект - уникальный, потому что мы занимаемся заказной разработкой (B2G), работаем с highload системами, сервис-ориентированной архитектурой и используем современные фреймворки и технологии. Сейчас мы формируем команду и ищем Data Scientist. Пишем пилотную версию чат-бота для ФНС (Федеральная налоговая служба). Это платформа поставки данных. В текущей версии нас ничего не ограничивает для выбора технологий. Для ускорения разработки мы выбрали готовую платформу для построения чат-бота Rasa. О проекте: ВПД (Внешняя поставка данных) - это пилот и некоторая оптимизация работы пользователей: помощь выполнения сценариев чат-бота для неавторизованных пользователей поиск некоторой информации внутри системы для авторизованных пользователей (распознавание намерений, поиск сущностей). Ближайшие планы: в июне 2023г выпустить пилот, далее развивать проект (выстраивать систему аналитики, обучения и переобучения и т.д.). Перспективы. В следующем году планируется большой контракт на создание публичного чат-бота для одной из федеральных инстанций. У него будет два интерфейса: web и Telegram. Поскольку проект масштабный, пользователей и сценариев будет много. Тебе предстоит: сбор, очистка, обработка и систематизация структурированных и неструктурированных производственных данных из различных источников формирование и проверка гипотез для оптимизации производственных процессов разработка математических моделей и алгоритмов машинного обучения для решения задач прогнозирования числовых рядов, обнаружения аномалий в данных, моделирования и оптимизации производственных процессов формирование и проверка гипотез для улучшения моделей разработка программных средств для взаимодействия математических моделей и моделей машинного обучения с остальными модулями программной системы предоставление аналитических выводов и предложений на основе полученной информации описание исследований, формирование отчетов по их итогам. Ты отлично справишься с задачамиnlp, если: имеешь промышленный опыт работы (от постановки задачи до внедрения) в области DS/ML от 3-х лет умеешь решать nlp задачи классификации и кластеризации отлично владеешь Python (DS/ML библиотеки). Мы предлагаем: трудоустройство с первого дня, зарплата белая формат работы на твой выбор: удаленная работа или работа в офисе в центре Екатеринбурга, или гибрид работа в команде с прямыми короткими коммуникации. Мы против формализма и бесконечных совещаний гибкий рабочий график. Мы начинаем во сколько удобно и не считаем часы за работой, готовы к сдвигам в графике, если это не мешает взаимодействию и результату расширенная программа ДМС (с стоматологией, вызовом врача на дом, массажем и телемедициной) развивающая среда: ты сможешь проходить курсы за счёт компании, ездить на IT-конференции, чтобы послушать других или выступить самому помним о праздниках, дарим подарки сотрудникам, веселимся вместе на корпоративах.","Machine Learning,Python,Data Analysis,NLP",Ренью,"Екатеринбург, Площадь 1905 года, улица Хохрякова, 3А"
7008,77213747,Data Analyst,з/п не указана,1–3 года,"Полная занятость,удаленная работа","ООО ""Экспертек БС"" разрабатывает и продвигает тиражируемые решения для предприятий торговли и сетей АЗС, предоставляет комплексные услуги в области торговых аппаратно-программных систем. Основной функционал: Постановка задач на исследование данных Анализ предметной области в рамках задач Формирование из ядра хранилища витрин (широких таблиц) для расчета контрольных процедур (технология SQL, в части БД PostgreSQL и ClickHouse) Формирование кода контрольных процедур для расчета витрин для дашбордов (технологии SQL, Python, Airflow, в части БД ClickHouse) Формирование дашбордов (технологии SQL, jinja, в части БД ClickHouse, в части BI Superset) Анализ витрин из различных источников Составление спецификаций на дашборды и контрольные процедуры Наши ожидания: Высшее образование (математика, статистика, техническое) Опыт работы в роли специалиста по визуализации данных, исследователя данных или аналитика данных от 2х лет Опыт работы с большим объемом информации, консолидация и декомпозиция данных Опыт использования SQL для извлечения, очистки и преобразования данных Подготовка и анализ данных в Python Составление/ использование ER-моделей. Готовы предложить: Оформление в соответствии с ТК РФ Конкурентоспособная ""белая"" заработная плата, обсуждается с успешным кандидатом, пропорционально опыту Годовой бонус Полис ДМС со стоматологией (с первого дня работы) Страхование здоровья и жизни сотрудников, мат.поддержка в различных жизненных обстоятельствах. Крупные проекты в масштабах страны Возможность получения опыта в одном из крупнейших Т-интеграторов России График работы 5/2 ,пятница-сокращенный день. Благодарим Вас за интерес‚ проявленный к нашей Компании. Примерный срок рассмотрения резюме - 14 дней. Отсутствие ответа в течение двух недель означает‚ что, к сожалению‚ на сегодня у нас нет подходящих вакансий. Ваше резюме будет сохранено в резерв, и, в случае открытия более подходящей вакантной должности, с Вами свяжутся дополнительно. Если Ваш опыт работы и пожелания соответствуют требованиям и возможностям компании - мы свяжемся с Вами по указанным в резюме контактам.","Математическая статистика,Анализ данных,Статистический анализ,Аналитика,SQL,Python,BPMN,оптимизация SQ",К СБНТЕК,"Москва, Тульская, Шаболовская, Загородное шоссе, 1к1"
7009,78618459,Data аналитик,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Разработка автоматизированной управленческой отчетности. Анализ банковского рынка. Анализ финансовых показателей банка и построение прогноза таких показателей. Участвовать в разработке и реализации планов развития и усовершенствования работы управления. Рассмотрение поступающей корреспонденции, принятие по ней соответствующих решений, подготовка предложений и ответов на письма и запросы филиалов, Национального банка и других учреждений. Взаимодействие с органами государственного управления, коммерческими банками, субъектами хозяйствования, подразделениями Национального банка по решению вопросов, входящих в компетенцию управления. Требования: Высшее экономическое образование. Стаж работы в банковской системе не менее 2 (двух) лет. Знание законодательных и иных нормативно-правовых актов в сфере банковской деятельности. Знание принципов организации финансовой работы коммерческого банка. Навыки работы с соответствующими программными продуктами, прикладными электронными программами банка и другими техническими средствами, необходимыми для работы. Отсутствие отрицательных характеристик с предыдущих мест трудовой деятельности. Умение составлять на должностном уровне официальные письма и отвечать на административные запросы. Умение рационально использовать рабочее время, пунктуальность, исполнительность, коммуникабельность. Условия: Устройство согласно ТК КР. Пятидневная рабочая неделя. Полный социальный пакет.","Высшее образование,Взаимодействие с контрольными органами,Анализ текущих финансовых показателей,Высокая ответственность",БАКАЙ БАНК,
7010,77339764,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Привет! Мы открываем вакансию Senior Data Analyst в нашу дружную BI Team.  Чем мы занимаемся? В ЕДНОМ ЦУПС мы развиваем и поддерживаем высоконагруженный fintech, состоящий из множества продуктов и проектов, один из крупнейших на рынке. Сейчас мы обрабатываем миллионы платежей в день для более чем 13 миллионов клиентов. Мы разрабатываем сложные финансовые продукты от идентификационных протоколов и системы фрод-мониторинга до собственного высоконагруженного процессинга.  Что нужно делать: Формирование и поддержка отчетов в Полиматика.Аналитика сследовательский анализ данных, выявление закономерностей и отклонений сполнение ad hoc запросов Формирование и поддержка регулярных отчетов на Python (numpy, pandas), SQL (СУБД PostgreSQL, ClickHouse) Построение и сопровождение ETL-процессов Выявление потребностей заказчика, сбор и анализ требований к системе Разработка технических заданий и проектной документации. На что мы будем обращать внимание: Опыт работы аналитиком данных от 1 года Опыт написания SQL запросов Опыт программирования на языке Python Опыт работы с BI-инструментами Понимание работы OLTP- и OLAP-ориентированных БД Понимание теории вероятностей и математической статистики Знание технологий бизнес-аналитики Технический английский Умение работать с открытой документацией Будет плюсом опыт работы с VCS (git) и продуктами Полиматика. Также мы: спользуем Kanban, но планируем задачи на квартал вперед. Предоставляем систему бенефитов. Оформляем официально с первого дня работы. После испытательного предоставляем ДМС. Открыты к изучению новых подходов и технологий, всегда с радостью отправим на конференции и обучение! Как проходит собеседование: 40-минутное знакомство с HR и CTO компании Собеседование с будущим руководителем и командой.  Если в тебе это откликается - пиши нам! Мы будем рады знакомству!","Python,SQL,Data Mining,MS SQL,Git,Tableau",ЕДНЫЙ ЦУПС,
7011,78507896,Data Analyst/Business growth analyst,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Data-Driven Lab — международная IT-компания с головным офисом в Белграде. Мы разрабатываем продукты для разных сфер бизнеса: fintech, analysis. Cейчас они представлены в 150 странах. Наша цель — сделать эти продукты самыми удобными в мире. Наши инструменты для достижения этой цели — исследования, анализ данных и оптимизированный маркетинг. В нашей команде более 450 человек. Мы предлагаем релокацию в Сербию, но с нами можно работать и удаленно. Мы поставили перед собой амбициозные цели, поэтому собираем одну из сильнейших команд профессионалов. Ты будешь работать в комьюнити единомышленников и станешь частью команды профессионалов в своём деле. Среди наших коллег ребята из телекоммуникаций, финтеха и IT (Яндекс, Тинькофф, Альфа, Tele2, Мегафон и другие).  Тебе предстоит: скать и формулировать гипотезы по улучшению бизнес-показателей Заниматься поиском точек роста бизнеса и их внедрением Продумывать структуру метрик для оценки как всего бизнеса, так и различных инициатив или проектов Прогнозировать и отслеживать поведение этих метрик, выявлять ключевые факторы влияния и возможности их изменения Разрабатывать аналитические модели для разных направлений бизнеса Анализировать экономический потенциал и эффективность новых инициатив Заниматься улучшением методологии A/B тестов. Основная задача проекта: Наши задачи сконцентрированы вокруг анализа метрик для оценки как всего бизнеса, так и различных инициатив и проектов. Мы хотим построить систему быстрых обратных связей через аналитику для разных направлений бизнеса. Мы ожидаем, что ты обладаешь: Опытом работы в области продуктовой аналитики или анализа данных от 2-х лет Знаешь алгоритмы и структуры данных, теорию вероятности и мат. статистику на практике Владеешь Python и SQL, знаешь как работать с большим объемом данных меешь опыт визуализации результатов и построения дашбордов в любом инструменте меешь опыт работы с A/B-тестами, знаешь фреймворки проведения экспериментов, можешь самостоятельно анализировать результаты тестов Знаешь методы классификации: RFM, когортный анализ Умеешь за числами распознать физический смысл и находить причины явлений. Будет плюсом: Высшее математическое/экономическое образование Опыт построения ML моделей или теоретические знания об этом Опыты со сложными IT-продуктами и международными проектами Наличие знаний о том как устроен финансовый рынок. Наш стек технологий: Databricks с интеграцией в инфраструктуру GCP PostgreSQL Apache Airflow, DBT Kafka, RabbitMQ Scala, Python, SQL Jira, Confluence, Git Условия работы: Развитие экспертизы. Работа в команде с сильнейшими профессионалами своего дела. Возможности для нетворкинга, обмена опытом, внутреннего и внешнего обучения за счет компании. Возможность влиять на результат. Отсутствие бюрократии и необходимости большого количества согласований. Процессы внутри команды выстраиваются, можно легко повлиять на их развитие и выстраивание глобальных процессов. Комфортные условия. Гибридный график – можно совмещать работу в офисе с удаленкой. Гибкое начало рабочего дня (с 08:00 до 11:00). Приятная атмосфера в мультикультурном офисе и насыщенная корпоративная жизнь. Релокация. Возможность релокации в Сербию после исп. срока (на нас: билеты, аренда жилья, relocation bonus, полное сопровождение официального оформления). Офис. Зоны отдыха, самокаты, массажное кресло, настолки, PS4, кикер. На кухне всегда есть кофе, чай, фрукты, сладости. Стабильность. Конкурентная официальная з/п, продвинутая система бенефитов (медицина, спорт, доплата до оклада на больничном и т.д.). Если ты привык на все сложные задачи смотреть как на вызов, умеешь доказывать гипотезы, быть способным грамотно и ясно доносить, аргументировать с помощью данных свою точку зрения, то эта вакансия для тебя! Welcome to DDL!","Python,SQL,Анализ данных,Математическая статистика,Анализ бизнес показателей,Data Analysis,Аналитические исследования,A/B тесты,Математический анализ",Data-Driven Lab,
7013,78451060,Аналитик данных/Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Чем предстоит заниматься: Подготавливать и отправлять регулярную отчетность, осуществлять поддержку пользователей Подготавливать Ad-hoc аналитику для поддержки принятия бизнес-решений Контролировать качество и целостность данных Общаться с заказчиками, собирать ТЗ, прописывать методологию Создавать скрипты для обработки данных, собирать витрины Визуализировать отчеты в Tableau Писать документацию в Confluence. Наши ожидания: Высшее образование Опыт работы на аналогичных позициях от трех лет Опыт работы с большими массивами данных Знание SQL (написание сложных запросов, процедур, умение работать с чужим кодом) Знание Excel (работа со сводными таблицами, VBA) Умение работать с JIRA/Confluence Опыт создания дашбордов в Tableau или другой BI системе будет являться преимуществом. Мы предлагаем: Работа среди профессионалов финансового рынка Насыщенная корпоративная жизнь Возможность карьерного роста и профессионального развития Стабильный конкурентный доход Оформление согласно ТК РФ Комфортный офис в центре (м. Проспект Мира) Гибридный режим работы Корпоративные скидки и предложения для сотрудников.","MS SQL,BI,SQL,VBA,Power BI,Анализ данных,Анализ текущих финансовых показателей,Atlassian Jira,Базы данных,Отчетность,Сосредоточенность,Atlassian Confluence,Умение изучать",БКС Бизнес и процессы,
7014,78260313,Data Scientist,от 250 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Renue — IT-компания из Екатеринбурга. Мы специализируемся на разработке масштабных проектов для государственных и крупных IT-компаний в России и СНГ. Каждый наш новый проект - уникальный, потому что мы занимаемся заказной разработкой (B2G), работаем с highload системами, сервис-ориентированной архитектурой и используем современные фреймворки и технологии. Сейчас мы формируем команду и ищем Data Scientist. Пишем пилотную версию чат-бота для ФНС (Федеральная налоговая служба). Это платформа поставки данных. В текущей версии нас ничего не ограничивает для выбора технологий. Для ускорения разработки мы выбрали готовую платформу для построения чат-бота Rasa. О проекте: ВПД (Внешняя поставка данных) - это пилот и некоторая оптимизация работы пользователей: помощь выполнения сценариев чат-бота для неавторизованных пользователей поиск некоторой информации внутри системы для авторизованных пользователей (распознавание намерений, поиск сущностей). Ближайшие планы: в июне 2023г выпустить пилот, далее развивать проект (выстраивать систему аналитики, обучения и переобучения и т.д.). Перспективы. В следующем году планируется большой контракт на создание публичного чат-бота для одной из федеральных инстанций. У него будет два интерфейса: web и Telegram. Поскольку проект масштабный, пользователей и сценариев будет много. Тебе предстоит: сбор, очистка, обработка и систематизация структурированных и неструктурированных производственных данных из различных источников формирование и проверка гипотез для оптимизации производственных процессов разработка математических моделей и алгоритмов машинного обучения для решения задач прогнозирования числовых рядов, обнаружения аномалий в данных, моделирования и оптимизации производственных процессов формирование и проверка гипотез для улучшения моделей разработка программных средств для взаимодействия математических моделей и моделей машинного обучения с остальными модулями программной системы предоставление аналитических выводов и предложений на основе полученной информации описание исследований, формирование отчетов по их итогам. Ты отлично справишься с задачами nlp, если: имеешь промышленный опыт работы (от постановки задачи до внедрения) в области DS/ML от 3-х лет умеешь решать nlp задачи классификации и кластеризации отлично владеешь Python (DS/ML библиотеки). Мы предлагаем: трудоустройство с первого дня, зарплата белая формат работы на твой выбор: удаленная работа или работа в офисе в центре Екатеринбурга, или гибрид работа в команде с прямыми короткими коммуникации. Мы против формализма и бесконечных совещаний гибкий рабочий график. Мы начинаем во сколько удобно и не считаем часы за работой, готовы к сдвигам в графике, если это не мешает взаимодействию и результату расширенная программа ДМС (с стоматологией, вызовом врача на дом, массажем и телемедициной) развивающая среда: ты сможешь проходить курсы за счёт компании, ездить на IT-конференции, чтобы послушать других или выступить самому помним о праздниках, дарим подарки сотрудникам, веселимся вместе на корпоративах.","Machine Learning,Python,Data Analysis,NLP",Ренью,"Екатеринбург, Площадь 1905 года, улица Хохрякова, 3А"
7015,78740551,Data Scientist (HR-модели),з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Разработка моделей в направлении Human Resources. Построение моделей влияния обучения на эффективность, выявление факторов, влияющих на выполнение KPI. Разработка математической модели инструментария влияния на повышение эффективности сотрудников. Требования: Уверенное знание статистического анализа Опыт разработки интерпретируемых моделей  Опыт работы с табличными данными  Желателен опыт работы с графами, текстовой аналитикой (NLP) Продвинутое знание Python и стандартного DS стэка: sklearn, pandas, xgboost, tensorflow/pytorch Уверенное знание и владение SQL. Стэк: Hadoop, Impala Умение работать с зашумленными данными, проверка качества данных Проработка A/B тестирования гипотез Опыт разработки и доведения до прода моделей в коммерческих проектах Опыт командной работы (мы используем git, jira).","Python,SQL,Git,Atlassian Jira,Анализ данных",Газпромбанк,
7018,76164705,Middle Data Analyst / Product Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Привет! Мы - команда международной продуктовой компании со штатом в 1800+ человек. Вот уже больше 6-ти лет мы трудимся над нашим основным продуктом - многофункциональной web-платформой с микросервисной архитектурой и высокой нагрузкой. Главная ценность нашей компании - люди. менно поэтому мы ищем лучших из лучших специалистов, которым готовы предоставить возможность роста и развития внутри компании, достойную оплату труда и конкурентные условия работы, а также огромный коллектив талантливых людей, которые вероятнее всего могут стать не только твоими коллегами, но и друзьями:) Сейчас мы в поиске коллеги на позицию Data Analyst / Product Analyst уровня Middle в команду Data analytics. Твои задачи и зона ответственности: Анализ данных, поиск инсайтов Дизайн и анализ A/B тестов Генерация и проверка гипотез Проведение продуктовых исследований Построение дашбордов в BI системе. Для нас важно: Hard Skills: Уверенное знание SQL Уверенное знание Python для анализа данных Понимание статистики и теории вероятности Опыт работы с инструментами web-аналитики (Amplitude, Google Analytics) будет плюсом. Soft Skills: Автономность, умение находить лучшее решение задачи нициативность, внедрение новых решений и технологий в аналитику Структурное мышление, умение декомпозировать задачу, способность видеть закономерности в данных, глубоко погружаться в них. Наш стек: ClickHouse MySQL Python для анализа данных (pandas, numpy, scipy, plotly, statsmodels etc) Tableau / Holistics GTM Amplitude / Google Analytics. Для тебя: Дружная команда крутых специалистов и максимально комфортная рабочая атмосфера Сокращенный рабочий день (7 часов) и гибкое начало дня (с 9 до 12) Оборудованное рабочее место Возможность полностью удаленной работы Официальное трудоустройство Частичная компенсация курсов английского языка и занятий в фитнес-зале Доступ к корпоративной библиотеке Корпоративы с выездами на природу и призами, тимбилдинги, мастер-классы и тд Релокационный пакет и возможность получения отсрочки от призыва на мобилизацию.","SQL,Python,Статистика,Amplitude,Google Analytics,Русский — C2 — В совершенстве",Виэйинтеллидженс,
7020,78632812,Аналитик данных в Data Office,з/п не указана,1–3 года,"Полная занятость,полный день","Data Office появился пару лет назад. Наша команда: • строит хранилище данных для VK • запустила Data Portal как отдельный сервис для удобного взаимодействия с данными основные наши пользователи — маркетологи, менеджеры продуктов, аналитики, дата-сайентисты • провела десятки обучающих мероприятий для менеджеров и аналитиков • организовала сообщества DS/ML и Analytics и объединила дата-сайентистов и аналитиков всех продуктов VK • провела сотни продуктовых исследований.  Каждый день мы работаем с огромными объёмами данных (50 петабайт), используем современный стек технологий (Spark, Airflow, Presto, Vertica, ClickHouse) и разрабатываем современные дата-сервисы, которые помогают развиваться каждому продукту в компании.  Основные функциональные направления нашей работы: • Data Analytics, • Data Engineering, • Data Science, • Product and Service Development. щем специалиста, который поможет нам формировать регулярную аналитическую отчётность и проводить исследования различной сложности. Вам предстоит: • создавать и регулярно обновлять аналитическую отчётность • находить причины аномалий, ошибки в данных и курировать их исправление • исследовать данные источников, искать зависимости, выстраивать процессы с нуля • формировать growth-hacking идеи • выполнять ad-hoc задачи. У нас интересно, потому что: • мы анализируем данные, выдвигаем, разрабатываем и тестируем гипотезы по улучшению продуктовых метрик • вы сможете узнать, как устроены все продукты VK, поработать с их данными и реализовать с нуля новые проекты. Мы ожидаем, что вы: • получили высшее техническое образование • работали аналитиком данных не менее 2 лет • уверенно владеете SQL — знаете про сложные запросы и оконные функции • знаете Python на уровне обработки и анализа данных — Pandas, SciPy, NumPy, библиотеки matplotlib, plotly, seaborn • умеете интерпретировать результаты аналитики и превращать их в понятную форму для бизнеса — продакт-менеджеров и маркетологов • знаете основы статистики, математики, комбинаторики, эконометрики • умеете самостоятельно разбираться в бизнес-процессе, искать слабые стороны и придумывать решения. Приглашаем специалиста, который сможет работать в комбинированном режиме в офисе в Москве или Санкт-Петербурге. Ждём ваших откликов. Удачи!","MS SQL,Python,Анализ данных,ClickHouse,Hadoop","VK, ВКонтакте",
7023,78508667,Data Engineer,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Skillfactory — это одна из самых быстрорастущих российских EdTech-компаний, участник рейтинга РБК, резидент Сколково. Это группа из 3 компаний, куда входят: Школа Data Science, программирования и аналитики данных Skillfactory. Школа дизайна Contented. Skillfactory Высшее образование - сервис по созданию онлайн-магистратур совместно с ВУЗами. Наш продукт - образовательные курсы  Сейчас мы ищем Data Engineer, который будет заниматься проектированием и разработкой аналитических витрин данных и интеграционных решений, подключать новые источники данных и прорабатывать архитектуру процессов. Чем предстоит заниматься: Разработка, поддержка и оптимизация ETL-процессов Разрабатывать систему мониторинга работоспособности сайта Настраивать систему алертов об отклонении показателей и ключевых метрик Настраивать подключение к разным источникам данных через API Создание витрин данных. Что мы ждем от кандидата: Хорошее владение SQL (PostreSQL, MySQL, BigQuery) Есть опыт настройки ETL процессов (AirFlow) Хорошее знание Python Есть опыт настройки виртуальных машин и оптимизация производительности обработки данных Понимание принципов работы реляционных баз данных. Что мы предлагаем: Полную занятость (оформление по ТК) “Белую” зарплату и квартальные бонусы На 100% удаленную работу Много свободы и простор для инициативы и развития Помощь и поддержку команды. Пожалуйста, в сопроводительном письме укажите ваш стек, есть ли опыт работы в AirFlow (или аналогах?) и ваши зарплатные ожидания. До связи! :)",,Skillfactory,
7024,78464362,Data Quality Analyst / Аналитик по качеству данных,з/п не указана,1–3 года,"Полная занятость,удаленная работа","В связи с активным ростом в Бизнес единицу X5 Технологии нашей компании открыта вакансия Data Quality Analyst / Аналитик по качеству данных. Big Data является одним из приоритетных направлений нашей компании. В 2017 году, в рамках компании создан новый департамент по разработке продуктов на основе Big Data. Наша основная задача сейчас - создать инструменты для более качественного изучения трендов среди наших покупателей. Присоединившись к нашей команде, вы сможете применить свои знания и опыт для решения интересных и сложных задач, которые повлияют на десятки миллионов людей, посещающих нашу сеть ежедневно. Вакансия открыта в команде продукта CVM (Customer Value Management)  Наша команда занимается разработкой рекомендательной системы для покупателей на основе больших данных и предиктивной аналитики. Данная система позволит нам автоматизировать сегментацию покупателей и индивидуальные предложения промо акций для них. В нашей команде тебе предстоит: Создавать новые и поддерживать существующие инструменты по работе с данными Автоматизировать процессы по работе с данными Анализировать потребности в развитии инструментов управления данными Реализовывать/управлять активностями по разработке нового функционала Общаться с бизнес-заказчикоми и смежными подразделениями Документировать разработанные решения. Мы ждем тебя, если ты имеешь: Релевантный опыт работы от 2 лет Хороший уровень владения SQL (на уровне оконных функций) Понимание устройства хранилища данных Опыт работы с какими-либо из перечисленных СУБД: Postgres, Oracle, Greenplum, Hive Высшее техническое или математическое образование. Будет дополнительным плюсом: Опыт работы со стеком Hadoop Мы предлагаем: Удобный офисы у м.Савеловская, м.Добрынинская, м.Волгоградский проспект или удаленную работу Гибкий график работы (с 8/9/10 утра) Возможность обучаться и сертифицироваться за счёт компании: внешние тренинги и семинары по профессиональным тематикам, отраслевые конференции, программа развития управленческих навыков, очные мастер-классы, платформы онлайн-образования и многое другое Яркую корпоративную жизнь с большим количеством мероприятий, конкурсов и возможностей для творческой реализации Развитую систему компенсаций и льгот Широкий пакет ДМС (включая выезд за рубеж и стоматологию), страхование жизни и здоровья Скидки в магазинах сети Х5 («Пятёрочка», «Перекрёсток») Программу привилегий Prime-zone (скидки на товары и услуги и специальные предложения от компаний-партнёров) Материальную помощь сотрудникам, попавшим в сложную жизненную ситуацию Оформление по ТК РФ с официальной заработной платой. Присоединяйся к одной из самых быстрорастущих цифровых команд России! ООО ""КОРПОРАТВНЫЙ ЦЕНТР КС 5"" представляет бренд Х5 Тech",,X5 Tech,
7025,78786319,Data Analyst (middle/middle+) Core-analytics,з/п не указана,3–6 лет,"Полная занятость,полный день","В связи с расширением ищем аналитика данных уровня middle/midle+ в отдел аналитики бизнеса. Обязанности: исследования аудитории по основным метрикам (MAW, MAU, Active Base, WT, AWTPW) построение автоматизированных инструментов аналитики совершенствование системы метрик, по которой живет бизнес ad-hoc-запросы и рисерчи предиктивная аналитика. Требования: структурное, аналитическое мышление инструменты обработки данных (SQL, Python/R) понимание бизнес-метрик и взаимосвязей между ними опыт работы в аналитике данных от 2 лет опыт работы с системами визуализации данных (Data Studio, Power BI, Tableau, Splunk либо аналоги) высшее техническое образование Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","SQL,Python,Data Analysis,Reporting",Okko,"Москва, Баррикадная, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с13"
7026,78265110,Senior Data Scientist,от 300 000 руб. на руки,3–6 лет,"Полная занятость,полный день","«Сеть партнерств» – аккредитованная в Минцифре IT-компания. Мы создаем и развиваем новые продукты, технологические и маркетинговые решения. В июле 2021 мы запустили наш флагманский продукт – подписку «Огонь» ogon.ru Это B2C сервис, который объединяет продуктовые предложения независимых друг от друга партнеров в различных потребительских категориях.  Для реализации RoadMap на 2023 приглашаем в команду Senior Data Scientist Что предстоит делать: Осуществлять техническое руководство DS командой: заниматься выстраиванием технологических процессов, unit-тестирование, code-review, сборка, ведение документации, изучать SoTA фреймворки и библиотеки Вникать в бизнес-суть проектов и общаться с внутренними заказчиками, заниматься определением бизнес-метрик эффективности моделей Поддерживать, развивать текущие и новые проекты: прогнозирование действий пользователей (отток, использование офферов подписки), анализ обратной связи, рекомендательные модели, разработка поискового движка. Стек проекта: JupyterHub (Python) ClickHouse, PostgreSQL, Kafka, Influx DB Prometheus + Grafana Kubernetes + Docker Gitlab Nifi Tableau Что мы ожидаем: Опыт работы в data science от 3 лет и владение математическим аппаратом Отличное знание SQL, Python и ML библиотек и фреймворков Опыт построения CI/CD для ML Опыт работы с Git. Будет плюсом: Аккаунт с работами на Kaggle Опыт построения витрин данных Опыт работы с Docker Опыт c AutoML. Условия Проект с финансовой поддержкой крупных инвесторов нновационные сложные продукты, без легаси В команде: архитектор, дата-инженеры, ДБА, бизнес-аналитики, BI разработчики и девопс-инженеры - обеспечивают высокий уровень результата и профессионализм команды Белая заработная плата + бонусы в течение года до +30% к окладу Гибридный формат работы: удаленно + из офиса (м. Калужская) ДМС расширенный Увеличенный размер отпуска - 31 день.","Прогнозирование,Python,SQL,Tableau,Machine Learning,Data Analysis,Data Science,Git,Анализ данных",Сеть Партнерств,
7028,76269193,Data Analyst (Ташкент),з/п не указана,3–6 лет,"Полная занятость,полный день","О нас К нам приходят яркие, драйвовые, открытые личности, а мы стремимся дать каждому сотруднику все возможности для развития и реализации своего потенциала. Приходите и вы, у нас интересно! Кто мы Uzum — это новая уникальная компания в Узбекистане, первая технологичная экосистема сервисов в стране. Мы развиваем сразу несколько высокотехнологичных продуктов, чтобы у миллионов жителей страны был доступ к безграничному ассортименту товаров с быстрой доставкой, а также финансовые сервисы, помогающие в решении бытовых задач и развитии бизнеса. Мы строим собственную IT-платформу, развиваем систему логистики, привлекая к сотрудничеству сотни тысяч предпринимателей. Сейчас в нашей команде лучшие специалисты из ведущих компаний России и Узбекистана, готовые делиться своим опытом и вместе строить уникальный продукт. Подключайтесь к инновациям с Uzum! Чем придется заниматься: - Анализировать продукт  Что необходимо, чтобы все пошло как надо: самостоятельность ориентированность на бизнес Sql, python A/B тестирование Понимание финтеха/ банковских процессов Знание LTV метрик Уверенное знание теории вероятности и математической статистики Наш стэк (на данный момент): Clickhouse/Oracle Airflow Appsflyer Firebase Superset Что мы предлагаем: Возможность брать много ответственности — наши инженеры самостоятельно драйвят большие и сложные фичи внутри продукта Работу с сильной технической и продуктовой командой (у нас работают ребята из лучших Т-компаний России и Узбекистана) Продуктовый подход. Опираемся на исследования и метрики, фокусируемся на результате, который помогает доставлять товары за один день, независимо от стоимости заказа и региона  Гибкий график. Никто не контролирует, во сколько ты начинаешь работать и где находишься, главное — результат, который ты пообещал достичь Свобода действий. Каждый имеет возможность настраивать процессы, включаться в разнообразные проекты, запускать и развивать свои идеи, которые нужны людям Удаленку здорового человека или офис в IT-парке Ташкента. А можно и совмещать.","SQL,Python,Аналитика,A/B тесты,Теория вероятностей,Математический анализ,Русский — C2 — В совершенстве",«UZUM TECHNOLOGIES».,
7029,78409080,Data Analyst [кибербезопасность],з/п не указана,1–3 года,"Полная занятость,полный день","МТС Digital – сердце цифровой экосистемы МТС. 12 гильдий инженеров, суперкомпьютер, системы видеоаналитики, IoT, собственная лабора-тория AI и 20+ петабайт данных. Финтех, стриминг, гейминг, мобильные приложения, облачные сервисы. Каждый день мы работаем над тем, чтобы вывести мобильную и веб-разработку на новый уровень, благодаря сплоченным продуктовым командам и agile методологиям. Мы – центр по работе с данными в новом направление кибербезопасности компании МТС. Наша задача – это создание по-настоящему безопасной, надежной и гибкой инфраструктуры для работы с данными и обеспечение бизнеса передовыми аналитическими решениями. Наш центр являемся ядром всех продуктов подразделения, которые создают как принципиально инновационные B2C продукты, направленные на увеличение приватности наших клиентов в повседневной жизни, так и классические Б продукты B2B сегмента. Сейчас мы в поиске Data Analyst. Чем предстоит заниматься: вместе с командами продуктов формировать гипотезы и проверять их анализировать петабайты данных из самых разных источников и искать новые делать аналитику и визуализацию строить дешборды. Что мы ожидаем: знание языков: SQL, Python опыт работы с БД: PostgresSQL, MySQL, Oracle, PySpark/Hive, (ClickHouse, Veritica) опыт работы с: Superset, Metabase, PoweBI, Tableau, DataLens, Qlick. Что мы предлагаем: собственную платформу MTS Ocean для получения Т-ресурсов, а это значит, что деплой, мониторинг, observability - не будут для вас проблемой, вы сможете сосредоточиться на фичах профессиональные гильдии инженеров по направлениям, чтобы поддерживать друг друга и обмениваться опытом внутреннюю площадку TechTalks для обмена опытом, дискуссий, развития навыков самопрезентации участие во внешних IT конференциях. Мы выступаем на HighLoad++, DataFest, Mobius, Test Driven Conf, Joker, DevOps, Матемаркетинг и даже проводим собственную конференцию по архитектуре Hello, conference полезные курсы и вебинары в корпоративном университете и электронные библиотеки. А еще: медицинскую страховку с 1 месяца со 100% покрытием расходов, включая стоматологию, страхование жизни и здоровья в поездках за рубеж. А еще можно застраховать родственников с корпоративной скидкой доступ к сервису «Понимаю»: онлайн-консультации с психологом, юристом, экспертом по финансам или ЗОЖ. корпоративный и командный психолог в офисе и массажный кабинет единую подписку МТС Premium — KION light в онлайн-кинотеатре KION, сервис МТС Music, 30 дней бесплатного пользования подпиской OZON Premium скидки и предложения от партнеров на фитнес, занятия английским и прочее.",,МТС,
7030,78736467,Разработчик-исследователь / Data Scientist в Data Office,з/п не указана,3–6 лет,"Полная занятость,полный день","Data Office — центральный хаб данных VK. Мы создаём дата-продукты, делаем единую точку входа для всей аналитики в VK и автоматизируем различные сценарии работы с данными. Мы находимся в поиске самостоятельного специалиста по большим данным и машинному обучению, который будет помогать нам создавать новые дата-продукты и развивать существующие. Вам предстоит: исследовать данные, заниматься ad-hoc аналитикой, сегментацией/кластеризацией, антифродом и так далее разрабатывать и тестировать новые признаки строить и оптимизировать ML-модели создавать метрики оценки качества дата-продуктов разрабатывать продакшен-пайплайны для процессинга данных, в том числе с использованием ML. У нас интересно, потому что: мы анализируем данные, выдвигаем, разрабатываем и тестируем гипотезы по улучшению продуктовых метрик вы сможете узнать, как устроены все продукты VK, поработать с их данными и реализовать с нуля новые проекты. Мы ожидаем, что вы: обладаете хорошей математической подготовкой знаете классические алгоритмы и структуры данных уверенно владеете Python и SQL разбираетесь в алгоритмах и метриках ML, работали с ML-библиотеками знаете Luigi или Airflow работали с Hadoop (Spark, Hive, HDFS) уверенно взаимодействуете с командной строкой в Linux. Приглашаем специалиста, который сможет посещать офис в Москве или Санкт-Петербурге, работать в комбинированном режиме или удалённо. Ждем ваших откликов. Удачи!",,"VK, ВКонтакте",
7031,77399021,Middle Data аналитик (Middle Data Analyst),з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности:  Собирать и систематизировать данные, готовить аналитические материалы по деятельности компании  Визуализация больших массивов данных, моделирование данных для отчетов (Qlik Sense)  Преобразовывать большие массивы данных в инсайты с помощью автоматизированных отчетов и дэшбордов  Участвовать в реализации аналитических проектов (сбор, структурирование и анализ данных, генерация идей, поиск паттернов и представление результатов в понятном виде)  Помогать в определении точек роста компании  Сбор требований от заказчиков и оформление детальных требований к данным для команды разработки Требования:  Системное мышление, аналитический склад ума  Внимание к деталям, профессиональный скептицизм  Самостоятельность и ориентированность на результат  Стремление к развитию, быстрая обучаемость  Умение вести конструктивную коммуникацию с коллегами письменно и устно  Умение выстраивать причинно-следственные связи  Наличие технического/математического образования  Умение разбираться в данных (находить, понимать и соединять данные, представлять в структурированном виде, делать выводы)  Умение грамотно коммуницировать с коллегами, доносить выводы и наработки до бизнеса  Хороший уровень знания языка запросов SQL обязательно (умение читать и писать скрипты)  Опыт работы в построении аналитических дэшбордов будет плюсом (SAP Analytics Cloud, Qlik Sense, Tableau)  Знание Python (Pandas, Numpy) будет плюсом Условия: Уютный, современный офис в центре города, в шаговой доступности от станции метро, работа только в оффлайн формате Тимбилдинги, зону отдыха Ecodom (куда вы можете приехать со своими близкими), а также детский лагерь Скидки в Technofit (современный фитнес центр + безлимитное посещение более 30 групповых программ) нтересные задачи и новые проекты Возможность роста и обучения Cовременную технику Скидки в наших магазинах.","SQL,Анализ данных,Работа с большим объемом информации,Аналитическое мышление,Коммуникация,Работа в условиях многозадачности,Qlik Sense",TECHNODOM Operator (Технодом Оператор),
7032,76217954,Data Analyst (Partner`s sales),от 150 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Кто мы: BestDoctor — экосистема медицинских и страховых сервисов, созданная экспертами для удобного управления здоровьем. Мы меняем рынок медицинского страхования и отношение людей к своему здоровью с помощью качественного сервиса и принципиально нового клиентского опыта. Благодаря глубокой экспертизе в создании медицинских решений и любви к своему делу, нам удалось создать ту самую экосистему полезных, эффективных и, главное, простых медицинских сервисов для управления здоровьем компаний и людей. Чего мы достигли:  За семь лет мы вышли на второе место по числу клиентов среди insurtech компаний в Европе. Сегодня с нами уже 100 000+ застрахованных пользователей (40 000 из них мы подключили в 2021 году), а в списке клиентов — Aviasales, МТС Банк, Нетология, InDriver, Эвотор, Ivi.ru, Ostrovok.ru, VC.ru и еще 140 компаний.  Создали экосистему медицинских сервисов, которая включает в себя: сервис онлайн-поддержки 24/7, сервис онлайн записи в оффлайн клинику, свою виртуальную клинику, сервис второго мнения специалиста, чекапы, сервис психологической поддержки и др.  Запустили свою страховую BestInsure - на базе которой мы развиваем линейку страховых сервисов (страхование критических заболеваний, имущества, страхование от несчастного случая, страховки на время путешествия и др.). Один из наших успешных продуктов: страхование посуточной аренды с партнёрами sutochno.ru и Avito.ru. Подробнее о сервисе BestDoctor: https://bestdoctor.ru/ и https://hh.ru/article/29681 Кого мы ищем Мы ищем опытного data-аналитика в команду партнёрских продаж, который сможет выстроить систему метрик для контроля и принятия управленческих решений и выстраивания системы продаж, а также оптимизировать процессы при помощи данных и отчетов. Наш отдел Партнёрки занимается создание партнёрских программ с крупнейшими игроками рынка - МТС-Банк, Авито, Visa и многими другими. Для наш клиентов мы создаем генетические чекапы, дающие ответы на все вопросы, различные well-being продукты с нутрициологами и психологическими консультациями, а также семейные продукты заботы о здоровье. Тебе предстоит: Работать над ad-hoc запросами стейкхолдеров и предоставлять регулярную отчетность змерять ключевые показатели бизнес-процессов, строить понятные и удобные для принятия управленческих решений дашборды и отчеты Выстраивать системы метрик для отслеживания целевых показателей в рамках инициатив Лидировать методологию и вести расчет unit – экономики наших продуктов в разрезе ключевых центров формирования затрат Повышать качество данных совместно с командой DWH. Мы ожидаем, что ты: Отлично владеешь SQL: сложные запросы, cte, оконные функции. Круто, если умеешь понимать и оптимизировать план запроса Уверенно владеешь Tableau (actions, комбинированные графики, сложные визуализации, построение линий тренда, корреляционный анализ) Продуктовое мышление – это про тебя. Понимаешь приоритеты и цели бизнеса, самостоятельно погружаешься в продукт и выдвигаешь гипотезы по его развитию Умеешь общаться с разработчиками на одном языке и можешь самостоятельно взаимодействовать с заказчиками. Nice to have! Знание Python будут преимуществом Как мы нанимаем: Мы готовы оперативно выходить с оффером, если понимаем, что подходим друг другу. 1 этап - телефонное интервью с HR (15-20 минут) 2 этап - техническое интервью с тимлидом команды аналитики 3 этап - финальное интервью с CDO и HR. Почему с нами круто? Ты можешь подобрать формат работы под себя: офис (ст.м. Савёловская), микс, полная удаленка У нас гибкий график работы, который подойдет как жаворонку, так и сове Тебя будет окружать команда талантливых и мотивированных людей Мы предоставим тебе ноутбук и всю необходимую технику, которая позволит эффективно и комфортно работать ДМС от BestDoctor после испытательного срока.  Ты будешь частью большого социально значимого дела. Мы реализуем амбициозную задачу — меняем рынок страхования и здравоохранения, действительно помогаем людям, и у нас это отлично получается.  у тебя получится.","SQL,Tableau,Python,Data Analysis,Анализ бизнес показателей",BestDoctor,"Москва, Савёловская, Савёловская, Вятская улица, 27с15"
7035,78405363,Аналитик данных / Data Scientist,от 150 000 руб. на руки,1–3 года,"Полная занятость,полный день","Обязанности: Проверять продуктовые гипотезы и готовить Ad-hoc аналитику для поддержки принятия бизнес-решений. зучать поведение пользователей, формулировать гипотезы по улучшению их опыта. Планировать эксперименты вместе с командами маркетинга и продаж, проводить их и подводить итоги. Подготовка презентаций, ведение регулярных отчетных таблиц, загрузка и контроль входных - выходных данных. Анализ, оформление, подготовка аналитических записок. Разработка формул для расчетов. Мы ожидаем от вас: Высшее образование (обязательно с математическим или техническим уклоном). Опыт работы с OLAP-кубами, большими массивами данных. Опыт работы с неструктурированными данными. Продвинутое использование Microsoft Excel, Microsoft PowerBI. Продвинутое использование Python, Jupiter notebook, Scikit-learn, Pandas, Keras, Catboost. Опыт предобработки данных. Опыт исследовательского анализа данных. Опыт статистического анализа данных. Опыт применения машинного обучения в бизнесе. Вы знакомы с продуктовыми метриками и представляете, как их используют. Знаете SQL и применяли его для решения практических задач (желательно, по возможности). Умеете автоматизировать рутинные задачи с помощью программирования (желательно, по возможности). Грамотно излагаете свои мысли. Условия: Оклад обсуждается после финального собеседования с успешным кандидатом. График работы 5/2 10:00 - 19:00 (формат работы обсуждается). нтересные задачи в Компании с известным брендом на рынке элитной недвижимости. Дружный коллектив профессионалов.","Ad Hoc Analysis,Python,Olap (online analytical processing),База данных: Olap,Аналитическое мышление,Анализ данных,Jupiter,Pandas,PowerBI,Английский — B1 — Средний",Kalinka - Realty,"Москва, 1-й Казачий переулок, 7"
7036,78736467,Разработчик-исследователь / Data Scientist в Data Office,з/п не указана,3–6 лет,"Полная занятость,полный день","Data Office — центральный хаб данных VK. Мы создаём дата-продукты, делаем единую точку входа для всей аналитики в VK и автоматизируем различные сценарии работы с данными. Мы находимся в поиске самостоятельного специалиста по большим данным и машинному обучению, который будет помогать нам создавать новые дата-продукты и развивать существующие. Вам предстоит: исследовать данные, заниматься ad-hoc аналитикой, сегментацией/кластеризацией, антифродом и так далее разрабатывать и тестировать новые признаки строить и оптимизировать ML-модели создавать метрики оценки качества дата-продуктов разрабатывать продакшен-пайплайны для процессинга данных, в том числе с использованием ML. У нас интересно, потому что: мы анализируем данные, выдвигаем, разрабатываем и тестируем гипотезы по улучшению продуктовых метрик вы сможете узнать, как устроены все продукты VK, поработать с их данными и реализовать с нуля новые проекты. Мы ожидаем, что вы: обладаете хорошей математической подготовкой знаете классические алгоритмы и структуры данных уверенно владеете Python и SQL разбираетесь в алгоритмах и метриках ML, работали с ML-библиотеками знаете Luigi или Airflow работали с Hadoop (Spark, Hive, HDFS) уверенно взаимодействуете с командной строкой в Linux. Приглашаем специалиста, который сможет посещать офис в Москве или Санкт-Петербурге, работать в комбинированном режиме или удалённо. Ждем ваших откликов. Удачи!",,"VK, ВКонтакте",
7038,78260313,Data Scientist,от 250 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Renue — IT-компания из Екатеринбурга. Мы специализируемся на разработке масштабных проектов для государственных и крупных IT-компаний в России и СНГ. Каждый наш новый проект - уникальный, потому что мы занимаемся заказной разработкой (B2G), работаем с highload системами, сервис-ориентированной архитектурой и используем современные фреймворки и технологии. Сейчас мы формируем команду и ищем Data Scientist. Пишем пилотную версию чат-бота для ФНС (Федеральная налоговая служба). Это платформа поставки данных. В текущей версии нас ничего не ограничивает для выбора технологий. Для ускорения разработки мы выбрали готовую платформу для построения чат-бота Rasa. О проекте: ВПД (Внешняя поставка данных) - это пилот и некоторая оптимизация работы пользователей: помощь выполнения сценариев чат-бота для неавторизованных пользователей поиск некоторой информации внутри системы для авторизованных пользователей (распознавание намерений, поиск сущностей). Ближайшие планы: в июне 2023г выпустить пилот, далее развивать проект (выстраивать систему аналитики, обучения и переобучения и т.д.). Перспективы. В следующем году планируется большой контракт на создание публичного чат-бота для одной из федеральных инстанций. У него будет два интерфейса: web и Telegram. Поскольку проект масштабный, пользователей и сценариев будет много. Тебе предстоит: сбор, очистка, обработка и систематизация структурированных и неструктурированных производственных данных из различных источников формирование и проверка гипотез для оптимизации производственных процессов разработка математических моделей и алгоритмов машинного обучения для решения задач прогнозирования числовых рядов, обнаружения аномалий в данных, моделирования и оптимизации производственных процессов формирование и проверка гипотез для улучшения моделей разработка программных средств для взаимодействия математических моделей и моделей машинного обучения с остальными модулями программной системы предоставление аналитических выводов и предложений на основе полученной информации описание исследований, формирование отчетов по их итогам. Ты отлично справишься с задачами nlp, если: имеешь промышленный опыт работы (от постановки задачи до внедрения) в области DS/ML от 3-х лет умеешь решать nlp задачи классификации и кластеризации отлично владеешь Python (DS/ML библиотеки). Мы предлагаем: трудоустройство с первого дня, зарплата белая формат работы на твой выбор: удаленная работа или работа в офисе в центре Екатеринбурга, или гибрид работа в команде с прямыми короткими коммуникации. Мы против формализма и бесконечных совещаний гибкий рабочий график. Мы начинаем во сколько удобно и не считаем часы за работой, готовы к сдвигам в графике, если это не мешает взаимодействию и результату расширенная программа ДМС (с стоматологией, вызовом врача на дом, массажем и телемедициной) развивающая среда: ты сможешь проходить курсы за счёт компании, ездить на IT-конференции, чтобы послушать других или выступить самому помним о праздниках, дарим подарки сотрудникам, веселимся вместе на корпоративах.","Machine Learning,Python,Data Analysis,NLP",Ренью,"Екатеринбург, Площадь 1905 года, улица Хохрякова, 3А"
7040,78178051,ESG – аналитик / Data-Miner,от 60 000 до 80 000 руб. на руки,1–3 года,"Полная занятость,гибкий график","Обязанности: Сбор информации из открытых источников Обработка информации, полученной от клиентов Сравнение и систематизация собранных данных Первичный анализ и оценка информации Ведение документации. Дополнительно: Участие в подготовке вебинаров и мероприятий Анализ тематических новостей. Требования: Умение находить информацию в интернете, построение сложных поисковых запросов Способность ориентироваться в единицах измерения, не путать тонны с литрами и т.п., а также переводить их друг в друга. Excel на уровне простых формул, Word с умением форматировать без лишних пробелов Английский – intermediate (B1). Желательные навыки: Элементарные навыки пользования финансовой отчетностью, поиска или вычисления выручки, EBITDA и т.п. Опыт в ESG – огромный плюс. Условия: Гибридный режим работы после периода обучения Гибкий график ДМС после испытательного срока Официальное оформление и белая зарплата.","Internet,Пользователь ПК,Excel,Поисковые системы,Английский язык (Intermediate),Систематизация информации,Работа с большим объемом информации,Английский — B1 — Средний",РАЭКС-Аналитика,"Москва, Весковский переулок, 3"
7041,77800691,Data Entry Specialist and Analyst,от 140 000 до 160 000 KZT на руки,не требуется,"Полная занятость,полный день",,,Maxinum Consulting Ltd,"Алматы, Алатау, улица Айманова, 124"
7042,78451060,Аналитик данных/Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Чем предстоит заниматься: Подготавливать и отправлять регулярную отчетность, осуществлять поддержку пользователей Подготавливать Ad-hoc аналитику для поддержки принятия бизнес-решений Контролировать качество и целостность данных Общаться с заказчиками, собирать ТЗ, прописывать методологию Создавать скрипты для обработки данных, собирать витрины Визуализировать отчеты в Tableau Писать документацию в Confluence. Наши ожидания: Высшее образование Опыт работы на аналогичных позициях от трех лет Опыт работы с большими массивами данных Знание SQL (написание сложных запросов, процедур, умение работать с чужим кодом) Знание Excel (работа со сводными таблицами, VBA) Умение работать с JIRA/Confluence Опыт создания дашбордов в Tableau или другой BI системе будет являться преимуществом. Мы предлагаем: Работа среди профессионалов финансового рынка Насыщенная корпоративная жизнь Возможность карьерного роста и профессионального развития Стабильный конкурентный доход Оформление согласно ТК РФ Комфортный офис в центре (м. Проспект Мира) Гибридный режим работы Корпоративные скидки и предложения для сотрудников.","MS SQL,BI,SQL,VBA,Power BI,Анализ данных,Анализ текущих финансовых показателей,Atlassian Jira,Базы данных,Отчетность,Сосредоточенность,Atlassian Confluence,Умение изучать",БКС Бизнес и процессы,
7043,78683367,"Data Analyst, Compliance Department",з/п не указана,3–6 лет,"Полная занятость,полный день","We are Quadcode, a company that develops a SaaS trading platform for clients around the world.  The Data Analyst in the Compliance Department is responsible for providing analytical support to ensure compliance with regulatory requirements, policies, and procedures. The role involves collecting, analyzing, and interpreting complex data from various sources to identify patterns, trends, and potential risks that may impact the organization's compliance posture. Overall, the Data Analyst in the Compliance Department plays a critical role in ensuring the organization meets its compliance obligations by leveraging data analysis and insights to proactively identify and mitigate potential risks. Tasks in the role: collect, process, and analyze data related to compliance activities, including but not limited to risk assessments, audits, and investigations conduct in-depth data analysis to identify patterns, trends, anomalies and potential risks related to compliance issues develop and maintain dashboards, reports, and other data instruments to communicate compliance-related insights to stakeholders collaborate with cross-functional teams to identify areas of improvement and recommend solutions to address compliance risks conduct ad-hoc data analysis to support ongoing compliance initiatives and projects maintain a thorough understanding of regulatory requirements and industry best practices related to compliance and data analysis build a strategy for the development of analytics in compliance. Requirements: 2+ years of experience in data analysis, preferably in a compliance or regulatory environment practical experience writing complex SQL queries and optimizing them knowledge of Python experience with data visualization tools such as Tableau or Superset strong analytical skills and attention to detail excellent written and verbal communication skills ability to work independently and collaboratively in a fast-paced, dynamic environment English language proficiency at least at B2 level. Would be a plus: experience with Airflow and DBT systems. We offer: health insurance and mental health services 13th salary and 21 vacation days per year provided lunches or food allowance monthly tuition reimbursement (kindergartens/schools) opportunity to learn English and Greek sports reimbursement team buildings and parties bonuses for special events (e.g. child's birth).","Python,SQL,Английский — B2 — Средне-продвинутый",Quadcode,
7044,78260411,Data Scientist,от 250 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Renue — IT-компания из Екатеринбурга. Мы специализируемся на разработке масштабных проектов для государственных и крупных IT-компаний в России и СНГ. Каждый наш новый проект - уникальный, потому что мы занимаемся заказной разработкой (B2G), работаем с highload системами, сервис-ориентированной архитектурой и используем современные фреймворки и технологии. Сейчас мы формируем команду и ищем Data Scientist. Пишем пилотную версию чат-бота для ФНС (Федеральная налоговая служба). Это платформа поставки данных. В текущей версии нас ничего не ограничивает для выбора технологий. Для ускорения разработки мы выбрали готовую платформу для построения чат-бота Rasa. О проекте: ВПД (Внешняя поставка данных) - это пилот и некоторая оптимизация работы пользователей: помощь выполнения сценариев чат-бота для неавторизованных пользователей поиск некоторой информации внутри системы для авторизованных пользователей (распознавание намерений, поиск сущностей). Ближайшие планы: в июне 2023г выпустить пилот, далее развивать проект (выстраивать систему аналитики, обучения и переобучения и т.д.). Перспективы. В следующем году планируется большой контракт на создание публичного чат-бота для одной из федеральных инстанций. У него будет два интерфейса: web и Telegram. Поскольку проект масштабный, пользователей и сценариев будет много. Тебе предстоит: сбор, очистка, обработка и систематизация структурированных и неструктурированных производственных данных из различных источников формирование и проверка гипотез для оптимизации производственных процессов разработка математических моделей и алгоритмов машинного обучения для решения задач прогнозирования числовых рядов, обнаружения аномалий в данных, моделирования и оптимизации производственных процессов формирование и проверка гипотез для улучшения моделей разработка программных средств для взаимодействия математических моделей и моделей машинного обучения с остальными модулями программной системы предоставление аналитических выводов и предложений на основе полученной информации описание исследований, формирование отчетов по их итогам. Ты отлично справишься с задачамиnlp, если: имеешь промышленный опыт работы (от постановки задачи до внедрения) в области DS/ML от 3-х лет умеешь решать nlp задачи классификации и кластеризации отлично владеешь Python (DS/ML библиотеки). Мы предлагаем: трудоустройство с первого дня, зарплата белая формат работы на твой выбор: удаленная работа или работа в офисе в центре Екатеринбурга, или гибрид работа в команде с прямыми короткими коммуникации. Мы против формализма и бесконечных совещаний гибкий рабочий график. Мы начинаем во сколько удобно и не считаем часы за работой, готовы к сдвигам в графике, если это не мешает взаимодействию и результату расширенная программа ДМС (с стоматологией, вызовом врача на дом, массажем и телемедициной) развивающая среда: ты сможешь проходить курсы за счёт компании, ездить на IT-конференции, чтобы послушать других или выступить самому помним о праздниках, дарим подарки сотрудникам, веселимся вместе на корпоративах.","Machine Learning,Python,Data Analysis,NLP",Ренью,"Екатеринбург, Площадь 1905 года, улица Хохрякова, 3А"
7047,78365379,Data Analyst,з/п не указана,3–6 лет,"Проектная работа/разовое задание,полный день","Мы в компании «INSITECH Development» работаем над различными IT проектами, как собственными, так и для наших клиентов - лидеров российского рынка. Мы активно осваиваем новые направления и аудитории. «INSITECH Development» — команда единомышленников, которая создает инновационные продукты и ценит своих сотрудников. Мы растем и расширяемся. Работа над проектами происходит с использованиями гибкого фреймворка SCRUM Для нас очень важно что бы у Вас было: Уверенное знание математической статистики и умение использовать ее в работе Уверенное знание Python на уровне стандартных библиотек для анализа данных (numpy, pandas, scikit-learn, statsmodels) Хорошее знание Pyspark Знание ML Хорошее владение SQL (join, фильтрация, агрегирование, группировка) Работа у нас — это: Команда профессионалов, готовых поддержать ваши инициативы Возможность работы с новыми технологиями Гибкий график Возможность удаленной работы Достойная зарплата — размер обсудим на собеседовании Будем благодарны если Вы коротко расскажете о себе в сопроводительном письме. С нетерпением ждем Ваших откликов!","Data Mining,Python,SQL,Pyspark,ML,Big Data,Математическая статистика,Pandas,Анализ данных,Статистический анализ,Data Science,Spark,Tableau",INSITECH Development,
7049,78301838,Digital Data Analyst,от 150 000 до 249 000 руб. на руки,более 6 лет,"Полная занятость,полный день","Responsibilities: Generate and test hypotheses for conversion growth together with our agencies Predict the cost and likelihood of conversion: CPO, CPL, etc. Building an unified Brand database from various sources (Data of e-commerce, registrations on the site, Smart TV Users, mobile app, data from media campaigns, etc.), development of a long-term communication strategy with different segments of the Brand database Develop data-driven proposals for business process optimization and work them through with internal stakeholders. Communicate and Collaborate with internal business stakeholders, data science peers from Agencies and the Colleagues responsible for data storage. Regular A/B testing, hypotheses, test setup, analysis of results, debriefing, performance reporting Making forecasts of site performance indicators (traffic, revenue, conversion, average check, bounce rate and deliverability). Audit existing data processes to ensure they are functioning correctly. Work with performance team to help architect solutions when problems exist Track the implementation of KPIs, conduct a deep factor analysis of deviations, prepare proposals based on the results of the analysis and contribute to their implementation Determination and prediction of the unsubscription rate, fraud search, analysis of appeals to the Brand through various channels (website, social networks, instant messengers, customer service, etc.) Development of a strategy for managing communication channels with Subscribers, setting up personalized communication processes (e-mail, messengers, push notifications, calls, etc.) Evaluate demand and calculate unit economics, calculate payback and break-even point Requirements: 5+ years experience in data science or analytics, data marketing with data management responsibilities The ability to find data insights and a willingness to understand the essence of the processes that this data shows MS Excel, SQL – advanced user, able to quickly work with big data sets. Strong analysis skills, experience with searching insights in data and developing recommendations based on analytics. Intermediate+ English. Excellent communication skills, willing and readiness to communicate with internal customers. Ability to balance multiple, competing directions and manage multiple projects successfully Possess knowledge of methods and metrics of statistical analysis and machine learning, understanding of their applicability, and ability to explain them to the Colleagues Experience in implementing projects in the field of data analysis Experienced in the use of statistical analysis/modeling - correspondence analysis, time series analysis and other regression, clustering, factor analysis etcюб Proficient in use statistical software (Python, SQL) Knowledge of the principles of Google Marketing Platform tools and ability to work with Google Tag Manager Understanding attribution models for each digital channel Conditions: Registration according to the Labor Code of the Russian Federation Working hours at office 9:00 – 18:00 Trial period of 3 months Medical insurance (VMI), Life insurance after the trial period Lunch allowance Incentive pay according to corporate policy. Place of work: Business office building near M. Belorusskaya Salary is negotiable","Data Science,SQL,MS PowerPoint,Big Data,Анализ данных,Marketing Strategy Development,Analytical skills,MySQL,Статистический анализ,Английский — C1 — Продвинутый",HS Ad,"Москва, 4-й Лесной переулок, 4"
7052,78409080,Data Analyst [кибербезопасность],з/п не указана,1–3 года,"Полная занятость,полный день","МТС Digital – сердце цифровой экосистемы МТС. 12 гильдий инженеров, суперкомпьютер, системы видеоаналитики, IoT, собственная лабора-тория AI и 20+ петабайт данных. Финтех, стриминг, гейминг, мобильные приложения, облачные сервисы. Каждый день мы работаем над тем, чтобы вывести мобильную и веб-разработку на новый уровень, благодаря сплоченным продуктовым командам и agile методологиям. Мы – центр по работе с данными в новом направление кибербезопасности компании МТС. Наша задача – это создание по-настоящему безопасной, надежной и гибкой инфраструктуры для работы с данными и обеспечение бизнеса передовыми аналитическими решениями. Наш центр являемся ядром всех продуктов подразделения, которые создают как принципиально инновационные B2C продукты, направленные на увеличение приватности наших клиентов в повседневной жизни, так и классические Б продукты B2B сегмента. Сейчас мы в поиске Data Analyst. Чем предстоит заниматься: вместе с командами продуктов формировать гипотезы и проверять их анализировать петабайты данных из самых разных источников и искать новые делать аналитику и визуализацию строить дешборды. Что мы ожидаем: знание языков: SQL, Python опыт работы с БД: PostgresSQL, MySQL, Oracle, PySpark/Hive, (ClickHouse, Veritica) опыт работы с: Superset, Metabase, PoweBI, Tableau, DataLens, Qlick. Что мы предлагаем: собственную платформу MTS Ocean для получения Т-ресурсов, а это значит, что деплой, мониторинг, observability - не будут для вас проблемой, вы сможете сосредоточиться на фичах профессиональные гильдии инженеров по направлениям, чтобы поддерживать друг друга и обмениваться опытом внутреннюю площадку TechTalks для обмена опытом, дискуссий, развития навыков самопрезентации участие во внешних IT конференциях. Мы выступаем на HighLoad++, DataFest, Mobius, Test Driven Conf, Joker, DevOps, Матемаркетинг и даже проводим собственную конференцию по архитектуре Hello, conference полезные курсы и вебинары в корпоративном университете и электронные библиотеки. А еще: медицинскую страховку с 1 месяца со 100% покрытием расходов, включая стоматологию, страхование жизни и здоровья в поездках за рубеж. А еще можно застраховать родственников с корпоративной скидкой доступ к сервису «Понимаю»: онлайн-консультации с психологом, юристом, экспертом по финансам или ЗОЖ. корпоративный и командный психолог в офисе и массажный кабинет единую подписку МТС Premium — KION light в онлайн-кинотеатре KION, сервис МТС Music, 30 дней бесплатного пользования подпиской OZON Premium скидки и предложения от партнеров на фитнес, занятия английским и прочее.",,МТС,
7057,78786319,Data Analyst (middle/middle+) Core-analytics,з/п не указана,3–6 лет,"Полная занятость,полный день","В связи с расширением ищем аналитика данных уровня middle/midle+ в отдел аналитики бизнеса. Обязанности: исследования аудитории по основным метрикам (MAW, MAU, Active Base, WT, AWTPW) построение автоматизированных инструментов аналитики совершенствование системы метрик, по которой живет бизнес ad-hoc-запросы и рисерчи предиктивная аналитика. Требования: структурное, аналитическое мышление инструменты обработки данных (SQL, Python/R) понимание бизнес-метрик и взаимосвязей между ними опыт работы в аналитике данных от 2 лет опыт работы с системами визуализации данных (Data Studio, Power BI, Tableau, Splunk либо аналоги) высшее техническое образование Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","SQL,Python,Data Analysis,Reporting",Okko,"Москва, Баррикадная, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с13"
7058,77339764,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Привет! Мы открываем вакансию Senior Data Analyst в нашу дружную BI Team.  Чем мы занимаемся? В ЕДНОМ ЦУПС мы развиваем и поддерживаем высоконагруженный fintech, состоящий из множества продуктов и проектов, один из крупнейших на рынке. Сейчас мы обрабатываем миллионы платежей в день для более чем 13 миллионов клиентов. Мы разрабатываем сложные финансовые продукты от идентификационных протоколов и системы фрод-мониторинга до собственного высоконагруженного процессинга.  Что нужно делать: Формирование и поддержка отчетов в Полиматика.Аналитика сследовательский анализ данных, выявление закономерностей и отклонений сполнение ad hoc запросов Формирование и поддержка регулярных отчетов на Python (numpy, pandas), SQL (СУБД PostgreSQL, ClickHouse) Построение и сопровождение ETL-процессов Выявление потребностей заказчика, сбор и анализ требований к системе Разработка технических заданий и проектной документации. На что мы будем обращать внимание: Опыт работы аналитиком данных от 1 года Опыт написания SQL запросов Опыт программирования на языке Python Опыт работы с BI-инструментами Понимание работы OLTP- и OLAP-ориентированных БД Понимание теории вероятностей и математической статистики Знание технологий бизнес-аналитики Технический английский Умение работать с открытой документацией Будет плюсом опыт работы с VCS (git) и продуктами Полиматика. Также мы: спользуем Kanban, но планируем задачи на квартал вперед. Предоставляем систему бенефитов. Оформляем официально с первого дня работы. После испытательного предоставляем ДМС. Открыты к изучению новых подходов и технологий, всегда с радостью отправим на конференции и обучение! Как проходит собеседование: 40-минутное знакомство с HR и CTO компании Собеседование с будущим руководителем и командой.  Если в тебе это откликается - пиши нам! Мы будем рады знакомству!","Python,SQL,Data Mining,MS SQL,Git,Tableau",ЕДНЫЙ ЦУПС,
7059,78632812,Аналитик данных в Data Office,з/п не указана,1–3 года,"Полная занятость,полный день","Data Office появился пару лет назад. Наша команда: • строит хранилище данных для VK • запустила Data Portal как отдельный сервис для удобного взаимодействия с данными основные наши пользователи — маркетологи, менеджеры продуктов, аналитики, дата-сайентисты • провела десятки обучающих мероприятий для менеджеров и аналитиков • организовала сообщества DS/ML и Analytics и объединила дата-сайентистов и аналитиков всех продуктов VK • провела сотни продуктовых исследований.  Каждый день мы работаем с огромными объёмами данных (50 петабайт), используем современный стек технологий (Spark, Airflow, Presto, Vertica, ClickHouse) и разрабатываем современные дата-сервисы, которые помогают развиваться каждому продукту в компании.  Основные функциональные направления нашей работы: • Data Analytics, • Data Engineering, • Data Science, • Product and Service Development. щем специалиста, который поможет нам формировать регулярную аналитическую отчётность и проводить исследования различной сложности. Вам предстоит: • создавать и регулярно обновлять аналитическую отчётность • находить причины аномалий, ошибки в данных и курировать их исправление • исследовать данные источников, искать зависимости, выстраивать процессы с нуля • формировать growth-hacking идеи • выполнять ad-hoc задачи. У нас интересно, потому что: • мы анализируем данные, выдвигаем, разрабатываем и тестируем гипотезы по улучшению продуктовых метрик • вы сможете узнать, как устроены все продукты VK, поработать с их данными и реализовать с нуля новые проекты. Мы ожидаем, что вы: • получили высшее техническое образование • работали аналитиком данных не менее 2 лет • уверенно владеете SQL — знаете про сложные запросы и оконные функции • знаете Python на уровне обработки и анализа данных — Pandas, SciPy, NumPy, библиотеки matplotlib, plotly, seaborn • умеете интерпретировать результаты аналитики и превращать их в понятную форму для бизнеса — продакт-менеджеров и маркетологов • знаете основы статистики, математики, комбинаторики, эконометрики • умеете самостоятельно разбираться в бизнес-процессе, искать слабые стороны и придумывать решения. Приглашаем специалиста, который сможет работать в комбинированном режиме в офисе в Москве или Санкт-Петербурге. Ждём ваших откликов. Удачи!","MS SQL,Python,Анализ данных,ClickHouse,Hadoop","VK, ВКонтакте",
7060,76217954,Data Analyst (Partner`s sales),от 150 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Кто мы: BestDoctor — экосистема медицинских и страховых сервисов, созданная экспертами для удобного управления здоровьем. Мы меняем рынок медицинского страхования и отношение людей к своему здоровью с помощью качественного сервиса и принципиально нового клиентского опыта. Благодаря глубокой экспертизе в создании медицинских решений и любви к своему делу, нам удалось создать ту самую экосистему полезных, эффективных и, главное, простых медицинских сервисов для управления здоровьем компаний и людей. Чего мы достигли:  За семь лет мы вышли на второе место по числу клиентов среди insurtech компаний в Европе. Сегодня с нами уже 100 000+ застрахованных пользователей (40 000 из них мы подключили в 2021 году), а в списке клиентов — Aviasales, МТС Банк, Нетология, InDriver, Эвотор, Ivi.ru, Ostrovok.ru, VC.ru и еще 140 компаний.  Создали экосистему медицинских сервисов, которая включает в себя: сервис онлайн-поддержки 24/7, сервис онлайн записи в оффлайн клинику, свою виртуальную клинику, сервис второго мнения специалиста, чекапы, сервис психологической поддержки и др.  Запустили свою страховую BestInsure - на базе которой мы развиваем линейку страховых сервисов (страхование критических заболеваний, имущества, страхование от несчастного случая, страховки на время путешествия и др.). Один из наших успешных продуктов: страхование посуточной аренды с партнёрами sutochno.ru и Avito.ru. Подробнее о сервисе BestDoctor: https://bestdoctor.ru/ и https://hh.ru/article/29681 Кого мы ищем Мы ищем опытного data-аналитика в команду партнёрских продаж, который сможет выстроить систему метрик для контроля и принятия управленческих решений и выстраивания системы продаж, а также оптимизировать процессы при помощи данных и отчетов. Наш отдел Партнёрки занимается создание партнёрских программ с крупнейшими игроками рынка - МТС-Банк, Авито, Visa и многими другими. Для наш клиентов мы создаем генетические чекапы, дающие ответы на все вопросы, различные well-being продукты с нутрициологами и психологическими консультациями, а также семейные продукты заботы о здоровье. Тебе предстоит: Работать над ad-hoc запросами стейкхолдеров и предоставлять регулярную отчетность змерять ключевые показатели бизнес-процессов, строить понятные и удобные для принятия управленческих решений дашборды и отчеты Выстраивать системы метрик для отслеживания целевых показателей в рамках инициатив Лидировать методологию и вести расчет unit – экономики наших продуктов в разрезе ключевых центров формирования затрат Повышать качество данных совместно с командой DWH. Мы ожидаем, что ты: Отлично владеешь SQL: сложные запросы, cte, оконные функции. Круто, если умеешь понимать и оптимизировать план запроса Уверенно владеешь Tableau (actions, комбинированные графики, сложные визуализации, построение линий тренда, корреляционный анализ) Продуктовое мышление – это про тебя. Понимаешь приоритеты и цели бизнеса, самостоятельно погружаешься в продукт и выдвигаешь гипотезы по его развитию Умеешь общаться с разработчиками на одном языке и можешь самостоятельно взаимодействовать с заказчиками. Nice to have! Знание Python будут преимуществом Как мы нанимаем: Мы готовы оперативно выходить с оффером, если понимаем, что подходим друг другу. 1 этап - телефонное интервью с HR (15-20 минут) 2 этап - техническое интервью с тимлидом команды аналитики 3 этап - финальное интервью с CDO и HR. Почему с нами круто? Ты можешь подобрать формат работы под себя: офис (ст.м. Савёловская), микс, полная удаленка У нас гибкий график работы, который подойдет как жаворонку, так и сове Тебя будет окружать команда талантливых и мотивированных людей Мы предоставим тебе ноутбук и всю необходимую технику, которая позволит эффективно и комфортно работать ДМС от BestDoctor после испытательного срока.  Ты будешь частью большого социально значимого дела. Мы реализуем амбициозную задачу — меняем рынок страхования и здравоохранения, действительно помогаем людям, и у нас это отлично получается.  у тебя получится.","SQL,Tableau,Python,Data Analysis,Анализ бизнес показателей",BestDoctor,"Москва, Савёловская, Савёловская, Вятская улица, 27с15"
7062,76164705,Middle Data Analyst / Product Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Привет! Мы - команда международной продуктовой компании со штатом в 1800+ человек. Вот уже больше 6-ти лет мы трудимся над нашим основным продуктом - многофункциональной web-платформой с микросервисной архитектурой и высокой нагрузкой. Главная ценность нашей компании - люди. менно поэтому мы ищем лучших из лучших специалистов, которым готовы предоставить возможность роста и развития внутри компании, достойную оплату труда и конкурентные условия работы, а также огромный коллектив талантливых людей, которые вероятнее всего могут стать не только твоими коллегами, но и друзьями:) Сейчас мы в поиске коллеги на позицию Data Analyst / Product Analyst уровня Middle в команду Data analytics. Твои задачи и зона ответственности: Анализ данных, поиск инсайтов Дизайн и анализ A/B тестов Генерация и проверка гипотез Проведение продуктовых исследований Построение дашбордов в BI системе. Для нас важно: Hard Skills: Уверенное знание SQL Уверенное знание Python для анализа данных Понимание статистики и теории вероятности Опыт работы с инструментами web-аналитики (Amplitude, Google Analytics) будет плюсом. Soft Skills: Автономность, умение находить лучшее решение задачи нициативность, внедрение новых решений и технологий в аналитику Структурное мышление, умение декомпозировать задачу, способность видеть закономерности в данных, глубоко погружаться в них. Наш стек: ClickHouse MySQL Python для анализа данных (pandas, numpy, scipy, plotly, statsmodels etc) Tableau / Holistics GTM Amplitude / Google Analytics. Для тебя: Дружная команда крутых специалистов и максимально комфортная рабочая атмосфера Сокращенный рабочий день (7 часов) и гибкое начало дня (с 9 до 12) Оборудованное рабочее место Возможность полностью удаленной работы Официальное трудоустройство Частичная компенсация курсов английского языка и занятий в фитнес-зале Доступ к корпоративной библиотеке Корпоративы с выездами на природу и призами, тимбилдинги, мастер-классы и тд Релокационный пакет и возможность получения отсрочки от призыва на мобилизацию.","SQL,Python,Статистика,Amplitude,Google Analytics,Русский — C2 — В совершенстве",Виэйинтеллидженс,
7066,78464362,Data Quality Analyst / Аналитик по качеству данных,з/п не указана,1–3 года,"Полная занятость,удаленная работа","В связи с активным ростом в Бизнес единицу X5 Технологии нашей компании открыта вакансия Data Quality Analyst / Аналитик по качеству данных. Big Data является одним из приоритетных направлений нашей компании. В 2017 году, в рамках компании создан новый департамент по разработке продуктов на основе Big Data. Наша основная задача сейчас - создать инструменты для более качественного изучения трендов среди наших покупателей. Присоединившись к нашей команде, вы сможете применить свои знания и опыт для решения интересных и сложных задач, которые повлияют на десятки миллионов людей, посещающих нашу сеть ежедневно. Вакансия открыта в команде продукта CVM (Customer Value Management)  Наша команда занимается разработкой рекомендательной системы для покупателей на основе больших данных и предиктивной аналитики. Данная система позволит нам автоматизировать сегментацию покупателей и индивидуальные предложения промо акций для них. В нашей команде тебе предстоит: Создавать новые и поддерживать существующие инструменты по работе с данными Автоматизировать процессы по работе с данными Анализировать потребности в развитии инструментов управления данными Реализовывать/управлять активностями по разработке нового функционала Общаться с бизнес-заказчикоми и смежными подразделениями Документировать разработанные решения. Мы ждем тебя, если ты имеешь: Релевантный опыт работы от 2 лет Хороший уровень владения SQL (на уровне оконных функций) Понимание устройства хранилища данных Опыт работы с какими-либо из перечисленных СУБД: Postgres, Oracle, Greenplum, Hive Высшее техническое или математическое образование. Будет дополнительным плюсом: Опыт работы со стеком Hadoop Мы предлагаем: Удобный офисы у м.Савеловская, м.Добрынинская, м.Волгоградский проспект или удаленную работу Гибкий график работы (с 8/9/10 утра) Возможность обучаться и сертифицироваться за счёт компании: внешние тренинги и семинары по профессиональным тематикам, отраслевые конференции, программа развития управленческих навыков, очные мастер-классы, платформы онлайн-образования и многое другое Яркую корпоративную жизнь с большим количеством мероприятий, конкурсов и возможностей для творческой реализации Развитую систему компенсаций и льгот Широкий пакет ДМС (включая выезд за рубеж и стоматологию), страхование жизни и здоровья Скидки в магазинах сети Х5 («Пятёрочка», «Перекрёсток») Программу привилегий Prime-zone (скидки на товары и услуги и специальные предложения от компаний-партнёров) Материальную помощь сотрудникам, попавшим в сложную жизненную ситуацию Оформление по ТК РФ с официальной заработной платой. Присоединяйся к одной из самых быстрорастущих цифровых команд России! ООО ""КОРПОРАТВНЫЙ ЦЕНТР КС 5"" представляет бренд Х5 Тech",,X5 Tech,
7067,77213747,Data Analyst,з/п не указана,1–3 года,"Полная занятость,удаленная работа","ООО ""Экспертек БС"" разрабатывает и продвигает тиражируемые решения для предприятий торговли и сетей АЗС, предоставляет комплексные услуги в области торговых аппаратно-программных систем. Основной функционал: Постановка задач на исследование данных Анализ предметной области в рамках задач Формирование из ядра хранилища витрин (широких таблиц) для расчета контрольных процедур (технология SQL, в части БД PostgreSQL и ClickHouse) Формирование кода контрольных процедур для расчета витрин для дашбордов (технологии SQL, Python, Airflow, в части БД ClickHouse) Формирование дашбордов (технологии SQL, jinja, в части БД ClickHouse, в части BI Superset) Анализ витрин из различных источников Составление спецификаций на дашборды и контрольные процедуры Наши ожидания: Высшее образование (математика, статистика, техническое) Опыт работы в роли специалиста по визуализации данных, исследователя данных или аналитика данных от 2х лет Опыт работы с большим объемом информации, консолидация и декомпозиция данных Опыт использования SQL для извлечения, очистки и преобразования данных Подготовка и анализ данных в Python Составление/ использование ER-моделей. Готовы предложить: Оформление в соответствии с ТК РФ Конкурентоспособная ""белая"" заработная плата, обсуждается с успешным кандидатом, пропорционально опыту Годовой бонус Полис ДМС со стоматологией (с первого дня работы) Страхование здоровья и жизни сотрудников, мат.поддержка в различных жизненных обстоятельствах. Крупные проекты в масштабах страны Возможность получения опыта в одном из крупнейших Т-интеграторов России График работы 5/2 ,пятница-сокращенный день. Благодарим Вас за интерес‚ проявленный к нашей Компании. Примерный срок рассмотрения резюме - 14 дней. Отсутствие ответа в течение двух недель означает‚ что, к сожалению‚ на сегодня у нас нет подходящих вакансий. Ваше резюме будет сохранено в резерв, и, в случае открытия более подходящей вакантной должности, с Вами свяжутся дополнительно. Если Ваш опыт работы и пожелания соответствуют требованиям и возможностям компании - мы свяжемся с Вами по указанным в резюме контактам.","Математическая статистика,Анализ данных,Статистический анализ,Аналитика,SQL,Python,BPMN,оптимизация SQ",К СБНТЕК,"Москва, Тульская, Шаболовская, Загородное шоссе, 1к1"
7068,78576605,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","щем Data Scientist'а в региональный центр компетенций по аналитике для направления ценообразования. Обязанности построение моделей машинного обучения в области клиентской аналитики анализ характеристик пользовательского поведения при объёмах данных на уровне десятков миллионов наблюдений контроль и совершенствование применяемых технологий машинного обучения интеграция источников данных и моделей в бизнес-процессы Банка Требования знание математической статистики, теории вероятностей и желание развиваться в этом направлении знание принципов машинного обучения и желание развиваться в этом направлении опыт получения и обработки сырых данных умение анализировать большие объемы данных, видеть скрытые тенденции и закономерности и описывать их хорошее знание Python и пакетов для научных вычислений знание английского языка на уровне чтения профессиональной литературы Приветствуется: опыт участия в соревнованиях по машинному обучению хорошая алгоритмическая подготовка опыт разработки и внедрения информационных систем Условия структура дохода: оклад + годовой бонус обучение и возможность развиваться профессионально заботу о здоровье: ДМС с первого дня и бесплатный фитнес льготные ставки по потребительским кредитам и ипотеке «ДомКлик» бесплатная подписка СберПрайм+",,Сбер для экспертов,
7071,77186128,Senior Data Analyst,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Чем предстоит заниматься: Проверять гипотезы, проводить разведывательный анализ данных и искать точки роста в маркетинговых и продуктовых взаимодействиях с пользователем Строить BI-отчетность по различным процессам компании Улучшать текущий процесс А/Б-тестирования Автоматизировать аналитические процессы совместно с другими аналитиками Активно участвовать и развивать data-driven подход в компании Работать над улучшением механизмов маркетинговой атрибуции доходов компании Наш стек: СУБД: PostgreSQL, ClickHouse, BigQuery ETL, enrichment, research: Airflow + Python BI: Redash + Superset Для успешного выполнения задач тебе потребуется: Опыт работы аналитиком от трех лет Уверенное знание математического аппарата для разведывательного анализа, проверки гипотез и проведения экспериментов Владение SQL на уровне решения любых задач выборки и обработки данных Владение python или другими ЯП для анализа данных Понимание принципов и метрик e-commerce и продуктовой аналитики Навыки разработки отчетности в BI-системах Знание английского языка на уровне В2 и выше Работа в Movavi – это: Быть частью продуктовой софтверной компании: все – от концепции до дистрибуции – делаем сами Работать с трендовым рынком мультимедиа Делать 20 приложений и программ, переведенных на 18 языков Получать отзывы от пользователей по всему миру. Нашими приложениями пользуются журналисты BBC из Англии, фотографы из США, видеооператоры из Бразилии, блогеры из России, мы сами, наши друзья, ваши друзья. Может быть, вы? :) Находиться в команде из профи, готовых делиться экспертизой Работать удаленно из любой точки мира Если ты не получил ответ на отклик в течение трех рабочих дней: 1. Проверь папку «Спам» в электронной почте. Возможно, письмо с ответом оказалось там. 2. Позвони или напиши нам.","Python,SQL,Английский язык,Анализ данных",Movavi,
7072,73072735,Data analyst (web analysis),з/п не указана,3–6 лет,"Полная занятость,полный день","RUTUBE - Крупнейший российский видеохостинг, где собраны различные категории видео: премьерные выпуски шоу и сериалов, прямые эфиры телеканалов, фильмы и мультфильмы, контент видеоблогеров. Мы стремимся сделать лучший видеосервис на базе высокотехнологичных решений, исследований и аналитики, который позволит смотреть качественный лицензионный контент, адаптированный под каждого пользователя. Что нужно делать: Сбор и консолидация данных для отчетности из различных источников автоматизация процесса сбора и разработка собственных витрин данных с помощью SQL, Python и других инструментов Подготовка ТЗ для разработки целевых витрин данных в DWH силами Т зучение данных в различных источниках выявление аномалий и отклонений в данных, влияющих на анализируемые показатели поиск способов улучшения качества данных в отчетах. Участие в процессе разработки методологии расчета показателей и процессе оптимизации бизнес-процессов, влияющих на сбор данных для отчетности Разработка, доработка, поддержка бизнес-справочников, используемых для формирования отчетности Разработка, доработка и поддержка отчетов в Excel и других системах аналитики Выполнение аналитических ad hoc запросов Что мы ждем от кандидата: Отличная экспертиза в системах веб-аналитики (обязательно)  Опыт получения данных из ЯМ/АМ с помощью API Хорошее знание SQL, опыт работы с ClickHouse приветствуется Знание Python (библиотеки для анализа данных) Знание Excel (Power Query, сводные таблицы) будет преимуществом Системное мышление, внимательность к деталям, способность работать с большими объемами данными в сжатые сроки Способность самостоятельно делать выводы, предлагать решения, аргументировать и презентовать результаты работы Что мы предлагаем: Опыт работы над крупнейшем видеосервисом страны Работу в команде профессионалов и творческих людей Достойный уровень дохода (обсуждается индивидуально с каждым кандидатом) Мы оформим ДМС не дожидаясь окончания испытательного срока Фрукты, овощи, кофе каждый день Гибкое начало рабочего дня Возможность работать по гибридному графику/удаленно (обсуждается индивидуально) Уютный офис в 3 минутах от ст. м. Сокол","Python,SQL,Базы данных,Яндекс.Метрика,Google Analytics",Rutube,"Москва, Аэропорт, Красный Балтиец, Сокол, Ленинградский проспект, 72к4"
7074,78103228,Аналитик DATA,от 70 000 до 150 000 руб. на руки,1–3 года,"Полная занятость,полный день","Обязанности: Аналитическая работа, работа с большими данными Data Science, умение работать Настройка и интеграция статистики с технической поддержкой Работа с скорингом Настройка и обучение машиностроение Работа с DPI трафиком Привлечение новых партнёров Наполнение баз новыми данными Требования: Образование высшее, специальное Уверенный пользователь, Эксель таблицы, знание формул Знания и опыт работы с тригерами Настройки гипотез на стороне оператора Работа с скорингом Настройка и обучение машиностроение Приветствуется знание программирование на языке Python Работа с DPI трафиком Опыт работы в Big-data в крупных компаниях, Банках Желание роста, активность, исполнительность, пунктуальность Приветствуется знание и опыт в данной сфере Условия: Рабочий день: 5/2 8 часовой рабочий день (возможность частичной удаленной работы) Оформление на работу: ТК РФ, ГПХ, договор с П спытательный срок: 2 месяца Заработная плата: 70 000 – 150 000 рублей в месяц (обсуждается на собеседовании) Дополнительные выплаты, социальные гарантии: Карьерный рост Местонахождение рабочего места: м. Деловой центр, Башня Федерации",,Кадровый центр Президент,
7075,78376755,Senior Data Analyst/Аналитик данных (аналитика соцмедиа),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы ищем руководителя направления аналитики данных (аналитика соц. медиа) в команду AI-Маркетинга «Департамента Маркетинга и Коммуникаций», занимающуюся анализом социальных медиа (Social media listening, social media analytics). Вам предстоит работать на стыке аналитики социальных медиа, визуализации и исследования данных (data-science). Вы будете работать в очень сильной, мотивированной и амбициозной команде. Ваша самостоятельность и ответственность – необходимые для работы качества. Некоторые из задач нашего управления: · автоматизированная аналитика информационного поля (СМ, Соц.Медиа) о Сбере и конкурентах · разработка ML-пайплайнов для обработки больших массивов данных из социальных медиа · выявление актуальных потребностей и проблем у потребителей · оценка эффективности маркетинговых коммуникаций и активаций · выявление и оценка трендов Необходимые навыки и опыт: · умение визуализации / разработки дешбордов · опыт работы с BI системами (Power BI, Tableau, Google Data Studio etc) · знание SQL · понимание рынка современных социальных сетей · умение расставлять приоритеты, планировать и работать в команде Несомненными плюсами будут: · опыт работы в аналитике соцмедиа, работа с системами мониторинга социальных медиа и СМ (Brand Analytics, Медиалогия, YouScan) · опыт анализа данных на Python · опыт разработки на react.js и/или vue.js · широкий кругозор в маркетинге, аналитике, банковской отрасли Условия · Профессиональное обучение и развитие · Мотивирующая система оплаты труда · Расширенный социальный пакет, корпоративные льготы (в т.ч. по внутренним программам кредитования и программам лояльности партнёров) · Участие в интересных и инновационных проектах · Отличные возможности для самореализации, результаты, которыми можно гордиться · Высокий уровень корпоративной культуры · Современный офис в шаговой доступности от ст. Кутузовская (метро и МЦК) · Многофункциональный спортивный зал (бесплатно)",,Сбер для экспертов,
7076,78277760,Data & Product Analyst (Пассивы физических лиц),з/п не указана,1–3 года,"Полная занятость,полный день","щем аналитика в команду, которая работает над вкладными продуктами банка. Задачи команды включают в себя реализация сложных ETL-процессов и создание витрин данных и задачи по аналитике.  Задачи: изучение данных о поведении клиентов и решение задач, связанных с пользовательской сегментацией, факторным анализом и поиском точек роста бизнеса генерация продуктовых гипотез по улучшению продукта (предстоит много заниматься discovery) проведение A/B тестов и интерпретация результатов доработка системы ключевых метрик и дэшбордов , позволяющие отвечать на вопросы о том, что происходит с продуктом. участие в аналитических исследованиях, необходимых для запуска и внедрения большого количества новых проектов. Требования: опыт работы в области анализа данных строго от 2-х лет уверенное знание SQL опыт применения статистических методов проверки гипотез, построения оценок и прогнозов сильные навыки визуализации данных, умение наглядно представлять важную информацию и делать выводы, основываясь на цифрах. Условия: официальное оформление по ТК РФ годовое премирование социальный пакет + ДМС корпоративная программа лояльности: бесплатная подписка на СберПрайм+, льготные условия по продуктам банка и скинки в компаниях партнерах треки для развития: большая корпоративная библиотека курсов, возможность обучения за счет компании.","SQL,A/B тесты,Бизнес-анализ,Анализ данных,BI",Сбер. IT,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
7081,78618503,Senior Data Analyst в команду A/B тестирования,з/п не указана,1–3 года,"Полная занятость,полный день","О проекте: Предоставление Self-service функциональности для запуска и улучшения x-sale коммуникаций (Customer Journey) с клиентами Сбера. Предложения, продвижение продуктов, развитие клиентской активности через релевантные и своевременные коммуникации с клиентами на доступных поверхностях взаимодействия с клиентом. Управление процессом из одной точки (единый UI). О команде: В рамках общего проекта есть задача по Self-service A/B-тестированию (A/B платформа). Мы создаем UI для end2end процесса запуска A/B тестов по улучшению CJ (новые продукты / измененные продуктовые условия / модели склонности / контент и проч.) Решение включает в себя цепочку от постановки гипотезы в очередь до масштабирования успешных пилотов. Для усиления команды в части работы с данными и автоматизации подведения итогов тестов ищем Senior DA. Обязанности Участие в разработке платформы AB-тестирования для процесса активных продаж розничным клиентам (CRM) в качестве аналитика данных Постановка требований к данным и анализ соответствия требованиям Разработка концептуальной модели и алгоритмов автоматизированного подведения итогов по A/B тестам Проектирование процедур подведения итогов по A/B тестам, разрезы, агрегации Постановка ТЗ на визуализацию данных (бизнес-отчетность) в BI (QlikSense, AmCharts) сследование и апробирование продвинутых подходов к анализу результатов A/B как часть функционала A/B платформы (линеаризация, бутстрап, CUPED и т.д.) Требования Высшее образование по направлению прикладная математика / физика / Т / финансы Опыт работы в банковской сфере / телекоме / консалтинге Опыт работы с базами данных, навыки написания сложных SQL-запросов (Postgre, Oracle, ClickHouse) Опыт работы с Hadoop (Hive, Impala, Spark) Владение методами анализа данных и инструментами подготовки отчетности T-shapped знания в сторону DE, DS Умение взаимодействовать с коллегами из смежных подразделений, достигать договоренностей, формализовывать требования Самостоятельность, умение вести проект / направление, декомпозировать задачи, соблюдать дедлайны, презентовать результат Является преимуществом: Знание языка программирования (Python) и опыт алгоритмизации процессов Опыт построения аналитических дэшбордов (отчетности) Понимание принципов AB-теста (подобие, значимость, конфигурация эксперимента) Опыт использования продвинутых методов анализа данных (кластеризация, классификация, прогнозные модели) Условия комфортный офис на Кутузовском проспекте с тренажерным залом, коворкинг-пространствами и кафе полный рабочий день, но гибкий график работы (можно выбрать режим начала работы в промежутке 7:00 - 10:30) ДМС, программы лояльности для сотрудников (льготное кредитование, предложения экосистемы Сбера) комьюнити data-people, множество программ профессионального обучения (курсы, тренинги, конференции, семинары).","A/B тестирование,CRM,A/B тест,x-sale,Hadoop,Spark,Python",Сбер для экспертов,
7082,75601449,Senior Аналитик / Senior Data Science (Москва),до 300 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Zaymigo – это современная FinTech компания на рынке онлайн кредитования. Работаем с 2013 года. У нас более 2 000 000 клиентов. В команде больше 130 человек. Мы создаем сервис, дающий людям простой доступ к деньгам в любой стране. Наша компания имеет гибкий подход к решению задач, реализуем лучшие предложения наших сотрудников, поощряем нестандартный подход к делу. Сейчас находимся в поиске аналитика данных (data scientist). Над какими задачами будем работать: Построение рисковых скоринговых моделей Мониторинг работы моделей и их валидация Анализ рисковой отчетности работы компании и подготовка рекомендаций Участие в проектах внутри команды риск-аналитиков. Наставничество команды риск моделистов Мы ждем от Вас: Серьезную математическую подготовку Опыт применения методов статистического анализа и моделирования Опыт работы с алгоритмами машинного обучения Уверенное знание языка Python для анализа больших данных Будут плюсом навыки владения любым программным обеспечением для статистического анализа данных: SPSS, Statistica, Stata, R и т.п. Опыт работы от 1 года в fintech компаниях, банках Присутствие в офисе. Что мы предлагаем: Возможность делать крутые проекты, участвовать во всех этапах деятельности аналитического отдела 8-часовой график работы Посещение отраслевых конференций за счет компании Официальное трудоустройство по ТК РФ Комплектация рабочего места по Вашим запросам Рост ЗП согласно уровню выполняемых задач Молодой, сплоченный коллектив, дружественный микроклимат в отделе Услуги корпоративного психолога Трудоустройство в аккредитованную IT компанию.","Python,Статистический анализ,Математическая статистика,Machine Learning,Анализ данных,Математическое моделирование,Регрессионный анализ,Data Science,Аналитическое мышление,Pandas,Numpy,Анализ временных рядов",Займиго МФК,"Москва, Курская, Курская, улица Земляной Вал, 8"
7084,77656659,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","IT-подразделение IEK GROUP ищет коллегу в распределенную команду разработки аналитических систем, которому было бы интересно вместе с нами развивать data-driven подход в IEK GROUP. Многое уже сделано, построено Хранилище данных (SQL SERVER EE 2019), создан портал бизнес-аналитики (SharePoint), бизнес ""вошел во вкус"" и активно использует OLAP и POWER BI. Данные для подобной аналитики приходится собирать в различных системах - 1С, WMS,CRM ... Мы плотно интегрированы с партнёрами нашей компании, поэтому обмен данных у нас не только внутренний, но и с внешними контрагентами. Мы предлагаем новые подходы к данным, разрабатываем различные ML- сервисы, которые помогают стать компании более эффективной. Уже реализована собственная система прогнозирования спроса, управления эластичностью цен и т.д. Работа построена в основном на принципах Agile, с MVP и желанием сделать хороший и полезный продукт! Работаем в Azur DevOps GIT. так, вливаясь к нам в команду Вам предстоит: Разрабатывать модели машинного обучения Поиск инсайтов в данных, проведение экспериментов Оценка качества и совершенствования моделей Участвовать в выводе моделей в продакшен вместе с командой разработки. Что ждём от Вас: Реализованные кейсы в области DS/ML Phyton+SQL Понимание основных принципов и алгоритмов ML Хороший математический бэкграунд Опыт перевода бизнес-задач в термины ml. Что предлагаем: Удаленный график работы Рабочий день с 09:00 до 17:30 (мскв) Достойный уровень дохода (зависит от профессиональных компетенций) Расширенный социальный пакет: ДМС, дополнительные отпускные дни, оплата больничного листа, материальная помощь в критических ситуациях, бесплатные оздоровительные/спортивные мероприятия Правительственные льготы – мы аккредитованная IT-компания Комфортная, доброжелательная рабочая атмосфера Корпоративные традиции и праздники, коллективные мотивационные программы Офис: 10-15 минут от м. ""Бульвар Дмитрия Донского"" на корпоративном транспорте (г. Щербинка).","SQL,Python,Olap (online analytical processing),Аналитическое мышление,MS SQL",IEK GROUP,
7085,76165484,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы запускаем амбициозный проект CVM в компании с ""0"" и ищем профессионалов в продвинутую команду! CVM - это системная работа с клиентской базой, на основании персонализированных предложений (учитывающих потребности клиентов), которые создаются с использованием продвинутой аналитики и нацелены на повышение долгосрочной ценности клиента (LTV) через повышение частоты покупок, размера средней корзины или предотвращение оттока. Обязанности: Запрос, подготовка и анализ данных Построение и совершенствование моделей машинного обучения Еженедельный анализ промо-кампаний до и после их внедрения (вкл. проверку гипотез) Синтез и представление результатов анализа эффективности кампании Поиск новых возможностей реализации персонализации промо-кампаний в данных Проведение А/B тестов и проверка эффекта для подтверждения коммерческой эффективности промо-кампании Разработка и поддержка общих моделей микросегментации, измерения эффекта от промо-кампаний, прогнозирования предпочтений клиента для использования во многих use cases, расчет LTV Разработка методологии и инструментов мониторинга качества и обновления моделей Создание и поддержка общих ML-библиотек, поддержание архитектуры среды разработки моделей Требования: Отличное знание SQL на уровне оконных функций Уверенные знания и применение методов математической статистики Наличие успешно завершенных проектов с использованием технологий анализа данных и машинного обучения Знание моделей машинного обучения, принципов их работы, методов оценки качества моделей, ключевых особенностей и ограничений Методы оценки значимости и отбора признаков Владение языками и средами для создания регулярно обновляемых моделей машинного обучения (Python, библиотеки pandas, sklearn, xgboost, tensorflow, PyTorch) Желательно: Релевантный опыт работы 2-3 года Желательно: опыт работы в экосистеме Hadoop Желательно: понимание принципов распределенных систем Опыт работы с Docker Высшее образование (Ведущие вузы), желательно математическое/техническое Ключевые навыки: Python SQL A/B тесты Математическая статистика Модели машинного обучения Linux Условия: Официальное оформление в соответствии с ТК РФ, полная стабильность Отсутствие бюрократии и плоская организационная структура Возможность вносить коррективы в процессы, в архитектуру и лояльный бизнес, постоянные коммуникации, возможность на равных обсуждать бизнес-фичи на стадии формирования Действительно высокий уровень дохода, оклад + годовая премия, полностью ""белый"". Гибкое начало работы, но 5/2, полный день. Возможен частично-удаленный формат работы. Офис- м/мцд Окружная или корп.транспорт 7 минут от м.Петровско-Разумовская. Хорошее техническое оснащение, никаких проблем с доступами на удаленной работе Расширенный полис ДМС До 20% скидка на продукцию компании Мы являемся официальной IT компанией в РФ (льготная ипотека, отсрочка от армии). ндексация дохода","Python,SQL,Linux,Power BI",Детский Мир,"Москва, Окружная, Окружная, Петровско-Разумовская, 3-й Нижнелихоборский проезд, 3с6"
7086,78633730,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Международный холдинг «ЕвроХим» специализируется на производстве минеральных удобрений. «ЕвроХим» - это 26 000 человек, 25 стран, 75 предприятий.  В направлении R&D компании АО «МХК «ЕвроХим» открыта вакансия ""Data Scientist"". Основная задача данной позиции - развитие направления по повышению операционной эффективности действующих производств и предприятий за счет применения цифровых технологий (ндустрия 4.0). Глобальная цель направления – реализация полномасштабной программы по внедрению на предприятиях группы компаний лучших научных, технических и цифровых решений и их взаимная интеграция.  Обязанности: Обработка данных, построение аналитических решений Формирование гипотез и определение источников данных Применение алгоритмов машинного обучения и инструментов для сбора и трансформации данных спользования и настройка инструментов для работы с большими массивами структурированных данных Разработка прототипов и работающих решений с помощью программных сред на Python. Требования: Опыт разработки в роли аналитика данных (Data science) не менее 3-х лет Опыт применения машинного обучения для реальных бизнес-задач, работы с сырыми данными, разработки моделей и их валидации Уверенное владение Python и знание библиотек (NumPy, Scikit-learn, XGBoost и пр.) Опыт работы с СУБД, умение писать сложные SQL-запросы Готовность к командировкам. Приветствуется: Знание Kafka, Spark, MLFlow Применения стека технологий разработки: Git. Условия: Оформление в соответствии с нормами ТК РФ, социальные гарантии Крупные проекты в компании–лидере отрасли Возможность модернизировать процессы реального производственного бизнеса в команде сильнейших экспертов Полис ДМС (включая стоматологию) Удаленная работа Доступ к корпоративной OnLine библиотеке Обучение в программах Корпоративного университета Корпоративный спорт, конференции, культурные мероприятия.","Python,SQL,Анализ данных,Data Science,Data Analysis","ЕвроХим, Минерально-Химическая Компания",
7087,78102902,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","ОБЯЗАННОСТ: Разработка ML - математических моделей предсказывающих сумму потенциального убытка по договорам ДМС Полный цикл построения математических моделей от подготовки данных до расчёта финансового результата и подготовки технического задания на внедрение. Подготовка аналитики по портфелю компании. Участие в различных проектах компании по широкому кругу задач блока андеррайтинга в рамках своей функциональной компетенции. ТРЕБОВАНЯ: Высшее образование (МГУ, МФТ, ВШЭ, МГТУ, МФ). Знание методов машинного обучения. Опыт обработки больших объемов данных. Знания SQL, Python (уровень не ниже middle), и библиотек для ML (CatBoost, GLM, Statsmodels, Pandas). Опыт работы от 1 года в data science. Опыт работы в финансовом секторе (страховые компании, банки) будет дополнительным преимуществом для соискателей. Уверенные знания высшей математики, теории вероятностей и базовые знания статистики. Знания и навыки практического применения методов статистического анализа данных. УСЛОВЯ: Работа в крупной и стабильной компании. Официальное трудоустройство по ТК РФ. Скидки на страховые продукты. Спорт, обучающие мероприятия. Заработная плата оклад + квартальная премия (обсуждается по телефону). Гибридный график работы 2/3 (офис + удаленный формат). Офис расположен: г. Москва, ул. Островная д.4 (рядом с офисом собственная, большая, бесплатная парковка). Корпоративный транспорт от ст. м. «Октябрьское поле» и «Кунцевская»",,"ВСК, САО","Москва, Островная улица, 4"
7090,78373670,"Data Analyst (middle/middle+), ""Customer Experience""",з/п не указана,3–6 лет,"Полная занятость,полный день","В связи с расширением ищем аналитика данных уровня middle/midle+ в отдел технической и CX аналитики. Обязанности: аналитика качества пользовательского опыта в сервисе на основании показателей проигрывания, ошибок и иных измеримых дефектов, влияющих на клиента поиск неоптимальных пользовательских путей в сервисе на основании данных аналитика причин оттока пользователей, влияние проблем пользователей на упущенную прибыль мониторинг контента, который пользователи видят в приложении поиск корреляции между клиентскими событиями и удовлетворенностью, определение драйверов лояльности/нелояльности аналитика показателей CX (NPS, CSI) в привязке к бизнес-показателям построение инфраструктуры данных по клиентскому опыту – обновляемые в режиме онлайн дашборды по всем источникам оценок, комментариев клиентов, результатов опросов. Что для нас важно: высшее техническое образование (Прикладная математика / нформатика / Статистика) уверенное владение SQL и Python знание математической статистики быстрая обучаемость, готовность постоянно изучать новые методы и подходы понимание и умение оценивать, как изменение в сервисе повлияет на бизнес. Что мы используем: Presto/Trino, Impala, ClickHouse, PostgreSQL, SberCloud Python и основные ML библиотеки: Pandas, NumPy, SciPy, Scikit-Learn BI среду Splunk. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL",Okko,"Москва, Баррикадная, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с13"
7091,78400616,Middle Data scientist,от 100 000 до 150 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Мы создали RANKS.pro — Систему оценки инвестиционной привлекательности акций. Мы анализируем более 50 000 компаний по всему миру с помощью Data Science. Проект динамично развивается командой профессионалов, для реализации новых проектов мы ищем опытного Data scientist'а, заинтересованного в быстром росте и долгосрочном сотрудничестве. Обязанности: Построение, оптимизация и оценка качества ML-моделей на больших наборах рыночных и финансовых данных. Выдвигать и проверять гипотезы относительно данных для использования в ML-моделях. Сопоставление математических метрик с бизнес-метриками Общение с аналитиками и совместный поиск улучшения моделей Постановка задач и их планирование Умение работать в команде Требования: Знание классических ML-методов регрессии, классификации, кластеризации (линейная регрессия, логистическая, деревья решений, градиентный бустинг, kNN) Знание математической статистики Отличное знание Python и опыт работы с Pandas, sklearn, XGBoost, CatBoost, matplotlib, seaborn Знание SQL (умение писать несложные запросы)  Будет преимуществом: Высшее образование (математическое/экономическое/техническое) Опыт в Data Science и промышленной разработке Опыт работы с финансовыми инструментами фондовой бирж Опыт работы в финтех-стартапах/IT-блоках банков нтерес к инвестициям Условия: Удалённая работа с официальным трудоустройством по ТК РФ или по контракту с НПД (самозанятые) Перспективы диктуются вашими амбициями и успехами Работа непосредственно с основателями IT-стартапа, обучение с наставником на начальном этапе Работа в команде без лишней бюрократии и с большой свободой действий","Python,Математическая статистика,SQL,Pandas,Машинное обучение",Ранкс,
7092,78374239,"Data Analyst (middle/middle+), ""Customer Experience""",з/п не указана,3–6 лет,"Полная занятость,полный день","В связи с расширением ищем аналитика данных уровня middle/midle+ в отдел технической и CX аналитики. Обязанности: аналитика качества пользовательского опыта в сервисе на основании показателей проигрывания, ошибок и иных измеримых дефектов, влияющих на клиента поиск неоптимальных пользовательских путей в сервисе на основании данных аналитика причин оттока пользователей, влияние проблем пользователей на упущенную прибыль мониторинг контента, который пользователи видят в приложении поиск корреляции между клиентскими событиями и удовлетворенностью, определение драйверов лояльности/нелояльности аналитика показателей CX (NPS, CSI) в привязке к бизнес-показателям построение инфраструктуры данных по клиентскому опыту – обновляемые в режиме онлайн дашборды по всем источникам оценок, комментариев клиентов, результатов опросов. Что для нас важно: высшее техническое образование (Прикладная математика / нформатика / Статистика) уверенное владение SQL и Python знание математической статистики быстрая обучаемость, готовность постоянно изучать новые методы и подходы понимание и умение оценивать, как изменение в сервисе повлияет на бизнес. Что мы используем: Presto/Trino, Impala, ClickHouse, PostgreSQL, SberCloud Python и основные ML библиотеки: Pandas, NumPy, SciPy, Scikit-Learn BI среду Splunk. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL",Okko,"Санкт-Петербург, Беговая, улица Савушкина, 126Б"
7093,78440207,Data Scientist (Senior),з/п не указана,1–3 года,"Полная занятость,полный день","Чем нужно будет заниматься: Полный цикл разработки моделей для перформанс маркетинга Банка: 1) аналитика данных, аккумулируемых о лидах, проработка совместно с дата-инженерами и заказчиком состава данных, необходимых для построения моделей 2) обсуждение целевых метрик модели с бизнесом 3) построение моделей для системы сквозной аналитики в сплите каналов коммуникаций по банку, моделей для оптимизации рекламных затрат с сегментированием пользователей по группам, оценка вклада перфоманса в органические выдачи через сайт, определение оптимальную цепочки «касаний» по клиенту для привлечения 4) передача моделей на внедрение и сопровождение внедрения 5) подготовка пилота по эффективности модели, запуск А/Б тестирования 6) подведение результатов пилота, аналитика результатов промышленного внедрения 7) мониторинг модели и последующее перестроение. Требования: опыт построения моделей для перформанс маркетинга (Банки, Т-компании: Яндекс, Мэйл.ру и тп) уверенное знание статистики, мат анализа, теории вероятностей, линейной алгебры глубокое понимание ML алгоритмов (линейная регрессия, бустинг, и т.д.) и оптимизационных алгоритмов - Impala Hadoop - Python (pandas, sklearn, numpy, xgboost, matplotlib, flask and etc.)) - умение представлять результаты в понятном бизнесу виде (Excel/Powerpoint).","Python,SQL,MS PowerPoint,Анализ данных,Математическая статистика,ml",Газпромбанк,
7094,78127250,Data аналитик,з/п не указана,3–6 лет,"Полная занятость,полный день","Газпром ЦПС – аккредитованная Т компания, осуществляющая цифровую трансформацию нефтегазовый сферы. В связи с созданием центра компетенция по управлению данными и запуском масштабного Т проекта, мы приглашаем Data аналитика присоединиться к нашей команде. Требования: Опыт участия в проектах разработки решений класса DWH от 3 лет Практический опыт системного анализа Владение SQL Умение структурировать, систематизировать и анализировать данные Умение четко излагать мысли Опыт участия в интеграционном и функциональном тестировании Опыт разработки проектной документации Дополнительным преимуществом будет владение промышленными средствами моделирования (Erwin либо Power Designer, IBM Data Architect, Sparx Systems Enterprise Architect и т.п.). Обязанности: Формирование и согласование требований к сбору и качеству данных Логическое моделирование предметной области Анализ источников данных, описание потоков данных и участие в их реализации в качестве системного аналитика Участие в интеграционном и функциональном тестировании Участие в подготовке проектной документации в части хранилищ и интеграционного взаимодействия Участие в развитии внутренней экспертизы. Условия: Работа в аккредитованной Т компании Конкурентная заработная плата Годовое премирование по итогам работы Ежегодная индексация заработной платы Льготная ипотека по ставке 5% (программа для аккредитованных Т компаний) ДМС со стоматологией в течение первого месяца работы Компенсация профессионального обучения: обучение, сертификация, курсы Участие в профессиональных конференциях Компенсация спорта Корпоративные мероприятия и спортивные активности Возможен гибридный характер работы.",,Газпром ЦПС,"Санкт-Петербург, Спортивная, проспект Добролюбова, 16к2"
7095,78271635,Middle Data Scientist в центр маркетинговой аналитики (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Middle Data Scientist в центр маркетинговой аналитики Описание продукта: В задачи нового Центра маркетинговой аналитики в Big Data входит помощь маркетинговым командам экосистемы принимать решения на основе больших данных и развитие, поддержка инструмента для оценки эффектов от инвестиций в маркетинг. Обязательно: от 2-х лет коммерческого опыта в построении ML- моделей знание Python на уровне уверенного пользователя, самостоятельное написание кода (не только встроенные библиотеки) знание основ математической статистики, дискретной математики знание методов визуального представление данных опыт работы с маркетологами Что предстоит делать? разрабатывать ML – модели, описывающие продукт изнутри собирать, очищать, обрабатывать и верифицировать данные совместно с внутренними командами МТС, используя внутренние инструменты МТС для сбора данных строить и презентовать рекомендации внутреннему заказчику на основе созданных моделей давать практические рекомендации внутреннему заказчику на основе эконометрических моделей искать продуктовые инсайты, основанные на данных проводить А/В тесты, решить задачи классификации Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта",,МТС,"Москва, Технопарк, проспект Андропова, 18к9"
7096,76913797,Data-Scientist / Дата-сайентист,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Employcity,
7101,78944533,Data Analyst (Conversational AI),з/п не указана,не требуется,"Полная занятость,гибкий график",CAE Technology has been present in Belarus since 2017 and unites a team of professionals in the development of software solutions for the main customer - the international group of companies CAE. Currently we are hiring Data Analysts for Conversational AI projects with a linguistics degree in English for a full-time role in our offices in Minsk or Gomel. Candidates without previous work experience but with excellent English are also welcome! Main duties: Constant work with text information Conduct a qualitative analysis of text data Data labelling Preparation of text information for neural networks in English We are looking for someone who: Has excellent verbal and written communication in English (C1) Has background in Linguistics Is advanced PC user Is ready for daily routine work with big text data Has analytical thinking and attentiveness Previous experience is not required Our conditions: - Work from office (Minsk or Gomel) - Full day (8 hours) - Flexible daily schedule - Salary twice per month to your USD bank account What we can offer you: Your lunch in the office is on us (we order and pay for it) Medical insurance (dental care and medicines are included) Healthy lifestyle activities compensation (not only sports) Discounts from our partners to enjoy and save your money Regular corporate events and parties Comfortable office and unique team:) Your chance to start in IT – apply for our vacancy!,"Английский язык,Английский — C1 — Продвинутый",СиЭй Текнолоджи / CAE Technology,
7108,77435865,Бизнес/системный аналитик (Big Data),з/п не указана,1–3 года,"Полная занятость,удаленная работа","В федеральной розничной сети ""Лента"" открыта вакансия Бизнес-аналитик в Департаменте Big Data. Обязанности: Выявление, управление и поддержка бизнес, функциональных и нефункциональных требований Разработка артефактов анализа: vision, use cases, функциональных спецификаций ПО, диаграмм и пр. Приемка реализованной функциональности Поддержание актуальности документации Взаимодействие с заказчиками, разработчиками, тестировщиками Требования: Системное мышление Владение основами теории алгоритмов, баз данных, систем и системного анализа, защиты информации Опыт моделирования рабочих процессов и данных, проектирования систем и написания спецификаций Опыт проектирования веб-сервисов, баз данных, API, пользовательских интерфейсов Владение основными нотациями моделирования (BPMN, UML) Базовые знания SQL Уверенное владение Excel (включая ВПР и сводные) Грамотная и структурированная письменная русская речь Внимание к деталям, переходящее в дотошность Владение английским на уровне чтения документации Готовность быстро и самостоятельно добрать недостающие hard skills Опыт работы в figma будет плюсом Условия: Удаленная работа Годовое премирование по результатам годовой оценки ДМС класса Люкс со стоматологией Оформление по ТК РФ, белая з.п. Внутреннее обучение и закрытые семинары от лидеров рынка Скидки на спорт и английский язык","UML,BPMN,SQL,Системный анализ,Бизнес-анализ","Лента, федеральная розничная сеть, IT",
7110,79281474,Аналитик Данных (продукт RU DATA),з/п не указана,3–6 лет,"Полная занятость,полный день","нформационная группа «нтерфакс» - лидер российского информационного рынка в сегменте В2В. нтерфакс- также крупная IT-компания с несколькими центрами программных разработок, расположенными в Москве и регионах. Проект RU Data ищет в молодую и активно развивающуюся команду Системного аналитика. Цель проекта – разработка инструментов сбора и предоставления информации по рыночным (биржевым) инструментам и механизмов формирования отчетности (регтех). Для этого ведется разработка REST-API, COM-API, расчетных микросервисов. Чем предстоит заниматься: Сбор требований из различных источников: интервью с заказчиком, законодательные акты, работающая система и ее окружение, документация на ПО других производителей. Анализ источников данных (объема, полноты, состава, качества данных), включая определения наличия конкретных типов финансовых данных. Проектирование сценариев обработки биржевых, финансовых и других данных из внешних источников. Разработка сценариев контроля качества данных, внедрение их в существующие и разрабатываемые системы Подготовка технических заданий для разработчиков. Контроль исполнения (авторский надзор). Подготовка иной проектной документации. Проектирование взаимодействия с внешними системами (интеграция). Что мы ожидаем увидеть в успешном кандидате: Опыт разработки технических заданий и/или спецификаций требований на разработку ПО. Опыт работы c СУБД Oracle или MS SQL, знакомство с SQL. Понимание формата XML, JSON. Опыт работы по направлениям ETL, Data Mining Знание основ функционирования финансового рынка (ценные бумаги, биржевые торги) Будет плюсом: Опыт написания пользовательских сценариев (use-case-ов). Опыт работы с CASE-средствами (MSVisio, Erwin Data Modeler или их аналогами). Что мы готовы предложить: Возможность работать в гибридном формате или удаленно Офис в историческом центре Москвы (Маяковская, 1 мин. ходьбы от метро) Официальное оформление, ""белая"" заработная плата, график работы 5/2 с 09:30 до 18:30, но это не жестко: всегда можно договориться на более гибкий график, ДМС (включая стоматологию) Тренинги и обучение, участие в профессиональных конференциях и корпоративных мероприятия.","XML,JSON,Excel,SQL",нтерфакс,
7113,76513079,Senior Data Engineer (Data Quality Team),з/п не указана,3–6 лет,"Полная занятость,полный день","inDrive — международная технологическая платформа транспортных и бытовых услуг. Мы входим в топ-2 мобильных сервисов для заказа поездок в мире: более 150 миллионов установок, более 2 миллиардов поездок, 700+ городов в 40+ странах мира. inDrive — продукт, которым ежемесячно пользуются десятки миллионов людей. Они совершают городские или междугородние поездки, заказывают грузоперевозки или курьерскую доставку, ищут работу и вызывают мастеров для оказания бытовых услуг. В inDrive работает более 2 000 сотрудников, из которых 450+ — разработчики, поделенные на 50+ кросс-функциональных команд. Мы ищем Senior Data Engineer, который будет разрабатывать инструментарий хранения и обработки больших данных компании, участвовать в проектировании архитектуры, нарабатывать и делиться экспертизой. Мы предлагаем стать частью команды разработки BigData платформы - центрального звена в анализе данных компании  В команде Data Engineering: 13 инженеров и руководитель. Всего в команде разработки более 200 сотрудников и мы продолжаем расширять команду. Мы не боимся использовать новые инфраструктурные решения (Google Cloud Platform, AWS). Мы свободны в принятии решений, будучи ограничены только законами о защите перс данных. нфраструктурные и архитектурные решения принимаем исключительно с трезвым взглядом на проблему и апеллируя к цифрам. Наш стек: используем Python/Scala для разработки под Spark Python/Java/Go для написания сервисов BigQuery/Clickhouse как OLAP СУБД Trino для Adhoc аналитики Apache Iceberg для хранения инкрементальных данных Apache Kafka как интеграционный слой между микро-сервисами Airflow для оркестрации ETL процессов. Разработку ведем на Github, CI/CD TeamCity, трекаем задачи в JIra, документацию введем в Confluence. Хотим развиваться в сторону Google Pub/Sub, Apache Beam, Kubernetes (в том числе Spark on Kubernetes), Kafka и открыты к любым идеям и решениям. Чем предстоит заниматься: Развивать культуру работы с данными Участвовать в создании создании единой систему обработки, хранения и валидации данных Разрабатывать и улучшать внутренний технический продукт контроля качества данных Разрабатывать алгоритмы проверки качества данных как внутри Data Platform так и вне ее сследовать и устранять проблемы в данных и процессах доставки данных Участвовать в проектировании системы и принятии архитектурных решений совместно с командой разработки Автоматизировать процессы реагирования на проблемы, от обнаружения до нотификации и устранения Разрабатывать интеграционные и юнит-тесты компонентов системы Улучшение процессов и систем тестирования результатов разработки Регулярно делиться экспертизой с нашим сильным комьюнити Data Engineers в области повышения качества данных и процессов. Ты подойдешь нам, если у тебя есть: Опыт разработки Data Pipelineов на Spark/Flink/DataFlow с применением Luigi/Airflow/Oozie Опыт работы с Google Cloud Platform и/или AWS Опыт собственной разработки или интеграции систем Data Quality Опыт глубокого разбора проблем вплоть до реверсинжиниринга действующих инструментов Опыт разработки на Python от 3 лет Понимание алгоритмов и принципов обработки данных Понимание архитектуры систем Data Management (DWH, DataLake) Понимание общих концепций программирования (шаблоны проектирования, ООП, модульность, чистая архитектура, 12-Factor App) Ярко выраженные качества ответственности за результат и проактивности в работе (мы верим, что идеи должны исходить не только от бизнеса, но и от сотрудников компании). Уверенное владение английским языком Для тебя мы предоставим: Работа по гибкому графику, оформление по ТК. Для сотрудников от года работы доступна программа «Офис без границ» — возможен временный переезд в любую точку мира и работа из этой локации (по согласованию с руководителем)  Релокация на Кипр или в Казахстан с помощью компании, релокационный пакет, оплата отеля на время поиска квартиры, дотации на аренду жилья, помощь в устройстве детей в школы и детские сады, страхование жизни и ДМС Регулярное внешнее и внутреннее обучение. У сотрудников есть возможность посещать профессиональные конференции в качестве участника или спикера Частично или полностью оплачиваемые дополнительные образовательные курсы Программа личностного роста Sinet Challenge, в которой мы ставим цели и вместе движемся к ним: Sinet Run для вовлечения в культуру бега, Sinet Challenge — частичная компенсация активного отдыха в период отпусков Ежемесячные мероприятия формата FunDay — корпоративы в различных форматах: от стендапов до походов в горы Приятное к важным датам — подарки от компании на свадьбу, при рождении ребенка и на день рождения. inDrive — команда тех, кто во благо постоянного роста умеет экспериментировать и учиться на ошибках. Здесь работают люди, которым не страшно брать на себя ответственность и создавать свои собственные правила, когда привычные не работают. Присоединяйся!","SQL,Spark,Big Data,SCALA,Python,Google Cloud Platform,AWS,PySpark,ETL,Airflow,BigQuery,Алгоритмы и структуры данных,MDM,Data Quality,Engineering,DataLake",inDrive,
7115,78618131,Специалист по машинному обучению и анализу данных / Data Scientist (Middle),з/п не указана,1–3 года,"Полная занятость,полный день","Марс в поиске Специалиста по машинному обучению и анализу данных / Data Scientist в центральную команду монетизации данных бизнес-сегмента Pet Nutrition. Задачи команды – проверка дата гипотез и разработка дата продуктов для большого количества бизнес функций внутри компании. деальный кандидат умеет работать с большими данными так, чтобы находить возможности для оптимизации продуктов и процессов, а также использовать модели для проверки эффективности различных вариантов действий. Вы будете: Взаимодействовать с заинтересованными сторонами в рамках всей организации, чтобы определить возможности использования данных компании для разработки бизнес-решений и монетизации данных звлекать и анализировать данные из баз данных компаний для оптимизации и улучшения инструментов, процессов и поиска точек роста компании Разрабатывать пользовательские модели данных и алгоритмов для применения к наборам данных Разрабатывать процессы и инструменты для мониторинга и анализа производительности модели и точности данных Представлять результаты моделирования для бизнес-аудитории, включая руководителей организации Реализовывать стратегию управления бизнес-данными и рекомендовать улучшения Проектировать, разрабатывать / рефакторить, разворачивать дата продукты Продвигать в организации использование разработанных внутри дата продуктов с помощью презентаций, документации и совместной работы бизнес функций Разрабатывать инструменты и автоматизировать рабочие процессы Превращать неструктурированные недостатки и болевые точки в конкретные бизнес и технические требования для проверки гипотез или разработки дата продуктов. Мы ожидаем: Ученая степень и соответствующий опыт в области статистики, математики, информатики или смежных областях Уверенное знание SQL, Python, алгоритмов машинного обучения и статистики Подтвержденный опыт создания пайплайнов машинного обучения, работающих в продуктивной среде разработки (обучение, оценка, использование в системах реального времени) Опыт использования облачных платформ (Azure ML, Google Cloud Platform ML, AWS SageMaker, Yandex Cloud Platform) и развертывания аналитики в продуктивной среде Опыт работы со стеком Azure (Data Lake, Database, Data Factory, Data Brick и т. д.) и/или Yandex Cloud (Data Proc, Data Sphere и т. д.) – будет плюсом Опыт визуализации данных с использованием Power BI/ggplot/plotly/ – будет плюсом Высокие навыки коммуникации, решения проблем, стремление к обучению Самостоятельного специалиста, с высокой ответственностью, а также готового преуспевать в развивающейся организации и привносить структуру в неструктурированные ситуации Средний или выше среднего уровень знания английского языка (разговорный и письменный). Мы предлагаем: Конкурентная зарплата, система бонусов, ДМС и страхование жизни с первого рабочего дня Корпоративная пенсионная программа Компенсация питания Оплата мобильной связи Гибкий рабочий график Дополнительный оплачиваемый отпуск при стаже работы от 5 лет Насыщенная образовательная программа, которую формируете вы",Английский — B2 — Средне-продвинутый,Марс,"Москва, Сокол, Ленинградский проспект, 72к1"
7116,79267194,Data engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы - IT компания, специализирующаяся на разработке «умных» информационных систем для медицины и ищем в свою команду Data Engineer. Занимаемся реализацией проекта федерального масштаба в сфере здравоохранения. Обязанности: Взаимодействие с data scientist’ами и аналитиками, работа над поиском новых способов генерации и улучшения качества данных. Data modeling, создание и поддержка датасетов и инструментов для их генерации. Развитие ETL и data ingestion пайплайнов. Развитие и улучшение существующих сервисов. Участие в проработке и реализации интеграций с другими сервисами и командами. Стек: Python, Pandas, Postgres, Airflow, S3. Требования: Опыт работы Data Engineer от 2х лет, предпочтительно с подготовкой датасетов для ML Представление о статистическом анализе данных, методах ML Отличное знание SQL, Python Опыт построения аналитического хранилища данных. Условия: Вы погрузитесь в специализацию IT в медицине и станете экспертом в этой области. Будете участвовать в реализации глобальных изменений и вместе с нами будете менять мир. Будете работа в коллективе профессионально зрелых и интересных коллег. Работа в атмосфере результативности и системности в сочетании с гибкими подходами к решению задач. Работа в офисе, гибридный и дистанционный форматы. Комфортный дресс-код smart casual и джинсы, чай на уютной кухне. Офис в 2 минутах от метро Менделеевская.",,Ртк-Элемент,"Москва, Менделеевская, Новослободская улица, 23"
7118,78519105,Data engineer (middle+),до 350 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Наши продукты - AI/ML-решения для крупных банков, ритейла и промышленности: системы предсказания спроса, сервисы персонализации и рекомендательные системы, поисковые системы для крупных ритейлеров и банков. Мы ищем data engineer'а для усиления нашего направления разработки систем прогнозирования спроса на товары в крупнейшем ритейле. Задачи: Разработка и развитие платформы прогнозирования - архитектура и реализация инструментов для построения ML-пайплайнов (подготовка данных, сбор фичей, обучение моделей, применение моделей, ведение ML-экспериментов и т.п.) Помощь коллегам/DS в оптимизации их работающих пайплайнов, проявлять про-активность с предложениями оптимизации Взаимодействие с коллегами/Devops по настройке окружений, деплоя кода, работы с инфраструктурой компании Общение с коллегами/DQ, выяснение деталей наполнения данных, участие в составлении БТ к данным Решение неожиданных проблем с данными, задержками их доставки. Минимальные требования: Уверенные знания Python 3+ (структуры данных, алгоритмы, концепции языка) Уверенные знания SQL: агрегации, джойны, вложенные запросы, индексы, оптимизации запросов Опыт работы с Hadoop, Spark Опыт разворачивания, настройки мониторинга и передача на поддержку разработанных решений. На что ещё смотрим: Опыт работы с Airflow и другими подобными инструментами для запуска регулярных задач Опыт Devops (Docker, Kubernetes, Gitlab-CI, настройка окружения на серверах и др.) Опыт разработки сервисов (Flask, Django, Asyncio и др.) Опыт проектирования высоконагруженных приложений и/или приложений работы с большими данными Будет плюсом опыт использования машинного обучения. У нас: Участие в быстром росте компании, работающей на перспективном AI рынке Возможность удаленное работы в любой точки мира или офис МСК Совместная работа с опытными разработчиками, аналитиками данных, менеджерами, продуктологами Гибкий график работы Оформление ТК РФ или ГПХ (вне рф) ДМС (включая стоматологию) после прохождения испытательного срока Уютный офис в центре Москвы (2 минуты от м. Сухаревская) со всем необходимым для комфортной работы. Особенно актуальное: Мы аккредитованная Т-компания со всеми вытекающими льготами.","Python,Spark,Hadoop,Docker,Kubernetes",Мамаева рина Анатольевна,
7120,78552507,Data Engineer (senior),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Анабар – система аналитики и управления продажами для продавцов на маркетплейсах. Продукт запустили Петр Марков (ex-Яндекс, ex-Циан) и Павел Тарасов (ex-Альфа-Банк, ex-Циан) в июле 2020. У нас есть довольные клиенты, выручка и мы удваиваемся по всем ключевым бизнес-метрикам каждый квартал. Количество продавцов на маркетплейсе удваивается каждый год + большинство из них работает сразу на нескольких маркетплейсах (Wildberries, Озон, Shopee). Т. е. на рынке много клиентов (и становится больше), у них много денег (и становится больше) и у них много проблем (и становится больше по мере усложнения самих маркетплейсов). деальная смесь, чтобы построить успешную компанию. Компанию делают люди, поэтому мы набираем команду единомышленников, которая сможет сделать лучший продукт на рынке. У нас уже есть сильные навыки Павла Тарасова в Machine Learning, команда разработки (которая тоже растет). Сейчас нам нужен middle-senior data engineer. Непосредственным руководителем будет Павел Тарасов (сооснователь). В Циан Павел построил и возглавлял департамент Machine Learning, поэтому ты будешь в хорошей компании и сможешь многому научиться. Можешь посмотреть выступление Павла Нам нужен человек, который умеет: - Создавать batch и streaming pipeline-ы обработки данных - Разруливание зависимостей потоков данных - Оптимизация SQL запросов - Тестирование и мониторинг качества данных  Тебе нужно будет делать: - Обрабатывать данные парсинга и создавать стабильные пайплайны с хорошей очисткой данных и контролем качества - нтегрироваться с api маркетплейсов и создавать витрины на основе данных площадок и парсинга Что мы ищем в тебе: - Отличное знание SQL - Знание python на уровне senior разработчика - Хотя бы одно из, лучше все: athena/presto, spark, clickhouse, Trino - Опыт работы с большими массивами данных Желательно: - Опыт решения аналитических задач - Работа с luigi/airflow - Опыт работы с облачным стеком - Опыт работы с hadoop стеком Что мы предлагаем:  - Конкурентоспособную “белую” зарплату - Дистанционную работу по Московскому времени (работать можно из любой точки мира) - Участие в превращении старт-апа в большую компанию - Погружение в быстрорастущую индустрию e-commerce - Быстрый рост навыков (нужно будет делать быстро много нового, это большая нагрузка и быстрый рост)","SQL,Python,ClickHouse,Hadoop,Анализ данных",ANABAR,
7121,78726443,Руководитель группы Data Science,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","О нас: Мы – отдельный департамент, который отвечает за работу с данными и за монетизацию данных в онлайн бизнесах Ленты Онлайн и Утконос. Мы развиваем и поддерживаем ETL-процессы, выстраиваем Data Governance, поддерживаем BI, встраиваем ML модели в наш CRM, сайт и приложение, встраиваем ML модели в процессы Коммерции и Операций.  Задачи, стоящие перед командой: • Аналитика в операционном блоке: прогнозирование спроса, оптимизация расписаний сотрудников, оптимизация логистики, построение цифрового двойника процессов сборки и доставки заказов. • Аналитика в коммерческом блоке: анализ промо-эффективности, оптимизация товарного справочника, анализ эластичности спроса по цене, построение промо-калькулятора, оптимизация регулярных цен, оптимизация распродаж, оптимизация промо и ассортимента.  Что сделано на текущий момент:  Реализовали многоуровневое прогнозирование спроса от часового для планирования расписаний до месячного для бюджетного планирования  Реализовали оптимизацию расписаний сотрудников магазинов и курьеров. Сотни магазинов уже пользуются сервисами.  Сделали интерфейсы на Streamlit, подготовку данных через Airflow, выкатку сервисов в k8s (dev, test, prod) через GitLab CI/CD, документацию в Confluence.  Разработали методику гео-АВ-тестов, для оценки бизнес-эффекта с учетом стат. значимости  Мы ожидаем, что ты: • меешь опыт применения DS/ML в реальных задачах, где твоя работа принесла пользу бизнесу • Умеешь эффективно коммуницировать с заказчиками из различных бизнес-подразделений, коллегами из Т и командой можешь четко формулировать свои идеи и объяснять сложные вещи простым языком • меешь опыт управления Data Science командой. Умеешь расставлять приоритеты и всегда имеешь видение развития команды и проектов. • Умеешь проводить AB тесты (еще лучше – гео AB тесты) • Знаком с алгоритмами математической оптимизации и их реализацией в различных солверах • Уверенно используешь SQL (Oracle/Postgres), Python • Сможешь написать веб-сервис, где будут крутиться ML модель  Работа у нас - это: • Поддержка команды профессионалов, готовых помочь разобраться в данных, новых инструментах, алгоритмах и библиотеках, а также поддержать твои инициативы • Нетоксичное ревью от коллег с соседних проектов • Внутренние митапы на которых можно узнать много нового.  Условия работы:  Возможность работать 100% удаленно  Офис в 5 мин. от м. Улица 1905 г./ Баррикадная  ДМС со стоматологией  Различные корпоративные программы скидки от партнеров  Аккредитованная Т компания","Python,FastAPI,SQL,PostgreSQL,Big Data,Математическая статистика,Прогнозирование,Data Science","Лента, федеральная розничная сеть, Супермаркет",
7124,79281445,Middle Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Корпоративно-инвестиционный блок отвечает за работу с юридическими лицами и индивидуальными предпринимателями от микробизнеса до крупнейшего. Ключевым направлением является развитие продуктов экосистемы и банковские услуги (кредиты, РКО, депозиты и т.д.), а также аналитические услуги и юридическое сопровождение бизнеса. Наше подразделение занимается разработкой рекомендательных моделей по продуктам Торгового финансирования по разным сегментам клиентов, а также работой с колл-центрами, разбросанными по нескольким городам (транскрибации), и CV-задачами (распознавание документов, автоматическая сверка, поиск ошибок/неточностей). Основная задача - рост продаж продуктов торгового финансирования во всех сегментах корпоративных клиентов Сбербанка, а также физических лиц. Обязанности Построение, поддержка и развитие рекомендательных систем по продуктам торгового финансирования (аккредитивы, эскроу) Глубокая продуктовая/клиентская аналитика и использование ее в моделях (кластеризации, сегментации, поиск новых фичей и пр.) Максимальное погружение в контекст задачи\систему продаж. 90% успеха состоит в понимании процесса, контекста и задачи, а не в подборе гиперпараметров модели Оптимизация бизнес процессов с использованием инструментов Process mining Требования Отличное понимание классического ML, опыт и знание основных необходимых библиотек (catboost, lightgbm, pandas, etc.) Уверенное знание SQL, умение строить сложные запросы Отличная математическая подготовка. Способность прочитать статью и имплементировать, например, кастомную лосс-функцию в модель Jupyter, pycharm, git, jira, conflience Плюсом будет Опыт работы со Spark/Hadoop (Pyspark) Практический опыт DL Понимание банковской специфики и финансов. Например, что такое финансовая отчетность компаний Условия Офис на метро Кутузовкая, прекрасная панорама Москвы с 23 этажа башни, спортзал Адекватные боссы, много адекватных людей вокруг Существенный годовой бонус ДМС с первого дня работы Безлимитный кофе/чай, печеньки Гибкое начало дня (с 8 до 11)","ML,Python,SQL",Сбер. Data Science,
7125,78617302,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Rubius – IT-компания со смелым характером. Мы разрабатываем софт для клиентов из различных отраслей – от промышленности и нефтегаза до ритейла и медицины. Обосновались в Томске, работаем по всему миру: наше программное обеспечение используют в США, Европе и Азии. Наши решения используют Apple, Tesla, Kaspersky, Amazon, IBM, Uber, Netflix, Газпром, РЖД и другие. В группу компаний входят представительства в США (Нью-Йорк), Казахстане (Алматы, резиденты Astana hub), ОАЭ (Дубай). В нашем профиле на hh.ru мы постарались подробно рассказать о нас, обязательно загляните:) Одна из наших команд, которая занимается искусственным интеллектом, приглашает Data Engineer, так как команда расширяется. Вам предстоит работать с большими данными совместно с аналитиками и командой ML. Мы ищем человека, который умеет собирать витрины, джойнить данные и проверять полученный результат. У нас есть экспертиза по синтезу аудио и видео, анализу изображений и видео, компьютерному зрению, предиктивной аналитике, обработке текстовых данных и тд. Мы исследуем разные сферы от логистики до медицины, погружаемся в сферы наших крупных заказчиков с головой, чтобы помочь оптимизировать процессы. Также команда разработала свой продукт для видео аналитики Visius. Чем предстоит заниматься: проектировать и собирать витрины данных по разработанному ТЗ проектировать, разрабатывать и поддерживать ETL-процессы для загрузки данных из/в Data Lake тестировать результаты преобразования данных и проверять их целостность писать документацию - комментировать код работать с data-аналитиками для создания новых и оптимизации существующих витрин Добро пожаловать к нам в команду, если есть: понимание основных операций ДБ и DWH опыт работы с Hadoop технологиями (Spark, Hive и тд) хорошее знание SQL, Python опыт работы с Azure/Yandex облачными платформами опыт работы с Airflow, Kafka будем плюсом Что мы предлагаем: Сотрудники компании – главная ценность Rubius. Мы поддерживаем свободу творчества и полёт инженерной мысли. Стремимся, чтобы каждый участник нашей команды раскрыл свой потенциал. Мы стараемся максимально заботиться о наших сотрудниках. Здесь удалённые и офисные команды чувствуют себя максимально комфортно. Про работу и оплату белая и своевременная заработная плата в зависимости от компетенций и уровня официальное трудоустройство до 10% ежемесячной премии за хорошие результаты помощь с home office возможно трудоустройство в нашей компании в Казахстане (для желающих получить заветную карту Visa) Про рост и развитие индивидуальный трек развития по желанию бесплатное обучение английскому языку бонус за профессиональное развитие (курсы, подкасты, литература по хард и софт скиллам) компенсация 50% за профессиональную сертификацию внутренние митапы на разные темы Про офис, плюшки и атмосферу оплачиваемые занятия спортом (даже в домашних условиях) программа ДМС после испытательного срока скидка для вас и родственников в Rubius Academy бонусы к рождению детей и свадьбе классные корпоративы и активности развитая и комфортная корпоративная культура, без иерархии и бюрократии А ещё у нас есть лучший офис в Томске, где тебя всегда ждут, сообщества по интересам (футбол, теннис, своя музыкальная группа, шахматный клуб...) и коллектив, где прислушиваются к мнению каждого. Подробнее о нашей компании можно почитать в нашем профиле на hh.ru. Откликайтесь!",,Rubius,"Томск, улица Нахимова, 13/1"
7133,79026313,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: • Разработка ETL- процессов • Разработка структуры данных в колончатой СУБД - курирование процесса разработки , контроль качества, разбор проблем • Разработка процессов извлечения данных из систем источников- курирование процесса разработки, контроль качества, разбор проблем • Разработка совместно с системными аналитиками алгоритмов регламентной инкрементальной загрузки • Отладка регламентных загрузок, разбор ошибок • Мониторинг исторической загрузки, разбор ошибок • Разработка витрин данных. Требования: • Знание SQL • Опыт работы с ETL инструментом • Практические навыки работы с Python • Опыт администрирование СУБД (желательно). Ключевые навыки: • Python • SQL • MS SQL • MS SQL Server • ООП","Python,SQL,ООП,MS SQL Server,ETL",Казах Софт Девелопмент,
7134,79122630,Data Engineer,з/п не указана,не требуется,"Полная занятость,полный день","В отдел бизнес-аналитики и финансового планирования требуется Data Engineer. Обязанности · сбор, обработка, анализ, загрузка данных для аналитических исследований · работа с базами данных на MS SQL, Postgre, GreenPlum, Hadoop · формирование аналитики по направлениям бизнеса · построение факторных моделей, выявление трендов, интерпретация результатов Требования · высшее образование (IT, математическое, техническое) · знание SQL, Hadoop Будет дополнительным преимуществом: · Опыт в программировании на python: pyspark, pandas, numpy · Навык работы с bash · git Условия · официальное трудоустройство · график работы 5/2 с 09.00-18.00 · ДМС, страхование жизни и здоровья, льготное кредитование, корпоративный фитнес · заработная плата - оклад + квартальное и годовое премирование · уровень оклада обсуждается на собеседовании",,Сбер для экспертов,
7137,72054128,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем в нашу практику по управлению данными дата-инженера. Вакансия обусловлена большим портфелем проектов в сфере DATA, предусмотренным стратегией развития нашей компании и имеющим высокий приоритет для бизнеса. Развитие ДАТА-практики охватывает контур компании и ее ключевых партнеров по цепочке создания ценности и предусматривает внедрение корпоративной платформы данных, включая построение классического DWH и озера данных (Data Lake), разработку приложений BI-аналитики и отчетности на платформе, обеспечение процессов интеграции данных. Работа организована по продуктовым командам, в которые входят представители бизнеса и Т (продакты, дата-инженеры, специалисты Data Science, аналитики данных и специалисты Т, отвечающие за сервисы платформы данных). Обязанности: Сбор и обработка данных из различных источников для проектов построения ML-моделей прогнозирования и ad-hoc аналитики по запросам бизнес-функций маркетинга, HR и финансов Анализ требований ко входящим потокам данных Проектирование потоков данных и схем загрузки Профилирование и очистка данных Разработка скриптов трансформации данных Разработка интеграционного взаимодействия (REST API) Подготовка витрин данных и поставка данных для контента в аналитические приложения Проведение ревью кода и участие в программе менторинга джуниор дата-инженеров команды. Наши пожелания к знаниям и опыту: Высшее образование Опыт работы в роли дата-инженера/ аналитика данных в продуктовых командах либо опыт участия в проектах построения DWH и Data Lake в роли ETL-разработчика – от 2 лет Твердые знания Python Навыки оптимизации SQL-запросов и опыт разработки на PostgreSQL, ClickHouse Опыт построения потоков данных (предпочтительно Ni-Fi, AirFlow) Практические навыки работы с данными на кластере Hadoop или S3 Опыт написания задач для Spark, Kafka Базовые навыки MLOps (в объеме самообслуживания) Предпочтителен опыт работы с Яндекс Облаком и/или Сбер Cloud Умение писать чистый поддерживаемый код и техническую документацию Мы предлагаем: Работа в масштабном бренде в сфере быстрого обслуживания с уникальной историей Достойный уровень оплаты труда Продвинутая система бенефитов (годовой бонус, ДМС, мобильная связь, частичная компенсация фитнеса, 3-х летний накопительный план от оклада и премий) Гибридный график работы Профессиональное развитие и карьерный рост Возможность принять участие в цифровой трансформации масштабного бренда","Python,SQL,PostgreSQL,ClickHouse,Hadoop,MLOps,Ni-Fi,S3,Spark,Kafka,DWH,Data lake,ETL,Базы данных,Big Data,Data",Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
7138,79179730,Data Engineer (remote),от 2 500 до 4 000 USD до вычета налогов,3–6 лет,"Полная занятость,полный день","LATOKEN is the supermarket of assets where it is easy to discover, exchange, earn and spend crypto. Mission: Well-structured and secure data and monitoring.  Story: Product, Finance, OKRs, and Dash Teams need well-structured and secure data and monitoring to analyze and track the improvement of the services and product performance. Key PROBLEM's: The monitoring system alerts for any downtime, latency, or success rate issues of the services. All company data and events are merged and consolidated into the Data Base (DWH, PostgreSQL, Segment, Indicative, Google Analytics) to support the Monitoring system, Token Discovery, OKRs and Analytical Dashes. Acquisition channels, conversions, and users are correctly mapped and easy to access. Token DB is representative of the market and token data is correct and complete with on-chain and smm data. (30k tokens by end of April) How: Create new data pipelines for business need. Maintain scripts and pipelines in case of problems or new requirements. Define necessary events, set up recording and make available for reports and dashboards. Maintain and update token DB. Constraints: All OKRs of the company are consolidated into Platform Ops. All scripts are consolidated into Gitlab. Main performance number: Ops OKR Health Second performance number: Free Space DWH Third performance number: Query response time, sec avg  Functions: • OKRs Health : Calculate OKRs correctly, daily and in time • DWH objects audit • Queries : Advice on optimization and writing queries to databases. • Data quality : Keep data in order and provide reliable reporting • Automation : Automation of OKRs and slack bots for automated ops processes • Audit : Audit of DWH state and automated scripts  Requirement skills and experience: 2+ years of PostgresSQL DB administration experience 2+ years of experience writing Python scripts and applications for loading data Experience in configuring a database in a high-availability architecture Experience in database optimization for different load profiles Experience in automating data loading from different sources (CRM, ERP, Web resorses) Eager to work with people with high-performance standards Will be a plus: Experience with financial data Experience as a data/product analyst","Python,DWH,PostgresSQL,CRM,ERP",LATOKEN,
7139,79226963,Data Engineer,от 2 500 до 4 000 USD до вычета налогов,3–6 лет,"Полная занятость,полный день","LATOKEN is the supermarket of assets where it is easy to discover, exchange, earn and spend crypto. Mission: Well-structured and secure data and monitoring.  Story: Product, Finance, OKRs, and Dash Teams need well-structured and secure data and monitoring to analyze and track the improvement of the services and product performance. Key PROBLEM's: The monitoring system alerts for any downtime, latency, or success rate issues of the services. All company data and events are merged and consolidated into the Data Base (DWH, PostgreSQL, Segment, Indicative, Google Analytics) to support the Monitoring system, Token Discovery, OKRs and Analytical Dashes. Acquisition channels, conversions, and users are correctly mapped and easy to access. Token DB is representative of the market and token data is correct and complete with on-chain and smm data. (30k tokens by end of April) How: Create new data pipelines for business need. Maintain scripts and pipelines in case of problems or new requirements. Define necessary events, set up recording and make available for reports and dashboards. Maintain and update token DB. Constraints: All OKRs of the company are consolidated into Platform Ops. All scripts are consolidated into Gitlab. Main performance number: Ops OKR Health Second performance number: Free Space DWH Third performance number: Query response time, sec avg  Functions: • OKRs Health : Calculate OKRs correctly, daily and in time • DWH objects audit • Queries : Advice on optimization and writing queries to databases. • Data quality : Keep data in order and provide reliable reporting • Automation : Automation of OKRs and slack bots for automated ops processes • Audit : Audit of DWH state and automated scripts  Requirement skills and experience: 2+ years of PostgresSQL DB administration experience 2+ years of experience writing Python scripts and applications for loading data Experience in configuring a database in a high-availability architecture Experience in database optimization for different load profiles Experience in automating data loading from different sources (CRM, ERP, Web resorses) Eager to work with people with high-performance standards Will be a plus: Experience with financial data Experience as a data/product analyst","Python,DWH,PostgresSQL,CRM,ERP",LATOKEN,
7142,78102401,"Менеджер по развитию бизнеса / BDM (BI,Data Governance, Data Quality, Big Data,Machine Learning)",з/п не указана,3–6 лет,"Полная занятость,полный день","КОРУС Консалтинг – российская Т-компания, признанный лидер в автоматизации ритейла, производства, логистики, финансов и нефтегаза. Мы входим в топ-5 крупнейших IT компаний Петербурга. Нас более 1000 человек, а за плечами более 20 лет опыта. За это время мы сделали более 1200 масштабных проектов для ведущих компаний России, а именно: Bonava, DPD, Nokian Tyres, Tele2, Азбука Вкуса, Газпром нефть, Дикси, нвитро, Леруа Мерлен, Магнит, Мегафон, О’КЕЙ, Петрович, Росатом, Яндекс.Деньги и это только начало списка. Мы любим данные. Мы поняли это более десяти лет назад, когда в составе группы компаний «КОРУС Консалтинг» ещё не было отдельного департамента аналитических решений и понятие «бизнес-аналитика» ещё не было так популярно. Наш Департамент аналитических решений (ДАР) погружен во все современные направления в области работы с данными: внедрение BI-систем и систем аналитической отчетности проектирование хранилищ и витрин данных разработка в области продвинутой аналитики и больших данных применение прикладных продуктов с использованием Machine Learning внедрение решений в области управлениям данными (Data Governance, Data Quality ...) разработка методологии и стратегии работы с данными. Сейчас нам требуется усиление - ищем коллегу на должность Менеджера по развитию бизнеса / BDM. Задачи, которые предстоит решать: Обеспечение выполнения квартальных, годовых и др. планов по продажам, достижение запланированной рентабельности Развитие отношений с выделенным пулом клиентов Поиск и формирование потребностей в клиентах по всем направлениям департамента Подготовка и оформление коммерческих предложений для клиентов, переговоры Оформление и согласование договоров с клиентами и внутри компании Выполнение аналитики продаж (формирование и анализ воронки продаж по ключевым клиентам) Управление процессом пре-сейла в рамках продажи Успешное ведение и закрытие сделок. Что поможет в работе: ""Погружение"" в бизнес заказчика, готовность ориентироваться в его проблемах и решать их Для нас важен опыт работы в IT на стороне исполнителя Проактивный подход к работе, самостоятельный поиск новых возможностей и вариантов продвижения нашего бизнеса Подтвержденный успешный опыт развития бизнеса и управления продажами в сегменте В2В на аналогичной должности. Наше предложение: Официальное оформление в штат компании Заработная плата обсуждается по итогам тех. собеседования. Знаем рынок, готовы обсуждать индивидуально Гибкое начало рабочего дня, возможность посещения офиса для коллег из Москвы, Санкт-Петербурга и Ярославля. Полная удалёнка для коллег из остальных городов России Открытая корпоративная культура, корпоративный волейбол, футбол и беговой клуб, участие в экологических программах, регулярные тимбилдинги Минимум бюрократии и отчётов, а совещания только по необходимости и с чёткой программой Корпоративный университет, менторство и развитие Полис ДМС, корпоративные тарифы на фитнес и занятия английским на ведущих платформах. Будем рады обсудить сотрудничество!","B2B Продажи,Ведение переговоров,Управление проектами,Анализ данных,Подготовка коммерческих предложений,Развитие продаж,Аналитическое мышление,Управление отношениями с клиентами,Ориентация на результат,Работа с ключевыми клиентами,Бизнес-анализ,Power BI,Big Data",КОРУС Консалтинг,
7150,76291546,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","RUTUBE - крупнейший российский видеохостинг, где собраны различные категории видео: премьерные выпуски шоу и сериалов, прямые эфиры телеканалов, фильмы и мультфильмы, контент видеоблогеров. Мы стремимся сделать лучший видеосервис на базе высокотехнологичных решений, исследований и аналитики, который позволит смотреть качественный лицензионный контент, адаптированный под каждого пользователя. Сейчас нам требуется Data Engineer, способный быстро погрузиться в новые задачи и усилить нашу команду. Что ты уже умеешь: Разработка витрин данных, интерактивных дашбордов и отчетов Работа с ad-hoc запросами Разработка потоков загрузки и обработки сырых данных на хранилище Создание и совершенствование, совместно с бизнес-командой, перечня основных операционных показателей и методологии их расчета Взаимодействие с заказчиком Построение логики формирования витрин данных, отчетов, выстраивание логики работы аналитических продуктов Участие в формировании требований на загрузку необходимых данных из источников, а также для подключения новых источников данных Поиск и анализ требуемой информации в различных источниках данных Работа с Git, Jira, Confluence. Что ты будешь делать: Навыки написания сложных и оптимальных SQL-запросов Владение Python для работы с данными Навыки настройки потоков данных в Apache AirFlow Опыт разработки дашбордов (Tableau, PowerBI, Superset, SSRS, ReDash, ect.) Знание принципов работы реляционных БД Навыки исследования и анализа данных, работы с большим объемом информации Знание подходов к проектированию структур данных Аналитический склад ума и системное мышление Опыт сбора и анализа бизнес-требований в области аналитики решений Опыт работы по специальности от 2 лет. Не обязательно, но круто, если ты: Владение инструментами интернет-аналитики(Яндекс Метрика, AppMetrica, GA) Опыт работы с СУБД ClickHouse. Что мы предлагаем: Опыт работы над крупнейшем видеосервисом страны Работу в команде профессионалов и творческих людей Достойный уровень дохода (обсуждается индивидуально с каждым кандидатом) Мы оформим ДМС не дожидаясь окончания испытательного срока Фрукты, овощи, вкуснейший кофе каждый день Гибкое начало рабочего дня Возможность работать по гибридному графику Уютный офис в пешей доступности от метро Сокол (БЦ Алкон).","Python,SQL,Tableau,SSRS,Power BI,ClickHouse,СУБД,Работа с базами данных,Atlassian Jira,Atlassian Confluence",Rutube,"Москва, Аэропорт, Красный Балтиец, Сокол, Ленинградский проспект, 72к4"
7151,77426640,Lead Data Engineer,от 300 000 до 400 000 руб. на руки,3–6 лет,"Полная занятость,гибкий график","Платформа ОФД (аккредитованная Т-компания) – крупнейший в России оператор фискальных данных. Резидент Сколково. У нас много данных: каждый 3-й чек, пробиваемый в России, находится на наших серверах (50 млн. чеков в день, 2 млрд уникальных названий товаров).  Одним из направлений бизнеса является аналитика, основанная на чековых данных. Направление BigData занимается тем, что из плохо структурированной информации делает аналитику, которая превращается в отчеты и продается.  Приглашаем на работу Tech Lead Data Engineer Что у нас есть: График работы гибрид, (1-2 раза в неделю в офисе, остальное время дома) Много данных: каждый 3-й чек, пробиваемый в России, находится на наших серверах. Мы принимаем до 50 млн чеков в день, имеем 2 млрд уникальных названий товаров в базе Развитая инфраструктура: есть несколько кластеров Hadoop, мощные машины, GPU Команда Big Data: продакты, аналитики, ресечеры, DS и DE, java-разработчики 80% кода мы пишем на Scala Железо и лицензии от компании Оформление по ТК РФ, белая зп Отсрочка от мобилизации, согласно условиям Минцифры ДМС (поликлиника, стоматология, госпитализация, скорая) Скидки в фитнес-клубы, мерч, подарки детям к праздникам Офис в 50 метрах от м. Спортивная/ МЦК Лужники. Удобная кухня, релакс-зона с тренажером, массажным креслом, приставкой и караоке Открытая рабочая атмосфера: ежемесячные статус-митинги с топами Пицца-пати за счет компании и корпоративные праздники Наш стек: Hadoop, Spark, Hive, SCALA, Python, Java, PostgreSQL, ClickHouse, Zeppelin/IntelliJ, AirFlow, ElasticSearch, Apache Superset GitLab, Docker, Jira, Confluence Чем предстоит заниматься: Управлять командой, состоящей из 4 Data Engineer`s Оптимизировать инфраструктуру и внутренние сервисы по обработке больших данных Разрабатывать ETL-процессы с использованием библиотеки Apache Spark на Scala Сотрудничать с DS для внедрения математических алгоритмов и ML-моделей в промышленные процессы Откликайся, если ты: Аналогичный опыт работы от 3-х лет, обязателен опыт управления командой меешь опыт управления командой Пишешь на Scala, Python SQL Знание Java будет плюсом спользуешь инструменты BigData: Airflow, Hadoop, Spark, Hive, Zeppelin","Python,Java,SCALA,SQL,Big Data,Hadoop,Spark,ETL",Платформа ОФД,"Москва, Лужники, Спортивная, Усачёва улица, 33с1"
7155,76954495,Data Engineer (DWH),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","PETER PARTNER – это молодая продуктовая IT-компания, которая занимается созданием собственных крутых финтех продуктов. Мы – команда профессионалов, готовых помочь с трудной задачей в понедельник утром и классно провести время в пятницу вечером. Придерживаемся agile-подхода. Для нас agile – это не только гибкая методология создания продуктов, но и прозрачность взаимоотношений внутри команды и вовлеченность каждого в общее дело. В нашем активе есть коммерчески успешные продукты. Мы реализовали систему по автоматизации торговли, которая интегрирована с крупными торговыми брокерами. Все продукты компании Peter Partner локализованы на множество языков и ими пользуется свыше 1 млн. человек в странах Азии, Африки и Южной Америки. Также, используя свой опыт в алгоритмах трейдинга мы разработали платформу, которая позволяет управлять активами на ведущих криптовалютных биржах. Мы работаем в технологически-сложной сфере и наша задача – сделать простой и удобный продукт, понятный для каждого. Наша команда развивает и поддерживает инфраструктуру для продуктовой аналитики в Peter Partner. Мы отвечаем за контуры обработки и трансформации данных (ETL), организацию хранения данных (DWH), средства визуализации (BI) и A/B тестирования. Мы в поисках Data-engineer который, также как и мы разделяет data driven подход, знает как искать insights в данных и сможет вывести наши продукты на новый уровень!) Это про тебя? Давай с нами!) ТЕБЕ ПРЕДСТОТ: Создание единого пайплайна обновления отчетности на базе Airflow + Clickhouse + Postgres Создание витрин с разными слоями данных (сырые данные, агрегированные данные, таблицы под отчеты и датасеты для BI), проектирование модели данных исходя из бизнес-требований Подключение и сверка новых источников Performance маркетинга Формирование стратегии по работе с данными с четкой, понятной и описанной структурой Проектирование структуры хранения данных (в том числе бэкапы, сжатие неиспользуемых данных), создание ETL-процессов Выстраивание и поддержка процессов data quality (health-метрики, алерты) Поддержка и развитие инфраструктуры A/B тестирования. НЕОБХОДМЫЕ НАВЫК: Уверенное владение Python. Владение SQL, понимание принципов оптимизации запросов и организации хранения данных Автономность и проактивность в работе - умение находить, подсвечивать и решать проблемные моменты самостоятельно, не дожидаясь задач со стороны Опыт разработки ETL-процессов с применением Airflow Опыт работы с Clickhouse Опыт работы с логированием пользовательских событий (в мобильном приложении) Желание разбираться в бизнес-особенностях данных с которыми предстоит работать. БУДЕТ ПЛЮСОМ: Понимание принципов разработки bi - как преимущество (SuperSet / Tableau / Looker / Power Bi или аналоги) Опыт решения DevOps задач - Docker, Kubernetes (или Nomad). НАШ СТЕК: Базы данных: Postgres, Clickhouse, Mongo DB Для ETL: Airflow, Airbyte, DBT, Jitsu, Pipeline платформа Hevo Внешние источники данных: Facebook и Google - рекламные кабинеты Branch - трекер атрибуций Apphud - выручка Amplitude - продуктовая аналитика. BI - Superset. МЫ ПРЕДЛАГАЕМ: Стать частью амбициозной IT-команды с крутыми процессами и насыщенной корпоративной культурой Официальное оформление, белую заработную плату График работы 5/2 с гибким началом рабочего дня с 8:00 до 11:00 и возможностью работать как в офисе, так и удаленно Работу в уютном, двухэтажном офисе с зоной отдыха, 2 кухнями и мини-библиотекой, и все это в 8 минутах ходьбы от ст.м. Выборгская Образовательные мероприятия внутри команды (мы их назвали “ppsync”), где можно не только обмениваться опытом, но и прокачать скиллы ораторского мастерства и выступлений на публике Регулярные командные мероприятия.","Postgres,Clickhouse,Mongo DB,Airflow,Airbyte,DBT,Branch,Apphud,Amplitude,Superset,Python,SQL,A/B тесты,Английский — B1 — Средний",Peter Partner,"Санкт-Петербург, Выборгская, Лесная, Петроградская, Гельсингфорсская улица"
7157,79226964,Data Engineer,от 2 500 до 4 000 USD до вычета налогов,3–6 лет,"Полная занятость,полный день","LATOKEN is the supermarket of assets where it is easy to discover, exchange, earn and spend crypto. Mission: Well-structured and secure data and monitoring.  Story: Product, Finance, OKRs, and Dash Teams need well-structured and secure data and monitoring to analyze and track the improvement of the services and product performance. Key PROBLEM's: The monitoring system alerts for any downtime, latency, or success rate issues of the services. All company data and events are merged and consolidated into the Data Base (DWH, PostgreSQL, Segment, Indicative, Google Analytics) to support the Monitoring system, Token Discovery, OKRs and Analytical Dashes. Acquisition channels, conversions, and users are correctly mapped and easy to access. Token DB is representative of the market and token data is correct and complete with on-chain and smm data. (30k tokens by end of April) How: Create new data pipelines for business need. Maintain scripts and pipelines in case of problems or new requirements. Define necessary events, set up recording and make available for reports and dashboards. Maintain and update token DB. Constraints: All OKRs of the company are consolidated into Platform Ops. All scripts are consolidated into Gitlab. Main performance number: Ops OKR Health Second performance number: Free Space DWH Third performance number: Query response time, sec avg  Functions: • OKRs Health : Calculate OKRs correctly, daily and in time • DWH objects audit • Queries : Advice on optimization and writing queries to databases. • Data quality : Keep data in order and provide reliable reporting • Automation : Automation of OKRs and slack bots for automated ops processes • Audit : Audit of DWH state and automated scripts  Requirement skills and experience: 2+ years of PostgresSQL DB administration experience 2+ years of experience writing Python scripts and applications for loading data Experience in configuring a database in a high-availability architecture Experience in database optimization for different load profiles Experience in automating data loading from different sources (CRM, ERP, Web resorses) Eager to work with people with high-performance standards Will be a plus: Experience with financial data Experience as a data/product analyst","Python,DWH,PostgresSQL,CRM,ERP",LATOKEN,
7158,79103682,Data \ Analytics Lead,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы - компания GRI, и мы ищем в нашу команду талантливых профессионалов, которые готовы стать не только частью нашей крутой команды, но и частью истории IT мира! Мы создаём первую в мире E-commerce платформу с функцией видеообращения и Dating-сервисом, где пользователи могут удобно и безопасно знакомиться, общаться и покупать товары. Мы разрабатываем и поддерживаем продукт ювелирной сети Sunlight, работая над его функционалом и удобством использования для наших клиентов. У нас в компании очень важно, чтобы каждый сотрудник чувствовал себя частью команды и мог реализовывать свой потенциал. Мы ценим коллег, которые работают с увлечением и ставят перед собой высокие цели. У нас открытая и дружелюбная атмосфера, и мы всегда готовы поддержать друг друга. Чем предстоит заниматься: Подготовка, валидация архитектуры решений, связанных с продвинутой аналитикой и управлением данными в рамках крупного E-commerce (веб\апп) Проведение бизнес-анализа задачи, предложение путей решения Участие в Разработке и руководство разработкой AA/ML алгоритмов для решения бизнес-задач Формирование команды Наставничество для будущей команды аналитики, формирование направлений развития Построение процессов работы с данными\слоями данных Формирование концепции, архитектуры и инфраструктуры (совместно с Т) хранения и работы с данными Обеспечение контроля полноты, качества и актуальности данных в системах Согласование приоритизации бэклога продуктовых команд и перераспределение ресурсов между командами (при необходимости) Определение набора необходимых атрибутов данных для каждого проекта и их формата Обеспечение правил хранения и сохранности данных, и правил доступа к ним Участвовать в проектировании и развитии единой архитектуры данных во всех корпоративных Т-системах и бизнес-процессах Участвовать в проектировании, внедрении Т инструментов и систем для сбора, обогащения, хранения, обработки, анализа, визуализации данных, в гибридном (доменном) формате озера данных/витрины данных Готовить аналитическую отчетность, дашборды, проверку бизнес гипотез на основе данных Участвовать в повышении уровня информационной грамотности сотрудников в области управления и эффективного использования корпоративных данных Помогать в координации деятельности (методологии, подходов, инструментов) аналитиков в функциональных подразделениях (бизнес-линиях) компании Что мы ожидаем от Вас: 3+ года работы в роли Руководителя (Тимлида) в области анализа данных/архитектора данных Опыт разработки/внедрения фреймворков по обработке и анализу данных: от выявления потребности бизнеса (гипотез, бизнес-целей), источников данных, нормализации до формирования аналитической отчетности/выводов, дашбордов Опыт формирования команд и управления техническими специалистами (IT/data professionals) Участие в проектах внедрения платформ и корпоративных моделей данных, внедрения инструментов/систем для работы с данными Отличные навыки коммуникации и опыт совместной работы в рамках кросс-функциональных команд, с участием топ-менеджеров Что мы предлагаем: нтересная работа в аккредитованной Т-компании Уровень ЗП готовы обсуждать Возможность реализовать собственные архитектурные решения Действительно крутые (в т.ч. международные) проекты Современное оборудование Комната отдыха с удобными диванами, игровая комната с нежнейшими пуфиками и PSP, ароматный кофе и вкусный чай со сладостями Большое количество скидок от наших партнеров, в том числе и на спорт в 13 городах России Корпоративная библиотека Гибкое начало рабочего дня Гибридный формат работы","Анализ данных,SQL,Big Data,Управление процессами,Data Analysis,Architecture,Визуализация данных,Организаторские навыки",GRI,
7160,79259932,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","нтер РАО-Онлайн – российская IT-компания, которая разрабатывает цифровые решения в сфере энергетики и ЖКХ. Мы работаем как над B2C, так и B2B продуктами: внедряем единую платформу для 50 миллионов клиентов энергосбытовых компаний и ЕРЦ и запускаем экосистему бытовых сервисов В связи с расширением IT команды мы ищем к себе Data Engineer. Обязанности: Проектирование и разработка конвейеров обработки данных (data processing pipelines), включая разработку и оптимизацию архитектуры данных (data architecture) Построение и поддержание инфраструктуры, необходимой для оптимального извлечения, преобразования и загрузки данных из различных источников (ETL/ELT) Создание и обновление документации по архитектуре и схемам обработки данных Дебагинг, тестирование и исправление ошибок в своём и чужом коде Взаимодействие с членами команды, включая ревью технических спецификаций и кода Участие в обсуждениях решений для обработки данных, процессов ETL/ELT и автоматизации рабочих процессов по обработке данных, включая координацию с бэкенд разработчиками, специалистами по аналитике данных и QA инженерами Взаимодействие с заказчиком (внутренним и внешним), поиск оптимальных решений для получения качественных данных. Требования: Понимание принципов работы с данными Опыт работы с реляционными и колоночными СУБД, уверенное владение SQL Владение Python (requests, regex, scrapy, sqlalchemy, иные библиотеки для работы с данными) Опыт разработки ETL/ELT процессов (Airflow, NiFi, иные). Будет плюсом наличие опыта работы с Loginom Условия: Комфортный офис в пешей доступности от метро Фрунзенская и Спортивная Гибкий график Официальное трудоустройство по ТК РФ и стабильная заработная плата Годовой бонус, который будет зависеть от личных KPI и результатов деятельности компании Расширенный пакет ДМС со стоматологией после испытательного срока Ежемесячные посиделки в офисе, на которых мы едим пиццу и знакомимся с новыми коллегами Сильная команда специалистов, у которых можно многому научиться и которые всегда готовы прийти на помощь нтересные задачи и возможность создавать продукты для миллионов пользователей",,"ООО ""нтер РАО - Онлайн""","Москва, Лужники, Спортивная, Фрунзенская, улица Усачёва, 10с1"
7161,78422892,Дата архитектор - Data architect,от 200 000 до 240 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Лидирует стрим проект, связанный с построением отчетности для целей планирования, в связи с этим требуется специалист. Обязанности: Постановка задач (в том числе написание спецификаций) и выполняет контроль разработки объектов в хранилище данных и отчетов Участвовать в воркшопах с функциональными и техническими экспертами для сбора и формализации требований, в том числе требований к отчетности и хранилищу данных Формировать критерии выбора хранилища данных и системы отчетности и выполнять оценку на соответствие им нескольких вариантов хранилища и отчётности Участвовать в разработке функциональной и технической архитектуры, включая интеграционные решения, удовлетворяющей функциональным и нефункциональным требованиям Участвовать в разработке модели данных под целевое решение и совместно с экспертами систем-источников разрабатывать ее маппинг на объекты систем-источников Поддерживать деятельность по интеграционному и пользовательскому тестированию, и запуску решения в продуктив Поддерживать деятельность, связанную с определением моделей и условий поддержки бизнес-приложения Выполнять необходимые активности, связанные с передачей бизнес-приложения на поддержку соответствующим командам Передавать вопросы и информацию о рисках на рассмотрение менеджеру проекта или старшему менеджеру по внедрению Выполнять задачи, согласованные с непосредственным руководителем. Требования: Опыт работы: 3-5 лет в поддержке бизнес-приложений, разработке или управлении проектами в различных функциональных областях Хорошие коммуникативные навыки и навыки межличностного взаимодействия Уверенное владение английским языком (intermediate/upper intermediate) Развитые аналитические навыки и навыки решения проблем Понимание бизнес-процессов в CPG/FMCG-компаниях Желателен опыт участия в роли аналитика/стрим лида в проектах по построению систем КХД, BI или внедрения систем планирования Возможность эффективно работать в гибкой и изменяющейся среде, управлять одновременно несколькими видами деятельности и приоритетами не создавая конфликтов. Условия: Трудоустройство в штат на основании ТК Удаленная работа по времени Мск, любой регион Уровень дохода в соответствии с навыками, по результатам встреч.",,7RedLines,
7165,79095952,Middle Data Scientist (Клиентская аналитика),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Компания MagnitTech— это опытная команда IT, которая создает экосистему современных цифровых продуктов Магнит: доставка продуктов, лекарств, инструменты для обеспечения лояльности клиентов, специальные проекты и продукты для внутренних нужд. Чем предстоит заниматься: Разрабатывать модели, позволяющие определять потребности и миссии клиентов на основании их покупок Разрабатывать алгоритмы кластеризации покупателей (бюджет, сегмент, портрет, потребность, RFM, L&G и т.д.) Разрабатывать алгоритмы кластеризации магазинов (бюджет, местоположение, состав покупателей и т.д.) Дорабатывать и оптимизировать существующие алгоритмы кластеризации Разрабатывать универсальные алгоритмы кластеризации не привязанные к конкретным данным. Стек технологий: Python, SQL, Git, Spark, S3, Linux, Bash, работа с облаками Мы ожидаем: Опыт работы с распределенными системами (HADOOP, YC DataProc, ClickHouse) посредством Spark Опыт работы с данными посредством SQL (Teradata, MS SQL, Postgres, Oracle) Знание математической статистики Знание систем контроля версий кода. Будет плюсом: Опыт работы с docker, airflow Умение найти баланс между сложностью и качеством модели. Мы предлагаем: Работу в максимально уютном и современном офисе в Москве или в Краснодаре, или удаленно График работы 5/2 с гибким началом Конкурентоспособную заработную плату Мы любим учиться! А компания всегда поддерживает и способствует профессиональному развитию специалиста Корпоративную технику для успешной и удобной работы Дружескую атмосферу и поддержку команды профессиональных и активных коллег Корпоративные скидки и программы лояльности от наших партнеров.","Python,Hadoop,Linux,SQL,Bash,Spark,Математическая статистика,Алгоритмы","МАГНТ, Розничная сеть",
7171,71072780,Старший аналитик Big data,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Формулирование постановки CR на доработку системы работы с данными, основываясь на информации, полученной от ключевых пользователей функций Отвечать на уточняющие вопросы разработчика во время реализации, при невозможности реализовать требуемый вариант, совместно с ключевым пользователем и разработчиком ищет ""компромисс"" Отвечать на вопросы КП по схеме данных внутри SAP BW (в том числе логика формирования аналитик и показателей) Помогать пользователям построить нужные им отчеты на базе имеющихся в BW данных (разовые не системные консультации) Участвовать в тестировании разработок SAP BW, проверять данные, аналитики и т.д. на соответствие постановки и бизнес логики Требования: Опыт работы в сфере аналитики продаж, планирования или финансов (управленческая отчетность или кредитный контроль) Образование Высшее - техническое, математика, менеджмент, экономика Знание английского языка, уровень - intermediate (как +) нужен будет для настройки шаблонов на англ. яз. Внимательность, умение слышать собеседника и ""переводить"" требования на системный уровень, умение вычленять суть из сказанного Работа с Excel, в том числе построение сложных графиков (2 оси, с наложением фильтров на модели данных). знание схемы устройства базы данных (как +), технический склад ума. Условия: График работы 5/2 Оформление строго по ТК РФ Уровень дохода обсуждается по итогам собеседования ДМС, страхование от несчастного случая Компенсация мобильной связи","Английский язык,SAP BW,MS Access,MS Visio,Excel,Продвинутый пользователь ПК,Английский — B2 — Средне-продвинутый","«Группа Черкизово», Центральный офис","Москва, Лесная улица, 5, корп. Б"
7173,77846851,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","12 лет компания Apptimizm создает удобные и полезные веб и мобильные сервисы. За нашими плечами огромный опыт и множество успешных реализаций бизнес идей. Каждый новый проект для нас — не только работа, но и любимое занятие. Мы сотрудничаем с такими компаниями как Канал RuTV, радио DFM, радио Монте-Карло, Icult.ru, BoomMarket, МТТ, Renault, Lada, Русское радио и многие другие. Мы с оптимизмом превращаем идеи клиентов в полноценные инструменты для ведения бизнеса. Предстоящие задачи: Дизайн и разработка витрин в Azure Дизайн, разработка и поддержка ETL процессов для загрузки данных в/из Data Lake Контроль качества и полноты данных (ручные и автоматические DQ тесты) нтеграции новых источников с DataLake Написание документаций Работать в связке с аналитиками и экспертами для получения end-to-end продукта. Мы ожидаем от тебя: Знание принципов построения DWH и баз данных Опыт работы с технологией Hadoop (HDInsight, Spark, Hive, Scala, etc.) Уверенное знание SQL, Python/Scala or Java 1+ лет опыта с Azure / Yandex Cloud Platform. Будет плюсом: Опыт работы с Greenplum Опыт работы с Nifi, Kafka, Airflow.","Hive,Python,SQL,Hadoop,Spark,Azure,ETL,DWH,DataLake,Yandex Cloud Platform",Апптимизм,
7174,79124147,"Data-аналитик команды ""Продуктовая отчётность""",з/п не указана,1–3 года,"Полная занятость,полный день","сследуйте, анализируйте и проектируйте бизнес-процессы!  щем Продуктового-Data-аналитика в бизнес-стрим ""Аналитика и Отчетность продаж Среднего и Малого бизнеса"" инновационной программы ВТБ ""600 дней"". Вам предстоит участие в проекте по разработке и внедрению системы управленческой, аналитической отчетности для продуктовых бизнес-стримов, развивающих банковские продукты для корпоративных клиентов сегмента Среднего и Малого бизнеса.  Вас ждут анализ требований пользователей (Владельцев продуктов (РО) продуктовых бизнес-стримов), разработка и автоматизация управленческой отчетности. А это значит и много совместной командной работы вместе с заказчиками-пользователями. Вы сами принимаете решения, отвечаете за результат и помогаете РО продуктовых бизнес-стримов блока Средний и Малый бизнес управлять развитием продуктовой линейки на основе созданной Вами аналитики!  Программа «600 дней» предполагает формирование более 300 кросс-функциональных команд, более 100 из которых уже успешно работают. В каждой из таких команд собрано максимум компетенций, чтобы сделать лучший продукт для пользователя: специалист по клиентскому опыту, дизайнер, аналитик, разработчики, тестировщики, ответственные за релиз обновлений. Такая команда способна полностью разработать продукт от гипотезы до готового решения. Никаких длительных согласований на высшем уровне — ответственность за продукт перед клиентом и руководством полностью несет команда и ее лидер. Де-бюрократизация процессов позволяет реализовывать яркие и смелые проекты в кратчайшие сроки. Больше проектов, а значит больше шансов проявить себя и построить карьеру.  Это тот самый момент, когда ваш опыт и знания помогут создавать лучшие продукты, которыми будут пользоваться миллионы людей.  это ваш личный вклад в цифровое будущее. Присоединяйтесь к нашей команде!  ОБЯЗАННОСТ: описание бизнес-процессов и требований для разработки бизнес-отчетности на основе которой определяется динамика продаж и вектор развития всей линейки банковских продуктов для корпоративных клиентов сегмента Среднего и Малого бизнеса подготовка данных для формирования отчетности на основе запросов из систем-источников проектирование моделей витрин данных в промышленном хранилище взаимодействие с Т командой проекта: постановка задач на разработку и автоматизацию разработка и поддержка регулярной отчётности по направлению: дэшборды, презентации поддержка отчетности и дэшбордов: добавление новых источников, аналитических разрезов, повышение уровня детализации и качества разработка требований для реализации ваших идей по отчетности на современных BI – инструментах (Qlik) подготовка оперативной аналитики для руководства и клиентских подразделений. ТРЕБОВАНЯ: высшее образование (экономическое/техническое/математическое) опыт аналитической работы, финансового контроля и планирования, подготовки финансовой и управленческой отчетности, сегментного анализа – в банковской/финансовой, телекоммуникационной или ритейл сферах опыт работы с большими объемами данных знание SQL (на уровне написания запросов средней сложности) обязателен работа с MS Excel на высоком уровне умение качественно визуализировать информацию, способность четко излагать свои мысли знание основ функционирования банков: продуктовой линейки, ценообразования, основных финансовых показателей будет дополнительным преимуществом понимание основ работы в корпоративных хранилищах данных. УСЛОВЯ: трудоустройство согласно Законодательству конкурентная заработная плата профессиональное обучение и развитие добровольное медицинское страхование, льготные условия кредитования корпоративная пенсионная программа, материальная помощь спортивная жизнь и корпоративные мероприятия возможность построить карьеру в ведущем банке России.","SQL,Подготовка презентаций,Linux,Проведение презентаций,MS SQL","ПАО ВТБ, Средний и малый бизнес","Москва, Выставочная, Деловой центр, Международная, Пресненская набережная, 10"
7183,79089818,Senior Data Scientist в направление рекламной платформы RnD (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior Data Scientist в направление рекламной платформы RnD Описание продукта: Рекламная платформа МТС включает в себя: 1. Программатик. DSP платформа, которая подключена ко всем популярным SSP и рекламным сетям. 2. Медиапланировщик. нструмент планирования маркетингового бюджета, определение наилучшего сплита как по основным каналам, так и внутри каналов. 3. Система аналитики. Аналитика трафика и событий. Построение MTA (Multi touch atributuon), сквозная аналитика. Обязательно: глубокое понимание статистических подходов и методов (регрессия, свойства распределений, оценка максимального правдоподобия, проверка гипотез и их правильное использование) и опыт их применения свободное владение основными библиотеками на Python (pandas, numpy, matplotlib, seaborn, etc.) коммерческий опыт применения классических алгоритмов машинного обучения (LR, RF, XGBoost/LGBM/CatBoost), понимание их преимуществ, недостатков и ограничений высокий уровень владения SQL опыт в распределённых/параллельных вычислениях с помощью следующих технологий: Hadoop, Spark, Dask и другие умение общаться с бизнес-заказчиком, объяснять простым языком полученные результаты и процесс работы алгоритма Желательно: опыт работы в медиа, понимание сферы digital рекламы стремление вникнуть в бизнес соответствующей отрасли диплом в области компьютерных наук, статистики, прикладной математики или другой релевантной анализу данных области английский язык (устный и письменный) на уровне Upper Intermediate опыт применения deep learning алгоритмов в NLP, CV направлениях (для подключения к R&D задачам) Что предстоит делать? собирать и обрабатывать данные из хранилищ компании подготавливать витрины данных, необходимые для разработки моделей машинного обучения. Задача частично закрывается data engineering специалистами разрабатывать модели машинного обучения как для MVP проектов, так и решений, выводящихся в production разрабатывать методологии применения различных ML алгоритмов для решения задач команды. подготавливать рекомендации по внедрению методологий и использованию продуктов для внутренних заказчиков компании проводить консультации и обмениваться идеями с младшими специалистами и коллегами по команде Стек технологий: Python, Pandas, Numpy, Matplotlib, Seaborn, LR, RF, XGBoost/LGBM/CatBoost, Hadoop, Spark, Dask. Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные и международные конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Python,SQL,Математическая статистика,Big Data,Machine Learning,NLP,Hadoop,Spark,Pandas,Numpy,Matplotlib,Seaborn",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
7186,79144555,Data engineer,з/п не указана,1–3 года,"Полная занятость,полный день","В Центр поддержки и сопровождения инструментов мониторинга защиты объектов открылся набор java разработчиков. Мы ждем именно твой отклик! Обязанности Анализ исходных данных в различных системах и форматах для решения бизнес-задач (оценка структуры, качества, полноты и применимости данных) Загрузка, очистка и трансформация больших объемов данных из различных источников в базу данных Проектирование и разработка аналитических витрин данных Мониторинг и оптимизация процессов загрузки, преобразования данных и сборки витрин Контроль качества загружаемых данных, разработка автоматизированных инструментов для оценки качества данных Разработка, поддержка и оптимизация инфраструктуры и внутренних сервисов для обработки больших объемов данных Разработка инструментов для автоматизации рутинных задач, связанных с обработкой данных Разработка и поддержка сопроводительной документации и спецификаций данных, развитие и поддержка базы знаний по вопросам работы с данными Предоставление экспертной поддержки внутренним потребителям (data analysts, data scientists) по вопросам, связанным с использованием данных. Требования Опыт работы в качестве Data Engineer / Data Analyst / ETL Developer Знание SQL на продвинутом уровне (аналитические функции, подзапросы, хранимые процедуры, оптимизация производительности) Опыт работы с большими объемами данных Знание основных понятий и концепций из области Data Warehouse Желателен опыт разработки витрин данных Опыт работы со стеком технологий Big Data является большим преимуществом Опыт работы по Agile (SCRUM, Kanban, и т.д.) приветствуется. Условия месторасположения офиса: ул. Академика Сахарова 2а График работы: 8:00-17:00 работа в крупнейшем банке России трудоустройство согласно ТК РФ регулярное корпоративное обучение ДМС, страхование от несчастных случаев и тяжелых заболеваний материальная помощь и социальная поддержка, корпоративная пенсионная программа льготные условия кредитования яркая и насыщенная корпоративная жизнь.",,Сбер для экспертов,
7188,77557350,Аналитик данных/Middle Data scientist (Computer Vision),з/п не указана,1–3 года,"Полная занятость,полный день","змерительная система — это программно-аппаратный комплекс, состоящий из различных датчиков, программного обеспечения, нейронных сетей и моделей. Данные с компонентов системы поступают в её головной компьютер, где оператор может получить информацию о состоянии объекта, результатах измерений. змерительные системы, разработанные «Северсталью», уже испытаны на собственных производствах компании. Эти эффективные решения компания готова адаптировать под задачи заказчика. В связи с расширением команды мы находимся в поиске Middle Data scientist (Computer Vision). Некоторые наши проекты: Системы видеоинспекции- поверхности металлопроката, которые обеспечивают определение и классификацию дефектов с помощью видеокамер, машинного зрения и нейросетей Системы измерения геометрических параметров и формы продукции с помощью лазерных триангуляционных датчиков позволяют измерять длину, ширину и толщину продукции, её планшетность и серповидность либо комплекс параметров Датчики промышленного интернета вещей, с помощью которых можно предотвратить травмирование продукции при погрузочно-разгрузочных работах.  В твои обязанности будет входить: Участие в анализе и проработке бизнес требований Контроль технической стороны процесса разметки изображений внешними и внутренними ресурсами Обучение CV модели (object detection, object tracking, object classification, segmentation) Доведение своей рисерч модели до состояния MVP и вносить доработки по результатам пилотирования Вывод решения в продакшн, поэтому помимо тренировок сеток специалист будет заниматься следующими задачами: · выбирать оптимальный дизайн решения для задачи · проводить trade-off между качеством и скоростью · оптимизировать работу алгоритмов в зависимости от условий работы (on edge, прунинг, квантизация) Тестирование в наших задачах SOTA решения и прикручивание их в прод, где это осмысленно В ситуациях, где данных для обучения классических моделей недостаточно, находить нестандартные решения. Основные требования: Хорошие знания Python и умение писать на нем качественный и понятный код Классический ML - кластеризация, классификация, регрессия и тд. Стек sklearn, numpy, pandas, xgboost/lightgbm Знания методов математической статистики и теории вероятностей. Знание базовых алгоритмов машинного обучения, хорошее понимание основ DL Теоретические знания методов DL и оптимизации (основные концепты + более углублённые знания в CV с упором на детекцию и сегментацию + основные метрики в задачах CV) Знание хотя бы одного из фреймворков по глубокому обучению TensorFlow\PyTorch Хорошее понимание основ классического компьютерного зрения (базовые морфологические операции, Discrete Fourier Transform, Hough transforms, Sobel derivatives) Опыт работы с задачами object detection, segmentation, classification Опыт работы с OpenCV Опыт автоматизированного сбора и разметки данных, опыт работы с CVAT Умение читать, понимать, имплементировать статьи по компьютерному зрению Умение решать задачи по CV без больших данных. Теоретическая подготовка в области RL и опыт использования алгоритмов RL Будет плюсом: Опыт работы с Linux Знание Docker, Docker Compose Опыт работы с разными видами сенсоров в области машинного зрения (камеры, радары, лидары и т.д.) Знакомство с GANами, attention-механизмами, архитектурами типа encoder-decoder, знакомство с semi- и unsupervised learning, знания в области NLP, а также опыт реализации кастомных архитектур Огромным плюсом будут навыки в оптимизации скорости инференса DL-моделей с кастомной архитектурой на CPU и GPU, а также опыт работы с TorchScript, TensorRT, ONNX, конвертацией моделей между фреймворками, etc. Опыт разработки и деплоймента DL-проектов Знание английского на уровне, достаточном для комфортного чтения статей и блогов Профиль на kaggle (необязательно). Мы предлагаем: Мощную команду профессионалов Дополнительную мотивацию в виде годового бонуса, социальный пакет и скидки от партнеров Развитие нон-стоп. Мы вкладываемся в людей как в самое дорогое. Создаем авторские учебные курсы. Привлекаем внешних экспертов и наставников. Гарантии стабильности. Трудоустраиваем по ТК РФ. Зарплата выплачивается 2 раза в месяц и регулярно индексируется. Есть ДМС со стоматологией с первого рабочего дня. Работаем по бессрочному договору. Возможность работы удаленно или в г. Череповце.","Python,SQL,MS SQL,Английский язык,PostgreSQL",Северсталь. IT & Digital,
7189,79090323,Middle/Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Дирекция мониторинга Agile занимается повышением прозрачности change-деятельности Сбера. Мы собираем данные по всем процессам в Банке, анализируем их и предоставляем для каждого уровня управления – от членов Правления Банка до владельцев продуктов – необходимую информацию для принятия решений на нашем дэшборде. Наша команда состоит из бизнес и Т-сотрудников, которые совместно работают над digital-инструментом мониторинга. Мы продолжаем увеличивать охват и глубину мониторинга и поэтому нуждаемся в новых силах. Мы ищем в команду middle/senior data scientist, который вместе с нами будет развивать бизнес-логику нашей системы мониторинга и готов комплектно решать задачи – от поиска проблем, проведения аналитики и подбора вариантов решения с помощью данных до работающих в production витрин, дэшбордов, алгоритмов и ML-моделеи. Обязанности Что нужно делать: - Погружаться в нюансы процессов и участвовать на встречах с пользователями - Разрабатывать прототипы pipeline сбора и обработки данных - Обучать модели машинного обучения и доводить их до production - Рассказывать внутри команды про свое решение и метрики Требования Что нужно уметь: - Обрабатывать и визуализировать данные с помощью Python (pandas, numpy, scipy, matplotlib, etc.) - Готовить витрины с помощью базового SQL (join’ы, оконки) - Писать качественный код: функциональный и ООП (pep 8) - Упаковывать модели в контейнер (Git, Docker, Linux) - Обучать классические модели машинного обучения (sklearn, lightgbm, catboost) - NLP: обрабатывать текстовые данные и применять нейронные сети к ним (nltk, genism, TF-IDF, word2vec, Bert, etc) Будет плюсом: - Знание алгоритмов и структур данных, желание писать качественный код - Умение автоматизации процесса мониторинга качества моделей и их калибровка Что мы ждем от кандидата: - Опыт работы DS от 2 лет - Уверенное знание математической статистики, базовых алгоритмов машинного обучения и NLP алгоритмов - Сильные аналитические навыки – умение найти и собрать релевантные данные, критически их оценить и сделать качественные выводы - Хорошие устные и письменные коммуникационные навыки, умение простым и понятным языком объяснять сложные вещи. Условия - Возможность решать амбициозные и инновационные задачи на пике технологических трендов в крупнейшем банке Восточной Европы - Работа в команде профессионалов - Офис бизнес-класса у метро Кутузовская со спортзалом - Возможности для профессионального развития и самореализации, участие в профильных конференциях и тренингах за счет Банка - Социальный пакет для сотрудников (ДМС, фитнес, льготные условия кредитования).",,Сбер для экспертов,
7192,79257772,Системный аналитик (Команда Data Governance),з/п не указана,3–6 лет,"Полная занятость,гибкий график","ОТП Банк входит в ТОП-50 крупнейших банков России, а на рынке потребительского кредитования и кредитных карт - мы одни из лидеров рынка. Банк активно меняется, выстраивая работу, в соответствии принципами agile. Сейчас agile-периметр ОТП Банка - это 9 Трайбов, 65+ команд и амбициозные цели по дальнейшему развитию. Agile в ОТП - это реальные проекты, современный стек технологий, уникальные банковские разработки и опыт крутых специалистов. О нас: Мы - команда Data Governance. Сейчас находимся в поиске системного аналитика для развития процессов и инструментов Data Governance. Цель: системный (80%) и бизнес-анализ (20%) требований, направленных на развитие к процессов и инструментов Data Governance. Что мы ждем: Высшее образование (техническая специализация будет плюсом) Опыт работы с хранилищами данных Опыт подготовки логической/физической модели данных, процессов и систем Понимание жизненного цикла данных и разработки программного обеспечения. Чем предстоит заниматься: Подготовка и поддержание в актуальном состоянии описаний и мета-описаний структур данных и схем потоков данных, Data Governance, Data Lineage Реализация и развитие контролей качества данных Визуализация данных, проектирование и макетирование дашбордов и отчётов Разработка логической/физической модели данных Участие в построении нового Хранилища данных и Озера данных. Нам важно: Знание основных банковских продуктов, основ бухгалтерского учета, основных банковских бизнес-процессов Знание принципов построения хранилищ данных, ETL процессов Опыт работы системным аналитиком не менее 2 лет Уверенные знания SQL Структурное мышление, возможность самостоятельно принимать решения Что мы предлагаем: Красивый офис/удобное рабочее место (м. Войковская) или удаленный формат Возможность изменять время начала и конца рабочего дня по согласованию с руководителем Отсутствие строгого дресс-кода (мы лояльны к любому проявлению личного стиля) Программы поощрения ОТП Мания (когда ты за внутреннюю валюту можешь купить себе как толстовку, так и day-off, например) Welcome pack ДМС (а также возможность его замены на фитнес) Льготные условия по кредитам и депозитам BestBenefits – сервис скидок и привилегий (техника и электроника, рестораны и доставка, обучение, отдых, спорт, красота и здоровье, товары, развлечения, услуги, детские товары и развлечения) Управленческое обучение, развитие навыков личной эффективности, профессиональное развитие Участие в корпоративных и спортивных мероприятиях (он-лайн и офф-лайн) Корпоративная библиотека МФ и Bookcrossing Детские подарки к Новому Году.",,"ОТП Банк, АО (OTP bank)","Москва, Войковская, улица Клары Цеткин"
7194,79192759,Data engineer DWH,до 250 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Команда профессионалов, за плечами которой создание нескольких успешных FinTech проектов в странах Юго-Восточной Азии, развивает новый, еще более амбициозный проект. Мы решаем интересную и крутую задачу – построение онлайн-банка в Азии. Мы ищем Middle+ Data Engineer-а в нашу команду DWH, которая на текущий момент состоит из 7 человек. Мы отвечаем за данные, их качество и строим аналитику, то есть принимаем важные бизнес решения на их основе. Основные обязанности: Разрабатывать и улучшать среду DWH (ETL / ELT pipelines, DDL, и тд), обеспечивать производительность и стабильность, при необходимости участвовать в анализе инцидентов Внедрять и сопровождать Data Catalog, Data linage, Metadata management tool, Data Quality project, решать сложные задачи по реализации никем ранее не реализованного функционала Требования: Опыт создания архитектуры ETL/ELT потоков данных Опыт работы с airflow, написание собственных операторов, хуков Опыт промышленного программирования на Python от 3х лет, умение оптимизировать существующий код, уменьшение boilerplate Опыт работы с DWH от 2х лет в роли аналитике, разработчика, понимание архитектуры DWH, его слоев и компонент Опыт моделирования данных, понимание что такое ERD Опыт работы с системами DQ, выстраивания собственных DQ инструментов как плюс Стрессоустойчивость, самостоятельность Преимущества: Опыт работы с dbt Опыт работы с datahub Образование: Оконченное высшее образование - математика, физика, computer science Что мы предлагаем: Комфортный офис в Москва-Сити с возможностью работать из любой точки мира Официальное трудоустройство, конкурентная заработная плата Гибкий рабочий график для оптимального баланса между работой и личной жизнью Высокий уровень корпоративной культуры, корпоративные мероприятия Прекрасная возможность профессионального развития в молодой и динамично развивающейся компании.","ETL,Python,Airflow,dbt,Git,PostgreSQL,DWH",Ок Софт,"Москва, Центральный административный округ, Пресненский район, Московский международный деловой центр Москва-Сити"
7206,79098637,Data Analyst (Управление кредитных рисков МСБ),з/п не указана,1–3 года,"Полная занятость,полный день","Наша команда занимается управлением портфелем кредитов малого и микро бизнеса и разработкой стратегий принятия решения крупнейшего банка РФ. Мы ищем человека, который сможет усилить команду, поддержит функцию по анализу больших данных при разработке и изменении стратегий принятия решений и урегулирования проблемной задолженности клиентов малого и микро бизнеса , погрузится в стратегию принятия решений, примет участие в совершенствовании инновационных кредитных продуктов ММБ на Российском рынке. Обязанности: Сбор данных для проведения портфельного риск-менеджмента ММБ Сбор данных для оценки бизнес инициатив Расчет эффекта от бизнес инициатив Формирование регулярной отчетности по направлению кредитных рисков ММБ Менеджер витрин данных ММБ (контроль качества данных) Подготовка бизнес требований на доработку Витрин данных Тестирование прототипов витрин по итогам реализации бизнес требований на доработку. Что ждем от кандидата: Высшее техническое, экономическое или фундаментальное образование (мехмат, физфак, бизнес-информатика) Системное мышление и хорошие аналитические навыки, умение докапываться до сути проблемы Умение работать с большими данными (знание MS SQL, PL/SQL, Python) Умение общаться как с бизнесом, так и с разработкой Умение быстро вникать в новую предметную область и разбираться в процессах и задачах, требующих модернизации и развития Опыт работы в сегменте ММБ (от 1 года) в бизнес или риск подразделениях банков и базовые представления о методах моделирования и измерения точности моделей PD, LGD, EAD приветствуются Условия: Профессиональное обучение, семинары, тренинги, конференции Годовые премии ДМС, сниженные ставки по кредитованию, программы лояльности для сотрудников Самые инновационные, амбициозные проекты и задачи Комфортный офис «Sbergile Home» с просторными опенспейсами, лаунж зонами, кафе, рестораном и оборудованными кухнями Бесплатный фитнес-зал Место работы – БЦ Президент Плаза (м. Кутузовская).",,Сбер для экспертов,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
7209,79189245,Аналитик безопасности Big Data (Security champion),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Приглашаем АНАЛТК БЕЗОПАСНОСТ BIG DATA (SECURITY CHAMPION) присоединиться к команде ПАО РОСБАНК. В Росбанке возможен полностью дистанционный формат работы: откуда работать - решать только тебе! Ты можешь работать из любой точки РФ! Приходи к нам, чтобы работать над амбициозными и интересными проектами и наслаждаться балансом между работой и личной жизнью! Росбанк – частный универсальный банк, работающий на российском рынке с 1993 года. Росбанк обслуживает порядка 1,5 млн активных розничных клиентов, около 83 тысяч активных клиентов малого бизнеса и около 10 тысяч активных клиентов корпоративного бизнеса более чем в 60 регионах России. Росбанк входит в ТОП 5 самых надежных российских банков по версии журнала Forbes и включен Банком России в число 13 системно-значимых кредитных организаций России. Наш банк имеет наивысшие кредитные рейтинги российских и международных рейтинговых агентств. ОБЯЗАННОСТ: Анализ текущей архитектуры безопасности Big Data (Data Lake, Greenplum, BI и т.д.) Сопровождение, развитие и разработка ролевой модели Big-Data платформы Повышение уровня зрелости BSIMM и OWASP SAMM в процессах командах DATA Контроль и консультация по устранению уязвимостей кода DATA-команд, а так же внедрение QualityGate Формирование плана и сопровождение устранения выявленных уязвимостей разработки в Big-Data по процессу Quality Gate Построение архитектуры тэгирирования данных в Big Data-системах Сопровождение и консультация команд по созданию и утверждению матрицы доступов к данным платформы сследование и развитие эффективности журналирования событий безопасности Big-Data платформы. ТРЕБОВАНЯ: Знание базовых архитектурных принципов безопасности систем на уровне ОС/БД/Приложений Опыт работы в разработке многоуровневых ролевых моделях Опыт работы с системами анализа уязвимостями и устранение выявленных уязвимостей Опыт в создании экосистемы доступов в стеке Big-data платформ.  БУДЕТ ПРЕМУЩЕСТВОМ: Наличие сертификатов в области обеспечения безопасности Big Data и баз данных Разработка на Python, Си, SQL, Java Опыт анализа лог-систем и построение логики анализа Опыт работы со стеком HDFS/HBase/Hive/Ranger, Greenplum и BI. УСЛОВЯ: Полностью дистанционный формат работы – это возможность работать из любой точки РФ Стабильный и прозрачный доход: зарплата и премии по результатам работы График 5/2 31 календарный день оплачиваемого отпуска Забота о здоровье сотрудников: программа ДМС, включая стоматологию и консультации психолога, страхование при выезде за рубеж, скидки на абонементы в фитнес-клубы, страхование жизни Дополнительная оплата за больничный лист: доплата сверх пособия по болезни до оклада (до 5 рабочих дней в год) Кадровый электронный документооборот, который позволяет подписывать кадровые документы (дополнительные соглашения к трудовому договору, приказы и т.п.) в электронном виде Личностное развитие и рост: корпоративная электронная библиотека Альпина с книгами, курсами, тестами по бизнесу и саморазвитию, возможность прохождения бесплатного обучения и тренингов, участия в регулярных встречах корпоративных клубов и скидки на курсы он-лайн школ Скидки и привилегии по кредитам, ипотека на льготных условиях, льготные условия обслуживания и т.п. Программа корпоративных скидок и привилегий Primezone: развлечение, отдых, товары для взрослых и детей, услуги (авиакомпании, рестораны, магазины электроники и т.п.), обучение Программа волонтерства и благотворительности Сообщества по интересам сотрудников.","Big Data,Power BI",«РОСБАНК»,
7212,71354549,Chief Data Scientist / DS Team Lead,з/п не указана,3–6 лет,"Полная занятость,полный день","Responsibilities: Collaborate, coach, and learn with a growing team of experienced Data Scientists and Data Trainees Collaborate with business partners to develop novel ways to meet objectives utilizing cutting edge techniques and tools Share passion for Data Science with broader enterprise community identify and develop long-term processes, frameworks, tools, methods and standards Effectively communicate the analytics approach and how it will meet and address objectives to business partners Advocate and educate on the value of data driven decision making focusing on the “how and why” of solving problems Lead analytic approaches, integrating work into applications and tools with data engineers, business leads, analysts and developers Create repeatable, interpretable, dynamic and scalable models that are seamlessly incorporated into analytic data products Engineer features by using their business acumen to find new ways to combine disparate internal and external data sources Domain Expertise: Bachelor’s degree required, in quantitative discipline and demonstrated Data Science skill set 4+ years work experience, 1+ year work experience as a team lead Python or R proficiency working with DataFrames and proficiency writing complex SQL queries Proficiency with Machine Learning to solve clustering, classification, regression, anomaly detection, simulation and optimization problems on large scale data sets Proven ability to merge and transform disparate internal & external data sets together to create new features Experience with Big Data technologies preferred — Hadoop, Spark, H20.ai, Cloud AI platforms, containerization Experience with supporting deployment, monitoring, maintenance and enhancement of models preferred Experience with data visualization tools preferred — Tableau, R Shiny, Plotly, etc. We Offer: Competitive salary Advanced benefits package (annual bonus, health insurance, mobile compensation, partial fitness compensation, 3-year saving plan) Professional development and career growth Ability to take part in digital transformation in a large company","Python,Machine Learning,SQL,Big Data,Spark,Data Analysis,Teambuilding,ML",Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
7213,77824574,Data engeneer,з/п не указана,3–6 лет,"Полная занятость,полный день","Функциональные задачи -реализовывать платформу данных и инструментарий для работы аналитиков, -строить витрины данных, надежные и оптимальные пайплайны обработки данных. Требования к должности - SQL, Python, CI/CD, Linux, Bash. Возможна удаленная работа. Офис м. Академическая","Python,SQL,Linux,Bash,Умение принимать решения",Май,"Москва, Академическая, улица Дмитрия Ульянова"
7214,79271442,Data engineer (middle),з/п не указана,1–3 года,"Полная занятость,полный день","Мы команда Digital Apps, и мы занимаемся развитием маркетинговых технологий для Сбербанка. Мы создаем инструменты сквозной аналитики, позволяющие отследить весь пользовательский путь от просмотра баннера до первой транзакции, автоматизировать запуск рекламы в Digital и эффективнее управлять ей. Наша основная цель – быть #1 в привлечение клиентов в цифровом пространстве. Задачи: Загрузка, очистка и трансформация больших объемов данных из различных источников (RDBMS, Hadoop, плоские файлы) в рабочую область (платформы Hadoop) Проектирование и разработка аналитических витрин данных Проектирование и разработка коннекторов для ETL процессов Мониторинг и оптимизация процессов загрузки, преобразования данных и сборки витрин Разработка, поддержка и оптимизация инфраструктуры и внутренних сервисов для обработки больших объемов данных Разработка инструментов для автоматизации рутинных задач, связанных с обработкой данных Hard Skills: SQL на продвинутом уровне (аналитические функции, подзапросы, хранимые процедуры, оптимизация производительности). Cтек технологий Big Data (Hadoop, Spark, Hive/Impala) и любой СУБД. Знание понятий и концепций DWH Python (PySpark, Pandas, NumPy, REST API) Airflow/Dagster/Oozie BitBucket\Git Bash HTML, JavaScript Знание YAML Soft Skills: Внимательность к деталям Аналитические навыки Коммуникационные навыки Ответственность Будут плюсом Hard+Soft: Знание банковского бизнеса Опыт работы по Agile (SCRUM, Kanban, и т.д.) Опыт работы в качестве Data Engineer / Data Analyst / ETL Developer Знание Scala/ Java, Maven",,Сбер. IT,"Москва, Кутузовская, Кутузовский проспект, 32"
7215,78936775,Data Engineer (ДАДМ),з/п не указана,3–6 лет,"Полная занятость,полный день","Вместе с нами ты будешь: Заниматься проектированием и разработкой витрин данных для анализа и моделирования Заниматься мониторингом и оптимизацией процессов сборки витрин Заниматься загрузкой и обработкой данных из различных источников Заниматься поддержкой и развитием базы знаний Предоставлять экспертную поддержку внутренним потребителям(data analysts,data scientists) Какие знания и навыки для нас важны: Знание SQL Хорошее знание устройства Hadoop,Spark,Hive/Impala Опыт разработки на Python/Scala/Java Понимание основных концепций DWH Понимание базовых команд Git и основных приципов работы Будет плюсом: Опыт работы с банковскими данными Опыт работы с различными СУБД в роли разработчика/аналитика витрин данных Опыт работы с Airflow","DWH,Hadoop,Hive,Git,Python,SCALA,SQL","ннотех, Группа компаний",
7227,77723392,Системный аналитик Big data,з/п не указана,1–3 года,"Полная занятость,полный день","АО «ЭнергосбыТ Плюс» - является крупнейшей энергоснабжающей организацией. С 2010 года ""Энергосбыт Плюс"" взял курс на цифровизацию и развитие Т по всем ключевым направлениям . Предполагается, что построение цифровой инфраструктуры внутри компании не только позволит усовершенствовать бизнес-процессы, но и поможет клиентам чувствовать себя комфортно в городской среде. АО «ЭнергосбыТ Плюс» объявляет конкурс на вакансию ССТЕМНОГО АНАЛТКА BIG DATA в команду нформационных технологий Вам предстоит: Сбор требования, разработка технического задания, ввод в эксплуатацию, тестирование, мониторинг работы микросервисов, постановка задач для устранения проблем, написание паспортов систем Мы ожидаем от Вас: Знания методологии хранилищ данных Знание нормальных форм и проектирование в нотации DFD Опыт подготовки сложных скриптов (SQL, Python (sqlalchemy)) Опыт сбора требований и написания технической документации Опыт создания функциональных схем (Visio) Опыт работы в микросервисной архитектуре Опыт работы с CI/CD инструментами Мы предлагаем: Офис - возможно размещение в одном из регионов присутствия Компании (Самара, Пермь, Саратов, Екатеринбург, жевск, Ульяновск, Владимир, ваново, Киров, Нижний Новгород, Оренбург, Чебоксары, Пенза, Саранск) Конкурентные условия оплаты труда Корпоративный пакет социальных льгот Обучение и помощь в период адаптации (наставничество, внутреннее корпоративное обучение) Возможность профессионального и карьерного роста Возможность работать в режиме Home officе","Python,SQL,MS Visio,Обучение и развитие,Big Data",Т Плюс,
7228,79018174,Manager / Senior Manager to Data & Analytics department,з/п не указана,более 6 лет,"Полная занятость,полный день","About the Data & Analytics Department PwC is one of the first Big-4 companies in Kazakhstan to invest in a dedicated Data & Analytics department. At the moment, the team consists of almost 20 professionals with different backgrounds and work experiences. Main directions of the department are: Decision Intelligence, Business Intelligence Engineering, Digital Analytics, Data Governance, and Research & Analytics. Data & Analytics team has many common projects with PwC Strategy & Operations Consulting, ESG Consulting, and Digital Consulting teams. The team operates in Kazakhstan, Uzbekistan, Kyrgyzstan, Azerbaijan, Georgia, and Mongolia. PwC Kazakhstan is looking for a Manager / Senior Manager to join our Data & Analytics department. The main focus will be on: business development, people management, project management, and sales. Requirements: 5+ years of experience in the Data & Analytics field with at least two years of experience in a managerial or leadership role to lead a team of analysts and data scientists, set goals, and establish priorities Strong understanding of database technologies, data management, data visualization, and data warehousing. Experience with SQL and / or other relevant programming languages Familiarity with ETL tools and business intelligence platforms such as Tableau, Power BI, or QlikView. Experience with cloud technologies, such as Microsoft Azure or Google Cloud Platform, would be a plus Experience in managing multiple projects, setting timelines and budgets, and overseeing project execution to ensure the timely delivery of results Excellent communication skills to present complex data analysis to non-technical stakeholders, build relationships with cross-functional teams, and communicate effectively with a client’s senior executives A deep understanding of the business and its goals, with the ability to translate business needs into data-driven solutions Familiarity with industry-specific data trends, regulations, and compliance requirements, as well as the ability to stay up-to-date with emerging data technologies and tools","SQL,Tableau,Big Data,Power BI,QlikView",PricewaterhouseCoopers,"город Алматы, проспект Аль-Фараби, 34"
7229,68115103,Data Scientist (Рекомендательные системы),з/п не указана,1–3 года,"Полная занятость,полный день",,,Сбер. IT,"Москва, Кутузовская, Кутузовский проспект, 32"
7231,74257288,Data аналитик (Рекламная платформа),з/п не указана,1–3 года,"Полная занятость,полный день","Мы - новая быстрорастущая команда, создающая сервис, который будет управлять цифровыми рекламными поверхностями и платформой по размещению рекламы на поверхностях Банка и Экосистемы. спользуя данные СБЕРа и технологические решения его экосистемы, мы сможем реализовать уникальный сервис на рынке digital marketing. Он позволит нам показывать пользователям рекламу, которая будет нравиться и которая будет делать рекламные продукты эффективными и измеримыми для рекламодателей. Если вы талантливый и амбициозный специалист в сфере Т, если вы хотите быть причастными к созданию лучших продуктов для лучших клиентов и уверенно отвечать за результаты, то мы рады принять вас в команду. Обязанности: проведение ad-hoc аналитики на данных рекламы (Hive, Spark, SQL) визуализация отчетности в BI инструментах (SuperSet, Qlik) работа с алгоритмами ML, подготовка обучающих выборок, анализ и сбор метрик. Требования: хорошие знания SQL, опыт работы с одной из реляционной БД - Oracle/PostgreSQL/mySQL/MS SQL Server уверенная работа с Python опыт аналитики с использованием инструментов Spark Streaming, Hbase, Spark, Kafka, Hive, Impala, Hue и т.д. навыки построения аналитических отчетов и дашбордов в BI инструментах понимание принципов модели распределенных вычислений, принципов организации Data Lake/DWH понимание подходов к организации разработки CI/CD. Условия: официальное трудоустройство согласно ТК РФ белая заработная плата страхование (от несчастных случаев, ДМС) оздоровительные программы для детей сотрудников возможность обучения за счет компании выплаты материальной помощи в особых/чрезвычайных случаях дисконт-программы от компаний партнеров (фитнес, страхование, туризм) льготное кредитование корпоративные цены на абонементы в крупные фитнес-сети комфортный офис и график работы 5/2.","Python,SQL,Data Mining,Oracle BI,Анализ данных",Сбер. IT,
7233,78936721,Data Engineer (ДАДМ),з/п не указана,3–6 лет,"Полная занятость,полный день","Вместе с нами ты будешь: Заниматься проектированием и разработкой витрин данных для анализа и моделирования Заниматься мониторингом и оптимизацией процессов сборки витрин Заниматься загрузкой и обработкой данных из различных источников Заниматься поддержкой и развитием базы знаний Предоставлять экспертную поддержку внутренним потребителям(data analysts,data scientists) Какие знания и навыки для нас важны: Знание SQL Хорошее знание устройства Hadoop,Spark,Hive/Impala Опыт разработки на Python/Scala/Java Понимание основных концепций DWH Понимание базовых команд Git и основных принципов работы Будет плюсом: Опыт работы с банковскими данными Опыт работы с различными СУБД в роли разработчика/аналитика витрин данных Опыт работы с Airflow","DWH,Hadoop,Hive,Git,Python,SCALA,SQL","ннотех, Группа компаний",
7237,78905162,Data Engineer в Data Lake,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы являемся частью централизованной аналитической платформы данных - Analytical Data Platform, которая включает в себя Data Lake (Hadoop) и аналитическое DWH (Green Plum).  В рамках нашего продукта мы решаем вопрос по стандартизации и автоматизации разработки загрузки/обработки ""сырых"" данных, за качество данных в бизнес слое DWH. Поддерживаем Hadoop и сервисы вокруг него.  Перед нами стоит задача развития современной аналитической платформы, включающей инструменты по сбору, хранению, обработке и анализу данных. Подразделения банка имеют возможность использовать разработанные нашей командой инструменты, процессы и интерфейсы для быстрой и независимой разработки для решения своих прикладных бизнес-задач, связанных с анализом данных. Пользователи нашей платформы - разработчики из продуктовых команд, решающие прикладные задачи ETL для автоматизации бизнес-процессов, Data Scientist'ы и аналитики, которые анализируют с помощью разных инструментов данные, хранящиеся в Data Lake, строят дашборды, обучают и применяют к новым данным модели машинного обучения.  Наш текущий стек: RHEL, Hadoop (а именно HDFS, YARN, Hive), Spark2/3, PostgreSQL, Airflow, NiFi, Zabbix, Rundeck, Jira/Confluence, Gitlab, Ansible, Docker, Grafana. Чем будешь заниматься в рамках своей экспертизы: заниматься ""платформизацией"" используемого стека с целью максимальной автоматизации и оптимизации процесса параллельной независимой разработки на платформе (скрытие сложности реализации низкоуровнего ПО типа Hadoop или Airflow за определенным уровнем абстракции путем разработки интерфейсов, процессов, CI/CD пайплайнов, соглашений, документации и т.д., чтобы продуктовые разработчики могли сосредоточиться на решении прикладных задач) прорабатывать архитектурные вопросы взаимодействия существующих и добавляемых компонентов платформы как между собой, так и с внешними системами (источники, потребители) оказывать поддержку разработчикам Data Lake из продуктовых команд эпизодически решать прикладные задачи на платформе для понимания опыта разработчиков из продуктовых команд - построение ETL-пайплайнов для загрузки в/из Data Lake с использованием платформенных инструментов осуществлять поддержку и решать инциденты в прод-контуре (в том числе от пользователей) проводить RnD, изучать новое open-source ПО (соответствует ли оно нашим стандартам и действительно ли закрывает выявленные потребности). Эта вакансия для тебя, если ты: работал с SQL и имеешь опыт написания запросов, тебя не пугают: join’ы, агрегатные функции, подзапросы, оконные функции имеешь опыт работы с любой из ""классических"" РСУБД (Oracle, MS-SQL PostgreSQL) в качестве разработчика/администратора писал код на Python или любом другом языке программирования общего назначения изучал HDFS и Hadoop, пробовал разворачивать дистрибутив Hadoop дома или в облаке использовал Hadoop, знаешь, как работает YARN, как эффективно хранить данные на HDFS, писал запросы в Hive писал код на Spark и можешь считать данные сервиса, используя его Rest API, отсортировать, отфильтровать их и сохранить результат на HDFS знаком с различными типами СУБД (SQL, NoSQL) и профилями использования (OLAP, OLTP) и можешь аргументированно выбрать оптимальный тип СУБД под задачу имеешь опыт работы с Airflow или любым другим оркестратором плотно работал с Hadoop в качестве разработчика/Data Engineer’а можешь определить для решения какой задачи выбор того или иного инструмента архитектурно более правильный можешь ставить задачи, планировать работу, общаться с заказчиками, быть наставником для менее опытных коллег Будет преимуществом, если ты: знаком с банковской предметной областью имеешь опыт разработки/внедрения систем класса DWH можешь деплоить приложения в Docker разбираешься в CI/CD практиках и инструментах можешь продемонстрировать один из своих проектов на GitHub умеешь писать на Java или Scala (на последней - применительно к использованию в связке со Spark). Что предлагаем: кросс-функциональные команды: владелец сервиса является неотъемлемым членом команды, непосредственно участвующим во всех процессах создания вверенного ему сервиса и жизни команды комфортную культуру открытости и отзывчивости сильные профессиональные IT-сообщества отсутствие бюрократии и дресс-кода гибридный формат работы (дом/офис) или полностью удаленный формат возможность проходить внутреннее и внешнее обучение понятную структуру дохода ДМС со второй недели работы со стоматологией и массажем в РФ страхование жизни и выезжающих за рубеж, страхование в направлении онкологии специальные предложения по вкладам и кредитам скидки от компаний-партнеров по программе Prime Zone в РФ доплату за 14 дней в году по больничному листу до оклада (после испытательного срока) доплату к отпускам, оформленным в январе и мае 3 оплачиваемых отгула в год.",,Райффайзен Банк,
7238,78902782,Data Engineer/Analyst DWH (Управление валидации),з/п не указана,3–6 лет,"Полная занятость,полный день","Команда Центра подготовки данных и отчетности Управления валидации Блока риски занимается сбором и проверкой качества данных, используемых при разработке моделей машинного обучения, выступает в качестве заказчика при разработке промышленных витрин данных, используемых в регулярных процессах валидации моделей, обеспечивает единовременными выгрузками данных по ad-hoc запросам. Мы ищем в команду Data-инженера по направлению работы с корпоративным сегментом клиентов. Обязанности Взаимодействие с разработчиками моделей (Data Scientists) и витрин с целью сбора данных Аналитика используемых источников (промышленные, пользовательские и т.д.), данных в этих источниках, алгоритмов сбора и обработки на соответствие сопроводительной документации (целям и задачам моделирования) Верификация корректности сбора данных Подготовка актуальных наборов данных для проведения валидации моделей и автоматизация их сбора для целей дальнейшего мониторинга Выработка рекомендаций по сбору и обогащению данных, подготовка требований на разработку/доработку витрин с целью автоматизации процесса. Навыки: Знание SQL на хорошем уровне Умение читать и разбираться в чужом коде Работа со сложными SQL запросами и большими объемами данных Знакомство с Python Знакомство с технологией Hadoop, Spark. Требования Высшее образование (техническое/математическое) Навыки коммуникации и взаимодействия с контрагентами Понимание принципов работы БД, построения кода Навыки работы с etl-инструментами приветствуются Опыт написания ТЗ на разработку витрин приветствуется Аналитический склад ума, системное мышление, командная работа Умение работать в режиме многозадачности. Условия График работы: 5/2, сокращенный рабочий день в пятницу Конкурентные условия труда, достойная заработная плата (оклад + годовая премии) ДМС для сотрудников и родственников Профессиональное обучение, семинары, тренинги, конференции Льготные условия по кредитам Сбербанка, а также скидки от партнеров Сбербанка Большой и комфортный офис со спортзалом.",,Сбер для экспертов,
7239,78936789,Data Engineer (ДАДМ),з/п не указана,3–6 лет,"Полная занятость,полный день","Вместе с нами ты будешь: Заниматься проектированием и разработкой витрин данных для анализа и моделирования Заниматься мониторингом и оптимизацией процессов сборки витрин Заниматься загрузкой и обработкой данных из различных источников Заниматься поддержкой и развитием базы знаний Предоставлять экспертную поддержку внутренним потребителям(data analysts,data scientists) Какие знания и навыки для нас важны: Знание SQL Хорошее знание устройства Hadoop,Spark,Hive/Impala Опыт разработки на Python/Scala/Java Понимание основных концепций DWH Понимание базовых команд Git и основных принципов работы Будет плюсом: Опыт работы с банковскими данными Опыт работы с различными СУБД в роли разработчика/аналитика витрин данных Опыт работы с Airflow","DWH,Hadoop,Hive,Git,Python,SCALA,SQL","ннотех, Группа компаний",
7241,76111917,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Приглашаем в команду Data Engineer'а  Вы нам подходите, если любите настраивать автоматический сбор данных из различных источников, а также бережно следите за их качеством и стабильностью, создавая все возможные алгоритмы мониторинга и уведомления. Какие задачи у Data Engineer'а? Участие в построении корпоративного хранилища данных (BigData) на платформе Microsoft для BI-системы и проектов скусственного интеллекта(DL/ML) Организация автоматизированного сбора данных с внешних и внутренних источников Сохранение данных в DWH согласно правилам Участие в реализации процесса ETL. Связь данных из разных источников, трансформация, подготовка, агрегация данных для анализа Применение скрапинга и парсинга Консультирование Аналитиков BI и DataScientist- потребителей данных Участие в разработке чат ботов для ВК и Телеграмм Прежде всего мы ценим: Навыки программирования на Python(pandas, numpy, selenium, unittest или pytest ) Навыки работы с SQL любого диалекта Понимание технологий интеграции между платформами (API, триггеры, webhook) Знание библиотек для написания парсеров Опыт работы с Git Мы предлагаем: Развитие в команде молодых профессионалов своего дела ндивидуальную программу адаптации и помощь наставника Оформление по ТК РФ и полностью белую заработную плату Один день в неделю работаем на удалёнке Доступ к электронной библиотеке Альпина Сразу после испытательного срока предоставляем ДМС со стоматологией Будь в форме – участвуй в спортивных мероприятиях (Петровский гребной марафон, ЗаБег.РФ, Футбол, Пляжный волейбол и др.)","SQL,Python,Numpy,Git,Machine Learning,DWH,ETL,Pandas,Data Analysis,Big Data,Парсинг",Главстрой Санкт-Петербург,"Санкт-Петербург, Старая Деревня, улица Оптиков, 4"
7243,75566599,Data engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы – команда, которая собирает, готовит и анализирует данные для принятия ключевых стратегических, оптимизационных и операционных решений в группе компаний. Среди задач, которые мы решаем: Сбор статистических данных из внутренних и внешних источников в наш data-lake на базе Hadoop (по заказу внутренних заказчиков и для реализации собственных идей) Создание подготовленных витрин данных для отделов бизнес/ финансовой аналитики и маркетинга Создание витрин данных со статистикой внутренних операционных показателей (в т.ч. хостинга) Создание удобных инструментов для пользователей для работы с нашими решениями и статистикой Сбор и подготовка данных из открытых источников Переход от пакетного к потоковому сбору и обработке данных. Сейчас мы ищем человека, с навыками в Data Engineering, готового участвовать в подготовке данных для внутренних пользователей. Плюсы – возможность развиваться в разных областях и много свободы для реализации своих идей и предложений. Обязанности: Разработка и поддержка автоматизированных ETL/ELT процессов на Spark/Hadoop (интеграция источников данных в Data Lake, создание витрин данных под потребности пользователей и сервисов) Сбор, обработка и парсинг ""сырых"" данных Написание сервисов для работы с внешними источниками/потребителями данных Поддержка и развитие хранилища данных. Must-have skills: Опыт промышленной разработки на Python Уверенные знания SQL/оконные функции/CTE Опыт работы с инструментами экосистемы Hadoop: Hive, Impala Наличие опыта разработки на Python / разработки на pySpark Опыт работы с Superset/Tableau Опыт написания DAG в Airflow/Luigi/Preset Знание основных понятий и концепций из области Data Warehousing Опыт разработки витрин данных. Несомненными плюсами будут: Опыт работы с docker, k8s, kafka Опыт работы с нереляционными БД Наличие профессионального интереса к развития архитектуры данных: хранение, транспортировка, обработка, применение, обеспечение AI/ML и DataOps Условия: Удаленный формат работы График работы 5/2 с гибким началом рабочего дня ДМС, с телемедициной и льготной стоматологией, скидки на фитнес и англ.язык, корпоративное оборудование Также, участие в различных профессиональных митапах и конференциях.","Python,SQL,Hadoop",RU-CENTER Group,
7245,78848021,DATA-аналитик (корпоративная модель данных),з/п не указана,более 6 лет,"Полная занятость,полный день","В команду блока по сквозным цифровым технологиям требуется Аналитик данных корпоративной модели данных Чем предстоит заниматься: техническое руководство комплексными проектами по разработке и внедрению информационных систем в атомной отрасли (в сфере сквозных цифровых технологий) системный анализ данных в информационных системах корпорации каталогизация данных, формирование data-lineage/data-provenance создание методических указаний для выполнения системного анализа данных в С-источниках, выполнения профилирования совместно с архитектором данных создание методических указаний по работе с бизнес-глоссарием создание базы знаний по направлению аналитики данных разработка соглашений о качестве данных, бизнес-правил, формирование требований к разработке инфопанелей для отражения результатов технических проверок в рамках анализа данных подготовка предложений по классификации данных по категориям Б (КТ, ПДн, ДСП, общедоступные), согласование с Б и владельцами данных, тегирование данных в каталоге разработка требований к инструментам управления данными, анализ функциональных возможностей, участие в подготовке и проведении апробаций, постановка на доработку/развитие организация взаимодействия с офисами управления данными дивизионов корпорации по вопросам работы с каталогом данных, бизнес-глоссарием, инструментами каталогизации, контроля качества данных. Мы ждём от кандидата: опыт работы с аналитикой данных не менее 5 лет опыт работы в должности Старшего аналитика данных /системного аналитика или на аналогичных лидерских позициях не менее 1 года опыт выполнения бизнес анализа, формализации бизнес-требований хорошее знание SQL, опыт выполнения системного анализа данных С, написания SQL запросов, выполнения самостоятельного ad-hoc анализа опыт работы в проектах по построению ХД и внедрению BI опыт работы с программными продуктами бизнес-аналитики опыт формирования технических спецификаций на разработку программного обеспечению, интеграции навыки формирования бизнес правил проверки качества данных, опыт разработки технических проверок посредством SQL запросов опыт организации базы знаний, работы с бизнес-глоссарием, каталогом данных компетенции по организации разработки как водопадной модели, так и по гибким методологиям опыт подготовки проектной документации, технических заданий и проведение контроля на соответствие на этапе реализации ответственными подразделениями, опыт проведения приемо-сдаточных испытаний. Приветствуется: знание предметных областей отрасли атомной энергетики участие в проектах внедрения RDM/MDM опыт разработки логических/физических моделей данных навыки разработки методических указаний выполнения системного анализа. Успешному кандидату готовы предложить: Комфортные условия работы: современные рабочие места, цифровые сервисы для сотрудников Обучение и развитие: собственная онлайн-платформа с программами профессионального и личностного роста – от инженерных курсов до изучения иностранных языков участие в конференциях, тренингах и конкурсах профессионального мастерства Карьерные возможности: карьерные консультации для построения экспертной или управленческой траектории роста, поддержка карьерного развития сотрудников Социальные программы: ДМС со стоматологией и госпитализацией, страхование несчастных случаев на производстве, линия психологической поддержки, финансовая помощь в особых жизненных ситуациях Корпоративная жизнь: тимбилдинги, спортивные активности и отраслевые соревнования, волонтерские движения, мероприятия для сотрудников и их семей","Анализ данных,Базы данных,Big Data,SQL,Power BI,Английский — B1 — Средний",Частное учреждение по цифровизации атомной отрасли «Цифрум»,"Москва, Холодильный переулок, 3"
7247,77737078,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Литрес – лидер рынка электронных книг в России и СНГ. Мы создаем книжные продукты уже более 17 лет. Каждый месяц 12,5 млн человек покупают, читают или слушают книги у нас. В группу компаний входят: онлайн-магазин litres., приложения «Литрес: Читай и Слушай онлайн» и «Литрес: Слушай аудиокниги», сервис для чтения по подписке MyBook, платформа для новых авторов «Литрес: Самиздат» и для чтецов – «Литрес: Чтец», социальная сеть для читателей LiveLib, приложение с аудиокнигами «Звуки Слов» и другие сервисы. Мы учредили первую в России премию в области электронных и аудиокниг «Электронная буква». Чем предстоит заниматься: Твоя цель - построить вместе с нами масштабируемое решение, которое будет предвосхищать ожидания пользователей, наших читателей и авторов, предоставляя им персонализированный контент, подсказки и аналитику. Мы хотим собрать это решение с нуля и с твоей помощью. Ядро такой системы - это алгоритмы машинного обучения, которые рассчитывают предпочтения миллионов конечных пользователей. Работая в нашей команде, ты будешь участвовать в исследовании, разработке, тестировании и внедрении алгоритмов классического и глубокого обучения в части рекомендаций. Наш стек: Python 3.10, Gitlab CI, MyPy, Flake, Black и интеграционные тесты на PyTest. Сервисы на FastAPI в тех же пайплайнах собираются в образ Docker и деплоятся в кластер Kubernetes. Данные мы храним и используем в MySQL, PostgreSQL, ClickHouse, Redis, Memchached. Мониторинги - Sentry, Prometheus, Grafana. Для проб моделей и тестов кода есть свои и облачные ресурсы с CPU и GPU. Справедливо и для production окружения. Сейчас у нас ~4000 rps на существующей системе и ожидания к новой системе как от хайлоад систем. Мы ожидаем от вас: Владение асинхронным Python и современным фреймворком веб-разработки на его основе (fastapi) Опыт разработки и проектирования функционала REST API Опыт работы с БД (Mysql/PostgreSQL). Уверенное владение SQL (в т.ч. оконные функции) и NoSQL (Redis, memcached) Опыт работы с Gitlab CI, k8s Знания теории вероятностей и статистики (распределения, проверка гипотез) Экспертные знания алгоритмов машинного обучения (наиболее интересны алгоритмы продуктовых рекомендаций) Практический опыт полного цикла решения ML задач: предобработка данных, выбор алгоритмов и тюнинг их параметров, оценка качества моделей, визуализация и т.д. Хорошее знание Python и ключевых DS-фреймворков (pandas, scipy, sklearn, catboost, lightgbm, желателен pyspark) Опыт написания качественного production кода, навыки работы с Git Условия: Комфортный офис в Москва-Сити башне «Меркурий» Официальное оформление по ТК РФ, стабильную белую заработную плату + ежеквартальную премию Удалённый, гибридный или офисный формат работы, стандартную рабочую неделю пн-пт (с гибким началом времени дня) После успешного прохождения испытательного срока: ДМС со стоматологией, ""Добросервис"" с неограниченной юридической и психологической консультацией, фитнес, курсы английского языка. Постоянные скидки от наших партнёров и многое другое Частичную компенсацию парковки Неограниченный доступ ко всем электронным и аудиокнигам Оплату профильных курсов, участие в конференциях Веселые и запоминающиеся корпоративы на природе и в офисе: играем в настолки, xbox и настольный теннис прямо в офисе. Заказываем пиццу каждую последнюю пятницу месяца Отсутствие дресс-кода :)","Python,REST API,SQL",Литрес,"Москва, Выставочная, Деловой центр, 1-й Красногвардейский проезд, 15"
7248,75566561,Data engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы – команда, которая собирает, готовит и анализирует данные для принятия ключевых стратегических, оптимизационных и операционных решений в группе компаний. Среди задач, которые мы решаем: Сбор статистических данных из внутренних и внешних источников в наш data-lake на базе Hadoop (по заказу внутренних заказчиков и для реализации собственных идей) Создание подготовленных витрин данных для отделов бизнес/ финансовой аналитики и маркетинга Создание витрин данных со статистикой внутренних операционных показателей (в т.ч. хостинга) Создание удобных инструментов для пользователей для работы с нашими решениями и статистикой Сбор и подготовка данных из открытых источников Переход от пакетного к потоковому сбору и обработке данных. Сейчас мы ищем человека, с навыками в Data Engineering, готового участвовать в подготовке данных для внутренних пользователей. Плюсы – возможность развиваться в разных областях и много свободы для реализации своих идей и предложений. Обязанности: Разработка и поддержка автоматизированных ETL/ELT процессов на Spark/Hadoop (интеграция источников данных в Data Lake, создание витрин данных под потребности пользователей и сервисов) Сбор, обработка и парсинг ""сырых"" данных Написание сервисов для работы с внешними источниками/потребителями данных Поддержка и развитие хранилища данных. Must-have skills: Опыт промышленной разработки на Python Уверенные знания SQL/оконные функции/CTE Опыт работы с инструментами экосистемы Hadoop: Hive, Impala Наличие опыта разработки на Python / разработки на pySpark Опыт работы с Superset/Tableau Опыт написания DAG в Airflow/Luigi/Preset Знание основных понятий и концепций из области Data Warehousing Опыт разработки витрин данных. Несомненными плюсами будут: Опыт работы с docker, k8s, kafka Опыт работы с нереляционными БД Наличие профессионального интереса к развития архитектуры данных: хранение, транспортировка, обработка, применение, обеспечение AI/ML и DataOps Условия: Удаленный формат работы График работы 5/2 с гибким началом рабочего дня ДМС, с телемедициной и льготной стоматологией, скидки на фитнес и англ.язык, корпоративное оборудование Также, участие в различных профессиональных митапах и конференциях.","Python,SQL,Hadoop",RU-CENTER Group,
7252,78834188,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","В практику по управлению данными крупнейшей сети ресторанов быстрого питания требуется дата-инженер. Вакансия обусловлена большим портфелем проектов в сфере DATA, предусмотренным стратегией развития компании и имеющим высокий приоритет для бизнеса. Развитие ДАТА-практики охватывает контур компании и ее ключевых партнеров по цепочке создания ценности и предусматривает внедрение корпоративной платформы данных, включая построение классического DWH и озера данных (Data Lake), разработку приложений BI-аналитики и отчетности на платформе, обеспечение процессов интеграции данных. Работа организована по продуктовым командам, в которые входят представители бизнеса и Т (продакты, дата-инженеры, специалисты Data Science, аналитики данных и специалисты Т, отвечающие за сервисы платформы данных). Обязанности: Сбор и обработка данных из различных источников для проектов построения ML-моделей прогнозирования и ad-hoc аналитики по запросам бизнес-функций маркетинга, HR и финансов Анализ требований ко входящим потокам данных Проектирование потоков данных и схем загрузки Профилирование и очистка данных Разработка скриптов трансформации данных Разработка интеграционного взаимодействия (REST API) Подготовка витрин данных и поставка данных для контента в аналитические приложения Проведение ревью кода и участие в программе менторинга джуниор дата-инженеров команды. Требования: Высшее образование Опыт работы в роли дата-инженера/ аналитика данных в продуктовых командах либо опыт участия в проектах построения DWH и Data Lake в роли ETL-разработчика – от 2 лет Твердые знания Python Навыки оптимизации SQL-запросов и опыт разработки на PostgreSQL, ClickHouse Опыт построения потоков данных (предпочтительно Ni-Fi, AirFlow) Практические навыки работы с данными на кластере Hadoop или S3 Опыт написания задач для Spark, Kafka Базовые навыки MLOps (в объеме самообслуживания) Предпочтителен опыт работы с Яндекс Облаком и/или Сбер Cloud Умение писать чистый поддерживаемый код и техническую документацию Условия: Работа в масштабном бренде в сфере быстрого обслуживания с уникальной историей Достойный уровень оплаты труда Продвинутая система бенефитов (годовой бонус, ДМС, мобильная связь, частичная компенсация фитнеса, 3-х летний накопительный план от оклада и премий) Гибридный график работы (один день в офисе, четыре из дома) Профессиональное развитие и карьерный рост Возможность принять участие в цифровой трансформации масштабного бренда",,Ventra,
7253,78286979,"Solution Architect / Presales Expert (BI,Data Governance, Data Quality, Big Data,Machine Learning)",з/п не указана,3–6 лет,"Полная занятость,полный день","КОРУС Консалтинг – российская аккредитованная Т-компания, признанный лидер в автоматизации ритейла, производства, логистики, финансов и нефтегаза. Мы входим в топ-5 крупнейших IT компаний Петербурга. Нас более 1000 человек, а за плечами более 20 лет опыта. За это время мы сделали более 1200 масштабных проектов для ведущих компаний России, а именно: Bonava, DPD, Nokian Tyres, Tele2, Азбука Вкуса, Газпром нефть, Дикси, нвитро, Леруа Мерлен, Магнит, Мегафон, О’КЕЙ, Петрович, Росатом, Яндекс.Деньги и это только начало списка. Мы любим данные. Мы поняли это более десяти лет назад, когда в составе группы компаний «КОРУС Консалтинг» ещё не было отдельного департамента аналитических решений и понятие «бизнес-аналитика» ещё не было так популярно. Наш Департамент аналитических решений (ДАР) погружен во все современные направления в области работы с данными: внедрение BI-систем и систем аналитической отчетности, проектирование хранилищ и витрин данных, разработка в области продвинутой аналитики и больших данных, применение прикладных продуктов с использованием Machine Learning, внедрение решений в области управлениям данными (Data Governance, Data Quality), разработка методологии и стратегии работы с данными. Задачи, которые предстоит решать: Проработка архитектур комплексных решений в части платформ и хранилищ данных Разработка нефункциональных требований и сопровождение их реализации Участие во внешних встречах (в presale-активностях), сбор функциональных и нефункциональных требований к решению Формирование и актуализация внутренней базы знаний (реестр проектного опыта (команды и компании), описание возможностей платформ, подготовка и описание демо-примеров) Развитие аналитической экспертизы в предметных областях (анализ опыта реализованных проектов, ведение информации в базе знаний) Подготовка и оформление технико-коммерческих предложений (с учетом рамок проекта, ограничений и допущений), презентаций, отработка архитектурных решений, разработка дорожных карт, концепций внедрения систем Gap-Fit анализ платформ с точки зрения покрытия функциональных и нефункциональных требований Взаимодействие с производственной командой, sales-менеджерами. Что поможет в работе: Навыки проектирования высоконагруженных и отказоустойчивых платформ данных Опыт работы в качестве архитектора решений или presale-консультанта от 2-х лет Опыт работы в командах по внедрению информационных систем Навык разработки технической документации Преимуществом будет опыт работы с такими инструментами, как Qlik, Tableau, MS Power BI. Наше предложение: Официальное оформление в штат компании, в соответствии с ТК РФ. Уровень дохода обсуждается индивидуально с каждым кандидатом (фикс на уровне рынка + переменная часть, в привязке к KPI). Возможность гибкого начала рабочего дня (с 8 до 10 часов). Гибридный формат работы (совмещение присутствия в офисе в Санкт-Петербурге или Москве с днями удалённой работы), возможность самостоятельно планировать свой день. Открытая корпоративная культура, корпоративный волейбол, футбол и беговой клуб, участие в экологических программах, регулярные тимбилдинги. Минимум бюрократии и отчётов, совещания только по необходимости и с чёткой программой. Широкие возможности профессионального развития: программы корпоративного университета, менторство от руководства департамента, обучение на внешних курсах на специальных условиях. Полис ДМС, корпоративные тарифы на фитнес и занятия английским на ведущих платформах. Комфортный современный офис, оборудованный технологичными переговорными и гостевой зоной. Будем рады обсудить сотрудничество!","MS PowerPoint,Бизнес-анализ,MS Project,MS Visio,Управление проектами,Оптимизация бизнес-процессов,MS Power BI,Qlik,Tableau,presale,внедрение С",КОРУС Консалтинг,
7260,78843112,Data Engineer направления разработки витрин данных,з/п не указана,1–3 года,"Полная занятость,полный день","Data Engineer Вместе с нами ты будешь: Заниматься проектированием и разработкой витрин данных для анализа и моделирования Заниматься мониторингом и оптимизацией процессов сборки витрин Заниматься загрузкой и обработкой данных из различных источников Заниматься поддержкой и развитием базы знаний Предоставлять экспертную поддержку внутренним потребителям(data analysts,data scientists) Какие знания и навыки для нас важны: Знание SQL Хорошее знание устройства Hadoop,Spark,Hive/Impala Опыт разработки на Python/Scala/Java Понимание основных концепций DWH Понимание базовых команд Git и основных приципов работы Будет плюсом: Опыт работы с банковскими данными Опыт работы с различными СУБД в роли разработчика/аналитика витрин данных Опыт работы с Airflow","Hive,Hadoop,Git,Python,SCALA","ннотех, Группа компаний",
7263,78707376,Data Scientist (ML Space),з/п не указана,1–3 года,"Полная занятость,полный день","В направление ML Space требуется DS-специалист для разработки облачных AI-сервисов. Приглашаем Data Scientist в команду ML Space, которая занимается развитием продукта ML Space - платформы для ML-разработки полного цикла: от трансфера и хранения BigData до деплоя и автоматического масштабирования готовой модели. Вам предстоит на основе данных заказчика и открытых источников создавать воспроизводимые ML-пайплайны, которые другими заказчиками смогут переиспользоваться на своих данных для решения схожих бизнес-задач. Будет необходимо заниматься уточнением бизнес-задачи, помощью в формализации потребностей, подготовкой данных для моделирования, написанием кода от baseline-модели до полноценного ML-пайплайна и публикации его на ML Space. Обязанности: Разработка ML-пайплайнов (AI-сервисов), в том числе в экспресс-режиме (разработка MVP, проверка/тестирование гипотез), подготовка EDA с помощью библиотек Python на данных клиентов Умение формулировать гипотезы, проверяемые с помощью ML Подготовка шаблона для запроса данных у клиента под конкретную задачу Помощь в формализации потребностей и формировании бизнес-требований, экспертный контроль качества полученных ML-моделей, достижение бизнес-целей заказчика Участие в развитии передовой платформы для полного цикла ML-разработки «ML Space» https://sbercloud.ru/ru/aicloud/mlspace. Требования: Хорошее знание Python, опыт разработки ML-пайплайнов (MLOps) Опыт в решении задач прогнозной (предиктивной) аналитики, например, предсказание спроса, динамическое ценообразование, предсказание поломок оборудования Понимание методологий минимум в 3 из перечисленных направлений: технологии CV, NLP, рекомендательные системы, временные ряды Уверенные знания в области классического машинного обучения (метрики, оценки качества, визуализации, интерпретации результатов моделирования) Коммерческий опыт работы с большими данными с помощью библиотек pandas, numpy, scikit-learn, знание и опыт разработки на фреймворке PyTorch и использование других фреймворков глубинного обучения (JAX, TensorFlow) Опыт работы с контейнерами Docker и с системами оркестрации (Kubernates) Опыт работы в Linux-средах обязателен Высшее образование по направлениям ПМ, программная инженерия. Преимущество отдается кандидатам из ШАДа, AI Masters (OzonMasters), MADE. Будет плюсом: Понимание REST, опыт работы с python-фреймворками инференса Kserve, Nvidia Triton (FastAPI, Flask и т. п.), понимание gRPC Умение работать с большими данными через Spark Знание SOTA-алгоритмов, умение их применить в практических кейсах Опыт продуктивизации ML-подобных решений/моделей (в идеале – продуктов, основанных на технологиях машинного обучения/компьютерного зрения/NLP), вывод ML-модели машинного обучения за стадию MVP Понимание механизмов распределенных вычислений (MPI, torch.distributed, horovod) Практический опыт работы с системами контроля версий (у нас GitLab) и системами управления проектами (стек Atlassian: Jira, Confluence и т. д.) в командной разработке Опыт реализации кейсов на данных компаний из разных отраслей (например, металлургия, АПК, ритейл и др.). Что мы предлагаем: Оформление в соответствии с трудовым законодательством РФ Конкурентный уровень дохода (оклад + годовой бонус) ДМС со стоматологией и возможностью подключения к программе своих детей и родственников Прозрачную систему мотивации, которая позволяет влиять на уровень дохода Работу в команде профессионалов Участие в создании инновационных продуктов Гибкое начало рабочего дня, пятница - сокращённый рабочий день Возможность работать удаленно Офис в центре Москвы Корпоративную мобильную связь Льготную программу ипотечного и потребительского кредитования Ещё у нас: Возможность вертикального и горизонтального роста Бонусные программы от компаний партнёров Возможность получения бонуса за закрытие вакансии по вашей рекомендации Материальная помощь при рождении детей и др. семейных обстоятельствах Обучение в Корпоративном университете Участие в профильных конференциях в качестве спикера или слушателя Корпоративная жизнь: спортивные комьюнити, клубы по интересам (настолки, интеллектуальные игры Обучение и развитие в компании.",,Cloud,"Москва, Улица 1905 года, 2-я Звенигородская улица, 12с2"
7264,78769358,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,гибкий график","Aristek Systems is actively involved in the development of innovative IT solutions for the US and European markets. Our team consists of over 150 highly qualified professionals of various IT-spheres.  Now we are looking for a Data Engineer to join our team! About the project: An E-learning platform with the possibility of interactive learning (3D, VR), where you can also store training manuals. This project is built on micro services, the main modules of the platform: - Storage of manuals and materials - Portal for training and retraining of teachers with obtaining a STEM certificate - Storage of participants' profiles (rating, academic performance, grades, schedules, etc.) - Automation of the platform's business processes (financial accounting, Human resources, etc.). This platform is one of the largest educational systems in the United States with about 15,000,000 registered users in the system.  User location: USA, Canada, Great Britain, Australia and New Zealand. One of the parts of the portal is being developed jointly with the world-famous CNN media corporation. Your Responsibilities at Aristek Systems  - Developing Data lake In with AWS Services. - Collect all Students/Teachers Activities etc. - Generate Reports in QuickSight and provide them for End Users. - Create/configure different types of Reports and share them in various parts of the Product. - Design department-wide principles and workflow for data quality management. - Works closely with a team of frontend and backend engineers, product managers, and analysts.  Required Skills and Experience  - 3+ years of experience in Data oriented teams - Strong Knowledge (writing effective queries) in MS SQL, MySQL - Knowledge of PowerBI/ QuickSight/ Tableau - English level: Intermediate (B1+) - Experience in developing data solutions based on AWS - Strong analytical skills, good communication skills, both oral and written. Benefits you get with us: - Team buildings, corporate parties and other extracurricular events - Gifts in case of important events in your life (birthday/wedding/the birth of a child) - Payment of advanced trainings, conferences and educational courses - Flexible working hours - Medical insurance in 30 medical centers - 50% payment of SkyEng English classes - 50% payment of Gold card AllSport (network of gyms, fitness, tennis courts, swimming pools, etc.) - Discount Card (discount card for various places: pubs, cafes, beauty salons, etc.) - The company will pay 50% of Mybook service (digital library).","SQL,Английский язык,PowerBI,QuickSight,Tableau,AWS,Английский — B2 — Средне-продвинутый",Аристек Системс,"Минск, Московская, Парк Челюскинцев, Площадь Якуба Коласа, Логойский тракт, 22а"
7265,76420732,Senior/Lead Data Scientist на продукт MTS Travel (Big Data),з/п не указана,более 6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior/Lead Data Scientist на продукт MTS Travel Описание продукта: MTS Travel - молодая дочерняя компания МТС, которая создает и развивает сервисы для путешественников по России и миру. Ее цель - стать №1 на рынке онлайн-бронирования отелей в РФ. MTS Big Data помогает сервису создавать и усиливать конкурентные преимущества через работу с большими данными. На данный момент команды поставили перед собой план по развитию проекта: 1) Собираем, обогащаем и подготавливаем данные из различных источников. 2) Строим рекомендательную систему, как для путешественников, так и для организаций предоставляющие услуги в путешествии. 3) Планируется устанавливать рейтинг отелям, рекомендовать цены, находить точки интереса вокруг отелей, предлагать альтернативные цены по текущему рынку, строить маршруты по достопримечательностям. 4) Проектирование системы аналитики для отелей Обязательно: коммерческий опыт работы в Data Science от 4-х лет умение вместе с продуктом сформировать Data-стратегию, ключевые задачи, и приоритизировать их знание A/B, Causal inference умение понять какие данные, в каком формате, в каком объеме понадобятся и сформировать задачу для DE на витрину / поток данных знание теоретической базы и опыт в построении RecSys, NBO-моделей практический опыт применения deep learning алгоритмов в NLP, CV направлениях (для подключения к R&D задачам) высокий уровень инженерной культуры работы с Git*(GitLab,GitHub, Bitbucket), работы с версионностью и стендами практический опыт вывода ML моделей в продакшн (нструменты AirFlow, MlFlow) Что предстоит делать? строить сильную команду, для решения амбициозных целей извлекать и обрабатывать массивы данных, а также автоматизировать эти процессы участвовать в разработке/проверке гипотез вместе с руководителем проекта и бизнес-заказчиком, интерпретировать результаты и оценивать качество разработанных моделей разрабатывать модели машинного обучения промышленного уровня вести техническую команду и ставить задачи дата-инженеру, дата-Science и дата-аналитику Стек технологий: Hadoop, Pyspark, Python, ML, Tableau, Jira, Confluence. Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","SQL,Python,A/B тесты,Математическая статистика,Аналитическое мышление,NLP,ML,RecSys",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
7268,78120333,"Data Scientist, Товарные рекомендации",з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Наша команда занимается персонализированным подбором контента для пользователей с целью повышения прибыльности компании. Наш сервис с runtime движком на Golang включает в себя онлайн ML: мы учитываем текущий товар, состояние корзины и другие факторы при ранжировании товаров. Data Scientist у нас – это сотрудник широкого профиля, занимающийся полным циклом вывода в production: от проверки идеи на Spark и Python до разработки новой части системы на Golang.  В отделе нет менеджеров, а решения принимаются на основе эмпирических данных. Члены команды закончили лучшие университеты и (или) имеют значительный опыт и знания, которые вы сможете перенять. Performance Review зависит от объективных измеримых критериев, следуя которым вы сможете профессионально расти предсказуемым образом. Наш стек: Python, Airflow, Golang, Hadoop stack (pySpark, yarn, hive, hdfs). Вам предстоит: Заниматься анализом данных на Python, Spark. Заниматься продуктовой аналитикой. Писать runtime движок на Golang. Мы ожидаем: Хорошее знание Python и Golang, или иметь желание быстро их изучить. Понимание алгоритмов ML. DL как плюс. Умение решать leetcode-medium. Наличие фундаментальной математической базы, знание алгоритмов. Знание и опыт работы на практике с большей частью нашего стека технологий. Мы предлагаем: Динамичный и быстроразвивающийся бизнес, ресурсы, возможность сделать вместе лучший продукт на рынке e-commerce. Свободу действий в принятии решений. Достойный уровень заработной платы. Профессиональную команду, которой мы гордимся. Возможность развиваться вместе с нашим бизнесом.","Python,pytorch,hadoop,data science,Разработка поисковых технологий,IT",Ozon нформационные технологии,"Москва, Деловой центр, Деловой центр, Международная, Пресненская набережная, 10"
7269,78692078,Data Scientist в команду Товарных Рекомендаций,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы ищем Data Scientist в команду Товарных рекомендаций для разработки рекомендательных алгоритмов. Результат вашей работы будет напрямую влиять на общую выручку компании. Вам предстоит: - Разрабатывать алгоритмы рекомендаций карточек товаров - Повышать релевантность рекомендаций для увеличения средней корзины пользователя - Взаимодействовать со смежными командами менеджеров, аналитиков и разработчиков. Мы ждем, что вы: - меете опыт работы в DS от 3-х лет - Работали с рекомендательными системами - Уверенно пишете на Python - Обладаете глубокими знаниями в ML и DL. Мы предлагаем: - Возможность создавать крутые продукты в крупнейшей компании - Гибридный или удаленный формат работы - Гибкое начало рабочего дня - Конкурентную заработную плату - спользование современного технологического стека - Гибкие бизнес-процессы, минимум бюрократии и согласований - Максимум возможностей для профессиональной самореализации.","Python,Pandas,NumPy,SkiPy,Scikit-learn,PostgreSQL,Greenplum,Clickhouse,Vertica,XGBoost,PyTorch",WILDBERRIES,
7271,78663781,Senior дата аналитик на продукт МТС Аналитика (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior дата аналитик на продукт МТС Аналитика Описание продукта: МТС Аналитика – это единая аналитическая платформа для анализа поведения пользователей в web и app приложениях экосистемы МТС. Наша цель – эффективная рекламная атрибуция, обогащенные Big Data полезные данные о когортах, кросс-продуктовый пользовательский путь и LTV пользователя и продукта, сдобренные собственным UI для визуализации метрик и командной работы. Обязательно: опыт работы в профессии от 3-х лет понимание работы веб-ресурсов: классические сайты, сайты с встроенными iframe, SPA понимание работы мобильных приложений знание Яндекс Метрики, AppMetica и Google Analytics на уровне сбора данных и логики формирования отчётов понимание работы Measurement Protocol опыт использования Python для выгрузки и обработки данных опыт применения SQL для решения задач аналитики: объединение данных разных таблиц, агрегирование данных, группировки, оконные функции опыт работы с аналитическими базами данных опыт работы с BI инструментами для визуализации данных (например, Tableau, Google Data Studio, Yandex DataLens или Superset) опыт решения задач маркетингового анализа с использованием различных моделей атрибуции понимание методологий разделения трафика по каналам для web и app ресурсов опыт выстраивания сквозной аналитики знание математической статистики Что предстоит делать? проводить анализ работы платформы проверять качество собираемых данных и оценивать потери формировать методологии обработки данных для расчета продуктовых метрик и передавать прототипы кода в команду разработки с сопровождением формировать прототипы отчетов интерфейса платформы участвовать в разработке моделей для оценки трафика (атрибуция, fingerprint и т.п.) работать с обратной связью от команд МТС после сдачи проекта в эксплуатацию Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16” MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","SQL,Python,Mathematical Statistics,Google Analytics,Google Tag Manager,Статистический анализ,Big Data,Математическая статистика,A/B тесты,WEB аналитика,Анализ данных",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
7272,77550414,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Основная задача департамента аналитики - делать бизнес эффективнее. Мы принимаем все продуктовые решения, опираясь на анализ данных, эксперименты и моделирование. щем Data Engineer, который станет частью команды DWH. Вам предстоит: Разрабатывать процесс ETL хранилища (на данный момент уже > 30тб данных) нтегрировать новые источники данных Организовать Data Quality и Data Governance Выстраивать CI/CD процессы Помогать аналитикам с архитектурой данных У нас вот такой стек: Clickhouse - для хранения данных и витрин аналитиков Kafka - для интеграций (+ Debezium в планах) Dagster + dbt Мы ожидаем, что Вы: Дата инженер, имеющий опыт работы с колоночными БД Знаете Python, работали с ETL-инструментами В совершенстве владеете SQL Понимаете отличия Data Vault и Anchor modeling Будет плюсом, если Вы: Ранее использовали Clickhouse, dbt, Airflow Условия: Оформление в соответствии с ТК РФ Гибридный или удалённый график работы и гибкое начало рабочего дня Достойный уровень компенсации, оклад + годовой бонус. Зарплату обсуждаем индивидуально с успешным кандидатом ДМС после испытательного срока (3 мес.) Корпоративная мобильная связь от МТС Работа в команде профессионалов, увлеченных своим делом и интересные задачи Современный и удобный офис с кухнями и зонами релакса, м. Тульская Скидки для сотрудников на фитнес, питание, на изучение английского языка, салоны- красоты Содействие в повышении компетенции и саморазвитии: тренинги, воркшопы, посещение профессиональных конференций Бесплатные подписки на продукты компании Корпоративная библиотека МФ (книги и вебинары) с даты трудоустройства Скидки от партнеров, скидки на страхование для членов семьи Кредитование по выгодной процентной ставке для участников зарплатного проекта от Банка Россия","ClickHouse,Python,Базы данных,DWH,Английский — A1 — Начальный",more.tv,
7274,78663746,Data Scientist / ML-инженер (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Мы ищем Data Scientist’ов и ML-инженеров в следующие продукты: Рекламная платформа RnD (Senior) В настоящий момент в команде основной фокус бизнес задач приходится на разработку маркетинговых продуктов – применение алгоритмов классификации, регрессии и рекомендательных систем для оптимизации медиа инвестиций. Перечень инициатив очень широкий – от задач стратегического планирования медиа бюджетов до оптимизации биддинговых стратегий в перформанс инструментах. МТС Travel (Senior/Lead) MTS Travel - молодая дочерняя компания МТС, которая создает и развивает сервисы для путешественников по России и миру. Ее цель - стать №1 на рынке онлайн-бронирования отелей в РФ. MTS Big Data помогает сервису создавать и усиливать конкурентные преимущества через работу с большими данными. Рекомендательная Платформа - Строки ( Senior) Команда занимается созданием персональных рекомендаций по жанрам для текстовых и аудио книг. В перспективе планируется сделать лучшие кросс-контентные рекомендательные модели, такие как подбор музыки по ходу прочтения книги, анализ текста книги, выделение облака тегов и эмоциональную окраску текста за счет добавления музыки, соответствующей настроению текста. Scoring Platform (Senior) Мы создаем скоринговую платформу, которая должна сократить и упростить путь от сбора данных до получения нашим клиентом вероятностной оценки в виде сервиса в личном кабинете. Маркетолог (Senior) Маркетолог - self service продукт. Маркетолог является самым крупным В2В продуктом по выручке в МТС. Мы занимаемся не только классическим вариантом телеком-рекламы, но также имеем собственный DCP, каналы, my target. Мы делаем модели, которые помогают клиентам сократить время и улучшить показатели. Обязательно: опыт работы от 2-х лет в области анализа данных и машинного обучения понимание, как работают ML-алгоритмы и не будете тратить время на эксперименты с заведомо плохими решениями понимание, когда нужно остановиться и использовать вместо ML более простые и быстрые подходы у вас продвинутые знания Python, в т.ч. основных ml-библиотек умение делать препроцессинг данных на SQL или PySpark умение работать с git есть базовые навыки работы в Linux/Unix знание минимум один из классических языков C, Java, Scala, C/C++/C# и есть опыт программирования в прошлом опыт вывода ml-решений в продакшн Что предстоит делать? выгружать и готовить/обрабатывать данные (находить аномалии и инсайты) перебирать гиперпараметры ml-моделей, пока кросс-валидация не даст нормальный результат :) дорабатывать ml-модели из стандартных библиотек проверять бизнес гипотезы в offline и готовить дизайн A/B тестов доводить модель до прода совместно с разработчиками Что вы найдете в команде Big Data? Стек технологий: работаем с данными на классическом hadoop-стеке (Spark, Hive) разрабатываем на python3: R&D делаем в Jupyter, продуктивизируем в PyCharm обучаем модели на отдельных мощных машинах с видеокартами Tesla V100 используем собственные разработки для скоринга больших данных и MLFlow для экспериментов храним код в gitlab, CI/CD в Jenkins, процессы запускаем в Airflow Команда: в команде Data Science сейчас 30 человек (во всей Big Data МТС более 300 человек). Все DS поделены на группы со своими лидами - есть группа рекомендательных систем, скоринга и другие. Каждую неделю мы обмениваемся опытом на совместных синках. DS работают в продуктах со своей автономной командой, в которой есть все роли: аналитики, DE, DS, разработчики, девопсы, менеджеры продукта. Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Python,Machine Learning,Data Science,Математическая статистика,Git",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
7275,78634572,Data Engineer,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Привет! Мы — Kokoc Group — группа компаний, объединяющая агентства и сервисы интернет-маркетинга. Все наши процессы (даже автоматизированные) разработаны и поддерживаются людьми. Поэтому мы считаем высшей ценностью компании комфорт и человеческое взаимодействие, а только потом — технологии.  У нас появилась потребность в усилении команды, поэтому мы открываем вакансию Data Engineer в агентстве Profitator.  Задачи: Написание скриптов для консолидация данных из различных источников, (Яндекс Метрика, Аналитикс, Яндекс Директ, Яндекс Видео, Яндекс Дзен, MyTarget, VK и др), ETL- процедуры. Оценка качества, очистка, обогащение, логический анализ и преобразование собранных исторических данных Поддержка имеющихся скриптов и процессов. Технологический стек: Python, Airflow, Docker-контейнеры, GitHub, БД СlickHouse, PostgreSQL, BigQuery, PowerBI Наши ожидания: Опыт Python (pandas, matplotlib, NumPy, Requests, psycopg2, re, httplib2, oauth2client, googleapiclient) от 2 лет Опыт работы с большим объёмом данных, продвинутый уровень владения SQL. Понимание специфики данных рекламных кабинетов и счетчиков (Google Analytics, Яндекс Метрика) Опыт разработки аналитической отчетности и сквозной аналитики от 2 лет Опыт стриминга сырых данных таких источников как Google Analytics, Яндекс Метрика, Яндекс Директ, VK, myTarget и др., CRM (битрикс-24 , АМО CRM, 1с, самописные CRM) и других внешних сервисов (Вордстат, br-analytics.ru, Симиларвеб) Опыт работы с BigQuery, БД PostgreSQL, СlickHouse, на сервере Ubuntu, организация и работа с Data Lake Английский на уровне чтения документации и API Умение работать в команде, слушать и задавать вопросы для уточнения постановки задачи у заказчика, саморазвитие и стрессоустойчивость. Будет плюсом: Знание основ эконометрики Опыт создание собственных дашбордов с визуализацией произвольных данных в MS Power BI. Предлагаем: Работу в крупнейшей группе компаний. Мы входим в топ-5 работодателей России в области маркетинга. В составе группы более 30 компаний и у нас уже более 800 сотрудников. Удобный формат работы. У нас есть офис в Москве на Цветном бульваре (можно посещать по желанию), также мы работаем удаленно в других городах. Конкурентную заработную плату. Готовы обсудить ваши ожидания и рассказать о нашем предложении. Здоровые взаимоотношения. Для нас важны честность и открытость, каждому из наших сотрудников предоставляется всесторонняя поддержка, возможность получения карьерных консультаций и индивидуальный план развития внутри компании. Дополнительные бонусы. Программа лояльности, корпоративный университет, участие в оплате внешнего обучения, скидки от партнеров, программа материальной помощи, карьерное консультирование.","Power BI,Python,PostgreSQL,SQL,Power Query,Google Analytics,Яндекс.Метрика",Kokoc Group,
7278,78721561,Data-инженер (DWH) / Разработчик SQL + Python,з/п не указана,1–3 года,"Полная занятость,полный день","Нам в Делимобиле нужен data engineer. В его качестве вам предстоит поддерживать и развивать систему, состоящую сейчас из batch-processing (DWH) на базе Vertica, real-time аналитики на основе MemSQL и пайплайнов с применением Kafka, Airflow, Python.  Чем предстоит заниматься: Проектирование логической и физической модели данных аналитических систем Обеспечение качества данных (своевременность, полнота, отсутствие ошибок, доступность документации, прозрачность потоков преобразования данных) нтеграция внутренних и внешних источников данных компании Построение внутренних инструментов data discoverу. Ждем от тебя: Знание современных архитектурных подходов DWH/Data Lake, Data Vault/Anchor Modeling, Lambda Architecture/Kappa Architecture Уверенная практика в MPP RDBMS (Vertica, Greenplum, Teradata, etc) Отличное владение Python 3, в том числе умение писать многопоточные приложения Экспертное знание SQL, предпочтительно Vertica-SQL Опыт работы с планировщиками/оркестраторами (Apache Airflow, Luigi, etc) Опыт работы с Kafka Опыт работы с NoSQL базами: MongoDB, Redis, Elasticsearch, etc. Будет плюсом: Опыт работы с технологиями стека Hadoop Опыт работы с CDC-системами (Debezium, GoldenGate, etc) Опыт работы с Docker, Kubernetes Опыт разработки в парадигме CI/CD Опыт работы с BI-инструментами (PowerBI, Tableau, QlikView, etc.) Что мы предлагаем: Работа в международном и развивающемся по всему миру сервисе Классная команда профессионалов, влюбленных в бизнес Скидки на каршеринг Обеды ДМС с первого дня Удалёнка или гибрид, гибкое начало рабочего дня","DWH,SQL,Python,Kafka,Vertica",Делимобиль,
7281,78754613,Data scientist (Центр валидации моделей розничного бизнеса),з/п не указана,1–3 года,"Полная занятость,полный день","Наша команда занимается оценкой и управлением модельного риска. Наши сотрудники участвуют в проектах по улучшению предиктивных моделей, моделей машинного обучения и оптимизации их применения в бизнес-процессах Сбера. Мы создаем инструменты для мониторинга, управления и снижения модельного риска по всем бизнес-направлениям. Чем интересна данная позиция? Участие в построении системы управления капиталом крупнейшего российского Банка Работа с самыми совершенными риск-моделями на российском рынке, влияющими на кредитные решения и величину капитала Банка нтересный опыт взаимодействия с множеством смежных подразделений Банка Продвинутый уровень Data Science (включая сложные неинтерпретируемые модели) Разработка автоматизированной системы мониторинга и платформенных сервисов валидации Множество задач по построению и совершенствованию бизнес-процессов (работа на стыке DS и менеджмента) Мы: Валидируем модели Сбера, способные значимо повлиять на финансовый результат, в том числе регуляторные модели, использующиеся для оценки капитала Банка и влияющие на общий Риск-аппетит Банка. Валидация – процесс всесторонней оценки разработанной статистической модели на предмет ее соответствия поставленным бизнес-требованиям и мировым практикам, качества используемого статистического алгоритма, а также потенциала улучшения модели. Модели стекаются к нам со всех уголков необъятного Сбера. Разрабатываем и автоматизируем методы для валидации моделей различных классов (в свете усложнения моделей Сбера особенно актуально) Строим систему отчетности для управления модельным риском Строим платформу для онлайн-мониторинга и автовалидации моделей Что будешь делать ты? Разбираться в структуре различных моделей DS, тестировать корректность модели, челленджить подход разработчика, разрабатывать альтернативные алгоритмы (внутренний Kaggle), оценивать применимость подхода с учетом имеющихся норм и макроэкономической конъюнктуры сследовать подходы к моделированию и валидации различных классов моделей, определять их методологию, применять передовые технологии и распространять наработки Автоматизировать алгоритмы валидации для внедрения в процессы автомониторинга Участвовать в практическом управлении моделями оценки капитала, разработке методологии их валидации и осуществлении их мониторинга Что мы ожидаем от кандидатов: Знание машинного обучения и статистического анализа (интересен любой опыт) Знание мат. статистики, алгоритмов, структур данных Знание Python и/или R и основных библиотек анализа данных Знание SQL, навыки работы с базами данных Опыт работы в рисках, знание основ управления рисками в Банке Коммуникабельность, умение эффективно вести переговорный процесс с подразделениями Банка Большой плюс: опыт работы с регуляторными моделями Basel Большой плюс: опыт модельной аналитики и управления модельным стэком в бизнес-процессе Чем мы отличаемся от других? Наша основная функция – валидация, но это включает в том числе и разработку альтернативных алгоритмов, ты научишься не только разрабатывать модели, но и тестировать их и смотреть на них с позиции владельца бизнес-процесса У нас можно познакомиться со всем многообразием моделей в экосистеме Сбера – работа не ограничивается рисковыми и регуляторными моделями Basel. В моделировании же, как правило, DS привязан к конкретной предметной области. У нас много работы не только в моделировании и валидации, но и в исследовательской деятельности по количественной оценке модельного риска Почему у нас интересно: Очень сильная команда (МГУ, МФТ, ВШЭ, РЭШ) Очень интересные задачи (на подумать, с *) на стыке ML, математики и бизнеса, fit-predict тут не пройдет, придется много узнавать, выяснять и думать Внушительный и разнообразный ландшафт моделей, много работы ""под капотом"" Возможность познакомиться с применением моделей в самых разнообразных бизнес-процессах, расширить «модельный кругозор» Условия работы: Работа с современным стеком технологий Возможность обучения за счет компании Регулярные DS-митапы, большое внутреннее DS сообщество Спортзал в офисе",,Сбер. Data Science,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
7282,78631857,Системный аналитик в Data Office,з/п не указана,1–3 года,"Полная занятость,полный день","Data Office появился пару лет назад. Наша команда: • строит хранилище данных для VK • запустила Data Portal как отдельный сервис для удобного взаимодействия с данными основные наши пользователи — маркетологи, менеджеры продуктов, аналитики, дата-сайентисты • провела десятки обучающих мероприятий для менеджеров и аналитиков • организовала сообщества DS/ML и Analytics и объединила дата-сайентистов и аналитиков всех продуктов VK • провела сотни продуктовых исследований.  Каждый день мы работаем с огромными объёмами данных (50 петабайт), используем современный стек технологий (Spark, Airflow, Presto, Vertica, ClickHouse) и разрабатываем современные дата-сервисы, которые помогают развиваться каждому продукту в компании.  Основные функциональные направления нашей работы: • Data Analytics, • Data Engineering, • Data Science, • Product and Service Development. щем специалиста, который поможет нам разрабатывать дата-сервисы. Вам предстоит: • собирать и анализировать требования к продукту, взаимодействовать с заказчиком • создавать ТЗ, ставить задачи разработчикам • вести проектную и пользовательскую документацию • разрабатывать форматы и описывать взаимодействия разрабатываемых и модифицируемых сервисов • сопровождать разработку • консультировать заинтересованных лиц по функциям и возможностям системы, а также по реализации требований • взаимодействовать с командами разработки и тестирования. У нас интересно, потому что: • мы анализируем данные, выдвигаем, разрабатываем и тестируем гипотезы по улучшению продуктовых метрик • вы сможете узнать, как устроены все продукты VK, поработать с их данными и реализовать с нуля новые проекты. Мы ожидаем, что вы: • работали системным аналитиком не менее 2 лет • занимались проектами с динамическим управлением — Agile, Scrum, Kanban • создавали ТЗ для разработчиков • разрабатывали функциональные требования, технические задания, проектную документацию • владеете базовыми знаниями протоколов передачи данных (HTTP, HTTPS, SOAP, бинарными протоколами) и форматами передачи данных (XML, JSON) • работали с базами данных и SQL • знакомы с клиент-серверной технологией • уверенно работаете в Jira и Confluence • описывали потоки данных и сценарии их обработки • умеете синхронизировать разрозненную информацию и приводить её к единообразию. Приглашаем специалиста, который сможет работать в комбинированном режиме в офисе в Москве или Санкт-Петербурге. Ждём ваших откликов. Удачи!","XML,HTTP,Atlassian Jira,MS SQL,Atlassian Confluence","VK, ВКонтакте",
7283,78576605,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","щем Data Scientist'а в региональный центр компетенций по аналитике для направления ценообразования. Обязанности построение моделей машинного обучения в области клиентской аналитики анализ характеристик пользовательского поведения при объёмах данных на уровне десятков миллионов наблюдений контроль и совершенствование применяемых технологий машинного обучения интеграция источников данных и моделей в бизнес-процессы Банка Требования знание математической статистики, теории вероятностей и желание развиваться в этом направлении знание принципов машинного обучения и желание развиваться в этом направлении опыт получения и обработки сырых данных умение анализировать большие объемы данных, видеть скрытые тенденции и закономерности и описывать их хорошее знание Python и пакетов для научных вычислений знание английского языка на уровне чтения профессиональной литературы Приветствуется: опыт участия в соревнованиях по машинному обучению хорошая алгоритмическая подготовка опыт разработки и внедрения информационных систем Условия структура дохода: оклад + годовой бонус обучение и возможность развиваться профессионально заботу о здоровье: ДМС с первого дня и бесплатный фитнес льготные ставки по потребительским кредитам и ипотеке «ДомКлик» бесплатная подписка СберПрайм+",,Сбер для экспертов,
7285,78042103,"Senior Data Scientist, Анализ текста (DS/NLP)",з/п не указана,3–6 лет,"Полная занятость,полный день","Мы — команда инженеров и датасаентистов в крупнейшем маркетплейсе с миллионами пользователей, хайлоадом и бигдатой. Нас знают все.  щем разработчиков в команду «Управления машинного интеллекта и исследований» WB.  Мы занимаемся повышением качества поисковой выдачи. Совершенствуем алгоритмы распознавания текстов, чтобы люди получали точные ответы даже на самые замысловатые запросы. Угадываем намерения наших пользователей с учетом опечаток и неточностей.  Чем предстоит заниматься: проводить А/Б-эксперименты, анализировать ранжирование и смотреть в данные оптимизировать поисковые алгоритмы с помощью ML и много экспериментировать. Мы ожидаем: знание Python (интерес к Go будет плюсом) знание алгоритмов и структур данных интерес к аналитике, ML и NLP (опыт с GPT — большой плюс). Предлагаем: сложные интересные задачи хорошую зарплату ДМС свободу в принятии решений профессиональный рост в команде увлеченных инженеров удаленку или офис минимум формализма и гибкий график ротацию между проектами (если захотелось чего-то нового). Аккредитация Минцифры: предоставляем все льготы для Т-специалистов.","NLP,ML,Data Analysis,Python,GPT",WILDBERRIES,
7288,78563803,Data аналитик (Виртуальные ассистенты),з/п не указана,3–6 лет,"Полная занятость,полный день","В стрим Виртуальные ассистенты, который создает систему управления персональными рекомендациями сотрудников, мы ищем Data аналитика.  Обязанности: Анализ исходных данных в системах-источниках Формирование гипотез и проверка на данных Разработка алгоритма расчета, автоматизация расчета Внедрение алгоритмов по оценке потерь/потенциала по метрикам в соответствии с логикой модели данных Написание процедур для расчета аналитических витрин на основе первичных данных Требования: Аналитические навыки: способность собирать данные, консолидировать, анализировать, формулировать, визуализировать, предлагать решения, основанные на data-driven подходе SQL, Python - обязательно. Hadoop - желательно. Опыт работы с большими объемами данных - обязательно Уверенные знания в области математики, теории вероятности, мат. статистики Развитые коммуникативные навыки: умение вести переговоры со смежными командами, умение отстаивать свою точку зрения, приводить доводы и обоснования Работа в команде по гибким методологиям Опыт самостоятельного ведения проектов от формирования гипотезы до подтверждения результатов","Python,SQL,Big Data,Data Analysis,Hadoop,Математический анализ,Математическая статистика,Теория вероятностей,Статистический анализ,Умение работать в условиях многозадачности,Работа в условиях многозадачности","ннотех, Группа компаний",
7289,78568157,Data Scientist (главный исследователь данных по КАСКО),з/п не указана,1–3 года,"Полная занятость,полный день","СТРАХОВОЙ ДОМ ВСК ПРГЛАШАЕТ В КОМАНДУ УПРАВЛЕНЯ ТАРФКАЦ  РСК-ТЕХНОЛОГЙ ГЛАВНОГО ССЛЕДОВАТЕЛЯ ДАННЫХ (DATA-SCIENTIST) ОБЯЗАННОСТ: Разработка ML - математических моделей предсказывающих сумму потенциального убытка по автострахованию КАСКО. Полный цикл построения математических моделей от подготовки данных до расчёта финансового результата и подготовки технического задания на внедрение. Подготовка аналитики по портфелю компании. Участие в различных проектах компании по широкому кругу задач блока андеррайтинга в рамках своей функциональной компетенции. ТРЕБОВАНЯ: Высшее образование (МГУ, МФТ, ВШЭ, МГТУ, МФ). Знание методов машинного обучения. Опыт обработки больших объемов данных. Знания SQL, Python (уровень не ниже middle), Statsmodels и библиотек для ML (CatBoost, GLM, Pandas). Опыт работы от 1 года в data science. Опыт работы в финансовом секторе (страховые компании, банки) будет дополнительным преимуществом для соискателей. Уверенные знания высшей математики, теории вероятностей и базовые знания статистики. Знания и навыки практического применения методов статистического анализа данных. УСЛОВЯ: Работа в крупной и стабильной компании. Официальное трудоустройство по ТК РФ. Корпоративное добровольное медицинское страхование (ДМС со стоматологией с первого дня работы в компании). Скидки на страховые продукты. Спорт, обучающие мероприятия. Заработная плата оклад + квартальная премия (обсуждается по телефону). Гибридный график работы 2/3 (офис + удаленный формат). Офис расположен: г. Москва, ул. Островная д.4 (рядом с офисом собственная, большая, бесплатная парковка). Корпоративный транспорт от ст. м. «Октябрьское поле» и «Кунцевская»","Python,Математическая статистика,SQL,Pandas,Статистический анализ,Машинное обучение,Data Science,MS SQL,Аналитическое мышление,Data Analysis,Математическое моделирование,Библиотеки: Statsmodels CatBoost GLM,СУБДД: MS SQL PostgreSQL Oracle,Apache Airflow,MLflow","ВСК, САО","Москва, Островная улица, 4"
7290,77472643,Middle/Senior Data Scientist (Operations),з/п не указана,3–6 лет,"Полная занятость,полный день","СберМаркет — технологический онлайн-сервис, помогающий делать покупки не выходя из дома. СберМаркет был создан на основе стартапа Instamart, присоединившегося к экосистеме Сбера в сентябре 2019 года. Наша миссия: экономить время, энергию и деньги людей для чего-то более важного. СберМаркет это: Один из лидеров рынка e-grocery в России Рост в 11 раз год к году Передовые технологии и собственная разработка Возможность задавать тренды в своей профессии и быть первопроходцем Классная команда и открытая корпоративная культура Быстрый рост и самостоятельное управление проектами Конкурентная зарплата и надежность. Мы хотим, чтобы клиент мог заказать продукты и товары с доставкой через нашу платформу из своих любимых магазинов, поэтому сотрудничаем уже с более 60 федеральными и региональными ретейлерами. Среди наших партнеров крупнейшие торговые сети: METRO, ЛЕНТА, АШАН, О'КЕЙ, Твой Дом и многие другие. Мы работаем на одном из самых крупных и динамичных потребительских рынков. СберМаркет-это дух, скорость и независимость стартапа, а так же сила и мощь крупнейшей в России экосистемы Сбера. Операции - сердце бизнеса. DS-команда операций работает на проектах, которые повышают операционную эффективность и помогают бизнесу стать прибыльным. Что предстоит делать: Стандартный ML (Гипотеза->Дизайн эксперимента->Построение модели->Анализ результатов->Гипотеза…) Катать модели в продакшн в виде микросервисов или задач по расписанию Строить аналитику и анализировать поведение моделей для новых инсайтов. Что ждем от тебя? Ты любишь погружаться в бизнес процессы и оптимизировать их с помощью математики Умеешь быстро делать MVP и тестировать гипотезы Слушал курс по методам оптимизации в университете и кайфанул с него Очень близок с классическим ML Умеешь писать код на Python эффективно (может отличить O(n) от O(n^2)) Хорошо владеешь SQL(можешь пояснить, чем OLAP от OLTP отличается) Наш стэк: Пишем в основном на Python, прототипируем в Jupyter, успешные эксперименты переносим на Airflow+Kubernetes Микросервисы разрабатываем на Python+GRPC, разворачиваем на собственной PaaS (Kubernetes,Gitlab CI,Helm, Prometheus) Аналитику, дашборды, мониторинги строим в Tableau, Metabase, Grafana Что мы предлагаем? Удаленный формат работы на территории РФ: Гибкое время начала дня Белая заработная плата Сильная команда коллег с kaggle grand и просто мастерами, выпускниками ШАДа Предоставляем всё необходимое оборудование для работы Развитие и рост (внешнее и внутреннее менторство, семинары, курсы, тренинги, внутреннее обучение) Поддержка участия в хакатонах - команда из опытных хакатонщиков, days off, сервера.","Python,Машинное обучение,Системное мышление,Аналитическое мышление,Умение принимать решения",СберМаркет,
7291,78631856,Системный аналитик в Data Office,з/п не указана,1–3 года,"Полная занятость,полный день","Data Office появился пару лет назад. Наша команда: • строит хранилище данных для VK • запустила Data Portal как отдельный сервис для удобного взаимодействия с данными основные наши пользователи — маркетологи, менеджеры продуктов, аналитики, дата-сайентисты • провела десятки обучающих мероприятий для менеджеров и аналитиков • организовала сообщества DS/ML и Analytics и объединила дата-сайентистов и аналитиков всех продуктов VK • провела сотни продуктовых исследований.  Каждый день мы работаем с огромными объёмами данных (50 петабайт), используем современный стек технологий (Spark, Airflow, Presto, Vertica, ClickHouse) и разрабатываем современные дата-сервисы, которые помогают развиваться каждому продукту в компании.  Основные функциональные направления нашей работы: • Data Analytics, • Data Engineering, • Data Science, • Product and Service Development. щем специалиста, который поможет нам разрабатывать дата-сервисы. Вам предстоит: • собирать и анализировать требования к продукту, взаимодействовать с заказчиком • создавать ТЗ, ставить задачи разработчикам • вести проектную и пользовательскую документацию • разрабатывать форматы и описывать взаимодействия разрабатываемых и модифицируемых сервисов • сопровождать разработку • консультировать заинтересованных лиц по функциям и возможностям системы, а также по реализации требований • взаимодействовать с командами разработки и тестирования. У нас интересно, потому что: • мы анализируем данные, выдвигаем, разрабатываем и тестируем гипотезы по улучшению продуктовых метрик • вы сможете узнать, как устроены все продукты VK, поработать с их данными и реализовать с нуля новые проекты. Мы ожидаем, что вы: • работали системным аналитиком не менее 2 лет • занимались проектами с динамическим управлением — Agile, Scrum, Kanban • создавали ТЗ для разработчиков • разрабатывали функциональные требования, технические задания, проектную документацию • владеете базовыми знаниями протоколов передачи данных (HTTP, HTTPS, SOAP, бинарными протоколами) и форматами передачи данных (XML, JSON) • работали с базами данных и SQL • знакомы с клиент-серверной технологией • уверенно работаете в Jira и Confluence • описывали потоки данных и сценарии их обработки • умеете синхронизировать разрозненную информацию и приводить её к единообразию. Приглашаем специалиста, который сможет работать в комбинированном режиме в офисе в Москве или Санкт-Петербурге. Ждём ваших откликов. Удачи!","XML,HTTP,Atlassian Jira,MS SQL,Atlassian Confluence","VK, ВКонтакте",
7296,78524374,Data Engineer в команду Retail Data,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы ищем Data Engineer'а, который станет частью Retail Data Team. Наша команда строит систему аналитики вокруг бизнес-модели, помогая эффективнее управлять стратегией. Наши ключевые фокусы: создание системы сквозных метрик команд ритейла Е2Е-сервис разработки аналитических продуктов: загрузка данных, проектирование витрин и создание дашбордов миграция на целевые инструменты (Greenplum, Zeppelin, Superset/PBI) ежедневные дашборды с ключевыми метриками кросс-продуктовые, клиентские исследования развитие сообщества аналитиков данных. Основные направления будущей работы: Витрины данных — проектирование, развитие и поддержка (Data Lake на Hadoop): -подключение к Data Lake новых источников данных -создание витрин данных по бизнес-домену Retail -настройка регламентной загрузки данных в витрины. Внешние интеграции: -настройка процессов передачи данных из Data Lake в другие системы-потребители -поддержка регламентных процессов. Работа над созданием аналитического ХД на базе MPP GreenPlum: -участие в проектировании аналитического ХД (Core, витрины) -реализация процессов загрузки и трансформации данных (Core, витрины). Развитие экосистемы Data Lake: -участие в проектировании инструментов, облегчающих работу других продуктовых команд с Data Lake -помощь платформенной команде в развитии Data Lake (автоматизация работы с метаданными, пилотирование нового функционала и т. Д.). Наша вакансия подразумевает получение и применение уникального опыта в части построения ETL-пайплайнов на основе Open-Source технологий (Spark, Hadoop, NiFi, Airflow, Kafka, GreenPlum). Наши ожидания: владение SQL на уровне написания сложных запросов: знание, что такое оконные функции, функции ранжирования, CTE не менее 2-3 лет опыта работы в области создания/обогащения витрин данных знакомство с различными типами СУБД (SQL, NoSQL) и профилями их использования (OLAP, OLTP) и способность аргументированно выбрать оптимальный тип СУБД под задачу опыт работы с Airflow или любым другим оркестратором умение писать код на Python и пользоваться GIT, знание, что такое Unit-тесты использование Hadoop знание, как работает YARN, как эффективно хранить данные на HDFS опыт написания запросов в Hive способность писать прозрачный читающийся код, разделять его на классы, применять паттерны. Будет плюсом: умение писать код на Spark и считать данные сервиса, используя его API, отсортировать, отфильтровать их и сохранить результат на HDFS опыт работы с Kafka или другим Message Broker'ом, знание основных концепций потоковой обработки данных опыт работы с инструментом DBT (Data Build Tool) знание банковской предметной области (особенно в части Retail) опыт разработки/внедрения систем класса DWH знание CI/CD практик и инструментов возможность продемонстрировать один из своих проектов на GitHub. Мы предлагаем: среду для самореализации, профессионального роста и плодотворной работы гибкий график, возможность удаленной работы культуру гибкого мышления, высокий уровень свободы и ответственности командную работу и поддержку регулярное посещение тренингов, митапов и конференций (в том числе как спикер) за наш счет отличный социальный пакет (ДМС со стоматологией, скидки на корпоративные продукты) отсутствие формализма и позитивный настрой.",,Райффайзен Банк,
7298,78567035,Middle Дата Аналитик в продукт МТС Маркетолог (Big Data),з/п не указана,1–3 года,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Дата Аналитика на продукт МТС Маркетолог Описание продукта: Продукт МТС Маркетолог помогает внешним и внутренним клиентам запускать таргетированные рекламные кампании на основе данных Big Data МТС. Мы формируем гипотезы, проводим AB тесты, ищем новые и необычные сегменты для клиентов, проводим Post аналитику рекламных кампаний, постоянно подключаем новые источники данных и работаем с ними. Обязательно: знание SQL на уверенном уровне (join, group by, CTE, window function, date/time functions) опыт работы на позиции аналитика данных от 1,5-2 лет умение работать в команде и общаться с заказчиком знание основ математической статистики ВУЗ – математика, информатика, маркетинг Что предстоит делать? собирать и валидировать данные сегментировать базу создавать прототипы витрин проводить A/B тестирование генерировать гипотезы и заниматься их проверкой работать с внутренними клиентами экосистемы МТС Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16” MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта",,МТС,"Москва, Технопарк, проспект Андропова, 18к9"
7304,78413803,Менеджер по анализу больших данных (Big data),з/п не указана,1–3 года,"Полная занятость,полный день","Кого мы ищем: В нашу дружную команду BDO мы ищем человека с живым умом и непреодолимым желанием приносить пользу. Если тебе нравится собирать и анализировать информацию, находить зависимости, придумывать улучшения и добиваться результата – у нас все это есть! Что мы предлагаем: Выдвигать и проверять гипотезы, внедрять улучшения, оценивать их эффективность Систематизировать и анализировать полученную информацию Много работы и поле для свершений Работать с командой амбициозных и увлеченных людей Работать в компании, где тебя слышат и ценят твой вклад На практике это значит, что ты будешь решать следующие задачи: Поддержка ключевых направлений: антифрод, качество продаж, гео-отчётность сегментация абонентской базы, исследование пользовательского поведения Оптимизация регулярных процессов: развитие существующих метрик, описание и формирование новых Операционная поддержка бизнес-заказчиков: решение их запросов, развитие успешных кейсов Монетизация внутренних и внешних проектов: разработка методологии, описание, реализация алгоритмов, составление технического задания на автоматизацию Описание требований для привлечения новых продуктивных источников данных, сопровождение процесса внедрения и приёмки Автоматизация проектов под задачи других команд Что для нас важно в тебе: Опыт работы с большими объёмами неструктурированных данных Отличное знание SQL Опыт работы в практических проектах по обработке больших данных в роли Data Science / Data Engineer / Data Analyst Владение Python / R Отличные знания пакета MS Office Не обязательно, но будет очень здорово, если ты: Опыт в телекоме и/или банковской сфере Владение инструментами из стека Hadoop: понимание разницы между Hive и Impala использование в работе Spark / PySpark / Scala Опыт ETL и организации обработки больших потоков данных Практический опыт в data mining, text mining, machine learning Опыт работы с web-crawling и технологиями индексации Опыт разработки БФТ, внедрения продуктов Что есть у нас и чем готовы делиться: Полное соответствие ТК РФ ндексируемая белая заработная плата, годовые бонусы Дополнительное медицинское страхование Компенсация затрат на мобильную связь Дополнительные материальные выплаты (пособия при рождении ребёнка, вступлении в брак и т. п.) Компенсация занятий спортом через год работы Скидки от партнёров Релокационный пакет при переезде из другого города Возможность удалённой работы Бесплатное прохождение курсов на одной из основных обучающих онлайн платформ нтересная работа в стабильной компании Возможности профессионального и карьерного роста Уникальная возможность работы с большим разнообразием аналитических задач Витаминно-фруктовой заряд по вторникам Зеленый свет для новых идей и предложений: мы часто делаем то, на что другие не отваживаются Современный офис класса «А» с развитой инфраструктурой (магазины, кафе, фитнес и т. д.) в пяти минутах пешком от метро Румянцево Так как офис очень просторный, есть возможность доехать до коллег на самокате","Python,Data Mining,SQL,Бизнес-анализ,MS SQL,Hadoop,Teradata,DWH,ORACLE,R,Sas",Tele2,"Новомосковский административный округ, Румянцево, Киевское шоссе, 22-й километр, 6с1"
7305,78407364,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Команда аналитического управления Центра комплаенс в поиске Главного аналитика Обязанности сследование новых источников данных, формирование новых признаков, проведение их оценки на значимость и стабильность во времени Сбор выборки для обучения и валидации моделей Проверка различных моделей для решения задачи (классификация, регрессия, выявление аномалий), выбор лучшей модели Формирование требования к витринам для команды инженеров Участие в пилотировании моделей, интерпретация полученных результатов Анализ результатов мониторинга работы моделей на Проме Требования Профильное высшее образование DS Хорошее знание теории вероятностей и статистики, умение проверять гипотезы на стат. значимость Знание Python и основных библиотек (numpy, pandas, scipy, sklearn) Умение производить отбор признаков различными методами Уверенное владение популярными алгоритмами машинного обучения и специализированными библиотеками (LightGBM, CatBoost и др.) Знание SQL Будет плюсом: Умение работать с Git, PySpark, Airflow Опыт применения DL моделей, понимание одного из популярных фреймворков PyTorch/Tensorflow/Keras Опыт построения моделей на графовых данных (задачи link prediction, anomaly detection) Базовое понимание архитектуры Transformers, опыт применения в NLP Успешное участие в соревнованиях или хакатонах Условия интересные задачи и работа в команде профессионалов социальные гарантии и стабильность (трудоустройство по ТК РФ ДМС, страхование от несчастных случаев и тяжелых заболеваний программы материальной помощи и социальной поддержки, корпоративная пенсионная программа льготные условия кредитования, скидки от компаний-партнёров) комфортные условия работы - Офис, пр-кт Старо-Петергофский, 30 к1 литер А достойная заработная плата (оклад + квартальные и годовые премии) возможности для развития (регулярное корпоративное обучение, возможность профессиональной сертификации, перспективы для развития карьеры) насыщенная корпоративная жизнь (социальные инициативы, волонтерство, спортивные, творческие мероприятия и поддержка в реализации новых бизнес-идей).",,Сбер для экспертов,
7306,77527309,Главный администратор данных (Chief Data Steward),з/п не указана,3–6 лет,"Полная занятость,полный день","МТС – это мультисервисная цифровая экосистема. Мы создаем и развиваем сервисы в сфере мобильной связи, больших данных, искусственного интеллекта, облачного хранения, медиа и финансов – все они делают жизнь людей проще и интереснее. Приглашаем в команду Главного администратора данных (Chief Data Steward), который будет заниматься внедрением лучших практик эффективного использования данных и помогать продуктовым командам при реализации практик в вертикалях бизнеса МТС (телеком, финтех, retail, IoT, AI).  Чем предстоит заниматься Внедрение практик Администрирования данных в одной из вертикалей бизнеса МТС Формирование и управление иерархией Администраторов данных (data stewards) Анализ текущих процессов управления данными в продуктовых командах Постановка задач Администраторам данных и контроль выполнения Внедрение процесса контроля качества данных и управления Data Quality инцидентами Внедрение процесса описания данных и управления метаданными (Каталог данных, Бизнес-Глоссарий) Внедрение процесса работы с нормативно-справочной информацией Внедрение процесса маппинга данных продуктовых команд на корпоративную модель данных Участие в разработке и внедрении методологии, процессов и процедур Data Governance Участие в разработке инструментов Data Governance в качестве заказчика для команд разработки и поддержки решений Распространение в Компании культуры работы с данными  Что мы хотим видеть в вас Высшее образование Т/экономическое/менеджмент Опыт работы в области Data Governance и/или аналитике данных Опыт управленческой работы Опыт работы с Каталогом данных (Data Catalog), бизнес-глоссарием (Business Glossary) Опыт работы с процессами и инструментами обеспечения качества данных Понимание жизненного цикла данных Понимание происхождения данных (data lineage) Понимание моделей данных Знание практик DMBOK DAMA Знание подходов к обработке и хранению данных в организациях (Data Lake, Data Mesh)  Мы предлагаем: Стабильную заработную плату и премии Удобный формат работы - офис или гибридный (удаленно + периодические приезды в офис) ДМС со стоматологией, страхование жизни, страхование при поездках за рубеж Корпоративная мобильная связь и интернет Саморазвитие - обучение в Корпоративном университете, у внешних провайдеров, а также доступ к онлайн-библиотеке Спорт - компенсация расходов на спорт, корпоративные соревнования по футболу, баскетболу и волейболу и различные спорт-программы Хороший отдых - отпуск 28 календарных дней + 3 календарных дня дополнительно ежегодно нтересные и сложные проекты, возможность участвовать в становлении и развитии направлений экосистемы","Data Catalog,Business Glossary,Data steward,DAMA,Метаданные,Качество данных,Каталог данных,Data quality,Управление данными,Data Governance",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
7307,78043382,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","О проекте: В продуктовой команде Квант в рамках Газпром-Медиа Холдинга открыта новая позиция Data Scientist на активно растущее направления Adtech-продукта DSP Getintent. В портфеле компании множество data, martech и аналитических продуктов, в числе которых: DSP, CDP, комплекс решений для DOOH, обогащение CRM, O2O, аналитика и другие продукты. Наш стек технологий: Python, Java, Hadoop MR, Spark, Airflow, SQL (PostgreSQL, Clickhouse), NSQL (Aerospike). Все проекты работают на Linux, поэтому нужно иметь базовые представления о Linux, уметь пользоваться командной строкой и писать простые скрипты на bsh. Вам предстоит заниматься: Созданием и оптимизацией рекомендательной системы рекламы спользованием моделей для улучшения торговых стратегий Анализом работы предикторов в рекламных кампаниях нтеграцией построенных моделей в проект Работой с данными высоконагруженных сервисов (порядка 100 млн. событий в день) Автоматизацией процессов анализа Улучшением существующей микросервисной архитектуры системы процессинга данных Вы нам подходите, если есть: Отличное знание Python Знание математической анализа, алгоритмов, структур данных и теории вероятности Знание классических алгоритмов машинного обучения Знание основных библиотеки машинного обучения: xgboost, catboost, scipy, pandas и т.п. Знание методов обработки категориальных признаков меете опыт проведения A/B- тестов и анализа их результатов меете опыт работы с Hadoop, Spark, SQL, Airflow Опыт работы с Java будет преимуществом Мы предлагаем: Официальное трудоустройство, полностью белая заработная плата без задержек ДМС (включая стоматологию и госпитализацию) сразу после испытательного срока, возможность страхования членов семьи Доплаты по больничному листу Удаленная работа с возможностью выхода в офис по желанию Корпоративные программы кредитования и страхования Скидки на спорт, кино, языковые курсы",,ГПМ Партнер,"Москва, Киевская, улица Раевского, 4с1А"
7308,78587217,ECommerce Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Accountabilities: Own development of ETL data pipelines, taking responsibility for designing, data modelling, coding, testing, scalability, operability, and ongoing metrics. Collaborate with product manager, business stakeholders, BI engineers, data analysts, data scientists, IT to deliver sustainable and quality results Partner with Sector team to leverage global solutions and best practices Build tools and libraries that reduce new pipeline development time Create metrics to measure the quality and validity of 2nd and 3rd party vendor data Research existing solutions internally and externally to identify gaps between business needs and offerings Research and document data abnormalities and track them as bugs with the engineering teams responsible Key Skills/Experience Required : Bachelor’s Degree (Computer Science or related preferred) 2+ years of professional experience using Python or similar programming language Knowledge of engineering best practices for the full software development life cycle, including coding standards, code reviews, source control management, continuous integrations, testing, and operations RDBMS databases and SQL language Microsoft Azure stack, AWS and GCP is a plus Nice to have: Knowledge of Web Scraping, Airflow, Kubernetes and Docker","azure,SQL,Airflow,Kubernetes,Docker,RDBMS,Python,data engineer,eComm,Databases,Английский — B2 — Средне-продвинутый",PepsiCo,"Москва, Сокол, Ленинградский проспект, 72к4"
7311,78381741,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Контур — экосистема для бизнеса. Каждая четвертая компания в стране решает бизнес-задачи, используя наши сервисы. Мы автоматизируем документооборот, бухгалтерию и отчетность. Делаем эти процессы простыми и быстрыми, а сервисы — удобными для клиента.  Data Science в Контуре помогает оптимизировать внутренние процессы и добавляет ценности в продукты. Например, чат-бот Сирена экономит около 25% времени консультантов техподдержки в чатах, а технология распознавания речи обрабатывает тысячи лет записей в год. Мы постоянно следим за прогрессом в технологиях и разрабатываем новые методы и алгоритмы, чтобы сделать инновации доступными для использования в продуктах и процессах компании. В Центре искусственного интеллекта представлены разные роли: есть дата сайентисты, разработчики и аналитики данных, девопсы, QA-специалисты, системные аналитики, проджекты и продакт-менеджеры. Свое железо (V100/A100) и асессорская служба позволяют нам не ограничивать себя при работе с чувствительными данными, а также крутая инфраструктурная команда создает, улучшает и развивает инструменты MLOps на любой вкус от ресерча до прода. Мы ищем Senior Data Scientist в направление оптимизации процессов продаж и маркетинга. Нам нужен человек, который разовьет направление продаж и маркетинга с точки зрения машинного обучения: составит дорожную карту применения Data Science в процессах продаж согласует с бизнесом и приоритизирует сам проверит и доведет до продакшена гипотезы, и, как результат, повысит эффективность продаж и маркетинга. Примеры задач, которые уже решали Речевая аналитика (после ASR): оценка эффективности работы менеджеров по продажам на основании анализа текста звонков. Работа с конверсией: оценка вероятности оплаты клиентом счета по сделке по набору параметров. Что ожидаем от вас Опыт работы в аналогичной роли от двух лет. Опыт решения задач и понимание работы алгоритмов NLP и Classic ML. Умение общаться на языке заказчика, погружаться в продуктовый контекст. Умение работать в команде. Опыт декомпозиции, приоритизации больших задач. Опыт доведения задач до продакшена. Желательно иметь опыт доведения задачи от формулировки на языке бизнеса до прода (от начала до конца) работы с высокой неопределенностью: прокапывание проблематики, осознанный выбор решения. Технологии Python, SQL. GitLab. Docker, Kubernetes, AirFlow. Classic ML, языковые модели (BERT etc.). Мы предлагаем Зарплата зависит от ваших технических знаний и навыков. Пересматриваем ее два раза в год. Нам важно, чтобы вам было комфортно: непринципиально, где вы находитесь и во сколько начинаете рабочий день, главное – выполненные задачи. Умеем работать в команде, находясь в разных точках мира (Таллин, Ташкент, Астана, Лимассол, Екатеринбург, Москва и т. д.). Мы поддерживаем участие в конференциях, митапах и обучающих проектах. Наши деврелы помогут написать статью на Хабр, снять видео или подготовиться к выступлению на конференции. У нас сильное инженерное сообщество: регулярно проводим техническую конференцию КонфУР, обмениваемся опытом между командами, проводим дизайн-ревью с экспертами в разных технологиях. Всегда найдется, с кем посоветоваться. А еще у нас есть инженерный совет. Он придумывает и реализует проекты, которые улучшают жизнь инженеров в компании. Максимум горизонтальных связей в коллективе, чтобы быстрее договариваться и решать рабочие задачи. Присоединяйтесь :)","NLP,Machine Learning,Python,Data Science",Контур,
7326,78102402,"Менеджер по развитию бизнеса / BDM (BI,Data Governance, Data Quality, Big Data,Machine Learning)",з/п не указана,3–6 лет,"Полная занятость,полный день","КОРУС Консалтинг – российская Т-компания, признанный лидер в автоматизации ритейла, производства, логистики, финансов и нефтегаза. Мы входим в топ-5 крупнейших IT компаний Петербурга. Нас более 1000 человек, а за плечами более 20 лет опыта. За это время мы сделали более 1200 масштабных проектов для ведущих компаний России, а именно: Bonava, DPD, Nokian Tyres, Tele2, Азбука Вкуса, Газпром нефть, Дикси, нвитро, Леруа Мерлен, Магнит, Мегафон, О’КЕЙ, Петрович, Росатом, Яндекс.Деньги и это только начало списка. Мы любим данные. Мы поняли это более десяти лет назад, когда в составе группы компаний «КОРУС Консалтинг» ещё не было отдельного департамента аналитических решений и понятие «бизнес-аналитика» ещё не было так популярно. Наш Департамент аналитических решений (ДАР) погружен во все современные направления в области работы с данными: внедрение BI-систем и систем аналитической отчетности проектирование хранилищ и витрин данных разработка в области продвинутой аналитики и больших данных применение прикладных продуктов с использованием Machine Learning внедрение решений в области управлениям данными (Data Governance, Data Quality ...) разработка методологии и стратегии работы с данными. Сейчас нам требуется усиление - ищем коллегу на должность Менеджера по развитию бизнеса / BDM. Задачи, которые предстоит решать: Обеспечение выполнения квартальных, годовых и др. планов по продажам, достижение запланированной рентабельности Развитие отношений с выделенным пулом клиентов Поиск и формирование потребностей в клиентах по всем направлениям департамента Подготовка и оформление коммерческих предложений для клиентов, переговоры Оформление и согласование договоров с клиентами и внутри компании Выполнение аналитики продаж (формирование и анализ воронки продаж по ключевым клиентам) Управление процессом пре-сейла в рамках продажи Успешное ведение и закрытие сделок. Что поможет в работе: ""Погружение"" в бизнес заказчика, готовность ориентироваться в его проблемах и решать их Для нас важен опыт работы в IT на стороне исполнителя Проактивный подход к работе, самостоятельный поиск новых возможностей и вариантов продвижения нашего бизнеса Подтвержденный успешный опыт развития бизнеса и управления продажами в сегменте В2В на аналогичной должности. Наше предложение: Официальное оформление в штат компании Заработная плата обсуждается по итогам тех. собеседования. Знаем рынок, готовы обсуждать индивидуально Гибкое начало рабочего дня, возможность посещения офиса для коллег из Москвы, Санкт-Петербурга и Ярославля. Полная удалёнка для коллег из остальных городов России Открытая корпоративная культура, корпоративный волейбол, футбол и беговой клуб, участие в экологических программах, регулярные тимбилдинги Минимум бюрократии и отчётов, а совещания только по необходимости и с чёткой программой Корпоративный университет, менторство и развитие Полис ДМС, корпоративные тарифы на фитнес и занятия английским на ведущих платформах. Будем рады обсудить сотрудничество!","B2B Продажи,Ведение переговоров,Управление проектами,Анализ данных,Подготовка коммерческих предложений,Развитие продаж,Аналитическое мышление,Управление отношениями с клиентами,Ориентация на результат,Работа с ключевыми клиентами,Бизнес-анализ,Power BI,Big Data",КОРУС Консалтинг,
7327,76934636,Senior Finance Data Analyst Народного банка Узбекистана,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Создание структуры данных для BI-tool, разработка дэшбордов Анализ бизнес-процессов и технических потоков данных для выявления проблем с качеством данных, а также потенциальных рисков возникновения таких проблем Разработка аналитических расчетов на SQL / Python Разработка решений «легкой автоматизации» (RPA, макросы, OLAP-кубы и другие инструменты) Участие в стратегическом проекте по развитию аналитического DWH Актуализация моделей данных для поддержания дэшбордов и аналитических расчетов в актуальном состоянии Участие в разработке и автоматизация предиктивных и статистических моделей Требования: Основное образование - Техническое / Математическое / Финансовое Дополнительное образование - Аналитик данных Сфера: аналитик данных, написание SQL-запросов и создание структуры данных для BI-tool Профессиональные компетенции: знание SQL на продвинутом уровне и опыт оптимизации запросов знание Python и опыт работы с BI-tool (Tableau, Power BI, ORACLE BI) понимание основных принципов разработки хранилищ данных опыт работы в сфере управления данными/качества данных, понимание основных характеристик качества данных и типовых причин проблем с качеством данных Личностные компетенции: Навыки профессионального общения Умение самостоятельно находить пути решения, аккуратно и быстро выполнять задачи, планировать своё и чужое время Помощь в оптимизации наших бизнес-процессов – от улучшения качества данных до автоматизации бизнес-операций Умение работать в команде Знание языков (укажите уровень владения): узбекский - Хорошо или свободно русский - Хорошо или свободно английский - Не ниже upper-intermediate Знание компьютерных программ: Excel, Power BI, SQL, Python, будет преимуществом опыт работы с BI-tool (Tableau, Power BI, ORACLE BI) Опыт с ML моделями – как преимущество Дополнительные требования базовые знания о банковских продуктах и основных процессах Условия: Комфортное рабочее место Корпоративное обучение Бесценный опыт трансформации Возможность карьерного развития 24 дня оплачиваемого отпуска","Python,SQL,Английский язык,Tableau,MS PowerPoint",Xalq Banki,
7329,78149780,Data engineer (направление предиктивной аналитики),з/п не указана,1–3 года,"Полная занятость,полный день","Отдел занимается созданием продуктов и реализацией проектов в области предиктивной аналитики. То есть фактически прогнозирует целевые события или действия пользователей и, таким образом, помогает внутренним и внешним заказчикам принимать решения. На основе анализа огромных объемов данных из различных источников строятся модели машинного обучения и аналитические сервисы, способные оценить, например, вероятность того, заинтересуют ли пользователя предложение покупки авто в кредит или, возможно, новые тарифы мобильного оператора. Задачи: создавать новые надежные и улучшать существующие пайланы, обрабатывающие терабайты данных разрабатывать новые витрины данных для аналитики и построения предиктивных моделей на основе многопетабайтного хранилища и множества источников интегрировать данные из новых источников с продакшен-системами, решающими задачи near real-time обработки данных, и ML-сервисами. Мы ожидаем от кандидата: понимание SQL, умение составить нетривиальный запрос (JOIN'ы, подзапросы и т.д.) написание читабельного кода на Python (уметь в 3-версию, не бояться) навыки работы с bash, git, linux, docker — опыт работы с экосистемой Hadoop: HDFS, Spark, Hive знания о работе ОС, базовых алгоритмах и структурах данных.","Python,Hadoop,data engineering","VK, ВКонтакте",
7335,78643248,Data Analyst,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Медиапоинт - digital-платформа игровой тематики. Мы работаем не только на территории России, но и на международном рынке. В настоящий момент мы расширяем бизнес, в связи с чем ищем Аналитика данных. Обязанности: Разработка моделей данных для решения аналитических задач Автоматизация регулярных процессов и отчетности Разработка гипотез по улучшению ключевых метрик и оптимизация конверсии на основании полученных данных Подготовка различных аналитических отчетов и обзоров по запросам бизнеса сследование большого объема необработанных данных, накопленных в бизнес-юните, работа с потребителями этих данных Тестирование систем и данных, расследование инцидентов в качестве данных, формирование требований к качеству данных. Требования: Опыт работы аналитиком данных от 1 года Аналитические навыки (умение анализировать и структурировать данные, умение делать выводы, выдвигать и проверять гипотезы) Python для анализа данных Продвинутое владение Excel (разработка дашбордов и моделей) Продвинутое владение SQL (мы работаем с Clickhouse, PostgreSQL, MySQL) Опыт работы в BI-системах приветствуется нтерес к таким сферам как betting, gambling, crypto. Условия: Полностью удаленная позиция или гибридный формат работы Гибкий график работы (пн-пт с 9/11 до 18/20) Позиция в международной компании с многолетним опытом работы в игровой сфере Дружный и амбициозный интернациональный коллектив Уровень заработной платы обсуждается на финальных этапах собеседования.",,Медиапоинт,
7340,77957886,Data Scientist (Разработчик AI/ML),з/п не указана,1–3 года,"Полная занятость,полный день","Мы аккредитованная Т компания! Наши сотрудники получают всё необходимые подтверждающие документы для военкоматов! Рассматриваем кандидатов разного уровня компетенций - Junior - Middle - Lead Обязанности: Выполнение функций Data Scientist-а при реализации проектов по предиктивной аналитике на промышленных предприятиях: Анализ производственных процессов и выработка требований к сбору данных Сбор, преобразование, очистка данных. Разработка и стандартизация ML-пайплайнов Конструирование признаков для ML-моделей (feature engineering) Выбор и обоснование моделей машинного обучения для решения бизнес-задач. Выбор и обоснование метрик для оценки моделей машинного обучения. нтерпретация результатов функционирования моделей машинного обучения. Поддержка и контроль метрик моделей в prod, консультирование пользователей по работе ML-моделей. Участие в разработке концепции и программы консультирования ключевых пользователей. Проведение обучения пользователей создаваемых систем предиктивного анализа. Полный цикл DS моделирования. Встраивание модели в Tibbo. Сбор требований и формирование разделов технических заданий систем предиктивного анализа.. Требования: опыт работы в должности Data Scientist или аналитик данных знание основных библиотек и фреймворков машинного обучения (sklearn, scipy, numpy, pyspark…), сертификаты о профессиональной подготовке в ML/DL знание Python, Jupyter notebook, PySpark, TensorFlow, PyTorch, Linux, bash Опыт работы по проектной деятельности Опыт участия в проектах по внедрению моделей машинного обучения в production Опыт разработки проектной документации: отчет по НР и разделов проектной документации по предиктивному анализу Личностные качества : самостоятельный поиск информации, ответственность за результат, умение планировать свою работу Условия: - Заработная плата по итогам собеседования - График работы с 8:00-17:00, пт до 15:45, возможен гибридный график - Офис м. Нагатинская - спытательный срок 3 месяца - ДМС (после испытательного срока) - Оформление по ТК РФ - Дружелюбный и профессиональный коллектив",,Промышленные инновации,"Москва, Нагатинская, 1-й Нагатинский проезд, 10"
7341,78717618,Data analyst,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","KIVORK- международная продуктовая компания в сфере IT. Вместе мы разрабатываем и управляем нашими собственными продуктами в области путешествий и транспорта. Наиболее важными проектами, которые сделали нас известными во всем мире, являются WowFare, Ovago, HOP2 и Arangrant. KIVORK имеет большой штат из более 1000 человек, работающих в различных офисах по всему миру, включая Молдову, Великобританию, ндию, США и местные удаленные команды в Казахстане, Армении, Украине. Сейчас мы ищем пополнение в нашу команду — аналитика данных (метапоиск), который поможет нам определить необходимые точки роста, чтобы поднять наш продукт на новый уровень. ТРЕБОВАНЯ: Подтвержденный опыт работы в аналитической роли от 3-х лет Уверенные знания Excel, Power BI, Python, SQL Аналитический склад ума со способностью генерировать значимые идеи о производительности Ответственность и инициатива Коммуникабельность, умение работать в команде. БУДЕТ ПРЕМУЩЕСТВОМ: Опыт работы в сфере OTA, гостеприимства Опыт с Google Analytics, Google Tag Manager Навыки A/B тестирования. ЧТО ТЫ БУДЕШЬ ДЕЛАТЬ: Анализ данных и составление сводных отчетов Преобразование больших объемов данных в полезную информацию с помощью дашбордов Проведение углубленного анализа в метапоиске, чтобы понять бизнес-процессы, оптимизировать производительность Определение и мониторинг показателей для оценки прогресса в достижении стратегических целей. ЧТО МЫ ПРЕДЛАГАЕМ: нтересные и перспективные проекты Работа в дружном коллективе Мотивирующая заработная плата Удаленная работа.","Анализ данных,SQL,Python,Power BI,MS Excel",KIVORK,
7344,78643247,Data Analyst,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Медиапоинт - digital-платформа игровой тематики. Мы работаем не только на территории России, но и на международном рынке. В настоящий момент мы расширяем бизнес, в связи с чем ищем Аналитика данных. Обязанности: Разработка моделей данных для решения аналитических задач Автоматизация регулярных процессов и отчетности Разработка гипотез по улучшению ключевых метрик и оптимизация конверсии на основании полученных данных Подготовка различных аналитических отчетов и обзоров по запросам бизнеса сследование большого объема необработанных данных, накопленных в бизнес-юните, работа с потребителями этих данных Тестирование систем и данных, расследование инцидентов в качестве данных, формирование требований к качеству данных. Требования: Опыт работы аналитиком данных от 1 года Аналитические навыки (умение анализировать и структурировать данные, умение делать выводы, выдвигать и проверять гипотезы) Python для анализа данных Продвинутое владение Excel (разработка дашбордов и моделей) Продвинутое владение SQL (мы работаем с Clickhouse, PostgreSQL, MySQL) Опыт работы в BI-системах приветствуется нтерес к таким сферам как betting, gambling, crypto. Условия: Полностью удаленная позиция или гибридный формат работы Гибкий график работы (пн-пт с 9/11 до 18/20) Позиция в международной компании с многолетним опытом работы в игровой сфере Дружный и амбициозный интернациональный коллектив Уровень заработной платы обсуждается на финальных этапах собеседования.",,Медиапоинт,
7345,78840014,Стажер Data engineer / Data analyst,з/п не указана,не требуется,"Стажировка,полный день","О команде: Наши продукты сфокусированы в подразделении Управления сети самообслуживания, мы ищем единомышленников для улучшения наших продуктов: Клиентский опыт на банкоматах. Система управления клиентским опытом на основе обратной связи от клиентов с применением AI-технологий. Раздел «На карте» в Сбербанк Онлайн, где клиент может найти Голосовые навыки в ассистенте Салют, которое помогают пользователям найти офисы банка и банкоматы. Функционал: Выполнение аналитики данных с инструментами: SQL, Hue, Spark, Python, GreenPlum. Проверка продуктовых гипотез с помощью данных. Участие в разработке промышленных витрин данных. Разработка BI дашбордов на ClickSense – мы научим. Создание метрик продуктов. Проведение аналитики операций на банкоматах / терминалах и поиск улучшений клиентского опыта. Проведение глубокой аналитики поведенческих трендов клиентов, формирование предложений по развитию бизнеса. Наши ожидания от кандидата: Уверенное знание основ статистики. Уверенное знание SQL. Владение Python и основными библиотеками для анализа данных. спользуемый стек: Python SQL Hue, Spark Qlik Sense GreenPlum Условия: 1. Уникальные масштабные проекты, работа в приоритетном направлении 2. Достойная заработная плата (оклад + годовая премии) 3. Современные рабочие места и программное обеспечение 4. потека выгоднее для каждого сотрудника и льготные условия кредитования 5. Бесплатная подписка СберПрайм+ 6. Скидки на продукты компаний-партнеров: Okko, Сбер Маркет, Delivery Club, Самокат, Сбер Еаптека и другие 7. ДМС с первого дня и льготное страхование для близких 8. Корпоративная пенсионная программа 9. Обучение за счет Компании: онлайн курсы в Виртуальной школе Сбера и неограниченный доступ к библиотеке, обучение в Корпоративном университете, тренинги, митапы и возможность получить новую квалификацию 10. Реферальная программа для сотрудников: можно пригласить в команду знакомых профессионалов и получить вознаграждение до 100 тыс. рублей 11. Скидки на отдых в лучшем в мире курортном комплексе Mriya Resort & SPA",,Сбер. IT,
7347,78995690,Data Scientist,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Приглашаем DATA SCIENTIST-A присоединиться к нашей команде. В Росбанке возможен полностью дистанционный формат работы: откуда работать - решать только тебе! Ты можешь работать из любой точки! Приходи к нам, чтобы работать над амбициозными и интересными проектами и наслаждаться балансом между работой и личной жизнью! Росбанк – частный универсальный банк, работающий на российском рынке с 1993 года. Росбанк обслуживает порядка 1,5 млн активных розничных клиентов, около 83 тысяч активных клиентов малого бизнеса и около 10 тысяч активных клиентов корпоративного бизнеса более чем в 60 регионах России. Росбанк входит в ТОП 5 самых надежных российских банков по версии журнала Forbes и включен Банком России в число 13 системно-значимых кредитных организаций России. Наш банк имеет наивысшие кредитные рейтинги российских и международных рейтинговых агентств. ОБЯЗАННОСТ: Анализ данных и постановка ТЗ на сборки витрин моделирования в части малого и среднего бизнеса Разработка моделей склонности, прогнозирования, классификации, приоритезации и пр. Выстраивание и поддержание системы скоринга клиентов и обновления моделей Разработка и внедрение в промышленный контур готовых моделей. ТРЕБОВАНЯ: Отличное знание SQL и баз данных Опыт моделирования: SAS EM, Python или R Желательно знание математической статистики, предиктивной аналитики, методов (regression, decision tree, neural network и т.д.) и опыт их применения на практике. УСЛОВЯ: Полностью дистанционный формат работы – это возможность работать из любой точки Стабильный и прозрачный доход: зарплата и премии по результатам работы График 5/2 31 календарный день оплачиваемого отпуска Забота о здоровье сотрудников: программа ДМС, включая стоматологию и консультации психолога, страхование при выезде за рубеж, скидки на абонементы в фитнес-клубы, страхование жизни Дополнительная оплата за больничный лист: доплата сверх пособия по болезни до оклада (до 5 рабочих дней в год) Кадровый электронный документооборот, который позволяет подписывать кадровые документы (дополнительные соглашения к трудовому договору, приказы и т.п.) в электронном виде Личностное развитие и рост: корпоративная электронная библиотека Альпина с книгами, курсами, тестами по бизнесу и саморазвитию, возможность прохождения бесплатного обучения и тренингов, участия в регулярных встречах корпоративных клубов и скидки на курсы он-лайн школ Скидки и привилегии по кредитам, ипотека на льготных условиях, льготные условия обслуживания и т.п. Программа корпоративных скидок и привилегий Primezone: развлечение, отдых, товары для взрослых и детей, услуги (авиакомпании, рестораны, магазины электроники и т.п.), обучение Программа волонтерства и благотворительности Сообщества по интересам сотрудников.","Python,Sas,SQL,R",«РОСБАНК»,
7349,78091483,Middle Data analyst,з/п не указана,1–3 года,"Полная занятость,удаленная работа",,,EXPF,"Москва, Октябрьская, Октябрьская, Полянка, улица Большая Якиманка, 26"
7351,78039606,Младший аналитик данных / Data Analyst Junior,з/п не указана,1–3 года,"Полная занятость,гибкий график","Привет! Мы команда IT-компании ""Читай Технологии"", входящей в крупнейший книжный холдинг России ""Читай-город - Буквоед - Book24"". Сейчас мы активно расширяем нашу команду отдела аналитики интернет-магазинов и ищем МЛАДШЕГО АНАЛТКА ДАННЫХ (DATA ANALYST)! Основное направление работы - аналитика маркетинговых активностей в e-commerce. ЧЕМ ПРЕДСТОТ ЗАНМАТЬСЯ: Выполнение аналитических отчетов на регулярной основе. Выполнение ad-hoc задач. Сбор и обработка данных из разных источников (создание ETL-процессов). Создание витрин данных и дашбордов. Подготовка данных для задач машинного обучения. Контроль метрик и выполнения КП отделов. НАШ ОЖДАНЯ: Знание python (pandas) и SQL Опыт визуализации данных Знание статистических методов Навык написания аналитических выводов Опыт работы от 1 года. МЫ ПРЕДЛАГАЕМ: Официальное трудоустройство с первого рабочего дня в аккредитованную IT-компанию Белая зп (сумму обсуждаем индивидуально) Скидка в наших магазинах Бесплатная электронная библиотека Оплата профильных конференций ДМС на льготных условиях Комфортный офис в 5 минутах от ст.м.Бутырская/Фонвизинская, Москва (либо офис в Санкт-Петербурге, ст.м. Площадь Ленина) Корпоративные скидки на фитнес и изучение иностранных языков Гибридный формат работы (1-2 раза в неделю в офисе, остальные удаленно) Гибкое начало рабочего дня.","Python,Анализ данных,Pandas,Визуализация данных,Data Analysis,SQL",Федеральная сеть книжных магазинов Читай-город,
7352,75687755,Data analyst,з/п не указана,1–3 года,"Полная занятость,удаленная работа","В Департамент кассовых и инкассационных сервисов приглашаем DATA АНАЛТКА ТРЕБОВАНЯ: Отличное знание SQL (SELECT, JOIN, агрегатные функции, PIVOT, ROLLUP, CUBE, APPLY) Опыт разработки таблиц (CREATE TABLE, INSERT (INTO), DROP, UPDATE, WITH) и создания запросов к серверу через OPENQUERY Опыт работы с SQL Server Agent (Job) Знание инструментов визуализации витрин данных (Power BI (DAX)) Знание элементов языка PL/SQL Oracle Знание и понимание принципов работы с MDS, SSAS (Tabular Cube), SSRS, Hadoop, Hive Опыт работы с GIT + Bitbucket (Pull Request), JIRA, Confluence будет преимуществом Знание функций, представлений, индексов, триггеров, хранимых процедур в частности импорта/репликации данных будет преимуществом. ОБЯЗАННОСТ: Выгрузка данных из корпоративного хранилища данных Проведение анализа для проверки гипотез совместно с бизнес-подразделениями Построение аналитических представлений и отчетов (таблицы, графики) в MS Power BI на основе данных из различных источников Анализ и оптимизация текущих дашбордов и отчетов в Power BI, их поддержка Получение данных по API, обработка ETL, анализ и визуализация через BI-системы и др.отчеты Обработка отчетов, сбор и анализ данных из других источников (БД, выгрузки в excel и др.) Связывание данных из различных источников по ключам, фильтрация данных по определенным признакам и условиям Анализ данных и контроль их качества (работа с источниками) Настройка отправки аналитических отчетов по событиям Подготовка презентационных материалов, проведение демонстраций разработанного функционала для пользователей Написание инструкций, описание логики дашбордов УСЛОВЯ: Стабильный и прозрачный доход: зарплата и премии по результатам работы График 5/2 Формат работы обсуждаем 31 календарный день оплачиваемого отпуска Забота о здоровье сотрудников: программа ДМС, включая стоматологию и страхование при выезде за рубеж, корпоративные спортивные команды и скидки на абонементы в фитнес-клубы Дополнительная оплата за больничный лист: доплата сверх пособия по болезни до оклада (до 5 рабочих дней в год) Личностное развитие и рост: корпоративная электронная библиотека Альпина, возможность прохождения бесплатного обучения и тренингов, участия в регулярных встречах корпоративных клубов и скидки на курсы он-лайн школ Скидки и привилегии по кредитам, ипотека на льготных условиях, льготные условия обслуживания и т.п. Программа корпоративных скидок и привилегий Primezone: развлечение, отдых, товары и услуги, обучение Программа волонтерства и благотворительности Сообщества по интересам сотрудников.","SQL,Oracle Pl/SQL",«РОСБАНК»,
7353,77725684,Data Scientist / ML-разработчик,з/п не указана,1–3 года,"Полная занятость,полный день","Наша компания «СтандартПроект» является лидером в области разработки высокоинтеллектуальных информационных корпоративных систем масштаба Big Data в России. Также у нас есть собственная лаборатория digital-продуктов на основе наших разработок. Мы 20 лет работаем с крупнейшими государственными, промышленными и финансовыми организациями.  сейчас у Вас есть возможность присоединиться к команде в качестве Data scientist. ВАМ ПРЕДСТОТ: 1. 50% Разработка ML моделей для высоконагруженных систем (+ доработка и переобучение этих моделей после внедрения) 2. 30% Анализ данных 3. 20% Подготовка сложных выгрузок с использованием SQL и python НАШ ОЖДАНЯ: Обязательно: 1. Опыт работы аналитиком от 1 года. Ждем от кандидата проактивного подхода к решению задач и критическое восприятие результатов собственных исследований. 2. Высшее техническое и/или экономическое образование. 3. Основы машинного обучения (CatBoost, Scikit-learn, XGBoost, Random forest, деревья решений). Желание применять и развиваться в области ML. 4. Знание Python (numpy, pandas, scipy и т.п.), умение работать в jupyter notebook. 5. SQL (сложные запросы, join’ы, вложенные запросы, оконные функции и т.д.). 6. Аналитический склад ума. 7. Знания в области математики, теории вероятности и мат. статистики. 8. Основы моделирования баз данных. 9. Знание английского на уровне чтения технической документации. Желательно: 1. Опыт внедрения алгоритмов машинного обучения 2. Опыт работы с Postgre SQL. 3. Опыт работы с распознаванием образов. 4. Опыт работы с Clickhouse. 5. Опыт работы с Linux. 6. Умение работать с гео-данными в python. Приветствуется: 1. Пройденные курсы по анализу данных. 2. Участия и победы в конкурсах и хакатонах. 3. Наличие пет-проектов с применением ML и оптимизационных алгоритмов. Условия: Конкурентную заработную плату Гибкое начало работы (старт работы 08.00 – 10.00) График работы: 5/2, СБ и ВС, праздники - выходные дни Формат работы: офис первые 3 месяца, далее офис или гибрид Офис в стиле Loft в 10-ти мин. пешком от метро Таганская БЦ Фабрика Станиславского Корпоративное питание в офисе - завтраки, обеды и ужины Полис ДМС Опыт работы над социально значимыми проектами Официальное трудоустройство в соответствии с ТК РФ с первого рабочего дня Работу в стабильной и активно развивающейся IT-компании, где нет бюрократии, и все сотрудники знают друг друга в лицо Регулярные корпоративные мероприятия (настолки, квесты и т.д.), подарки на НГ детям сотрудников и другие мероприятия для поддержания шикарного настроения.  Если укажите в резюме свой ник telegram, считайте, у Вас дополнительное преимущество :)","Python,SQL,ML,Machine Learning,Машинное обучение",СтандартПроект,"Москва, улица Станиславского, 21с2"
7354,78772429,Data Analyst,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Responsibilities: Collect and analyze data related to materials and inventory management, including purchase orders, inventory levels, lead times, and supplier performance. Develop and maintain reports and dashboards that visualize key metrics and KPIs related to materials and inventory management. Work with stakeholders within the Materials and Management department to identify areas for improvement and develop recommendations based on data insights. Collaborate with cross-functional teams to ensure data accuracy and completeness. Monitor data quality and ensure that data is maintained in accordance with departmental policies and procedures. Provide ad-hoc analysis and reporting as needed to support decision-making. Requirements: Bachelor's degree in Business Administration, Information Systems, or related field. Minimum of 2 years of experience as a Data Analyst, with a focus on materials and inventory management. Advanced proficiency in data analysis and visualization tools such as Excel, Tableau, and Power BI. Strong analytical skills and ability to translate data into meaningful insights. Excellent communication skills, both verbal and written. Ability to work collaboratively with cross-functional teams. Knowledge of materials and inventory management principles and best practices. Strong attention to detail and ability to work independently. Ability to manage multiple projects and priorities in a fast-paced environment. Conditions: 5/2 remote",,АтырауТехнвест,"Атырау, улица Максима Горького, 10"
7358,69166398,Аналитик данных / Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Аналитик данных / Data Analyst Сбер ищет аналитика данных. Если тебе интересно проверять продуктовые гипотезы, создавать витрины и дашборды, и ты хочешь участвовать в запуске крутых проектов в масштабе страны, откликайся. Тебе предстоит: проверять продуктовые гипотезы и готовить Ad-hoc аналитику для поддержки принятия бизнес-решений проводить A/B тесты и интерпретировать результаты создавать скрипты обработки данных, витрины и дашборды разрабатывать новые системы метрик и валидировать их контролировать качество и целостность данных. Мы ждем от тебя: высшее техническое или экономическое образование опыт работы с большими массивами данных знания SQL и Python опыт создания дашбордов в Tableau или другой BI системе навыки визуализации данных, умение наглядно представлять важную информацию и делать выводы, основываясь на цифрах. Мы предлагаем: стабильный оклад и социальную поддержку сотрудников официальное оформление с первого дня мощное оборудование за счет компании работу бок о бок лучшими из IT-индустрии, каждый из которых может поделиться своей экспертизой митапы внутри компании, участие в крупнейших конференциях обучение в одном из лучших Корпоративных университетов и в Виртуальной школе Сбера современный офис с тихими местами для работы и зонами релаксации и спортзалом расширенный ДМС с первого дня для сотрудников и льготное страхование для близких корпоративную пенсионную программу ипотеку ниже на 4% для каждого сотрудника бесплатную подписку СберПрайм+ и скидки на продукты компаний-партнеров.","Статистический анализ,Qlik Sense,Математическая статистика,SQL,Python,Анализ данных,Аналитическое мышление,Английский язык",Сбер. Экспертам и руководителям,
7361,78202092,Data аналитик (Junior),от 110 000 до 180 000 руб. до вычета налогов,1–3 года,"Полная занятость,удаленная работа","Вакансия: Junior Data аналитик для проекта по улучшению биллинговых услуг ведущих финансовых операторов Цели работы: Анализ и оптимизация процессов в биллинговых услугах банков Создание и настройка моделей аналитики данных для выявления трендов и предиктивной аналитики Разработка систем отчетности и визуализации данных для мониторинга и анализа бизнес-показателей Требования: Опыт работы от 1 года на аналогичной должности Знание языка SQL для работы с реляционными базами данных Понимание основных методов анализа данных и статистических методов Знание Excel и Python для анализа данных и создания моделей Важно: Обязательное прохождение математики по любой из программ - Яндекс. Практикум, Курсы Карпова, Проект Поиск или Популярная математика (popmath) Пожелания: Опыт работы с Power BI для создания визуализации и отчетности Опыт работы с крупными базами данных и Big Data технологиями Наличие сертификатов по Data аналитике Мы ищем кандидата, который готов развиваться и осваивать новые технологии, имеет высокую аналитическую способность и умение работать в команде. Вы сможете работать в динамичной компании и реализовывать свои идеи вместе с нами.","Python,Анализ данных,Аналитическое мышление,Работа с базами данных,Бизнес-анализ,Data Analysis,Математическая статистика",Омега,
7363,77536865,Data Scientist Junior/Junior+,з/п не указана,3–6 лет,"Полная занятость,полный день","Responsibilities: Collaborate with business partners to develop novel ways to meet objectives utilizing cutting edge techniques and tools Effectively communicate the analytics approach and how it will meet and address objectives to business partners Advocate and educate on the value of data driven decision making focusing on the “how and why” of solving problems Lead analytic approaches, integrating work into applications and tools with data engineers, business leads, analysts and developers Create repeatable, interpretable, dynamic and scalable models that are seamlessly incorporated into analytic data products Engineer features by using their business acumen to find new ways to combine disparate internal and external data sources Share their passion for Data Science with broader enterprise community identify and develop long-term processes, frameworks, tools, methods and standards Collaborate, coach, and learn with a growing team of experienced Data Scientists Stay connected with external sources of ideas through conferences and community engagements Domain Expertise: Bachelor’s degree required Graduate degree in quantitative discipline and demonstrated Data Science skill set, plus 3+ years work experience Must have Python or R proficiency working with DataFrames Must have proficiency writing complex SQL queries Must have proficiency with Machine Learning to solve clustering, classification, regression, anomaly detection, simulation and optimization problems on large scale data sets Must have proven ability to merge and transform disparate internal & external data sets together to create new features Advanced time series forecasting understanding – from classical linear approaches to ML ones Understanding the key business metrics and its application to ML models Experience with sophisticated data cleansing approaches & robust models Proficiency validating the current approaches and understanding the improvement area Experience with Big Data technologies preferred — Hadoop, Spark, H20.ai, Cloud AI platforms, containerization Experience with supporting deployment, monitoring, maintenance and enhancement of models desired Experience with data visualization tools preferred — Power BI, Tableau, R Shiny, Plotly, etc. Experience with AB testing preferred We offer: Competitive salary Advanced benefits package (annual bonus, health insurance, mobile compensation, partial fitness compensation, 3-year saving plan) Professional development and career growth Ability to take part in digital transformation in a large company","Python,Machine Learning,SQL,Big Data,Data science",Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
7368,78187598,Data QA,от 100 000 руб. на руки,1–3 года,"Полная занятость,удаленная работа","Добрый день!  Компания набирает несколько сотрудников для работы удаленно, с полной занятостью от 40 часов в неделю. Cо своей стороны предлагаем работу над интересными проектами на конкурентных условиях по заработной плате. В работе используем современные практики и технологии в области разработки программного обеспечения для автоматизации бизнеса.  Вот некоторые из них: Agile / Kanban test cases management systems unit tests / functional auto tests github / bitbucket ci / circleci / travis vagrant / docker / kubernetes amazon aws / google cloud composer / npm yii2- / laravel- based framework backbone / vuejs / gulp / webpack data science / machine learning и так далее Обязанности: Разработка сценариев тестирования интеграционных сервисов Озера Данных Участие в анализе поступающих задач и в постановке задач на разработку (до начала разработки необходимо сформулировать «Как проверить») Тестирование ETL, написание и поддержка SQL-скриптов для проверки данных Проведения функциональных тестирования web-приложений и сервисов, по завершению различных этапов разработки Требования: Уверенное знание SQL, на уровне написания запросов средней сложности Опыт работы с одной из реляционных СУБД Опыт работы в качестве тестировщика/системного аналитика/ETL разработчика на проектах создания аналитических платформ данных (DWH, Data Lake и пр.) Опыт создания скриптов/авто-тестов и тестирования ETL/ELT процессов с применением средств автоматизации функционального и нагрузочного тестирования будет плюсомОпыт командной разработки с использованием систем контроля версий (GIT), Jira, Confluence, CI/CD Опыт создания сценариев функционального тестирования Постоянное самообучение Быть внимательным к деталям Проявлять активную позицию в развитие проекта и компании Владение английским языком на уровне Intermediate и выше Условия: Удаленная работа Фулл-тайм 5/2 (дни можно выбрать) Регулярное индексирование заработной платы в соответствии с условиями рынка Относительно гибкий график, вы можете выбрать рабочие часы и дни. Но их нужно будет зафиксировать. Пересекаться с другими участниками проекта не менее чем на 3 часа в день Гарантия профессионального роста, как IT специалист  Собеседование по skype. Ждём ваших откликов и рассчитываем на взаимовыгодное сотрудничество.","Английский — B1 — Средний,Test case,Тестирование,Atlassian Jira,DWH,ETL,ELT,data lake,Databases",Перфект Системс,
7370,77996663,Data Architect,з/п не указана,3–6 лет,"Полная занятость,полный день","12 лет компания Apptimizm создает удобные и полезные веб и мобильные сервисы. За нашими плечами огромный опыт и множество успешных реализаций бизнес идей. Каждый новый проект для нас — не только работа, но и любимое занятие. Мы сотрудничаем с такими компаниями как Канал RuTV, радио DFM, радио Монте-Карло, Icult.ru, BoomMarket, МТТ, Renault, Lada, и многие другие. Мы с оптимизмом превращаем идеи клиентов в полноценные инструменты для ведения бизнеса.   Предстоящие задачи: Участие в формировании стратегии развития и поддержки архитектуры данных Сотрудничество с бизнес-подразделениями, подразделениями разработки ПО и IT-эксплуатации для определения их потребностей и перспектив Формирование и согласование планов работ по развитию методологий и систем обработки данных Формирование текущих статусов и проблем в архитектуре данных, передача их на более высокие уровни управления Анализ на этапе формирования требования к новой функциональности продуктов/IT-систем влияние на смежные IT-системы Проведение экспертной оценки запросов об изменениях, влияющих на архитектуру данных Формирование предложения и замечания в бизнес-функциональные требования. Согласование бизнес-функциональные требования к новым продуктам/системам Координация, разработка и согласование с поставщиками систем, бизнес-аналитиками, релиз-менеджерами и системными администраторами высокоуровневый IT-дизайн новых продуктов/IT-систем Формирование и передача на согласование описание архитектуры данных в рамках разработки высокоуровневого IT-дизайна новых продуктов/IT-систем Осуществление архитектурного сопровождения при внедрении/развертывании новых продуктов/IT-систем.  Мы ожидаем от тебя: Опыт работы на аналогичной должности 3-5 лет Опыт проектирования архитектуры данных (Entity-Relations Diagram, Data Flow Diagram), модели метаданных, аналитических витрин Отличные аналитические навыки и ориентированность на детали PMP/ PM Master (scrum/agile) приветствуется Глубокие знания принципов построения DataWareHouse, DataLake Глубокие знания принципов интеграции данных (ETL/ELT) Опыт работы со стэком Big Data (Hadoop, Spark, Hive, Kafka и пр) Глубокое понимание SQL Хорошее знание MS Azure data lake and Yandex Cloud Уровень знания английского языка (устный и письменный) не ниже upper intermediate.","SQL,Spark,Scrum,ETL,Agile,MS Azure data lake,Yandex Cloud,DataWareHouse,DataLake,Big Data,Entity-Relations Diagram,Data Flow Diagram",Апптимизм,
7372,78632954,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Кто мы Мы – команда МоегоСклада. Уже больше 15 лет развиваем и продаем веб-сервис, упрощающий жизнь малому и среднему бизнесу. У нас налажен и постоянно развивается процесс разработки. Сделанные в первый день работы тикеты могут уже завтра быть на проде. Продукт большой и сложный, пользователи активно делятся пожеланиями. Мы придумываем как реализовать полезный для людей продукт – и делаем. Мы делаем совершенно разные вещи - создаем новые фичи, пилим интеграции с самыми популярными маркетплейсами, поддерживаем наши работающие решения, делаем инструменты аналитики более ценными, улучшаем онбординг и дизайн, исследуем пользователей, развиваем API и многое-многое другое. Мы ищем того, кто Понимает принципы организации хранилищ данных, подходов к проектированию логической и физической моделей Хорошо знает SQL (в т.ч. DDL, агрегации, джойны, вложенные запросы, аналитические запросы, опыт оптимизации запросов) меет опыт оркестрации ETL с помощью Apache Airflow или других систем Знает и имеет опыт работы с PostgreSQL, Clickhouse Знает Python на уровне написания собственных операторов и хуков для Apache Airflow Будет плюсом: Опыт в построении CI/CD pipeline с использованием Gitlab CI Опыт работы с брокером сообщений Apache Kafka Опыт работы с Apache Nifi Построение отчётов и визуализации данных на основе Metabase или иных средств визуализации Чем предстоит заниматься: Разработка и поддержка инфраструктуры для хранения и обработки данных Участие в разработке и развитии текущих архитектурных решений по обработке данных Разработка новых ETL pipelines и поддержка существующих, используя внутренние и внешние источники данных Разработка дашбордов с использованием BI-системы Анализ требований к витринам данных (взаимодействие с владельцем продукта, разработчиками из других команд) Ведение документации Что мы предлагаем Официальное оформление и белую зарплату Гибкое начало рабочего дня Можно работать удаленно или в нашем комфортном офисе — в Москве в двух минутах от метро Автозаводская/удаленно Отсутствие бюрократии: все онлайн в удобном интранете В офисе — компенсируем оплату обедов, закупаем фрукты и перекусы Профессиональное развитие (оплата обучения, корпоративная библиотека, выступления на конференциях) 5 оплачиваемых “дней без больничного” в год Компенсация больничного и отпуска — 100 % оклада Компенсируем 50% затрат на спорт Предоставляем скидку 50% на сервис онлайн-психотерапии Возможность оформить отсрочку от призыва и мобилизации, льготную Т–ипотеку А еще мы дарим классный фирменный мерч Подключаем к ДМС со стоматологией после окончания испытательного срока.","Python,SQL,ClickHouse,PostgreSQL,BI,ETL,Apache Kafka,Apache Airflow",МойСклад,"Москва, Автозаводская, улица Ленинская Слобода, 19с2"
7379,79141488,Data Scientist middle/middle+ в ML-команду,з/п не указана,3–6 лет,"Полная занятость,полный день","Наша команда занимается построением ML моделей. При реализации кейсов и проведении пилотов находится множество инсайтов, которые помогают делать процессы эффективнее. Для развития этих инсайтов ищем коллегу, в обязанности которого будет входить нахождение решений на стыке ML и классической аналитики Перед командой стоят следующие вызовы: - Прогнозные и причинно-следственные модели - Аудио аналитика телефонных разговоров и записей взаимодействия с клиентами. В том числе перевод аудио в текст, вычленение эмоциональной подоплёки, определения лжецов - Текстовая аналитика записей. В том числе конспект разговоров, вычленение необходимых сущностей, определение лжецов - Гео аналитика клиентов. В том числе где и когда контактировать - Оптимизация бизнес процессов с использованием инструментов process mining Обязанности Фулл стек DS. От идей до оценки эффективности готового продукта. Работа ведётся при регулярном общении с бизнес-заказчиком. Сервис и деплой на python разработчике. Требования щем людей владеющими необходимыми для выполнения описанных функций навыками: Алгоритмами работы с табличными пространственными данными, временными рядами, аудио, текстами, гео процессами (опыт от 2 лет совокупно) Python3, включая стек библиотек для работы с машинным обучением Общением с бизнесом по проектам машинного обучения, ориентацией на бизнес результат, для senior дополнительный опыт управления проектами, в которых участвует несколько команд sql, jupyter, pycharm, git, jira, confluence Условия комфортный офис на Кутузовском проспекте с тренажерным залом, коворкинг-пространствами и кафе полный рабочий день, но гибкий график работы (можно выбрать режим начала работы в промежутке 7:00 - 10:30) ДМС, программы лояльности для сотрудников (льготное кредитование, предложения экосистемы Сбера) комьюнити data-people, множество программ профессионального обучения (курсы, тренинги, конференции, семинары).",,Сбер для экспертов,
7380,79120973,Data Engineer,от 2 500 до 4 000 USD на руки,3–6 лет,"Полная занятость,полный день","LATOKEN is the supermarket of assets where it is easy to discover, exchange, earn and spend crypto. Mission: Well-structured and secure data and monitoring.  Story: Product, Finance, OKRs, and Dash Teams need well-structured and secure data and monitoring to analyze and track the improvement of the services and product performance. Key PROBLEM's: The monitoring system alerts for any downtime, latency, or success rate issues of the services. All company data and events are merged and consolidated into the Data Base (DWH, PostgreSQL, Segment, Indicative, Google Analytics) to support the Monitoring system, Token Discovery, OKRs and Analytical Dashes. Acquisition channels, conversions, and users are correctly mapped and easy to access. Token DB is representative of the market and token data is correct and complete with on-chain and smm data. (30k tokens by end of April) How: Create new data pipelines for business need. Maintain scripts and pipelines in case of problems or new requirements. Define necessary events, set up recording and make available for reports and dashboards. Maintain and update token DB. Constraints: All OKRs of the company are consolidated into Platform Ops. All scripts are consolidated into Gitlab. Main performance number: Ops OKR Health Second performance number: Free Space DWH Third performance number: Query response time, sec avg  Functions: • OKRs Health : Calculate OKRs correctly, daily and in time • DWH objects audit • Queries : Advice on optimization and writing queries to databases. • Data quality : Keep data in order and provide reliable reporting • Automation : Automation of OKRs and slack bots for automated ops processes • Audit : Audit of DWH state and automated scripts  Requirement skills and experience: 2+ years of PostgresSQL DB administration experience 2+ years of experience writing Python scripts and applications for loading data Experience in configuring a database in a high-availability architecture Experience in database optimization for different load profiles Experience in automating data loading from different sources (CRM, ERP, Web resorses) Eager to work with people with high-performance standards Will be a plus: Experience with financial data Experience as a data/product analyst","Python,DWH,PostgresSQL,CRM,ERP",LATOKEN,
7388,79255620,Data scientist в команду развития скоринговых моделей,з/п не указана,1–3 года,"Полная занятость,полный день","Тебе предстоит: Строить и внедрять скоринговые модели Заниматься исследованием источников данных Реализовывать переменные и скоры для использования в моделях Развивать инструменты аналитики и построения скоринговых моделей для многих команд Тинькофф Менторить сотрудников, развивать их хард скиллы Что мы ждем: Опыт разработки ML-моделей Хорошее знание классического ML Знание Python, SQL Хорошее владение математической статистикой и теорией вероятности Умение работать с большими объемами информации и данных Будет плюсом: Высшее техническое образование Знание основ DL Опыт построения скоринговых моделей, А/Б тестирование Мы предлагаем: Работу в офисе у метро «Водный стадион». График работы — гибридный Платформу обучения и развития Тинькофф Апгрейд. Курсы, тренинги, вебинары и базы знаний. Поддержка менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Бесплатный фитнес-зал Tinkoff Sport. Тренируйтесь, посещайте групповые программы, грейтесь в сауне и участвуйте в спортивных турнирах Бесплатные обеды в Tinkoff Cafe. А если захотите перекусить, на каждом этаже есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","ML,Mathematical Statistics,Python,Математическое моделирование",Тинькофф,"Москва, Водный стадион, Головинское шоссе, 5А"
7392,78632954,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Кто мы Мы – команда МоегоСклада. Уже больше 15 лет развиваем и продаем веб-сервис, упрощающий жизнь малому и среднему бизнесу. У нас налажен и постоянно развивается процесс разработки. Сделанные в первый день работы тикеты могут уже завтра быть на проде. Продукт большой и сложный, пользователи активно делятся пожеланиями. Мы придумываем как реализовать полезный для людей продукт – и делаем. Мы делаем совершенно разные вещи - создаем новые фичи, пилим интеграции с самыми популярными маркетплейсами, поддерживаем наши работающие решения, делаем инструменты аналитики более ценными, улучшаем онбординг и дизайн, исследуем пользователей, развиваем API и многое-многое другое. Мы ищем того, кто Понимает принципы организации хранилищ данных, подходов к проектированию логической и физической моделей Хорошо знает SQL (в т.ч. DDL, агрегации, джойны, вложенные запросы, аналитические запросы, опыт оптимизации запросов) меет опыт оркестрации ETL с помощью Apache Airflow или других систем Знает и имеет опыт работы с PostgreSQL, Clickhouse Знает Python на уровне написания собственных операторов и хуков для Apache Airflow Будет плюсом: Опыт в построении CI/CD pipeline с использованием Gitlab CI Опыт работы с брокером сообщений Apache Kafka Опыт работы с Apache Nifi Построение отчётов и визуализации данных на основе Metabase или иных средств визуализации Чем предстоит заниматься: Разработка и поддержка инфраструктуры для хранения и обработки данных Участие в разработке и развитии текущих архитектурных решений по обработке данных Разработка новых ETL pipelines и поддержка существующих, используя внутренние и внешние источники данных Разработка дашбордов с использованием BI-системы Анализ требований к витринам данных (взаимодействие с владельцем продукта, разработчиками из других команд) Ведение документации Что мы предлагаем Официальное оформление и белую зарплату Гибкое начало рабочего дня Можно работать удаленно или в нашем комфортном офисе — в Москве в двух минутах от метро Автозаводская/удаленно Отсутствие бюрократии: все онлайн в удобном интранете В офисе — компенсируем оплату обедов, закупаем фрукты и перекусы Профессиональное развитие (оплата обучения, корпоративная библиотека, выступления на конференциях) 5 оплачиваемых “дней без больничного” в год Компенсация больничного и отпуска — 100 % оклада Компенсируем 50% затрат на спорт Предоставляем скидку 50% на сервис онлайн-психотерапии Возможность оформить отсрочку от призыва и мобилизации, льготную Т–ипотеку А еще мы дарим классный фирменный мерч Подключаем к ДМС со стоматологией после окончания испытательного срока.","Python,SQL,ClickHouse,PostgreSQL,BI,ETL,Apache Kafka,Apache Airflow",МойСклад,"Москва, Автозаводская, улица Ленинская Слобода, 19с2"
7403,79245437,Senior Data scientist / Machine learning engineer (команда рекомендаций и машинного обучения),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы применяем алгоритмы машинного обучения к рекомендациям контента. Не просто берем готовые решения, но и создаем собственные, пригодные к работе в условиях высоких нагрузок и больших данных. Помимо классического ML, мы используем deep learning и байесовские методы. Типичный пример нашего проекта — система, которая на ходу учится определять перспективность нового контента и аудиторию, среди которой он будет наиболее востребован. щем специалиста, который будет вместе с нами разрабатывать рекомендательную систему, искать возможности для роста и формировать планы по развитию продукта. Вам предстоит: • математически формулировать бизнес-задачи • использовать огромное количество разных данных • создавать гипотезы по улучшению сервиса, внедрять их и проверять работоспособность в офлайне, а в случае удачи искать способы реализации • проводить A/B-тесты и анализировать результаты экспериментов. У нас интересно, потому что вы сможете поработать с разнообразными state-of-the-art решениями в области рекомендательных систем, например: • с продвинутыми методами матричной факторизации для извлечения информации из истории просмотров и поиска • построением текстовых эмбеддингов • методами reinforcement learning • SNA-техниками для анализа социального графа • разработками big data и аналитикой поверх стека Apache Spark • product science для инсайтов и генерирования продуктовых гипотез • анализом границ применимости моделей, техниками explanation для понимания работы моделей и их специфик. Мы ожидаем, что вы: • имеете отличную математическую и алгоритмическую подготовку • знаете методы машинного обучения и умеете грамотно их использовать • работали с рекомендательными системами или интересуетесь ими • уверенно владеете Python, Java или Scala, а также любым из диалектов SQL. Будет плюсом, если вы: • умеете работать с фреймворками big data — Spark, Hadoop • знакомы с байесовскими методами машинного обучения. Приглашаем кандидата, который сможет посещать офис в Санкт-Петербурге или работать в гибридном графике. Ждем ваших откликов. Удачи!","Python,Java,Hadoop,Big Data,Spark,SCALA","VK, ВКонтакте","Санкт-Петербург, Гостиный двор, Невский проспект"
7405,79120973,Data Engineer,от 2 500 до 4 000 USD на руки,3–6 лет,"Полная занятость,полный день","LATOKEN is the supermarket of assets where it is easy to discover, exchange, earn and spend crypto. Mission: Well-structured and secure data and monitoring.  Story: Product, Finance, OKRs, and Dash Teams need well-structured and secure data and monitoring to analyze and track the improvement of the services and product performance. Key PROBLEM's: The monitoring system alerts for any downtime, latency, or success rate issues of the services. All company data and events are merged and consolidated into the Data Base (DWH, PostgreSQL, Segment, Indicative, Google Analytics) to support the Monitoring system, Token Discovery, OKRs and Analytical Dashes. Acquisition channels, conversions, and users are correctly mapped and easy to access. Token DB is representative of the market and token data is correct and complete with on-chain and smm data. (30k tokens by end of April) How: Create new data pipelines for business need. Maintain scripts and pipelines in case of problems or new requirements. Define necessary events, set up recording and make available for reports and dashboards. Maintain and update token DB. Constraints: All OKRs of the company are consolidated into Platform Ops. All scripts are consolidated into Gitlab. Main performance number: Ops OKR Health Second performance number: Free Space DWH Third performance number: Query response time, sec avg  Functions: • OKRs Health : Calculate OKRs correctly, daily and in time • DWH objects audit • Queries : Advice on optimization and writing queries to databases. • Data quality : Keep data in order and provide reliable reporting • Automation : Automation of OKRs and slack bots for automated ops processes • Audit : Audit of DWH state and automated scripts  Requirement skills and experience: 2+ years of PostgresSQL DB administration experience 2+ years of experience writing Python scripts and applications for loading data Experience in configuring a database in a high-availability architecture Experience in database optimization for different load profiles Experience in automating data loading from different sources (CRM, ERP, Web resorses) Eager to work with people with high-performance standards Will be a plus: Experience with financial data Experience as a data/product analyst","Python,DWH,PostgresSQL,CRM,ERP",LATOKEN,
7408,75825082,Data инженер,от 250 000 руб. на руки,1–3 года,"Полная занятость,гибкий график","Крупная компания (РФ и РБ), дистрибьютор запасных частей к европейским грузовым автомобилям приглашает на работу инженера по данным (Data Engineer) Мы развиваем сложные информационные системы, чтобы грузовой транспорт мог ежедневно доставлять товары в разные точки страны. Мы разрабатываем собственное комплексное решение с функциями товародвижения, системы управления складом и двором (WMS,YMS), блоком взаимоотношений с клиентом (CRM) и продажами (POS), с блоком аналитики. меем развитую систему филиалов и магазинов, интегрированных в корпоративную сеть и связанных с ЦОДами. щем в команду инженера по данным, который готов продолжить своё развитие в высоко технологичной и динамически развивающейся компании Обязанности: - создание корпоративного хранилища данных (DWH) - развитие и переработка существующих OLAP-кубов - развитие ETL процессов - подготовка и сопровождение витрин данных для BI визуализации и отчетов - построение плоской, многомерной отчетности и дашбордов - технологический стек: Основа - MS SQL Server/Integration/Analysis/Reporting Services/Power BI Требования: - опыт работы в качестве разработчика баз данных, DWH, ETL или OLAP в течение 2 лет - знание теории и практический опыт построения баз данный, хранилищ данных - отличное знание T-SQL (планы выполнения, оптимизация) - MS SQL Server (Database Engine, Integration Services, Analysis Services, Reporting Services, Power BI) - базовые знания MDX, DAX Желательно (будет плюсом): - базовые знания платформы .NET - знание одной из торговых учетных систем (1С, SAP, и др.) - экспертное знание принципов работы MS SQL (хранение данных, индексы, статистика, транзакции, уровни изоляции транзакций, блокировки) Условия: - на испытательные срок – 5/2 в офисе - Возможен гибридный график работы после испытательного срока - офис расположен по адресу 2-я Мелитопольская ул. метро Бульвар Дмитрия Донского (в шаговой доступности от жд. ст. Бутово - позитивная, созидательная среда и интересные проекты - работа в команде профессионалов, неравнодушных, активных, ответственных за свой результат. Почему у нас хорошо? Стабильность. Компания экономически устойчива и растёт каждый год. Честность. Мы работаем с полным соблюдением законодательства. Масштаб. Вы станете участником крупных проектов, полностью меняющих бизнес-процессы. нтерес. Вы попадёте в насыщенную событиями рабочую атмосферу крупной команды Т. Доверие. Лояльное руководство, отсутствие «чайка»-менеджмента. Комфорт. Мы за work-life balance – стараемся жить без переработок и отдыхать в выходные.",,ОМЕГА,"Москва, Бульвар Адмирала Ушакова, Бульвар Дмитрия Донского, Улица Горчакова, Улица Скобелевская, 2-я Мелитопольская улица, 4А"
7409,77577192,Разработчик курса/методист/преподаватель по Data Science,з/п не указана,3–6 лет,"Частичная занятость,удаленная работа","РДТЕХ - аккредитованная Т-компания с 30 летней историей и широким спектром реализованных проектов по внедрению информационных систем, и глубокой экспертизой сотрудников. Учебный центр РДТЕХ - авторизованный партнер компании Postgres Professional, поставщик образовательных программ по T-менеджменту. Мы приглашаем экспертов, готовых стать авторами учебных материалов для создания современного образовательного контента. Нам важны: Ключевое - способность самостоятельно разработать курс, возможно, и читать его знание Python, опыт работы с фреймворками: Tensor Flow, Keras, Theano, Scikit-learn, PyTorch, NumPy, Pandas, Seaborn опыт работы аналитиком/постановщиком задач в команде из 20-50 специалистов по созданию и поддержки отраслевых СУБД либо опыт работы с BI на уровне разработки кубов, отчетов, создания справочников/измерений, работа с OLAP/ROLAP/MOLAP/HOLAP структурами умение внедрять полученную модель в объекты заказчика желательна магистерская степень по чистой или прикладной матетатике или теоретической физике. Мы предлагаем: возможна как частичная, так и полная занятость, удаленная работа, коррекция загрузки. Вы сами определяете темы для чтения, формат, график и продолжительность наши авторы-эксперты имеют возможность обучаться в нашем УЦ на льготных условиях (скидки, в зависимости от курса и выбранного направления, могут составлять от 60% до 100% (полностью бесплатно) от цены на сайте, если обучение проходит в дистанционном формате также вы можете передать эту привилегию любому человеку по своему выбору.",,РДТЕХ,
7410,78306430,Python Backend Developer / Data Engineer,до 250 000 руб. на руки,1–3 года,"Полная занятость,удаленная работа","DataGo! (ex OWOX Russia) — одна из сильнейших команд в сфере маркетинговой аналитики в СНГ со своими собственными продуктами, решениями и центром экспертизы с многолетним опытом. DataGo! дает качественные данные аналитикам и прикладные отчеты маркетологам и product менеджерам. • Нам доверяют более 100 крупнейших клиентов РФ в сферах: E-commerce, Banking, Telecom, Pharma. • Официальный партнер Яндекс.Метрика и Яндекс.Cloud. • Самое большое количество успешных кейсов с использованием Google Cloud и Google Analytics среди всех партнеров Google в СНГ. Сейчас мы ищем человека с опытом на стыке бэкенд-разработки и дата-инженерии, который усилит нашу продуктовую команду и попадет в самое сердце разработки DataGo! Чем предстоит заниматься: Разрабатывать и улучшать наш продукт – стриминг данных – с помощью FastAPI Сервис высоконагруженный – около 4000 RPS Работать с интеграциями – разрабатывать коннекторы и пайплайны на aiohttp, asyncio Собирать, обрабатывать и доставлять данные в базы заказчиков (CLickhouse/GBQ) с помощью Airflow. Для нас важно: Наличие опыта разработки на Python (Pandas, Numpy), с асинхронным стэком в частности (FastAPI, asyncio, aiohttp) – от 2-ух лет Опыт работы с БД: Clickhouse, PostgreSQL, будет плюсом – GBQ Опыт разработки и общее понимание архитектуры высоконагруженных, масштабируемых сервисов Навыки работы с виртуальными машинами, Сelery, Redis, RabbitMQ, Nginx Навыки работы с облачными серверами – Google Cloud, Яндекс Облако. Что мы предлагаем: Оформление в аккредитованную Т-компанию со всеми преимуществами или оформление сотрудничества за рубежом, в любом случае - полностью удаленная работа из любой точки мира Конкурентную заработную плату до 250 000 рублей на руки Возможность работать в команде, которая сохранила дух стартапа – нас немного, мы очень классные и не позволяем никакой бюрократии влезать в наши процессы. Если считаешь, что все вышесказанное про тебя — ждём отклик!","Python,asyncio,aiohttp,FastAPI,Pandas,Numpy,ClickHouse,PostgreSQL,Google BigQuery,Celery,Nginx,Pytest,Airflow",DataGo!,
7411,67471218,Data Engineer (ETL Developer),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы в Lesta Games (Санкт-Петербург, Москва, Минск) ведем разработку игровых проектов в различных жанрах и для разных платформ, а также экспериментируем с инструментами и технологиями. Мы уже выпустили несколько игр, аудитория которых насчитывает миллионы игроков по всему миру. Но мы не планируем останавливаться на достигнутом – впереди много работы, чтобы сделать наши проекты еще более успешными.  Мы хотим делать наши проекты еще лучше, поэтому ищем Data Engineer/ETL Developer, который будет формировать логику взаимодействия с сырыми данными и их последующее преобразование в метрики для бизнес пользователей. Чем предстоит заниматься: Создавать средства взаимодействия с источниками данных, поддерживать используемые сторонние коннекторы. мплементировать логику ETL-трансформаций на Spark, PL/SQL, Hive, Impala. Поддерживать и оптимизировать существующие ETL-процессы. Создавать модели данных, удовлетворяющие потребности бизнес-заказчиков. Взаимодействовать с командами разработки с целью формирования консистентных логов и событий, достаточных для решения аналитических задач. зучать и внедрять лучшие практики разработки ПО в работу команды. Требования: Опыт работы ETL-разработчика/инженера по работе с данными. Опыт работы со Spark, Scala/Python Отличные знания в составлении запросов и трансформации данных с помощью SQL, PL/SQL. Опыт работы с системами контроля версий (Subversion, Git). Владение английским языком (чтение технической документации). Плюсом будет: Знание Hadoop-экосистем. Опыт оптимизации сложных запросов. Знакомство с продуктовой аналитикой, понимание принципов формирования продуктовых метрик. Что предлагаем Работу в аккредитованной IT-компании. Если вы из другого города, поможем с переездом. Расширенный полис ДМС. Спортзал и душевые в офисе, компенсация большей части стоимости годового абонемента сети спортклубов. Обучение: внутренние и внешние семинары, тренинги. Бесплатное питание (завтраки, ужины), компенсация обедов. Релакс-зоны с массажными креслами Yamaguchi и топовыми кофемашинами. Мы тестируем наши продукты в игровых с мощным железом и приставками. Но если хотите размяться в офлайне, у нас есть настольный теннис, хоккей и кикер. Work-life balance: приходим в офис с 9 до 10, уходим с 18 до 19.","Python,SCALA,Spark,SQL,Git",Lesta Games,
7413,77561854,Системный аналитик (продукт RU DATA),з/п не указана,1–3 года,"Полная занятость,полный день","нформационная группа «нтерфакс» - лидер российского информационного рынка в сегменте В2В. нтерфакс- также крупная IT-компания с несколькими центрами программных разработок, расположенными в Москве и регионах. Проект RU Data ищет в молодую и активно развивающуюся команду Системного аналитика. Цель проекта – разработка инструментов сбора и предоставления информации по рыночным (биржевым) инструментам и механизмов формирования отчетности (регтех). Для этого ведется разработка REST-API, COM-API, расчетных микросервисов. Чем предстоит заниматься: Сбор требований из различных источников: интервью с заказчиком, законодательные акты, работающая система и ее окружение, документация на ПО других производителей Подготовка технических заданий для разработчиков. В первую очередь для разработчиков надстройки и шаблонов Excel. Контроль исполнения (авторский надзор) Проектирование сценариев обработки биржевых, финансовых и других данных из внешних источников Разработка сценариев контроля качества данных, внедрение их в существующие и разрабатываемые системы Проектирование взаимодействия с внешними системами (интеграция) Подготовка проектной документации: Формулирование Технических требований на основе поступивших (собранных) бизнес-требований Создание и редактирование Технического задания Создание и актуализация спецификаций отдельных подсистем для внешних заказчиков Разработка иной проектной документации. Что мы ожидаем увидеть в успешном кандидате: Опыт разработки технических заданий и/или спецификаций требований на разработку ПО Уверенный пользователь Excel Опыт работы c СУБД Oracle или MS SQL, знакомство с SQL: проектирование структур данных, написание выборок (select-запросов) Понимание формата XML, JSON. Будет плюсом: Знание основ функционирования финансового рынка (ценные бумаги, биржевые торги) Опыт написания пользовательских сценариев (use-case-ов) Опыт работы с CASE-средствами (MSVisio, Erwin Data Modeler или их аналогами). Что мы готовы предложить: Возможность работать в гибридном формате или удаленно Офис в историческом центре Москвы (Маяковская, 1 мин. ходьбы от метро) Официальное оформление, ""белая"" заработная плата, график работы 5/2 с 09:30 до 18:30, но это не жестко: всегда можно договориться на более гибкий график, ДМС (включая стоматологию) Тренинги и обучение, участие в профессиональных конференциях и корпоративных мероприятия.","Системный анализ,XML,JSON,Excel,SQL",нтерфакс,
7416,79267342,Data Scientist (команда поиска и рекомендаций по RuStore),з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем специалиста по data science в команду поиска и рекомендаций по RuStore. Благодаря нашему поиску и системе рекомендаций миллионы посетителей находят в магазине приложений то, что им нужно, за пару кликов. Наша команда занимается улучшением качества поиска и рекомендаций. Мы исследуем, как можно применить современные подходы машинного обучения для ранжирования и построения ленты рекомендаций пользователей. Модели и алгоритмы, показавшие наилучшее качество, внедряются в продакшен — здесь нужно и знание С++ для получения наибольшей производительности, и понимание принципов построения высоконагруженных систем. сходные данные и аналитика обрабатывается на кластере с помощью Hadoop (Map-Reduce). спользуемый стек технологий: python, C++, java, pytorch, catboost, hadoop, clickhouse. Задачи: улучшать качество поисковой системы: разрабатывать модели и алгоритмы ранжирования делать рекомендации приложений на основе машинного обучения, в том числе персонализированные контентные рекомендации и текстовая релевантность работа с семантическими нейронными сетями. Требования: владение С++ или python знание классических алгоритмов и структур данных знание базовых алгоритмов машинного обучения опыт работы со стандартным ML-стеком (numpy, sklearn, pandas) и deep learning фреймворками (pytorch/tensorflow) знание и опыт в области современного NLP, в т.ч. знакомство с современными моделями (BERT, GPT) знание видов и подходов к разработке рекомендательных систем. Будет плюсом: опыт работы в интернет-проектах понимание пользовательских метрик качества.","Python,C++,Hadoop,PyTorch,Clickhouse,Machine learning",VK,"Москва, Аэропорт, Ленинградский проспект, 39с79"
7421,79120974,Data Base Architector,от 1 500 до 4 000 USD на руки,3–6 лет,"Полная занятость,полный день","LATOKEN is the supermarket of assets where it is easy to discover, exchange, earn and spend crypto. We are looking for Lead product developer IOS to level up our mobile app with CeDefi features for our 1.8 million mobile users. Mission: Well-structured, secure, and available DWH  Story: Product Teams need well-structured, secure, and highly available data, so product and performance data can be easily stored/accessed/analyzed Key PROBLEM's: All company data is consolidated into DWH and updated on a daily basis. How: Create new data pipelines for business need Maintain scripts and pipeline in case of problems or new requirement Constraints: All OKRs of the company are consolidated into Platform Ops All scripts are consolidated into Gitlab Main performance number: Ops OKR Health Second performance number: ClickUp Completion Rate Third performance number: Query response time, sec avg  Functions: • DWH objects audit • Queries: Advice on optimization and writing queries to databases • Automation: Automation of OKRs and slack bots for automated ops processes • Audit: Audit of DWH state and automated scripts  Requirement skills and experience: 2+ years of PostgresSQL DB administration experience 2+ years of experience writing Python scripts and applications for loading data Experience in configuring a database in a high availability architecture Experience in database optimization for different load profiles Experience in automating data loading from different sources (CRM,ERP, Web resources) * Eager to work with people with high performance standards Will be a plus Experience with financial data Experience as a data analyst.","Python,DWH,PostgresSQL,CRM,ERP",LATOKEN,
7428,77583539,TL Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Oskelly первая в России мобильная ресейл-платформа для покупки и продажи одежды и аксессуаров люксовых брендов со всего мира. На нашей платформе разгружают свой гардероб звезды кино, эстрады и спорта, предприниматели, fashion-блогеры и инфлюенсеры: Александр Рогов, Филипп Киркоров, Наташа Гольденберг, Марьяна Ро, рина Дубцова, Ната Якимчик и многие другие.Наша миссия – доказать, что мода и шопинг могут быть экологичными и этичными. Что тебе сейчас важно знать о нас? Наша команда состоит из экспертов-аутентификаторов, IT- специалистов, специалистов по работе с клиентами, маркетологов, аналитиков и многих других специалистов, которые разделяют нашу философию и полностью погружены в тематику ресейла. Каждый день мы добавляем 1000+ новых товаров на платформу Oskelly и проводим экспертизу для каждой вещи, прикрепляя сертификат подлинности к посылке. Мы в Oskelly меняем культуру потребления в России и создаем комьюнити для людей с хорошим вкусом. Чем предстоит заниматься: Выстраивание и развитие процессов обработки данных компании в облачной инфраструктуре Реализацию платформы данных и инструментария для работы аналитиков, data science Участие в формировании команды (найм, мотивация, координация) Управление командой (декомпозиция, оценка, codereview) Анализ требований и оценка реализации проектов Что мы ожидаем от вас: Опыт работы в роли Data Engineer Lead от 1 года или Senior Data Engineer от 3 лет Опыт программирования на Python или Java/Scala/Kotlin Опыт работы с ETL инструментами NiFi/AirFlow/etc Опыт работы с PostgreSQL/MySQL/MSSQL/Oracle Будет плюсом: Опыт работы с Hadoop, Spark Опыт работы с микросервисной архитектурой в разработке Опыт работы с очередями и брокерами сообщений Kafka/RabbitMQ Опыт работы с BI инструментами Tableau/Superset/Metabase/PowerBI Мы предлагаем: Оформление в соответствии с ТК РФ График работы 5/2 с 10:00 до 19:00 по Москве, c возможностью полностью работать удаленно","TypeScript,Java,Python,Spark,Hadoop,Data Science,Kafka,ORACLE,MySQL,принимать решения и за их результаты отвечать самостоятельно,Power BI",Оскели Групп,
7430,77449060,Менеджер проектов (Big Data/Retail Audit),з/п не указана,1–3 года,"Полная занятость,полный день","Платформа ОФД – крупнейший в России оператор фискальных данных Мы обслуживаем 700 тыс. клиентов - ритейлеров от мелкой розницы до крупнейших торговых сетей. Обрабатываем 50 млн. чеков в день с каждой третьей кассы в России Работаем с большим портфелем собственных инновационных продуктов, основанных на современных технологиях в области бизнес-аналитики, больших данных и машинном обучении. Развиваем аналитические сервисы, инструменты управления бизнесом и новые услуги на основе обработки массивов данных (Big Data) Приглашаем Менеджера проектов направления ритейл аудит в команду развития продуктов на больших данных. Наш проект: Бонусная программа поддержки владельцев малой розницы за продажу продукции крупных производителей и выполнения KPI (вывод на полку, расширение ассортиментной матрицы, увеличение продаж, увеличение доли продаж производителя в категории). Разработка финансово юридических схем, личного кабинета производителя и клиентов, взаимодействие с потенциальными заказчиками (производителями). Задачи: определение потребностей клиентов по поступающей информации от продаж формирование композиции решения для заказчика декомпозиция решения на задачи и постановка их в разработку через JIRA контроль сроков и качества выполнения задач проверка полученных результатов совместно с аналитиками и/или руководителем направления при необходимости помощь в описании решения в рамках договора совместно с менеджером по продажам при необходимости презентация решения заказчику Требования: Опыт работы в ритейл сегменте: производители / дистрибьюторы / сети / аналитические агентства Опыт работы проектным менеджером от 2 лет Аналитический склад ума и внимание к деталям Отличное знание MS Excel, хорошее знание MS PowerPoint знание SQL будет плюсом Условия: Работа в гибридном графике (офис/дом) Удобный офис близко от м. Спортивная/Лужники с кухней и релакс-зоной Трудоустройство по ТК РФ с первого дня и белая заработная плата ДМС (стоматология, госпитализация, скорая) за счет компании и особые тарифы для подключения родных Возможности для профессионального развития и карьерного роста","MS PowerPoint,Аналитические исследования,MS Access,Анализ данных",Платформа ОФД,"Москва, Лужники, Спортивная, Усачёва улица, 33с1"
7435,79240771,Data engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","СберАвто — уникальный для российского рынка сервис для выбора, покупки и доставки автомобилей онлайн. В СберАвто можно подобрать автомобиль, заказать независимый осмотр автомобиля и доставку авто прямо к дому, а также онлайн оформить кредит и страховку.  все это – не выходя из дома, с помощью нескольких сообщений в чате с личным помощником. Наша миссия – превратить покупку автомобиля в простой, быстрый и безопасный процесс стать единой точкой входа по всем вопросам, связанным с покупкой авто – от его выбора, проверки и покупки до страхования, оформления кредита и доставки в любой регион России. Вам предстоит: Разработка, тестирование витрин данных с использованием инструментов Hadoop и Greenplum, вывод их в промышленное использование и дальнейшая поддержка в соответствии с требованиями группы Тесное взаимодействие с командой BI-аналитики, подготовка витрин данных для построения дэшбордов Разработка интеграционных решений между хранилищем данных и ДЗО группы «Сбер». Консолидация данных по кластеру «Автоидустрия» в аналитическом слое хранилища данных Оптимизация существующих разработок: оптимизация вычислений, Refactoring, code review Ad-hock задачи Наши ожидания: Опыт программирования на Scala /Java / Python Опыт работы с инструментами Hadoop (Hive, Spark, Oozie, HDFS, YARN), понимание внутренней архитектуры Опыт работы с ведущими СУБД (PostgreSQL, Teradata, Oracle) Знание SQL на уровне оптимизации сложных запросов Знания принципов построения распределенных систем хранения и обработки данных Знание классических алгоритмов и структур данных Понимание архитектуры хранилищ данных Уверенная работа с git, bitbucket, jenkins Умение тестировать и документировать собственный код, а также работать с существующим кодом Опыт работы в Greenplum будет преимуществом Мы предлагаем: Участие в амбициозном проекте экосистемы Сбер Работу в команде профессионалов, реализацию идей по улучшению сервиса нтересные и амбициозные задачи Достойный уровень ежемесячного дохода ДМС + Стоматология Полное соблюдение ТК РФ Материальную поддержку: у нас принято финансово помогать при рождении ребенка или в сложной жизненной ситуации Скидки на фитнес, английский язык Оборудование и другие ресурсы","Big Data,SQL,Hadoop,Python,Анализ данных,Базы данных,Визуализация данных",СБЕРАВТО,
7440,79177561,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы в Space307 разрабатываем международную торговую платформу. Каждый день у нас в онлайне 255 тысяч уникальных пользователей из 100+ стран. У нас плоская структура и нет просто исполнителей. Каждый из нас — спец в своей области, и принцип работы простой: к нам приходят с проблемой, а мы отвечаем решением. Наш проект с большим количеством фич и вся разработка ведется в кросс-функциональных командах. Мы ищем коллегу, опытного Data Engineer в нашу команду. ЧТО ПРЕДСТОТ ДЕЛАТЬ?: Администрировать кластеры hadoop, vertica, k8s, clickhouse, kafka. Разрабатывать, оптимизировать и стандартизировать etl. Развивать платформу и ее части data lake, dwh. Развивать инструменты для self service аналитиков и других продуктовых команд. Писать и поддерживать сервисы для обработки данных - python ,go. МЫ ОЖДАЕМ, ЧТО ТЫ: Владеешь хотя бы одним языком программирования из списка python/go/sql на хорошем уровне. Работал с hadoop/spark. меешь опыт работы с linux(в том числе администрирование). Хорошо знаком с k8s. Работал с любой MPP базой данных. ЧТО ТЕБЯ ЖДЁТ В SPACE307: Комфорт и достойные условия: гибкий график, удалённая работа ворлдвайд и, конечно же, конкурентный уровень заработной платы Честность, прозрачность и отсутствие бюрократии Структура, в которой нет «СЕО минус четыре» — мы все равны и каждый отвечает за результат Мероприятия на любой вкус: тренинги, семинары, конференции, лекции, мастер-классы. А также тимбилдинги и корпоративы, впечатляющие своим масштабом Хакатоны, марафоны, квесты и турниры: коллеги объединяются в команды, создают крутые идеи и проекты и получают за это не менее крутые призы Настоящая команда: здесь дают честный фидбэк, приходят на помощь и болеют за результат.","Linux,Spark,SQL,DWH,Kafka,Python,ClickHouse,Hadoop,ETL",Space307,"Санкт-Петербург, Горьковская, Чкаловская, улица Кропоткина, 1"
7441,79255262,Senior Data Scientist (Rec. system),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы делаем рекомендательную систему, которая является одним из ключевых ML-сервисов в Okko. Простые задачи мы уже решили, остались интересные. Обязанности: исследование применимости различных алгоритмов в рекомендательной системе моделирование входных данных имплементация исследованных моделей. Требования: знание основ статистики понимание классических ML-алгоритмов опыт и понимание в DL (предпочтительнее pytorch) понимание процесса исследования и внедрения ML-моделей навыки презентации результатов – упрощать несущественные детали, оставляя суть способность проанализировать статьи и имплементировать описываемые алгоритмы знание SOTA в рекомендательных системах знания Python3.7+. Что мы используем: Python (sklearn, catboost, xgboost, seaborn, numpy, scipy, statsmodels) Базы данных и SQL: Trino, ClickHouse, PostgreSQL, Redis, etc. Для автоматизации процессов: Airflow, FlaskAPI/FastAPI, Python демоны BI-инструменты: Splunk Bitbucket, Jira, Confluence. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,deep learning,ML",Okko,"Москва, Баррикадная, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с13"
7442,78447491,Product Owner/Менеджер продукта (Big Data),з/п не указана,1–3 года,"Полная занятость,полный день","Лента — третий по выручке в России ритейлер (>400 млрд. руб. в год). Мы в департаменте BIG DATA Ленты строим внутренние продукты, которые зарабатывают деньги и улучшают опыт наших покупателей. BIG DATA в Ленте создана недавно и растет семимильными шагами, так что у нас есть отличные условия для карьерного и профессионального роста, а также возможность создать коммерческие продукты с высоким value для бизнеса. Мы ищем сильных продакт-менеджеров, которые помогут нам сделать удобные и полезные ML продукты. Тебя ждут следующие задачи: Формировать стратегию развития продукта и Roadmap, защищать перед бизнес заказчиками или стейкхолдерами Моделировать экономику продукта, вести P&L, а также формировать и защищать продуктовую команду для реализации стратегии, участвовать в найме команды Управлять продуктом (или группой продуктов) от этапа бизнес-потребности и MVP до его внедрения в бизнес и монетизации Лидировать продуктовые команды, состоящие из дата-инженеров, бизнес аналитика (-ов), дата-саинтистов Выстраивать взаимодействие с внутренними заказчиками и другими подразделениями Ленты/Севергрупп Выявлять потребности бизнеса, формировать и тестировать гипотезы, декомпозировать бизнес-задачи в задачи и ТЗ для каждого из членов продуктовой команды и участников рабочей группы Объяснять бизнес-логику нового решения по DS направлению бизнес-заказчикам, проводить Demo по продукту Отслеживать и улучшать продуктовые метрики Проводить AB-тесты Мы ожидаем: Подтверждаемый опыт не менее 2х лет в управлении внутренними продуктами / коммерческими продуктами / проектами в сфере IT с применением методологий agile и scrum Приветствуется технический / аналитический бэкграунд Опыт создания и управления дата продуктами (понимание построенияDSмоделей, ML Ops архитектуры, BI систем, хранилищ данных) Умения выявлять потребности бизнеса, собрать продукт, оценить требуемые ресурсы, обосновать коммерческую целесообразность и поставить грамотное техническое задание Умение презентовать результат заказчику, объяснить понятным языком нюансы D Мы предлагаем: ДМС класса Люкс со стоматологией оформление по ТК РФ возможность работать удаленно 100% времени скидка на занятия с репетитором по английскому языку скидки на фитнес, возможность заниматься корпоративным спортом (футбол, волейбол)","Agile Project Management,Scrum,Управление продуктом,Английский язык,Python","Лента, федеральная розничная сеть, IT",
7446,72740316,Quant / Data Scientist (Руководитель направления Управление рисками),з/п не указана,3–6 лет,"Полная занятость,полный день","Наши эксперты и руководители работают над глобальными проектами, создают условия для роста и успехов всех сотрудников, а также делятся совей экспертизой во внешней среде ЧЕМ ПРЕДСТОТ ЗАНМАТЬСЯ: Доработка существующих моделей оценки ипотечных ценных бумаг и связанных деривативов (python): - Развитие внутренней симуляционной OAS модели - Участие в калибровке моделей машинного обучения, описывающих поведение ипотечных пулов Участие в развитии лучших на рынке публичных инструментов оценки ЦБ: ицб.дом.рф, калькулятор.дом.рф НАШ ПОЖЕЛАНЯ К СОСКАТЕЛЮ: Образование высшее (финансово-экономическое или техническое (при наличии знаний в области экономики и финансов) Желательно наличие профессиональных сертификатов (CFA, CQF, FRM) Опыт работы на связанных с количественной аналитикой позициях в финансовой сфере Понимание принципов работы финансовых рынков, инструментов с фиксированной доходностью, деривативов на процентные ставки (желательно) Опыт разработки финансовых моделей, оценки финансовых инструментов Опыт работы с большими массивами данных, хорошее знание SQL, базовые навыки аналитического программирования (Python, R) Желательно знание Latex, Jupyter lab, а также Shell, Git, Kubernetes Хорошее знание офисного ПО (MS Excel, Word, PowerPoint), опыт в написании отчетов, навыки презентаций ЧТО МЫ ПРЕДЛАГАЕМ: Оформление в соответствии с ТК РФ, полностью белая зарплата Гибридный формат работы Конкурентный уровень заработной платы + премии по итогам работы в соответствии с утвержденными внутренними политиками Расширенная программа ДМС, включая стоматологию Компенсация абонемента в фитнес-клуб (до 70% от стоимости) Компенсация обучения английскому языку (до 50% от стоимости) Профессиональное обучение Специальные условия по кредитам и ипотеке от Банка ДОМ.РФ для сотрудников Корпоративные скидки у партнёров группы ДОМ.РФ Активная социальная жизнь (спортивные, интеллектуальные мероприятия).","SQL,Python",ДОМ.РФ,
7447,78148984,Data Engineer (Apache NiFi),з/п не указана,1–3 года,"Полная занятость,удаленная работа","ПК Digital — аккредитованная IT-компания крупнейшего в России застройщика ПК. Мы занимаемся автоматизацией всех функций компании и делаем строительную отрасль технологичной: разрабатываем системы, хранилища данных, мобильные приложения, сайты, боты. Всё это для того, чтобы создавать лучшие дома. Мы приглашаем тебя присоединиться к нашей команде в роли Data Engineer (Apache NiFi). Команда управления НС занимается развитием MDM-систем, управлением качеством данных и внедрением новых решений для бизнеса. Предстоит разрабатывать и поддерживать ETL процессы для загрузки и преобразования разнородных данных, реализовывать отдельные компоненты для расширения функций MDM-системы. Твои будущие задачи: Проектировать и разрабатывать dataflow: извлечение, трансформации и записи данных Разрабатывать и конфигурировать элементы данных из СУБД,REST, ESB,S3 Разрабатывать маппинг и преобразование данных к требуемому формату (JOLT,XSLT) Разрабатывать dataflow элементов отладки (logging) и уведомлений (email,telegramm) Диагностировать и исправлять проблемы ETL dataflow Писать правила валидации JSON схем поступающих данных Писать тесты для отладки и проверки dataflow Анализировать постановку задач на обработку данных со стороны аналитиков Взаимодействовать с заинтересованными лицами по детализации требований и сбору необходимой информации для успешной реализации задачи Реализовать алгоритмы контроля качества данных Формулировать диаграммы dataflow Справиться с задачами поможет: Опыт работы c ETL (NIFI или Informatica или Airflow или Spoon или другие) Знание и навыки использования следующих процессоров: Execute SQL/Execute SQL, Record, Invoke HTTP, PutDatabase Record, HandleHttpRequest/HandleHttpResponse Уверенные знания SQL Понимание XML,REST API,SOAP Опыт работы с данными в формате JSON (схемы, преобразование) Понимание принципов работы с очередями (RabbitMQ,Kafka) Опыт использования WEB API Знание Python или Java на уровне от junior Знание основ Linux систем Мы предлагаем: Быстрый рост и развитие Система адаптации — за новичком закрепляется ментор Home office из любой точки. По желанию можно приехать в офис, если ты в Москве (м. Баррикадная) Электронная библиотека от МФ Официальное трудоустройство, годовой бонус Скидки и бонусы от партнёров по программе лояльности: спорт, обучение, путешествия, сервисы ПК","ETL,SQL,NIFI",ПК,
7452,79179362,Data Engineer в Практикум,з/п не указана,3–6 лет,"Полная занятость,гибкий график","Яндекс Практикум — это образовательный сервис, который помогает людям освоить профессию с нуля или приобрести навыки, чтобы преуспеть в текущей. Главная ценность для нас — успех наших студентов, который подтверждают наши исследования. Команда дата-инженеров разрабатывает, эксплуатирует и развивает аналитическую инфраструктуру, которая помогает принимать решения другим командам Практикума. У нас атмосфера стартапа, мы много экспериментируем, работаем с гипотезами и непрерывно улучшаем внутренние процессы. Стремимся применять лучшие практики в инженерии данных, минимизировать toil work и автоматизировать процессы эксплуатации. Что нужно делать: заниматься инфраструктурой обработки данных для аналитики и пользовательских сервисов проектировать и создавать витрины данных из «сырых» продуктовых источников и внешних API настраивать эффективное обновление данных развивать логическую архитектуру DWH для удобной работы аналитиков отвечать за стабильность и надежность DWH и улучшать их формулировать требования для новых источников данных и встраивать их в существующие модели агрегаторов данных. Мы ждем, что вы: больше трёх лет работали инженером данных работали со специализированными аналитическими базами данных Greenplum, Vertica, ClickHouse, Teradata работали с AWS, PostgreSQL пишете на Python или Go чистый оптимальный код, который легко поддерживать и тестировать, или хотите этому научиться покрываете свой код тестами разрабатывали ETL-процессы хорошо знаете SQL и понимаете устройство реляционных баз данных проектировали витрины для дашбордов готовы принимать решения и отвечать за них хотите строить нагруженные системы и понимаете, как это делать понимаете принципы отказоустойчивости и масштабирования сервисов. Условия: участие в развитии социально-значимого образовательного сервиса интересные задачи, возможность влиять на процессы и видеть результаты своей работы гибкий график возможность работать удалённо или из офиса премии каждые полгода для всех, кто успешно прошёл ревью расширенная программа ДМС (со стоматологией) и оплата 80% стоимости ДМС для супругов и детей компенсация оплаты питания и мобильной связи программы жилищных займов для сотрудников под 3% или без процентов оплата обучения и участия в профильных конференциях тренажёрный зал, массаж и капсула для сна в офисе скидки у партнёров компании.","Python,SQL,PostgreSQL,ClickHouse,Teradata,Базы данных,DWH,Data Analysis",Яндекс,
7461,79281902,Data Engineer (Комплаенс),з/п не указана,1–3 года,"Полная занятость,полный день","Команда занимается развитием платформы данных Комплаенс. В задачи команды входят: аналитика источников и подготовка технических требования на их использование разработка витрин данных для построения отчетности, исследований и интеграционных потоков снабжение данными процессов Комплаенс внедрение прогнозных моделей разработка отчетных форм мониторинг процессов передачи данных В задачи сотрудника будет входить: разработка механизмов и объектов для хранения данных, аналитика данных в источниках (исследование, проектирование и разработка модели данных и хранилищ и витрин данных, механизмов наполнения хранилищ из источников данных, разработка enterprise решений). Так же потребуется написание unit-тестов на разработанный функционал (где применимо). Функционал: загрузка источников Комплаенс в ядро Облака данных подготовка данных для аналитиков разработка витрин данных автоматизация расчёта витрин и моделей данных интеграция с потребителями рассчитанных значений визуализация данных Комплаенс (аналитическая отчётность). Ожидаемые знания и умения: Hadoop, ANSI SQL, PL/SQL, PL/pgSQL, Java, Python, ETL владение SQL навыки проектирования баз данных знания в области мат. статистики навыки разработки на Java или Python умение документировать разработку. Дополнительно: опыт построения интеграционных решений знание Scala,брокеров сообщений, ETL-инструментов, в том числе IPC будет плюсом. Условия: Конкурентная оплата труда + бонусы по результатам работы Возможность посещения всероссийских и международных IT-конференций Профессиональное развитие: тренинги, митапы, мастер-классы, изучение английского языка не выходя из офиса, доступ к различным образовательным платформам ДМС и страховка от несчастных случаев, льготные условия для близких родственников Льготные предложения от компаний-партнеров, корпоративные условия от ведущих фитнес-клубов и многое другое Офис в бизнес центре “Даниловская мануфактура”. Шаговая доступность от МЦК Верхние котлы, станции метро Тульская или офис метро Кутузовская, 7 мин пешком. Корпоративный транспорт, парковка для сотрудников.","SQL,Java,Python,hadoop,QlikView,Английский — A1 — Начальный",Сбер. IT,
7465,67996180,Senior Data engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы находимся в поиске Ведущего Data engineer'a, который будет заниматься развитием направлений: ""Цифровая аналитика"", ""Антифрод"", "" Платформа DataLake"". Ваши задачи: Реализация ETL в Hadoop (с помощью Airflow) Работа с различными источниками данных: Oracle, MS SQL, API личных кабинетов, микросервисы Батч и стримы с помощью PySpark и Kafka Подготовка витрин для анализа (Hive + Spark+ SQL) Наш стек: Ванильный hadoop Kafka Spark Airflow ClickHouse Jira ,Confluence GitLab Мы ждем от будущих коллег: Уверенное владение Python Опыт использования эко-системы Hadoop: HDFS, Apache AirFlow, Hive, Kafka,Spark Знание SQL Опыт работы с реляционными базами данных (Oracle)","Data Engineer,Python,SQL,Hadoop,ORACLE","Компания «СПОРТМАСТЕР», Sportmaster Lab",
7469,79255519,Data Scientist middle+/senior (Транскодинг),з/п не указана,3–6 лет,"Полная занятость,полный день","Сейчас в Okko создается новый продукт – Видеоплатформа. Это B2B-инструмент для работы с видеоконтентом. Ключевое значение для разработки продукта имеют обработка видео (транскодинг) и оптимизация процессов, связанных с ней. В команду транскодинга мы ищем человека, который сможет сформировать и вывести ML-решения для улучшения продукта, а также найдет баланс между математическими способами решения задач и ML. Обязанности: исследование применимости различных алгоритмов в рекомендательной системе и в системах с применением компьютерного зрения моделирование входных данных интеграция исследованных моделей в системах проведение экспериментов с созданными моделями автоматизация процессов подготовки данных оптимизация потребления ресурсов сервисами, а также повышение утилизации ресурсов и применения ML интеграция сервисов с распределенными системами (Базы данных, Очереди). Требования: высшее техническое/математическое образование знание математической статистики и высшей математики критичны для решения наших задач умение инициализировать новое направление от идеи и построения инфраструктуры до вывода решения в прод для конечных пользователей знание основ статистики понимание классических ML-алгоритмов способность анализировать статьи и имплементировать описываемые алгоритмы базовые знания о Сomputer Vision знание Python желателен опыт работы с видео, изображениями, с рекомендательными системами. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,Machine learning,Сomputer Vision",Okko,"Санкт-Петербург, Беговая, улица Савушкина, 126Б"
7470,79255243,"Data Engineer (""Платформа экспериментов"")",з/п не указана,3–6 лет,"Полная занятость,полный день","A/B эксперименты – ключевой инструмент для принятия решений в компании Okko. Все гипотезы мы проверяем через эксперименты. Сейчас наш бизнес довольно быстро растёт, растёт и количество запускаемых экспериментов, которые нужно качественно и быстро анализировать. Во многом от того, насколько точно будут проанализированы эксперименты, зависят принимаемые решения и, как следствие, будущее нашего бизнеса. Если ты понимаешь, что соответствуешь требованиям и веришь в то, что вместе мы сможем построить лучшую платформу экспериментов на рынке СНГ, откликайся на вакансию! щем коллегу, который энергично погрузится в тонкости работы экосистемы данных в Okko и поможет в решении следующих задач: внедрение ETL-процессов на Airflow участие в проектировании горячего и холодного хранилища для платформы эксперименты участие в построении DWH участие в проектировании модели данных администрирование существующих BI-инструментов Что мы используем: Clickhouse, PostgreSQL, Trino, AWS, SberCloud Python и основные ML библиотеки: Pandas, NumPy, SciPy, Scikit-Learn. Требования: уверенное знание Clickhouse, Postgres, HDFS знание Python понимание, чем отличается data vault, якорная модель, снежинка, звезда опыт работы с kafka умение организовывать ETL-процессы опыт построения DWH опыт проектирования модели данных опыт работы с большими объемами данных умение работать в командной строке Unix-систем. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,ETL,dwh",Okko,"Москва, Баррикадная, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с13"
7474,79255279,Senior Data Scientist (Rec. system),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы делаем рекомендательную систему, которая является одним из ключевых ML-сервисов в Okko. Простые задачи мы уже решили, остались интересные. Обязанности: исследование применимости различных алгоритмов в рекомендательной системе моделирование входных данных имплементация исследованных моделей. Требования: знание основ статистики понимание классических ML-алгоритмов опыт и понимание в DL (предпочтительнее pytorch) понимание процесса исследования и внедрения ML-моделей навыки презентации результатов – упрощать несущественные детали, оставляя суть способность проанализировать статьи и имплементировать описываемые алгоритмы знание SOTA в рекомендательных системах знания Python3.7+. Что мы используем: Python (sklearn, catboost, xgboost, seaborn, numpy, scipy, statsmodels) Базы данных и SQL: Trino, ClickHouse, PostgreSQL, Redis, etc. Для автоматизации процессов: Airflow, FlaskAPI/FastAPI, Python демоны BI-инструменты: Splunk Bitbucket, Jira, Confluence. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,deep learning,ML",Okko,
7477,79255076,"Data Engineer (""Платформа экспериментов"")",з/п не указана,3–6 лет,"Полная занятость,полный день","A/B эксперименты – ключевой инструмент для принятия решений в компании Okko. Все гипотезы мы проверяем через эксперименты. Сейчас наш бизнес довольно быстро растёт, растёт и количество запускаемых экспериментов, которые нужно качественно и быстро анализировать. Во многом от того, насколько точно будут проанализированы эксперименты, зависят принимаемые решения и, как следствие, будущее нашего бизнеса. Если ты понимаешь, что соответствуешь требованиям и веришь в то, что вместе мы сможем построить лучшую платформу экспериментов на рынке СНГ, откликайся на вакансию! щем коллегу, который энергично погрузится в тонкости работы экосистемы данных в Okko и поможет в решении следующих задач: внедрение ETL-процессов на Airflow участие в проектировании горячего и холодного хранилища для платформы эксперименты участие в построении DWH участие в проектировании модели данных администрирование существующих BI-инструментов Что мы используем: Clickhouse, PostgreSQL, Trino, AWS, SberCloud Python и основные ML библиотеки: Pandas, NumPy, SciPy, Scikit-Learn. Требования: уверенное знание Clickhouse, Postgres, HDFS знание Python понимание, чем отличается data vault, якорная модель, снежинка, звезда опыт работы с kafka умение организовывать ETL-процессы опыт построения DWH опыт проектирования модели данных опыт работы с большими объемами данных умение работать в командной строке Unix-систем. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,ETL,dwh",Okko,"Санкт-Петербург, Беговая, улица Савушкина, 126Б"
7481,79155981,Data Engineer (remote),от 200 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Кто мы: BestDoctor — экосистема медицинских и страховых сервисов, созданная экспертами для удобного управления здоровьем. Мы меняем рынок медицинского страхования и отношение людей к своему здоровью с помощью качественного сервиса и принципиально нового клиентского опыта. Благодаря глубокой экспертизе в создании медицинских решений и любви к своему делу, нам удалось создать ту самую экосистему полезных, эффективных и, главное, простых медицинских сервисов для управления здоровьем компаний и людей. Чего мы достигли:  За семь лет мы вышли на второе место по числу клиентов среди insurtech компаний в Европе. Сегодня с нами уже 100 000+ застрахованных пользователей (40 000 из них мы подключили в 2021 году), а в списке клиентов — Мегафон, Aviasales, МТС Банк, Нетология, InDriver, Эвотор, Ivi.ru, Ostrovok.ru, VC.ru и еще 140 компаний.  Создали экосистему медицинских сервисов, которая включает: сервис онлайн-поддержки 24/7, сервис онлайн записи в оффлайн клинику, своя виртуальная клиника, сервис второго мнения специалиста, чекапы, сервис поддержки психологов и др. Наша следующая цель — сделать все продукты, входящие в экосистему BestDoctor, мультисервисными, разработать подбор индивидуальных программ, создать возможность управлять бюджетом, улучшить HR-кабинет и умную маршрутизацию каждого сотрудника для B2B сегмента.  для этого ищем лучших экспертов, чтобы вместе захватить рынок. Подробнее о сервисе BestDoctor: https://bestdoctor.ru/ и https://hh.ru/article/29681 О проекте: За время существования компании мы накопили много данных и разных инструментов аналитики. На этих данных мы строим предложения для новых клиентов и продлеваем старых, проводим переговоры с клиниками и непосредственно помогаем нашим пациентам. Главная задача - весь этот информационный поток перенести в чётко организованную систему сбора, обработки и анализа данных любого объёма. Сейчас мы планируем вести сборку data lake house на базе GreenPlum, куда будут сливаться данные всех источников, таких как, PostgreSQL, Yandex,Google drive, сторонние API и др.). Мы мигрируем туда с Postgres+Astroniomer. Также у нас будет большой проект с фичастором и MLFLOW. В твоих задачах будет много архитектуры и хорошего продакшн кода, перенос, рефакторинг старого и написание очень динамического и автоматизированого нового, а также опыт с очень крутым датасайнсом, аналитикой и продуктом. В целом, тебе предстоит: Мигрировать даги с Airflow c Астрономера на Кубер Развивать и оптимизировать GreenPlum(PXF) даги Пилить Data Managment нового поколения нтегрировать сторонние API. Что для нас важно: Опыт программирования на Python 3 Опыт работы с Airflow Отличные знания и опыт работы с SQL. Опыт работы с GreenPlum и PostgreSQL Дополнительным плюсом будет: Опыт работы с Apache Kafka Навыки в DevOps / опыт работы с Docker Опыт работы с Apache Spark Опыт работы с хранилищами (DataVault Anchor LakeHouse FeatureStore) Как мы нанимаем: Мы готовы оперативно выходить с оффером, если понимаем, что подходим друг другу. 1 этап - телефонное интервью с HR (15-20 минут) 2 этап - техническое интервью с лидом аналитики 3 этап - финальное интервью с CDO и HR. Почему с нами круто: Мы меняем рынок медицинского страхования, и у нас это отлично получается В нас поверили и проинвестировали топовые венчурные фонды в России: российский Winter Capital, шведский VNV Global и австрийская страховая компания Uniqa Удаленный формат работы (будем рады тебя видеть у нас в офисе (м.Савёловская) У нас гибкий график работы, который подойдет как жаворонку, так и сове Тебя будет окружать команда талантливых и мотивированных людей Мы предоставим тебе ноутбук и всю необходимую технику, которая позволит эффективно и комфортно работать Медицинское обслуживание через систему BestDoctor.  Ты будешь частью большого социально значимого дела. Мы реализуем амбициозную задачу — меняем рынок здравоохранения, действительно помогаем людям, и у нас это отлично получается.  у тебя получится!","PostgreSQL,Python,SQL,AirFlow,GreenPlum",BestDoctor,
7482,76221565,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Привет! Мы — Кошелёк, приложение, которое заменяет бумажник с пластиковыми картами. Каждый день наша команда решает сложные задачи, чтобы покупки миллионов людей были проще. Наши партнёры — торговые сети, банки и платёжные системы, а ещё мы занимаемся разработкой платёжных сервисов, с помощью которых Кошелёк превращается в универсальный инструмент для выгодного шоппинга. Ежемесячно Кошельком пользуется 12,5 миллионов человек, в том числе наши друзья, родные и близкие.  это далеко не предел! Присоединяйся к команде Кошелька и меняй мир покупок вместе с нами! В Кошельке мы собираем и анализируем много разной информации. В данный момент у нас около 30 TB сжатых сырых данных и мы активно растем. У нас полностью потоковая обработка событий в реальном времени и хранилище в Яндекс Облаке. Активно интегрируемся в экосистему ""Тинькофф"". Чем предстоит заниматься: Всего у команды инженеров данных в нашей компании есть три направления работы: 1) нфраструктура. Это поддержка всех наших серверов, сервисов и инструментов. Сейчас у нас используются ClickHouse, Greenplum и MSSQL (постепенно отказываемся). Потоковая обработка событий с использованием RabbitMQ, Kafka и Flink. Сырые данные мы храним в Yandex Object Storage, а обрабатываем в Airflow. Кроме того, есть и PowerBI, и Metabase, и Zeppelin, и Jupyter. Нужно следить за тем, чтобы это все работало и улучшать. 2) Data Pipelines. Управление потоками данных, наполнение Data Lake и DWH, создание детального слоя и витрин. Для этого используются Kafka, Flink и Airflow. 3) Автоматизация работы аналитиков. Сюда входит создание скриптов и инструментов, которые помогают автоматизировать рутинные задачи. Что мы ждём от вас: Свободное владение SQL (на уровне оптимизации запросов) Опыт коммерческой разработки (предпочтительно на Python/Java) Опыт работы с потоками данных и их загрузкой (ETL, батчи, потоковая обработка) Опыт работы с MPP хранилищами (предпочтительно Greenplum и ClickHouse) Понимание принципов работы Big Data стека Желателен опыт с Airflow, Flink и Kafka. Со своей стороны предлагаем: возможность делать приложение, которым пользуется каждый четвёртый житель России работу с сильной инженерной командой оформление по ТК РФ с первого дня работы, конкурентную белую зарплату ДМС со стоматологией и оплату мобильной связи помощь с переездом для кандидатов из других городов (welcome бонус) гибкий график, возможность гибридной или полностью удалённой работы оплату профильных курсов и конференций спорт пять раз в неделю в офисе — йога, зумба, растяжка и силовые тренировки командные мероприятия, экскурсии и тимбилдинги мы регулярно проводим тематические митапы с экспертами, внутренние лекции для сотрудников, а также готовы инвестировать в профильное обучение и развитие сотрудников.","DWH,Big Data,ETL,Java,Python,ClickHouse,Greenplum,Airflow,Английский — B1 — Средний",Приложение «Кошелёк»,"Санкт-Петербург, Чкаловская, Лодейнопольская улица"
7484,79155951,Data Engineer (remote),от 200 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Кто мы: BestDoctor — экосистема медицинских и страховых сервисов, созданная экспертами для удобного управления здоровьем. Мы меняем рынок медицинского страхования и отношение людей к своему здоровью с помощью качественного сервиса и принципиально нового клиентского опыта. Благодаря глубокой экспертизе в создании медицинских решений и любви к своему делу, нам удалось создать ту самую экосистему полезных, эффективных и, главное, простых медицинских сервисов для управления здоровьем компаний и людей. Чего мы достигли:  За семь лет мы вышли на второе место по числу клиентов среди insurtech компаний в Европе. Сегодня с нами уже 100 000+ застрахованных пользователей (40 000 из них мы подключили в 2021 году), а в списке клиентов — Мегафон, Aviasales, МТС Банк, Нетология, InDriver, Эвотор, Ivi.ru, Ostrovok.ru, VC.ru и еще 140 компаний.  Создали экосистему медицинских сервисов, которая включает: сервис онлайн-поддержки 24/7, сервис онлайн записи в оффлайн клинику, своя виртуальная клиника, сервис второго мнения специалиста, чекапы, сервис поддержки психологов и др. Наша следующая цель — сделать все продукты, входящие в экосистему BestDoctor, мультисервисными, разработать подбор индивидуальных программ, создать возможность управлять бюджетом, улучшить HR-кабинет и умную маршрутизацию каждого сотрудника для B2B сегмента.  для этого ищем лучших экспертов, чтобы вместе захватить рынок. Подробнее о сервисе BestDoctor: https://bestdoctor.ru/ и https://hh.ru/article/29681 О проекте: За время существования компании мы накопили много данных и разных инструментов аналитики. На этих данных мы строим предложения для новых клиентов и продлеваем старых, проводим переговоры с клиниками и непосредственно помогаем нашим пациентам. Главная задача - весь этот информационный поток перенести в чётко организованную систему сбора, обработки и анализа данных любого объёма. Сейчас мы планируем вести сборку data lake house на базе GreenPlum, куда будут сливаться данные всех источников, таких как, PostgreSQL, Yandex,Google drive, сторонние API и др.). Мы мигрируем туда с Postgres+Astroniomer. Также у нас будет большой проект с фичастором и MLFLOW. В твоих задачах будет много архитектуры и хорошего продакшн кода, перенос, рефакторинг старого и написание очень динамического и автоматизированого нового, а также опыт с очень крутым датасайнсом, аналитикой и продуктом. В целом, тебе предстоит: Мигрировать даги с Airflow c Астрономера на Кубер Развивать и оптимизировать GreenPlum(PXF) даги Пилить Data Managment нового поколения нтегрировать сторонние API. Что для нас важно: Опыт программирования на Python 3 Опыт работы с Airflow Отличные знания и опыт работы с SQL. Опыт работы с GreenPlum и PostgreSQL Дополнительным плюсом будет: Опыт работы с Apache Kafka Навыки в DevOps / опыт работы с Docker Опыт работы с Apache Spark Опыт работы с хранилищами (DataVault Anchor LakeHouse FeatureStore) Как мы нанимаем: Мы готовы оперативно выходить с оффером, если понимаем, что подходим друг другу. 1 этап - телефонное интервью с HR (15-20 минут) 2 этап - техническое интервью с лидом аналитики 3 этап - финальное интервью с CDO и HR. Почему с нами круто: Мы меняем рынок медицинского страхования, и у нас это отлично получается В нас поверили и проинвестировали топовые венчурные фонды в России: российский Winter Capital, шведский VNV Global и австрийская страховая компания Uniqa Удаленный формат работы (будем рады тебя видеть у нас в офисе (м.Савёловская) У нас гибкий график работы, который подойдет как жаворонку, так и сове Тебя будет окружать команда талантливых и мотивированных людей Мы предоставим тебе ноутбук и всю необходимую технику, которая позволит эффективно и комфортно работать Медицинское обслуживание через систему BestDoctor.  Ты будешь частью большого социально значимого дела. Мы реализуем амбициозную задачу — меняем рынок здравоохранения, действительно помогаем людям, и у нас это отлично получается.  у тебя получится!","PostgreSQL,Python,SQL,AirFlow,GreenPlum",BestDoctor,
7485,67984722,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура • Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных • Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем Возможность работы в аккредитованной Т-компании Работу в офисе. График работы — гибридный Платформу обучения и развития Тинькофф Апгрейд. Курсы, тренинги, вебинары и базы знаний. Поддержка менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Компенсацию такси и 50% затрат на спорт от стоимости абонемента Компенсацию обедов. А если захотите перекусить, есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,Работа с базами данных,ETL,Базы данных,DWH,СУБД,Databases",Тинькофф,"Санкт-Петербург, Площадь Александра Невского 1, Херсонская улица, 12-14"
7492,73888455,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура • Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных • Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем Возможность работы в аккредитованной Т-компании Работу в офисе у метро «Водный стадион». График работы — гибридный Платформу обучения и развития Тинькофф Апгрейд. Курсы, тренинги, вебинары и базы знаний. Поддержка менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Бесплатный фитнес-зал Tinkoff Sport. Тренируйтесь, посещайте групповые программы, грейтесь в сауне и участвуйте в спортивных турнирах Бесплатные обеды в Tinkoff Cafe. А если захотите перекусить, на каждом этаже есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,Работа с базами данных,ETL,Базы данных,DWH,СУБД",Тинькофф,
7493,79261592,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Команда Axenix (ex-Accenture) продолжает работу на российском рынке и аккумулирует 30-ти летний консалтинговый опыт внедрения инновационных решений. Наша экспертиза - стратегия и консалтинг, технологии и операции, направленные на цифровизацию бизнеса. В России мы работаем в офисах в Москве, Твери и Ростове-на-Дону, а также удаленно. Постоянно обмениваемся опытом и экспертизой. На данный момент мы ищем Data Engineer в команду Data&AI. Чем Вы будете заниматься? Настройка и модификация конфигурационных файлов при подключении нового источника или изменении уже подключённого Создание соответствующего дистрибутива Установка дистрибутива на ДЕВ/ПС/ПРОМ стендах Тестирование, ПС, вывод в ПРОМ. Что мы ожидаем от кандидата: Oracle GoldenGate. Знакомство с принципами работы сервиса Apache Hadoop. Понимание на уровне теории (в т.ч. распределённое хранение данных), минимальный опыт работы с HDFS через консоль Linux или HUE Apache HBase. Понимание, что собой представляет собой NO-SQL база данных, принцип работы Основы работы с реляционными БД. SQL – на уровне junior аналитика данных Apache Kafka. Принципы работы Linix, GIT - практический опыт. Мы предлагаем: Возможность профессионального и карьерного роста Гибридный/удаленный формат работы Конкурентоспособный уровень дохода и регулярное повышение по результатам Performance Review ДМС с первого дня работы, включая стоматологию, в лучших клиниках для тебя, твоего партнера и детей до 18 лет Страхование жизни в размере годового оклада Дополнительные 5 дней оплачиваемого отпуска в год Ежемесячная денежная компенсация на питание Программа корпоративных привилегий PrimeZone (более 1000 ведущих поставщиков продуктов и услуг) Возможность обучения и сертификации за счет компании.",,Axenix (ранее Accenture),
7501,77720409,нженер данных / Data Engineer,з/п не указана,1–3 года,"Полная занятость,удаленная работа","В команду разработки ищем инженера данных. Команда выполняет одну из ключевых функций в компании, развивая следующие решения: - Единый «узел» для интеграционных решений инфраструктуры - Хранилище данных для аналитических задач компании - Кубы данных (MDX) как self-service инструмент для сотрудников. Каждое решение встраиваем в систему контроля качества данных. Обмениваемся опытом, вместе осваиваем на практике новые технологии и инструменты. Возможность удаленки или работы из офиса А-класса. Ваши задачи: Разработка SQL скриптов. Анализ и доработка чужого кода Подготовка ETL/ELT пакетов для загрузки данных Развитие и сопровождение контроля качества данных Документация разрабатываемых продуктов Развитие и сопровождение MDX кубов. Мы ожидаем: Опыт работы от 1 года на позициях SQL разработчика, аналитика или инженера данных Знание TSQL, DML Умение анализировать и доработать чужой код Знание основ построения хранилищ данных Знание любого языка программирования (желательно Python). Мы предлагаем все, что есть в стабильной компании: Трудоустройство в нашу дочернюю аккредитованную IT-компанию со всеми полагающимися льготами Стабильный и прозрачный доход: размер заработной платы обсуждается по итогам собеседования Премия по результатам работы за квартал Сокращенный рабочий день в пятницу ДМС после успешного прохождения испытательного срока Возможность удаленной работы. ... и даже немного больше: Развиваем наших сотрудников с помощью профильных курсов, тренингов, мастер-классов, лекций и курсов для прокачки soft-skills Предлагаем инструменты для самообучения: онлайн библиотека, онлайн платформа K-AMPUS Поможем легче адаптироваться и успешно пройти испытательный срок с закрепленным наставником Опытные и вовлеченные коллеги, готовые оказать поддержку в любой ситуации Возможность проявлять инициативу, воплощать свои идеи и привносить свой вклад в развитие транспортно-логистической отрасли.","Transact-SQL,SQL,Python,DML",НефтеТрансСервис,
7502,67984755,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура • Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных • Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем Возможность работы в аккредитованной Т-компании Работу в офисе. График работы — гибридный Платформу обучения и развития Тинькофф Апгрейд. Курсы, тренинги, вебинары и базы знаний. Поддержка менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Компенсацию такси и 50% затрат на спорт от стоимости абонемента Компенсацию обедов. А если захотите перекусить, есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,Работа с базами данных,ETL,Базы данных,DWH,СУБД,Databases",Тинькофф,"Ростов-на-Дону, улица Суворова, 91"
7513,76402191,Разработчик Hadoop Big Data (стрим Витрины ПК),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Вместе с нами ты будешь: Проектирование и разработка SQL-процедур, обработчиков данных на Spark (Scala) и ETL-процессов (в т.ч. AirFlow) Оптимизация производительности кода Разработка и ведение схемы данных Участие в проведении тестирований Взаимодействие с аналитиками, командами развития платформ, DevOps инженерами Развитие wiki в Confluence Какие знания и навыки для нас важны: Опыт работы с инструментарием Hadoop (HDFS, Yarn, Spark, Hive) Опыт работы с промышленными DWH на основе MPP СУБД (Teradata, Exadata, Greenplum), от 2-х лет Знание теории построения DWH ETL - практический опыт проектирования и разработки регламентных потоков данных при помощи Airflow SQL - уверенные знания (DML,DDL), опыт разработки хранимых процедур Опыт работы с библиотекой Pandas Опыт работы с Impala Понимание принципов и инструментария CI/CD (Git/Bitbucket, Teamcity)","SQL,Hadoop,Spark,Hive,SCALA","ннотех, Группа компаний",
7520,76671592,Разработчик Hadoop Big Data (стрим Витрины ПК),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Вместе с нами ты будешь: Проектирование и разработка SQL-процедур, обработчиков данных на Spark (Scala) и ETL-процессов (в т.ч. AirFlow) Оптимизация производительности кода Разработка и ведение схемы данных Участие в проведении тестирований Взаимодействие с аналитиками, командами развития платформ, DevOps инженерами Развитие wiki в Confluence Какие знания и навыки для нас важны: Опыт работы с инструментарием Hadoop (HDFS, Yarn, Spark, Hive) Опыт работы с промышленными DWH на основе MPP СУБД (Teradata, Exadata, Greenplum), от 2-х лет Знание теории построения DWH ETL - практический опыт проектирования и разработки регламентных потоков данных при помощи Airflow SQL - уверенные знания (DML,DDL), опыт разработки хранимых процедур Опыт работы с библиотекой Pandas Опыт работы с Impala Понимание принципов и инструментария CI/CD (Git/Bitbucket, Teamcity)","SQL,Hadoop,Spark,Hive,SCALA","ннотех, Группа компаний",
7529,79174830,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем Возможность работы в аккредитованной Т-компании Работу в офисе. График работы — гибридный Профессиональное развитие. Вы получите доступ к библиотеке с технической литературой, тренингами и мастер-классами для сотрудников Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Компенсацию такси, парковки и 50% затрат на спорт от стоимости абонемента Компенсацию обедов. А если захотите перекусить, на каждом этаже есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,ETL,Greenplum",Тинькофф,"Самара, проспект Карла Маркса, 201Б"
7530,79260554,Data Engineer/ETL-developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Международный холдинг «ЕвроХим» специализируется на производстве минеральных удобрений. «ЕвроХим» - это 26 000 человек, 25 стран, 75 предприятий.  В направлении R&D компании АО «МХК «ЕвроХим» открыта вакансия ""Backend Developer"". Основная задача данной позиции - разработка ETL-сервисов для направления по повышению операционной эффективности действующих производств и предприятий за счет применения цифровых технологий (ндустрия 4.0). Глобальная цель направления – реализация полномасштабной программы по внедрению на предприятиях группы компаний лучших научных, технических и цифровых решений и их взаимная интеграция.  Обязанности: Разрабатывать ETL-процессы и фреймворки по загрузке данных в Data Lake и формировать витрины данных Проектировать модели витрин данных в DWH Разрабатывать процессы применения алгоритмов продвинутой аналитики сследовать и анализировать информационные потоки и данные Разрабатывать сервисы управления процессами загрузки и схемы подключения новых источников данных в Data Lake Документировать свою работу в Confluence. Требования: Наличие опыта: Python, Apache Kafka, Airflow, Nifi. ETL Опыт работы с «классической» РСУБД в качестве разработчика: знание SQL на продвинутом уровне, опыт оптимизации запросов Будет плюсом опыт работы с не реляционными СУБД или БДВР Опыт разработки и внедрения систем класса DWH, понимание концепции распределенных высоконагруженных систем хранения и обработки данных Опыт в разработке сложных ETL процессов и их автоматизации Опыт работы с оркестратором Apache Airflow или Apache NiFi Понимание принципов работы с потоковым данными (Apache Kafka) Умение писать код на Python. Условия: Оформление c первого рабочего дня в аккредитованную Т-компанию в соответствии с нормами ТК РФ, социальные гарантии Крупные проекты в компании–лидере отрасли Возможность модернизировать процессы реального производственного бизнеса в команде сильнейших экспертов Полис ДМС (включая стоматологию) Удаленная работа Доступ к корпоративной OnLine библиотеке Обучение в программах Корпоративного университета Корпоративный спорт, конференции, культурные мероприятия.","DWH,СУБД,Big Data,Базы данных,ETL,SQL,Python,ООП,Kafka,Spark,Apache Kafka,Numpy,Алгоритмы,Confluence,Linux","ЕвроХим, Минерально-Химическая Компания",
7535,79174743,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем Возможность работы в аккредитованной Т-компании Работу удаленно Платформу обучения и развития Тинькофф Апгрейд. Курсы, тренинги, вебинары и базы знаний. Поддержка менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Компенсацию 50% затрат на спортивные занятия от стоимости абонемента Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,ETL,Greenplum",Тинькофф,"Уфа, улица Гоголя, 60"
7541,79127171,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Контур — экосистема для бизнеса. Наши сервисы помогают тратить меньше времени на рутину, делают общение с контрагентами и госорганами проще и прозрачнее. У нас продуктовая разработка: 121 команда развивает как внутренние сервисы, которые приносят пользу внутри Контура, так и продукты для наших клиентов. У нас есть команда, которая разрабатывает инфраструктурный сервис Контур.Метрика. м пользуются разработчики, аналитики, менеджеры разработки, маркетологи и все, кто принимает решения на основе данных. Ребята любят исследовать и внедрять новые подходы, всегда открыты для идей и улучшений. Команда растет и ищет опытного Data Engineer'a. Задачи 1. Настраивать, поддерживать и развивать ETL-процессы (AirFlow и наша инфраструктура для настройки потоков). 2. Лидить зону Airflow: внедрять новые подходы, стандарты, драйвить изменения, работать над бэклогом, понимать потребности пользователей, предлагать решения. 3. Писать конвертеры и адаптеры в нашей инфраструктуре по настройке потоков. 4. Проводить ревью кода аналитиков данных. Стек Python, Airflow, Kubernetes, Redash C#, Net Core, Docker, Gitlab CI, Ansible, Git Octopus, Teamcity, Moira, Graphite, Grafana, YouTrack Singular, Vault MS SQL, ClickHouse. Мы предлагаем много интересных задач, современные технологии и инструменты, есть пространство для проверки гипотез и экспериментов свободу для развития в смежных областях (девопс, дата-аналитика) быструю обратную связь от пользователей и внутренних заказчиков: сразу видно, как можно влиять на жизнь Контура комьюнити опытных python-разработчиков, внутренние митапы и конференции, возможность прокачивать хард-скиллы в разработке. Требования опыт разработки на python: работы с данными, оптимизации запросов, проектирования и решения архитектурно сложных задач опыт настройки ETL-процессов опыт работы с SQL понимание CI/CD концепции знание баз данных, особенно аналитических опционально — опыт работы с Airflow. опционально — опыт работы с Airflow.","Python,ETL,Airflow,SQL",Контур,
7542,79127174,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Контур — экосистема для бизнеса. Наши сервисы помогают тратить меньше времени на рутину, делают общение с контрагентами и госорганами проще и прозрачнее. У нас продуктовая разработка: 121 команда развивает как внутренние сервисы, которые приносят пользу внутри Контура, так и продукты для наших клиентов. У нас есть команда, которая разрабатывает инфраструктурный сервис Контур.Метрика. м пользуются разработчики, аналитики, менеджеры разработки, маркетологи и все, кто принимает решения на основе данных. Ребята любят исследовать и внедрять новые подходы, всегда открыты для идей и улучшений. Команда растет и ищет опытного Data Engineer'a. Задачи 1. Настраивать, поддерживать и развивать ETL-процессы (AirFlow и наша инфраструктура для настройки потоков). 2. Лидить зону Airflow: внедрять новые подходы, стандарты, драйвить изменения, работать над бэклогом, понимать потребности пользователей, предлагать решения. 3. Писать конвертеры и адаптеры в нашей инфраструктуре по настройке потоков. 4. Проводить ревью кода аналитиков данных. Стек Python, Airflow, Kubernetes, Redash C#, Net Core, Docker, Gitlab CI, Ansible, Git Octopus, Teamcity, Moira, Graphite, Grafana, YouTrack Singular, Vault MS SQL, ClickHouse. Мы предлагаем много интересных задач, современные технологии и инструменты, есть пространство для проверки гипотез и экспериментов свободу для развития в смежных областях (девопс, дата-аналитика) быструю обратную связь от пользователей и внутренних заказчиков: сразу видно, как можно влиять на жизнь Контура комьюнити опытных python-разработчиков, внутренние митапы и конференции, возможность прокачивать хард-скиллы в разработке. Требования опыт разработки на python: работы с данными, оптимизации запросов, проектирования и решения архитектурно сложных задач опыт настройки ETL-процессов опыт работы с SQL понимание CI/CD концепции знание баз данных, особенно аналитических опционально — опыт работы с Airflow.","Python,ETL,Airflow,SQL",Контур,
7554,79127178,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Контур — экосистема для бизнеса. Наши сервисы помогают тратить меньше времени на рутину, делают общение с контрагентами и госорганами проще и прозрачнее. У нас продуктовая разработка: 121 команда развивает как внутренние сервисы, которые приносят пользу внутри Контура, так и продукты для наших клиентов. У нас есть команда, которая разрабатывает инфраструктурный сервис Контур.Метрика. м пользуются разработчики, аналитики, менеджеры разработки, маркетологи и все, кто принимает решения на основе данных. Ребята любят исследовать и внедрять новые подходы, всегда открыты для идей и улучшений. Команда растет и ищет опытного Data Engineer'a. Задачи 1. Настраивать, поддерживать и развивать ETL-процессы (AirFlow и наша инфраструктура для настройки потоков). 2. Лидить зону Airflow: внедрять новые подходы, стандарты, драйвить изменения, работать над бэклогом, понимать потребности пользователей, предлагать решения. 3. Писать конвертеры и адаптеры в нашей инфраструктуре по настройке потоков. 4. Проводить ревью кода аналитиков данных. Стек Python, Airflow, Kubernetes, Redash C#, Net Core, Docker, Gitlab CI, Ansible, Git Octopus, Teamcity, Moira, Graphite, Grafana, YouTrack Singular, Vault MS SQL, ClickHouse. Мы предлагаем много интересных задач, современные технологии и инструменты, есть пространство для проверки гипотез и экспериментов свободу для развития в смежных областях (девопс, дата-аналитика) быструю обратную связь от пользователей и внутренних заказчиков: сразу видно, как можно влиять на жизнь Контура комьюнити опытных python-разработчиков, внутренние митапы и конференции, возможность прокачивать хард-скиллы в разработке. Требования опыт разработки на python: работы с данными, оптимизации запросов, проектирования и решения архитектурно сложных задач опыт настройки ETL-процессов опыт работы с SQL понимание CI/CD концепции знание баз данных, особенно аналитических опционально — опыт работы с Airflow.","Python,ETL,Airflow,SQL",Контур,
7597,78162669,Менеджер по удаленным продажам (по привлечению клиентов/лидогенератор/data researcher),от 60 000 руб. на руки,1–3 года,"Полная занятость,гибкий график","Мы американская IT компания, занимающаяся разработкой и продвижением собственного B2B программного обеспечения в похоронной индустрии США. Наш основной продукт это Cemetery Workstation – платформа готовых онлайн решений, которая модернизирует бизнес-операции, документооборот, учет участков и облегчает жизнь сотрудникам компаний-клиентов. Наша компания находится в активной фазе привлечения новых клиентов и на данный момент мы ищем в наш отдел продаж нового специалиста по лидогенерации с опытом ведения холодной коммуникации с потенциальными клиентами. Требуются знание английского языка, упорство, трудолюбие и настойчивость, а мы своей стороны предоставим поддержку сильной команды, доступ к необходимому ПО, сервисам и все, что нужно для продуктивной работы. Обязанности: - Качественный отбор целевых лидов и их скоринг на основе заданных параметров (локация, индустрия, категория и пр.) - Поиск и внесение информации по лидам в Copper CRM - Чистка, проверка и валидация собранных данных - Первоначальный контакт с потенциальными клиентами для определения необходимой потребности - Подготовка отчетов/ведение аналитики по итогам работы компаний - Участие в написании цепочки сообщений, в том числе с использованием чата GPT-3 - Чистка, проверка и валидация собранных данных. Требования: - Английский не ниже уровня Intermediate - Положительный опыт работы в IT компании на схожей позиции (предпочтительно) - Грамотная устная и письменная речь - Умение гуглить нужную информацию, используя linkedin, facebook, twitter, instagram etc. - Системность, целеустремленность, аналитический подход, нацеленность на общий результат. Условия: - Совокупный доход от 60 000 рублей (оклад + премия) - Гибкое начало рабочего дня - Возможность работать удаленно - Дружный и молодой коллектив.","входящие звонки,исходящие звонки,оформление заказов,Грамотная речь,Консультирование клиентов по телефону,Пользователь ПК,телефонные продажи,Активные продажи,продажи,Английский язык,Лидогенерация,Английский — C1 — Продвинутый",Честный Агент,
7599,78329281,Senior data scientist (экономические показатели),з/п не указана,3–6 лет,"Полная занятость,полный день","Задачи: Разработка моделей для прогнозирования развития проектов, реализуемых на площадке, их интеграция в цифровые продукты и интерпретация результатов моделирования Организация деятельности по выявлению качественных и количественных взаимосвязей между свойствами объектов, анализируемых в проектах Расширение практики использования инструментов продвинутой аналитики (advanced analytics) Разработка и реализация концепции создания центра в области продвинутой аналитики и исследования данных Взаимодействие с дата-офисом в целях развития Т-инфраструктуры и создания центра продвинутой аналитики Оперативное руководство деятельностью команды аналитиков (3-4 ед.), развитие компетенций команды, наставничество Требования: Высшее образование (математика, матметоды в экономике, экономическая статистика) Опыт реализации прикладных исследовательских и консалтинговых проектов по заказу органов власти от 3-х лет Владение Python / R / SQL на уровне уверенного пользователя, самостоятельное написание кода Знание статистических пакетов анализа данных (STATA, EViews, SPSS, MATLAB) Понимание современных инструментов управления данными, BI, аналитикой, ML и DS Развитые презентационные и коммуникационные навыки Английский язык – upper intermediate и выше Наличие публикаций в ведущих научных журналах (социально-гуманитарный блок) Приветствуется менеджерский опыт, готовность брать ответственность за результат команды Проактивность и ориентация на практический результат Учёная степень в области социально-гуманитарных наук будет преимуществом Мы предлагаем: Стать частью динамичной и быстроразвивающейся организации (мы работаем в атмосфере стартапа) Возможность решать интересные и важные государственные задачи федерального масштаба и видеть результаты своей работы Доступ к данным для научных исследований, развитая партнерская сеть с ВУЗами и компаниями-лидерами цифровизации Рабочее взаимодействие с руководством федеральных органов власти и командами членов Правительства РФ Современный офис с коворкингом, митинг-румами и ситуационным центром Программа ДМС",,Аналитический центр при Правительстве Российской Федерации,"Москва, Киевская, Киевская, Кутузовский проспект, 2/1с6"
7623,79110323,Data scientist (Управление рисками корпоративных клиентов),з/п не указана,1–3 года,"Полная занятость,полный день","Мы — амбициозная и дружная команда, ежедневно исследующая данные корпоративных клиентов Сбербанка. Наши модели – двигатель не имеющих аналогов в России продуктов в сфере управления рисками корпоративных клиентов. Сводная статистика о нас: Мы решаем задачи по 8 основным направлениям (от монументального ПВР до всеобъемлющих графов и молодого и амбициозного ESG) 95% наших моделей разрабатываются с применением облачных технологий Мы придерживаемся единого стандарта работы, используем JIRA/Confluence/BitBucket, у нас есть единый бэклог 25% нашей команды имеют западное образование и опыт работы в странах Европы Мы сотрудничаем с передовыми ВУЗами в 3-ёх городах России Просрочка по кредитному продукту на основе наших моделей стремится к 0. В команде с заказчиками мы: Погружаемся в предметную область Прорабатываем постановку задачи щем и исследуем данные Выбираем оптимальные методы моделирования Разрабатываем и верифицируем модели Готовим отчеты о разработке и презентуем результаты Мониторим модели Наслаждаемся результатом. В рамках работы над задачей мы будем: Разрабатывать и улучшать инструменты для машинного обучения (внутренние наработки, библиотеки) спользовать прогнозное моделирование, чтобы оптимизировать бизнес риск метрики Работать в команде с портфельными менеджерами, чтобы понять нужды бизнеса и предложить возможные решения Разрабатывать модели машинного обучения Разрабатывать архитектуру пилотов для тестирования гипотез Прокачивать коллег и развиваться самим. Качественные факторы кандидатов с высоким Feature important: Диплом в области компьютерных наук, статистики, прикладной математики или другой релевантной области Опыт работы от 3х лет с одной или несколькими СУБД: Oracle, MS SQL, Teradata либо СУБД стэка Bigdata Опыт работы с хранилищами данных от 1го года Опыт работы в роли аналитика с функцией подготовки выгрузки данных для заказчика Сильные компетенции в области реляционных СУБД и хранилищ данных: Глубокое понимание статистических подходов и методов (регрессия, свойства распределений, оценка максимального правдоподобия, проверка гипотез и их правильное использование) и опыт их применения Знания и опыт применения алгоритмов машинного обучения (GLM/Regression, Trees, Random Forest, Boosting), а также знание их преимуществ, недостатков и ограничений Приветствуется знание принципов работы нейронных сетей и опыт использования библиотек для их обучения (Keras/PyTorch/TensorFlow) Знание Python и основных DS библиотек Отличные знания английского языка (устный и письменный) как преимущество Опыт в распределённых/параллельных вычислениях с помощью следующих технологий: Hadoop, Spark, Dask и другие как преимущество А ещё у нас есть: Развитая IT архитектура. Мощный GPU кластер, возможность расчётов на суперкомпьютере top30 в мире Работа над передовыми задачами в банковском секторе Постоянное развитие: обучающие курсы от лучших университетов и компаний (МФТ, ВШЭ, NVIDIA и другие), участие в международных конференциях Большую сильную команду Развитое DS community.",,Сбер. Data Science,"Санкт-Петербург, Старо-Петергофский пр., д.30"
7652,79100536,Data инженер junior,з/п не указана,не требуется,"Полная занятость,полный день","Бюро кредитных историй Cкоринг Бюро является крупнейшим российским БК. Наша компания предоставляет финансовым организациям в Российской Федерации услуги по управлению рисками, аналитики и предотвращению мошенничества, которые необходимы для развития бизнеса, такие как: Создание, обработка и распространение кредитных историй и отчетов по заемщикам Защита конфиденциальной информации Предоставление аналитических услуг для банков и компаний Компания постоянно разрабатывает новые информационные продукты, и дорожит их качеством. Поэтому, проводит поиск специалистов по тестированию функционала. Обязанности: Написание сложных SQL запросов в БД, подготовка датасетов для аналитики отчетности зучение структуры витрин, анализ данных. Аналитика отчетности Добавление данных Оптимизация процесса забора данных (индексы, снижение времени расчёта данных и тд.( объём данных у нас в десятках террабайт) Создание регулярных отчетов для банков по запросам. Взаимодействие со смежными отделами ( разработка , аналитика и тд.). Требования: Отличное знание SQL Обязательно ! техническое / экономическое образование . SQL уровня написание разнообразных СЛОЖНЫХ запросов, понимание структуры данных. опыт работы с БД, python хорошее знание exсel Мы предлагаем: работу в стабильной международной компании с 20-летней историей комфортную и дружелюбную рабочую атмосферу офисный формат работы комфортный и стильный офис в бизнес-центре на м. Комсомольская возможность профессионального развития и карьерного роста множество корпоративных плюшек на любой вкус. Плюсом будет: Опыт работы с Sas. Опыт работы с большими данными . Перспективы Прокачать технические навыки и приобрести ценный опыт, сформировать большой багаж знаний в области корпоративных продуктов в процессе работы с информацией . Условия: трудоустройство по ТК РФ, бессрочный трудовой договор годовой бонус гибридный график с возможностью удаленки 1 раз в неделю ежегодная индексация заработной платы ДМС со стоматологией (софинансирование ДМС для супругов и детей) страхование жизни от несчастных случаев Фитнес в нашем БЦ (софинансирование) возможность изучения английского языка за счёт компании в офисе корпоративные мероприятия и подарки для сотрудников и членов семей транспортная доступность: м. Комсомольская (7-10 минут пешком).","SQL,Python,Анализ данных,Аналитическое мышление,Работа с большим объемом информации,Работа с базами данных,Базы данных,Аналитика,Sas",Бюро кредитных историй Скоринг Бюро,"Москва, Комсомольская, Каланчевская улица, 16с1"
7684,76829230,Senior Data Scientist (Лимасол/Ереван),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Привет! Мы - крутая команда Click, мы успешно создаем и развиваем IT-продукты на международном рынке. Мы разрабатываем высоконагруженную рекламную платформу, позволяющую рекламодателям и владельцам ресурсов привлекать новых клиентов и пользователей. Мы используем уникальную технология сбора и обработки информации о портретах и предпочтениях посетителей интернет ресурсов, основанную на ML, наши бекэнды принимают десятки тысяч запросов на подбор рекламного предложения каждую секунду, а в DWH хранятся терабайты данных. Мы постоянно растем, и сейчас ищем Senior Data Scientist в нашу команду удаленно или с релокацией в Лимасол или Ереван! Мы предлагаем: Комфортные офисы в Лимассоле и Ереване, помощь с релокацией Возможность удаленной работы, если вы уже переехали 100% официальная заработная плата в соответствии с вашими ожиданиями и опытом Гибкое начало рабочего дня (начало с 10.00 до 12.00, окончание с 19.00 до 21.00) Полный соц. пакет (доплата до 100% оклада при отпускных и больничных) Премии по результатам работы, регулярное performance review Корпоративная техника Оплата посещений профильных конференций, компенсация курсов Сильная команда разработки и тестирования, гибкие подходы к разработке Актуальный стек и гибкость в выборе технологий CI/CD и низкий time to market Широкий спектр задач с использованием supervised, unsupervised и reinforcement learning алгоритмов Насыщенная корпоративная жизнь и мероприятия, о которых с радостью расскажем на интервью! Наши пожелания к кандидату: Python для анализа и визуализации данных и машинного обучения от 3-х лет Знание SQL (написание запросов, понимание принципов организации БД) Знание как работают традиционные алгоритмы, использующиеся для машинного обучения и опыт их практического внедрения и поддержки в производственной среде Навыки работы с количественной информацией, знания теории вероятностей и математической статистики (мы активно применяем их в работе) Умение самостоятельно конвертировать бизнес задачу в алгоритмическую, предложить метрики для оптимизации и различные методы решения. Основные задачи будущего коллеги: Работать над рекомендательными системами, используя современные теоретические наработки - Multi-Armed Bandits, Counterfactual Learning, Factorization Machines, etc. Строить полный цикл системы мониторинга и аналитики ML решений, развивать аналитическую инфраструктуру Планировать, проводить и оценивать результаты A/B-тестов, выдвигать гипотезы Совершенствовать существующие и добавлять новые метрики о состоянии рекламной сети, настраивать и улучшать автоматизированный мониторинг. Оставляйте ваши отклики здесь или в телеграм, будем рады ответить на вопросы и рассказать подробности вакансии!","Python,Математическая статистика,SQL,Статистический анализ,Pandas,Reinforcement Learning,Multi-Armed Bandits",Click,
7687,79170579,QA инженер (C#) в команду Compliance Data Engineering,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Твоя будущая команда занимается развитием и поддержкой системы комплаенс-контроля, большой частью которой является принятие решений по операциям клиентов в режиме реального времени и предотвращение подозрительной и незаконной активности в Банке. Ребята реализуют как требования внутренних бизнес-заказчиков, так и требования регуляторов – Росфинмониторинга и Банка России. От надёжности и скорости работы системы зависит репутация всего банка.  Система построена таким образом, что большой поток транзакций обрабатывается очень быстро крайне ограниченными ресурсами. Помимо этого в системе реализовано разветвленное воркфлоу по работе с клиентами, попавшими в зону внимания комплаенс-контроля, которое регулярно адаптируется под запросы пользователей.  В команде уже есть три опытных тестировщика-автоматизатора и требуется ещё один. Тебе доверим заниматься функциональным, интеграционным и регрессионным тестированием (C#): 20% ручное, 80% авто развивать тестовый фреймворк и разрабатывать автотесты локализовывать дефекты и заводить задачи в трекинговой системе обеспечивать качество на всех этапах жизненного цикла ПО активно взаимодействовать с аналитиками, бизнес-заказчиками, разработчиками. От тебя ждем опыт автоматизированного тестирования на C# от 1-го года знание SQL на уровне простых запросов (SELECT, JOIN, DELETE) понимание жизненного цикла программного обеспечения опыт работы с любой системой баг-трекинга и ведения тест-кейсов  Будет плюсом (если ты с этим знаком, то будет проще) опыт работы с очередями сообщений опыт нагрузочного тестирования Мы предлагаем возможность работать из офиса или удаленно. Главное — договориться с командой работу в структуре без строгой иерархии, где ваш руководитель — это играющий тренер работу по принципам Agile присоединиться к QA-коммьюнити в банке, где коллеги обмениваются опытом и помогают друг другу участие в регулярных митапах профессиональных сообществ внутреннее и внешнее обучение за счет банка участие в профессиональных конференциях в качестве спикера или слушателя. Например, мы регулярно ходим на HighLoad или JPoint страховку со стоматологией, которая работает как в Москве, так и в регионах особые условия по нашим продуктам, например, ипотеке, банковским картам или накопительным счетам и вкладам.",,Райффайзен Банк,
7708,77557349,Аналитик данных/Middle Data scientist (Computer Vision),з/п не указана,1–3 года,"Полная занятость,полный день","змерительная система — это программно-аппаратный комплекс, состоящий из различных датчиков, программного обеспечения, нейронных сетей и моделей. Данные с компонентов системы поступают в её головной компьютер, где оператор может получить информацию о состоянии объекта, результатах измерений. змерительные системы, разработанные «Северсталью», уже испытаны на собственных производствах компании. Эти эффективные решения компания готова адаптировать под задачи заказчика. В связи с расширением команды мы находимся в поиске Middle Data scientist (Computer Vision). Некоторые наши проекты: Системы видеоинспекции- поверхности металлопроката, которые обеспечивают определение и классификацию дефектов с помощью видеокамер, машинного зрения и нейросетей Системы измерения геометрических параметров и формы продукции с помощью лазерных триангуляционных датчиков позволяют измерять длину, ширину и толщину продукции, её планшетность и серповидность либо комплекс параметров Датчики промышленного интернета вещей, с помощью которых можно предотвратить травмирование продукции при погрузочно-разгрузочных работах.  В твои обязанности будет входить: Участвовать в анализе и проработке бизнес требований Контролировать техническую сторону процесса разметки изображений внешними и внутренними ресурсами Обучать CV модели (object detection, object tracking, object classification, segmentation) Доводить свой рисерч моделей до состояния MVP и вносить доработки по результатам пилотирования Выводить решения в продакшн, поэтому помимо тренировок сеток специалист будет заниматься следующими задачами: · выбирать оптимальный дизайн решения для задачи · проводить trade-off между качеством и скоростью · оптимизировать работу алгоритмов в зависимости от условий работы (on edge, прунинг, квантизация) Тестировать в наших задачах SOTA решения и прикручивать их в прод, где это осмысленно В ситуациях, где данных для обучения классических моделей недостаточно, находить нестандартные решения. Основные требования: Хорошие знания Python и умение писать на нем качественный и понятный код Классический ML - кластеризация, классификация, регрессия и тд. Стек sklearn, numpy, pandas, xgboost/lightgbm Знания методов математической статистики и теории вероятностей. Знание базовых алгоритмов машинного обучения, хорошее понимание основ DL Теоретические знания методов DL и оптимизации (основные концепты + более углублённые знания в CV с упором на детекцию и сегментацию + основные метрики в задачах CV) Знание хотя бы одного из фреймворков по глубокому обучению TensorFlow\PyTorch Хорошее понимание основ классического компьютерного зрения (базовые морфологические операции, Discrete Fourier Transform, Hough transforms, Sobel derivatives) Опыт работы с задачами object detection, segmentation, classification Опыт работы с OpenCV Опыт автоматизированного сбора и разметки данных, опыт работы с CVAT Умение читать, понимать, имплементировать статьи по компьютерному зрению Умение решать задачи по CV без больших данных. Теоретическая подготовка в области RL и опыт использования алгоритмов RL Будет плюсом: Опыт работы с Linux Знание Docker, Docker Compose Опыт работы с разными видами сенсоров в области машинного зрения (камеры, радары, лидары и т.д.) Знакомство с GANами, attention-механизмами, архитектурами типа encoder-decoder, знакомство с semi- и unsupervised learning, знания в области NLP, а также опыт реализации кастомных архитектур Огромным плюсом будут навыки в оптимизации скорости инференса DL-моделей с кастомной архитектурой на CPU и GPU, а также опыт работы с TorchScript, TensorRT, ONNX, конвертацией моделей между фреймворками, etc. Опыт разработки и деплоймента DL-проектов Знание английского на уровне, достаточном для комфортного чтения статей и блогов Профиль на kaggle (необязательно). Мы предлагаем: Мощную команду профессионалов Дополнительную мотивацию в виде годового бонуса, социальный пакет и скидки от партнеров Развитие нон-стоп. Мы вкладываемся в людей как в самое дорогое. Создаем авторские учебные курсы. Привлекаем внешних экспертов и наставников. Гарантии стабильности. Трудоустраиваем по ТК РФ. Зарплата выплачивается 2 раза в месяц и регулярно индексируется. Есть ДМС со стоматологией с первого рабочего дня. Работаем по бессрочному договору. Возможность работы удаленно или в г. Череповце.","Python,SQL,MS SQL,Английский язык,PostgreSQL",Северсталь. IT & Digital,
7730,69379894,нженер / Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","НПКЦ диагностики и телемедицины («Радиология Москвы»), – государственная компания с более чем 20-летним опытом работы в здравоохранении. Наш Центр - ведущая экспертная организация по развитию и повышению эффективности службы лучевой и инструментальной диагностики в России. Обязанности: Проведение тестирований сервисов на основе технологий искусственного интеллекта (-Сервисов). Подготовка протоколов тестирования. Создание программного кода в соответствии с техническим заданием (готовыми спецификациями). Оптимизация программного кода с использованием специализированных программных средств. Оценка и согласование сроков выполнения поставленных задач. Аналитика результатов работы -Сервисов. Подготовка отчетных и демонстрационных материалов по проведенным разработкам Требования: Опыт работы frontend разработчиком (средний или базовый уровень) Опыт создания пользовательских интерфейсов Высшее образование (предпочтительные направления - медицинская техника, медицинская кибернетика, биофизика, медицинская физика, инженерное дело), ученая степень будет преимуществом Базовые навыки программирования (Python) Работа с медицинскими данными (принципы получения данных радиологических исследований, формат DICOM) Ведение и составление технической и отчетной документации Мы ценим: Стремление достигать результата Желание постоянно развиваться Готовность к динамичным изменениям скренность и открытость Умение работать в команде Навыки самоорганизации. Мы предлагаем: Официальное трудоустройство График 5/2 с 9.00 до 17.30, сб и вс выходные Годовая премия, белая зарплата! Выплаты 2 раза в месяц Возможность прохождения дополнительного образования по направлению от центра! Участие в амбициозных проектах в масштабах отрасли и страны Сопричастность к решению «сверхзадач» в системе здравоохранения Наставничество и поддержка в развитии на международном уровне Возможность развиваться опережающими темпами, участвуя в программах обучения Стать частью яркой профессиональной команды Дружный коллектив молодых и талантливых специалистов Карьерный рост.","Медицинское оборудование,Написание научный статей,Научная деятельность,Научные исследования",ГБУЗ «Научно-практический клинический центр диагностики и телемедицинских технологий ДЗМ»,"Москва, улица Петровка, 24"
7734,79103187,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности: Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования: Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем: Возможность работы в аккредитованной Т-компании. Работу в офисе. График работы — гибридный Профессиональное развитие. Вы получите доступ к библиотеке с технической литературой, тренингами и мастер-классами для сотрудников Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Компенсацию такси, парковки и 50% затрат на спорт от стоимости абонемента Компенсацию обедов. А если захотите перекусить, на каждом этаже есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,Работа с базами данных,ETL,Базы данных",Тинькофф,"Рязань, улица Кудрявцева, 56"
7801,75624204,Руководитель направления по анализу данных/pre-Chief Data Officer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы — команда «Ваш инвестор». Уже 10 лет мы инвестируем в людей, создавая лучшее будущее для человечества. Знаем не понаслышке как предоставлять уникальный сервис для клиента, и являемся надежным партнером в финансовых вопросах. В копании поступает и накапливается (частично сохраняется, обрабатывается) значительное количество данных. Обработка, хранение, анализ данных осуществляется локально на уровне функциональных подразделений (и отдельных Т-систем) - без единых инфраструктурных решений, методологии, инструментов, дашбордов (BI решений). В связи с развитием компании через анализ данных/проверку гипотез на основе данных, мы сейчас в поиске руководителя группы/направления по анализу данных //”pre-Chief Data Officer” (pre-CDO). Чем предстоит заниматься: Разработкой и реализацией пилотного проекта по анализу данных в области клиентского взаимодействия/анализа клиентской базы, рынка (на основе витрин данных/аналитических срезов) Участвовать в проектировании и развитие единой архитектуры данных во всех корпоративных Т-системах и бизнес-процессах Участвовать в проектировании, внедрении Т инструментов и систем для сбора, обогащения, хранения, обработки, анализа, визуализации данных, в гибридном (доменном) формате озера данных/витрины данных Обеспечивать качество данных посредством активного взаимодействия с руководством компании и владельцами данных, а также непрерывного мониторинга процессов генерации и обработки данных Готовить аналитическую отчетность, дашбордов, проверка бизнес гипотез на основе данных Участвовать в повышении уровня информационной грамотности сотрудников в области управления и эффективного использования корпоративных данных Создать (развивать) группы и управлять работой Data Professional’ов (аналитиков, инженеров, исследователей, администраторов данных) Помогать в координации деятельности (методологии, подходов, инструментов) аналитиков в функциональных подразделениях (бизнес-линиях) Компании. Мы ждем от тебя: 3+ года - работы в роли Руководителя (тимлида) в области анализа данных/Архитектора данных в сетевом ритейле, FMSG или в финансовом секторе Опыт разработки/внедрения фреймворков по обработке и анализу данных - от выявления потребности бизнеса (гипотез, бизнес-целей), источников данных, нормализации до формирования аналитической отчетности/выводов, дашбордов Опыт формирования команд и управления техническими специалистами (IT/data professionals) Участие в проектах внедрения платформ и корпоративных моделей данных, внедрения инструментов/систем для работы с данными (DWH, Data Lake, Data Mart, Data Mesh/Fabric, BI) Отличные навыки коммуникации и опыт совместной работы в рамках кросс-функциональных команд, с участием топ-менеджеров. Мы предлагаем: Возможность реализовать интересные и сложные проекты в рамках роста и развития компании Рост и развитие вас как профессионала Работа в команде единомышленников ДМС, корпоративная связь, компенсация занятий спортом У нас свой центр обучения и развития, также есть возможность учиться у внешних экспертов за счет компании Активная корпоративная жизнь (корпоративные мероприятия, спорт движение, участие в профессиональных и отраслевых конференция, корпоративная библиотека и т.д.) Стабильный доход (оклад и KPI) Оформление согласно ТК РФ.",,Ваш инвестор,"Новосибирск, Фабричная улица, 53"
7840,78851235,Data Scientist (digital marketing),з/п не указана,3–6 лет,"Полная занятость,полный день","О проекте Наш клиент – крупнейший западный фармацевтический производитель расширяет свою команду digital аналитики и приглашает рассмотреть позицию Senior digital/omnichannel marketing analysts. В распоряжении отдела богатая цифровая инфраструктура. CRM, email marketing platform, MDM, Web портал (1С Битрикс), чат-боты, мобильные приложения, сопутствующие каналы (SMS/SEO/Paid media). Эта инфраструктура генерирует внушительные объемы транзакционных данных. меть стройную сквозную аналитику и уметь интерпретировать данные в бизнес-кейсы – главная задача успешного кандидата. Чем предстоит заниматься: Лидирование направления сквозной аналитики в области digital marketing в компании (в команде уже есть 2 аналитика и аутсорс-команда для гибкости) Разработка аналитических отчетов в области цифрового маркетинга Поиск точек роста рекламных кампаний и дистрибуция знаний до внутреннего заказчика Контролировать внедрение новых функций в постоянно развивающейся omnichannel экосистеме Обильно взаимодействовать с зарубежной командой с целью приведения в соответствие аналитику локальную и глобальную (таксономия, naming convention, подходы, глобальные изменения в инфраструктуре). Что ожидаем от кандидата: Опыт построения экосистемы сквозной digital marketing аналитики – обязателен Портфолио через данные. Умение погрузиться в дату ad-hock’ом, найти корреляции и аномалии, положить их на слайды и объяснить бизнес-языком – твоя супер способность Широкий кругозор в области построения отчетов. Ты эмпатичен к бизнесу и знаешь наверняка, на что хочет смотреть бизнес Ты знаешь основы прототипирования отчетов. Где круговые диаграммы незаменимы, а где они вредят Опыт управления командой и кросс-функционального взаимодействия Hard skills – Pbi, DAX, Python, SQL, BigQuery, Data studio, ETL, MDM, AWS а также глубокое понимание принципов и инструментов в digital promo (CPC, LTV, CPM, MAU, DAU, Retention, CDP, SEO, Paid media, GA/YM, принципы работы веб-сайта, веб-сервера, UA, cookies и т.п.) Широкий кругозор в принципах проектирования реляционных (и не очень) баз данных и построения BI моделей Опыт работы с SalesForce будет плюсом Уверенный английский язык. Условия: Официальное трудоустройство согласно ТК РФ через кадрового провайдера (входит в реестр IT компаний), белая з\п. Доступ к цифровой инфраструктуре и проектам международного уровня. Компания в партнерстве с ведущими технологическими игроками мира - AWS, Microsoft, Google, Salesforce и т.д. Обширный горизонт для развития. Компания ориентирована на предиктивную/продуктовую аналитику, ML, и имеет необходимые технологии. Молодой дружный коллектив с международной культурой. Agile, Scrum, Waterfall – применяется там, где это полезно. Дополнительное медицинское страхование (поликлиника, стоматология, стационар). Уютный офис в центре города. Full time с удобным графиком.","Английский язык,Power BI,ETL,Data Analysis,DAX,AWS,Digital Marketing,Python,LTV,CPC,Pbi,Google Analytics,Яндекс.Метрика,Английский — B2 — Средне-продвинутый",AUXO (Атос АйТи Солюшенс энд Сервисез),
7844,77080599,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура • Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных • Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем Возможность работы в аккредитованной Т-компании Работу в офисе. График работы — гибридный Платформу обучения и развития Тинькофф Апгрейд. Курсы, тренинги, вебинары и базы знаний. Поддержка менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Компенсацию такси и 50% затрат на спорт от стоимости абонемента Компенсацию обедов. А если захотите перекусить, есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,ETL,DWH,СУБД,Databases",Тинькофф,
7845,77082533,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура • Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных • Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем Работу в офисе. График работы — гибридный Профессиональное развитие. Вы получите доступ к библиотеке с технической литературой, тренингами и мастер-классами для сотрудников Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Компенсацию такси и 50% затрат на спорт от стоимости абонемента Компенсацию обедов. А если захотите перекусить, на каждом этаже есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,ETL,DWH,Clickhouse,Greenplum",Тинькофф,
7894,78859492,Enterprise Data Architect (Germany),з/п не указана,3–6 лет,"Полная занятость,полный день","Наш партнер, известный немецкий ритейлер, ищет Архитектора корпоративных данных. Работа на полную ставку (от 38 до 45 часов в неделю) в районе Дюссельдорфа, Германия (возможна частичная работа из дома). Компания обеспечивает релокацию в Германию из-за рубежа. Мы позаботимся о вашей визовой заявке и переезде в Германию. Ваши члены семьи (супруг, дети до 18 лет) также получат визу. О компании: Работа команды Data&Analytics направлена на создание на основе данных добавленной стоимости для компании и ее клиентов по всему миру. Сотрудники участвуют в международных проектах и разрабатывают индивидуальные решения в области данных и аналитики для своих бизнес- и IT-команд. Команда поддерживает другие функции в принятии важных решений на основе надежных данных и современным методов аналитики. Ваши обязанности: Разработка, создание и поддержка корпоративных логических моделей данных и словарей данных Сотрудничество с заинтересованными сторонами в бизнес- и IT-сообществах для определения и документирования требований к данным и метаданным (физическим и логическим) Контроль и обеспечение безупречного функционирование каталога данных Владение IT-приложением каталога данных, обеспечение внедрения разработанных решений Координация разработки коннекторов и сканеров метаданных Предоставление поддержки третьего уровня и помощь в анализе и устранении сбоев сервиса Требуемые квалификации: 5+ лет опыта работы в области архитектуры данных с акцентом на моделирование данных и управление метаданными Владение инструментами моделирования данных Знание и практический опыт работы с платформами каталога данных, такими как Collibra или Informatica Знание API-платформ и стратегий интеграции данных Умение координировать разработку программного обеспечения, структурированное мышление и навыки решения проблем Свободное владение английским языком в устной и письменной форме (минимальный уровень С1) Опыт работы с SAP (как дополнительное преимущество) Преимущества: Пакет релокации Конкурентоспособная заработная плата и пакет льгот Дружелюбная рабочая среда с возможностями для личностного и профессионального роста Работа с передовыми технологиями и проектами в области машинного обучения и искусственного интеллекта Гибкий график работы и возможности удаленной работы Доступ к программам непрерывного обучения и развития Если вас заинтересовало описание позиции - подавайте заявку и отправляйте дополнительную информацию с сопроводительном письме","Английский язык,Моделирование,Architecture,Анализ данных,Английский — C1 — Продвинутый",Transparent Hiring,Мюнхен
7899,78794747,Devops на проект Data lake,з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем DevOps-инженера c функцией Hadoop администрирования на проект банковский проект. Основными задачами которого будет развернуть платформу Data Lake (на базе Hadoop) с нуля, настроить все необходимые компоненты для построения современного стека для работы с данными. Платформа Data Lake: будет являться частью централизованной Data Platform и поможет в стандартизации и автоматизации бизнес-процессов по загрузке и обработке “сырых” данных, обеспечении нужных таблиц в корпоративном реляционном хранилище DWH и развитии Data Science инициатив. Будущие пользователи нашей платформы - это разработчики и аналитики из продуктовых команд, Data Scientiest-ы, которые будут решать прикладные задачи бизнеса. Наш стек: Hadoop (HDFS, YARN, Spark, Hive), Airflow, Bitbucket, Teamcity, Nexus, Jira/Confluence, Ansible, Docker, Grafana/Zabbix. Чем предстоит заниматься: – участвовать в пилоте по разворачиванию Data Lake (Hadoop) – развернуть дистрибутив Hadoop на целевом железе – поддерживать и проводить troubleshooting, тестирование и анализ возникающих issues платформы – настроить репликацию данных между Production и DR площадками – оказывать поддержку разработчикам Data Lake из продуктовых команд – настроить мониторинги по основным сервисам (HDFS, Yarn, Hive, Spark, Kerberos + Ranger, Jupyterhub и др.) – проводить RnD, изучать новое open-source ПО Требования к кандидатам: Опыт работы с одним из дистрибутивов Hadoop (Arenadata, Cloudera и т.д.) Администрирование Hadoop кластеров (Подойдет даже если кандидат хоть как-то пересекался с этим) Опыт администрирования Linux (желательно RHEL, CentOS) Опыт работы с Docker Опыт работы с Ansible Понимание общих принципов построения процессов CI/CD Уверенное знание Python Опыт написания shell-скриптов Как преимущество Знание Java Опыт работы с Nexus, Teamcity Опыт работы с Kubernetes Опыт работы с базами данных (PostgreSQL) Опыт работы с системами мониторинга Zabbix, Grafana, Prometheus Мы предлагаем: Работу в стабильной аккредитованной Т компании, основанной в 1992 году Уровень заработной платы обсуждается ндивидуальный план развития в рамках ежегодной аттестации Удаленный формат работы, никакого физического железа Реализация своих теоретических знаний на практическом боевом проекте Привлекательный соц. пакет: медстраховка для сотрудника и его детей. Доступ к базе корпоративному порталу «среда развития».","Hadoop,PostgreSQL,Kubernetes,TeamCity,Linux,Docker,Ansible,CI/CD,Hive,DevOps,Arenadata",IBS,
7905,78391528,Data engineer (Беспилотные автомобили),з/п не указана,3–6 лет,"Полная занятость,полный день","Яндекс хочет сделать повседневную жизнь людей более безопасной, удобной и комфортной. Мы ставим перед собой масштабную цель: оказаться в числе первых в мире компаний, создавших технологии беспилотного управления автомобилем и роботом-доставщиком. Чтобы воплотить это в жизнь, мы создаём команду увлечённых, умных и целеустремленных профессионалов. Развитию технологий беспилотного вождения помогает анализ данных. Так, за управление флотом и прозрачность ежедневных процессов отвечает операционная аналитика, за векторы будущего развития технологии — продуктовая и стратегическая. Развитию аналитики помогает выстраивание процессов управления данными, а у нас одни только сенсоры поставляют петабайты данных. щем специалистов, которые помогут решать задачи по анализу данных. Что нужно делать: проектировать и создавать витрины данных по процессам и технологиям YSDC во внутренней инфраструктуре Яндекса реализовывать ETL-процессы по формированию аналитического слоя данных создавать процедуры мониторинга контроля качества данных создавать модель управления данными и выстраивать операционные процессы по управлению данными. Мы ждем, что вы: окончили технический вуз, отлично знаете мат. статистику, теорию вероятностей, методы оптимизации системно мыслите, умеете получать, структурировать и систематизировать информацию, чётко излагаете мысли уверенно знаете SQL, понимаете принципы построения моделей хранения и обработки данных знаете Python. Будет плюсом, если вы: работали с хранилищами данных и проектировали схемы данных или ETL-процессы в реальных задачах знаете инструменты оркестрации ETL-пайплайнов (Airflow или аналоги) работали с YT/YQL и другими инструментами инфраструктуры Яндекса владеете современными инструментами визуализации данных на основе открытых фреймворков Superset, Seaborn, Shiny или промышленных BI-сред PowerBI, SAP BI, Tableau, Grafana, DataLens, Pentaho или их аналогов знаете методы машинного обучения, участвовали в соревнованиях по программированию или обработке данных (Kaggle, TopCoder, ACM или подобных) или решали подобные задачи.","Python,SQL,Big Data,PySpark,Airflow",Яндекс,
7922,77909262,Data engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Lamoda Group – это крупнейшая в России и СНГ онлайн-платформа по продаже fashion & lifestyle товаров. Мы в поиске нженера по работе с большими данными в направление дата инжиниринга, который будет участвовать в значимых для инфраструктуры данных в Lamoda проектах: Миграция данных в облако – ключевого проекта, который реализует вся команда. Развитие единой дата платформы – self service каталог для пользователей, который позволяет автоматически получать информацию о том, где лежат данные, как их найти, кто владелец. Проработка архитектуры для A/B системы и других задач R&D направления – проектирование новых решений для оптимизации, анализ и подбор инструментов. Чем предстоит заниматься: Разрабатывать и создавать лучшую на рынке платформу данных электронной коммерции нового поколения Проектировать и разрабатывать ETL пайплайнов на Airflow для Spark, Streaming, Hive, Trino etl Оптимизировать действующие пайплайны и джобы на Spark - мониторить нагрузку на кластер и оптимальность затрачиваемых джобами ресурсов и если необходимо оптимизировать Обеспечивать качество данных в разных системах, проектировать платформу Data Quality - предоставлять заказчикам данных платформу quality чеков, мониторинга и алертинга о текущем состоянии данных Взаимодействовать с аналитиками и ML специалистами для создания/развертывания инструментов и наборов данных, соответствующих их вариантам использования - поддерживать регулярные связи с другими командами для развития платформы AB тестов и MLOps Анализировать и внедрять инструменты инжиниринга данных Проектировать хранилища данных на основе Hadoop, настраивать производительность, мониторинг, планировать емкости кластера Hadoop и другой инфраструктуры - думать над тем что и как грузить и в каких партициях Решать задачи, связанные с внедрением облачной инфраструктуры - разрабатывать новую архитектуру хранилища в рамках текущего переезда в облако. Мы ожидаем: Опыт работы со стеком Hadoop (YARN, HDFS, HBase, Hive) Опыт работы в Spark Знание систем контроля версий (git) Опыт работы с Python Хорошее понимание СУБД, SQL Страсть к инженерным наукам и информатике вокруг данных. Как плюс: Опыт работы с Docker, Kubernetes Опыт с Kafka Опыт с облачными технологиями (AWS, GCP, Yandex) Опыт с Clickhouse, Greenplum. Мы предлагаем: Гибкий график работы: можно самостоятельно планировать время, нам важен сам результат Работаем в гибридном режиме — можно приезжать в офис или работать из дома ДМС с первого месяца, со стоматологией и чек-апом здоровья раз в год Бесплатные сессии с коучами и психологами, которые помогут с определением профессиональных целей и поиском баланса между работой и личной жизнью Оплата участия в профессиональных конференциях, также организуем мероприятия, куда можно ходить и спикером, и зрителем, где сотрудники обмениваются опытом от технических тем до путешествий и бизнеса Ноутбук и другая необходимая техника для работы, частичная компенсация для организации рабочего места дома Ежемесячные промокоды на Lamoda до 25% Корпоративная программа привилегий PrimeZone со скидками от партнеров Офис на Полежаевской с йогой, тренажерным залом и капсулой сна, а также коворкинг в центре Санкт-Петербурга.","Hadoop,Hive,Python,Spark,Big Data,ETL,SQL",Lamoda Tech,"Москва, Полежаевская, Хорошево, проспект Маршала Жукова, 1с1"
7928,76363320,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура: Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl). Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов. Требования Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом. Мы предлагаем Возможность работы в аккредитованной Т-компании. Работу в офисе. График работы — гибридный. Платформу обучения и развития Тинькофф Апгрейд. Курсы, тренинги, вебинары и базы знаний. Поддержка менторов и наставников, помощь в поиске точек роста и карьерном развитии. Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким. Компенсацию такси и 50% затрат на спорт от стоимости абонемента. Компенсацию обедов. А если захотите перекусить, есть кухня с чаем, кофе и фруктами. Достойную зарплату — обсудим ее на собеседовании.","SQL,Hadoop,ETL,DWH,СУБД",Тинькофф,"жевск, улица Ленина, 21"
7935,77902560,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура • Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных • Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем Возможность работы в аккредитованной Т-компании Работу в офисе. График работы — гибридный Платформу обучения и развития Тинькофф Апгрейд. Курсы, тренинги, вебинары и базы знаний. Поддержка менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Компенсацию такси и 50% затрат на спорт от стоимости абонемента Компенсацию обедов. А если захотите перекусить, на каждом этаже есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,Работа с базами данных,ETL,Базы данных,DWH,СУБД,Databases",Тинькофф,
7937,76402167,Разработчик Hadoop Big Data (стрим Витрины ПК),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Вместе с нами ты будешь: Проектирование и разработка SQL-процедур, обработчиков данных на Spark (Scala) и ETL-процессов (в т.ч. AirFlow) Оптимизация производительности кода Разработка и ведение схемы данных Участие в проведении тестирований Взаимодействие с аналитиками, командами развития платформ, DevOps инженерами Развитие wiki в Confluence Какие знания и навыки для нас важны: Опыт работы с инструментарием Hadoop (HDFS, Yarn, Spark, Hive) Опыт работы с промышленными DWH на основе MPP СУБД (Teradata, Exadata, Greenplum), от 2-х лет Знание теории построения DWH ETL - практический опыт проектирования и разработки регламентных потоков данных при помощи Airflow SQL - уверенные знания (DML,DDL), опыт разработки хранимых процедур Опыт работы с библиотекой Pandas Опыт работы с Impala Понимание принципов и инструментария CI/CD (Git/Bitbucket, Teamcity)","SQL,Hadoop,Spark,Hive,SCALA","ннотех, Группа компаний",
7938,77904641,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем Возможность работы в аккредитованной Т компании Работу в офисе. График работы — гибридный Профессиональное развитие. Вы получите доступ к библиотеке с технической литературой, тренингами и мастер-классами для сотрудников Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Компенсацию такси, парковки и 50% затрат на спорт от стоимости абонемента Компенсацию обедов. А если захотите перекусить, на каждом этаже есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,ETL,Greenplum",Тинькофф,
7939,78680148,DWH Архитектор (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","«AUTOMATE-BUSINESS» осуществляет разработку полного цикла аналитических систем от этапа бизнес-требований заказчика до полного внедрения продукта, включая поддержку миграции данных и составление технической документации на разработанный продукт. Подробная информация о Компании и о реализованных проектах: https://automate-business.ru Мы в поиске опытного DWH Архитектора (Big Data) на новый проект для крупного ресурсодобывающего холдинга. Архитектурная схема предоставляется на собеседовании. Чем предстоит заниматься? Проработкой бизнес и технических требований к продуктам направления Выстраиванием архитектуры решений Участвовать в выборе технологий и средств реализаций решения Участвовать в разработке, анализе и оптимизации решений Взаимодействовать с командой разработки (заказчик, аналитики, разработчики) и контролировать архитектурные решения Сопровождать проект на стадии реализации и внедрения Участвовать в презентации разработанных решений Участвовать в тестировании разработанной функциональности Основной стэк: Kafka, S3, Greenplum, Airflow, Сlickhouse, Cubernetes. Что мы ждем от кандидата? Аналогичный опыт от 2-х лет Понимание архитектурных принципов построения информационных решений Опыт работы по методологиям разработки Agile (Scrum) Технический английский язык. Что мы предлагаем? Форма взаимодействия для сотрудничества обсуждаются с кандидатом (Полная занятость по ТК РФ/проектная работа) Достойный уровень оплаты Работа в центре Нижнего Новгорода в офисе, либо удаленный формат Рабочее место, оборудованное современной техникой. Присоединяйся к нашей команде и создавай лучшие решения для клиентов!","Kafka,S3,Big Data,Data Warehouse,Agile,Scrum,GreenPlum,Clickhouse,Airflow,Cubernetes",Аутомэйт-Бизнес,"Нижний Новгород, улица Соревнования, 3"
7948,78537830,Data Base Architector,от 1 500 до 4 000 USD на руки,3–6 лет,"Полная занятость,полный день","LATOKEN is the supermarket of assets where it is easy to discover, exchange, earn and spend crypto. We are looking for Lead product developer IOS to level up our mobile app with CeDefi features for our 1.8 million mobile users. Mission: Well-structured, secure, and available DWH  Story: Product Teams need well-structured, secure, and highly available data, so product and performance data can be easily stored/accessed/analyzed Key PROBLEM's: All company data is consolidated into DWH and updated on a daily basis. How: Create new data pipelines for business need Maintain scripts and pipeline in case of problems or new requirement Constraints: All OKRs of the company are consolidated into Platform Ops All scripts are consolidated into Gitlab Main performance number: Ops OKR Health Second performance number: ClickUp Completion Rate Third performance number: Query response time, sec avg  Functions: • DWH objects audit • Queries: Advice on optimization and writing queries to databases • Automation: Automation of OKRs and slack bots for automated ops processes • Audit: Audit of DWH state and automated scripts  Requirement skills and experience: 2+ years of PostgresSQL DB administration experience 2+ years of experience writing Python scripts and applications for loading data Experience in configuring a database in a high availability architecture Experience in database optimization for different load profiles Experience in automating data loading from different sources (CRM,ERP, Web resources) * Eager to work with people with high performance standards Will be a plus Experience with financial data Experience as a data analyst.","Python,DWH,PostgresSQL,CRM,ERP",LATOKEN,
7950,78549287,Архитектор Data/ETL,з/п не указана,3–6 лет,"Полная занятость,полный день","КОМПАНЯ «АЙ-ТЕКО» - ведущий российский системный интегратор и поставщик информационных технологий для корпоративных заказчиков. Активно действует на рынке IT России с 1997 года, входит в ТОП-400 крупнейших российских компаний, ТОП-10 крупнейших IT-компаний России. В связи с активным развитием внутренних проектов в компании открыта вакансия АРХТЕКТОР DATA/ETL ЧЕМ ПРЕДСТОТ ЗАНМАТЬСЯ: АНАЛТЧЕСКАЯ ЧАСТЬ Cогласование и уточнение требований к системе копирования Cогласование и уточнение требований к системе трансформации OLAP кубов SAS РАЗРАБОТКА Разработка архитектуры системы копирования данных SAS Разработка архитектуры системы трансформации OLAP кубов SAS Настройка тестовой центральной ETL среды и тестовой MPP Greenplum Модуль копирования таблиц в staging по добавленным заданиям SAS (transport_worker_mpp.sas) Модуль управления (добавления) заданиями (add_copy_tasks.sas) Процесс перенос таблиц Staging в конечные таблицы хранилища (loopJob.sas) Процесс создания view на основе мета данных для интеграции c SAS EG (MPPGenerateViews.sas) Разработка модуля трансформации OLAP кубов SAS в плоские таблицы Реализация ETL-процесса c копированием таблиц SAS Оптимизация производительности Проведение нагрузочного тестирования Адаптация разработанного функционала для переноса на продуктивный стенд ДОКУМЕНТАЦЯ Разработка приемо-сдаточной документации Согласование результатов на тестовом стенде Участие в приемо-сдаточных испытаниях ЧТО ХОТМ УВДЕТЬ ОТ ВАС: Опыт работы с базами данных в качестве аналитика/разработчика от пяти лет Опыт участия в проектах по созданию и развитию DWH Опыт разработки OLAP-кубов Понимание принципов разработки с помощью ETL инструментария Опыт разработки высоконагруженных систем Опыт разработки логической и физической моделей данных Понимание предметной области Телеком Понимание нюансов работы платформ Teradata, SAS, Greenplum (особенности DDL,DML,PL/SQL) МЫ ГАРАНТРУЕМ: Работу в стабильной компании, белая заработная плата График работы 5/2 Социальный пакет (медицинская страховка, включая стоматологию) Корпоративный спорт: скидки на посещение фитнес-клубов, футбольная и волейбольная секции Работа в команде, использующей гибкий подход к разработке Оформление в соответствии с ТК РФ с первого дня работы Работа в развивающемся IT-проекте с командой специалистов высокого уровня, возможность развития и обмена опытом, корпоративное обучение","Teradata,Sas,Greenplum,DDL,DML,PL/SQL,DWH,OLAP,ETL",Ц АЙ-ТЕКО,
7953,78381745,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Контур — экосистема для бизнеса. Каждая четвертая компания в стране решает бизнес-задачи, используя наши сервисы. Мы автоматизируем документооборот, бухгалтерию и отчетность. Делаем эти процессы простыми и быстрыми, а сервисы — удобными для клиента.  Data Science в Контуре помогает оптимизировать внутренние процессы и добавляет ценности в продукты. Например, чат-бот Сирена экономит около 25% времени консультантов техподдержки в чатах, а технология распознавания речи обрабатывает тысячи лет записей в год. Мы постоянно следим за прогрессом в технологиях и разрабатываем новые методы и алгоритмы, чтобы сделать инновации доступными для использования в продуктах и процессах компании. В Центре искусственного интеллекта представлены разные роли: есть дата сайентисты, разработчики и аналитики данных, девопсы, QA-специалисты, системные аналитики, проджекты и продакт-менеджеры. Свое железо (V100/A100) и асессорская служба позволяют нам не ограничивать себя при работе с чувствительными данными, а также крутая инфраструктурная команда создает, улучшает и развивает инструменты MLOps на любой вкус от ресерча до прода. Мы ищем Senior Data Scientist в направление оптимизации процессов продаж и маркетинга. Нам нужен человек, который разовьет направление продаж и маркетинга с точки зрения машинного обучения: составит дорожную карту применения Data Science в процессах продаж согласует с бизнесом и приоритизирует сам проверит и доведет до продакшена гипотезы, и, как результат, повысит эффективность продаж и маркетинга. Примеры задач, которые уже решали Речевая аналитика (после ASR): оценка эффективности работы менеджеров по продажам на основании анализа текста звонков. Работа с конверсией: оценка вероятности оплаты клиентом счета по сделке по набору параметров. Что ожидаем от вас Опыт работы в аналогичной роли от двух лет. Опыт решения задач и понимание работы алгоритмов NLP и Classic ML. Умение общаться на языке заказчика, погружаться в продуктовый контекст. Умение работать в команде. Опыт декомпозиции, приоритизации больших задач. Опыт доведения задач до продакшена. Желательно иметь опыт доведения задачи от формулировки на языке бизнеса до прода (от начала до конца) работы с высокой неопределенностью: прокапывание проблематики, осознанный выбор решения. Технологии Python, SQL. GitLab. Docker, Kubernetes, AirFlow. Classic ML, языковые модели (BERT etc.). Мы предлагаем Зарплата зависит от ваших технических знаний и навыков. Пересматриваем ее два раза в год. Нам важно, чтобы вам было комфортно: непринципиально, где вы находитесь и во сколько начинаете рабочий день, главное – выполненные задачи. Умеем работать в команде, находясь в разных точках мира (Таллин, Ташкент, Астана, Лимассол, Екатеринбург, Москва и т. д.). Мы поддерживаем участие в конференциях, митапах и обучающих проектах. Наши деврелы помогут написать статью на Хабр, снять видео или подготовиться к выступлению на конференции. У нас сильное инженерное сообщество: регулярно проводим техническую конференцию КонфУР, обмениваемся опытом между командами, проводим дизайн-ревью с экспертами в разных технологиях. Всегда найдется, с кем посоветоваться. А еще у нас есть инженерный совет. Он придумывает и реализует проекты, которые улучшают жизнь инженеров в компании. Максимум горизонтальных связей в коллективе, чтобы быстрее договариваться и решать рабочие задачи. Присоединяйтесь :)","NLP,Machine Learning,Python,Data Science",Контур,
7955,78522628,Менеджер процессов Data Security,з/п не указана,1–3 года,"Полная занятость,полный день","Приглашаем в нашу команду МЕНЕДЖЕРА ПРОЦЕССОВ DATA SECURITY ОБЯЗАННОСТ: Настройка и обновление системы Настройка и контроль подключения системы к файловым хранилищам Настройка и контроль подключения системы к контролерам домена Формирование аналитических отчетов в системе Настройку правил инвентаризации хранимых данных Установка и поддержание работоспособности компонентов Проведение аналитики бизнес-процессов автоматизированных систем, создание политик Б. ТРЕБОВАНЯ: Высшее образование - информационная безопасность Знание спектр cyberpeak, varonis datadvantage: Понимание принципов устройства операционных систем Windows/Unix Опыт установки и настройки операционных систем Windows, Unix, Mac Навыки работы в PowerShell Знание серверных компонентов. УСЛОВЯ: Стабильный и прозрачный доход: зарплата и годовая премия по результатам работы График 5/2, работа в комбинированном формате (удаленно/офис - территориально м. Академическая (10 мин от метро) Забота о здоровье сотрудников: программа ДМС Личностное развитие и рост: организуем обучение и повышение квалификации сотрудников компании Профессиональные и благотворительные мероприятия.","cyberpeak,varonis datadvantage,нформационная безопасность,PowerShell",«РОСБАНК»,
7967,79064726,Data Engineer / ETL разработчик,з/п не указана,1–3 года,"Полная занятость,полный день","Мы - самый большой Бэкофис процессинга в Европе! У нас интересные и сложные задачи, действительно высокая нагрузка и большие объемы данных. щем разработчика витрин данных на проект построения Единого Семантического Слоя (ЕСС) по предметной области Карты и Кредитные Карты. Чем предстоит заниматься: Проектирование и разработка ETL-потоков. Построение витрин данных Верификация поставленных аналитиком задач (S2T - Source to Target) Поддержка внедрения функционала на этапах ПС и ОПЭ. Наши ожидания: Коммерческий опыт от 2-х лет Хорошее владение SQL – опыт написания/чтения сложных запросов с использованием аналитических функций Знание Apache Spark, Hadoop (или только Hadoop) Общее понимание устройства хранилищ данных Умение работать с большими объёмами данных Знание общих подходов к оптимизации Работа с GIT. Плюсом будет: Умение проводить системный анализ Знание Java на начальном уровне, т.к. используется Framework Hermes – собственная разработка Банка. Что мы предлагаем: Повышение и перемещение внутри экосистемы Сбера Корпоративный университет, Виртуальная школа Сбера, повышение квалификации, IT конференции, митапы, библиотека - обучение за счет компании ДМС с первого дня, страхование от несчастных случаев и тяжелых заболеваний Подписка СберПрайм+ для сотрудников, скидки и бонусы от компаний партнёров Материальная помощь и социальная поддержка, корпоративная пенсионная программа Льготные условия по ипотеке Спортзал прямо в офисе Яркая и насыщенная корпоративная жизнь Формат работы: офис 5/2, гибкое начало рабочего дня.",,Сбер. IT,"Москва, Кутузовская, Кутузовский проспект, 32"
7980,78329582,IT Специалист/Data Science Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Чем предстоит заниматься: Участие в сборе требований от бизнес заказчиков Разработка моделей и алгоритмов, оптимизирующих процессы работы по ключевым производственным переделам цементных предприятий Проверка гипотез с помощью статистических методов для поиска ключевых инсайтов, идентификации трендов, измерения производительности, подтверждение экономических эффектов Внедрение и сопровождение эксплуатации разработанных моделей для использования в рабочих процессах предприятий Тиражирование разработанных моделей и алгоритмов по предприятием Холдинга Что мы ждем от кандидата: Высшее техническое образование Опыт работы не менее 2 лет в решение прикладных DS задач, аналитических задач Опыт реализации не менее 2-3 проектов по машинному обучению и/или предиктивной аналитике Опыт разработки моделей машинного обучения для решения промышленных задач (желательно) Навыки коммуникации, желание работать в кросс-функциональных командах. Уверенное владение Python и его стека библиотек для машинного обучения. Опыт работы с базами данных, уверенное знание SQL и навык писать оптимизированные запросы к БД. Наличие реального опыта построения предиктивных моделей и запуска на prod-контуре Понимание специфики решения индустриальных задач Умение интерпретировать результаты и понятно презентовать результаты анализа Опыт в исследовательских проектах (желательно) Понимание технологий обработки больших данных (желательно) Нейросети (желательно) Что мы предлагаем: Достойная заработная плата Стабильная заработная плата 2 раза в месяц Корпоративное обучение, возможности профессионального и карьерного роста ДМС широкого спектра со стоматологией после испытательного срока Возможность выбрать начало дня с 8/9/10 утра Комфортабельный офис класса А на территории которого находятся фитнес-клуб/аптеки/магазины/столовые/кафе/парковые зоны Корпоративные мероприятия, подарки для детей сотрудников сключается возможность удаленной работы. Локация и транспортная доступность: Офис м. Славянский бульвар/ БКЛ Давыдково БЦ ""Верейская Плаза 4"" От м.Славянский бульвар доставка корпоративным транспортом – 10 минут От БКЛ Давыдково общественным транспортом - 10 минут.","Управление проектами,Базы данных,Data Analysis,Предиктивная аналитика,Машинное обучение",Цемрос,"Москва, Кунцевская, Кунцевская, Славянский бульвар, Верейская улица, 29с34"
7988,79026328,Ведущий аналитик качества данных / Lead Data Quality Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","мы ищем Ведущего аналитика качества данных для разработки процедур по улучшению показателей качества данных в нашей организации. На этой роли вы будете заниматься анализом, тесно работать с инженерами данных, архитекторами, распорядителями данных и владельцами для улучшения процедур сбора и хранения данных, а так же лидировать процесс по разработке и внедрению инструмента обеспечения качества данных Вы будете: Разрабатывать системы показателей оценки качества данных для повышения осведомленности о качестве данных организации и путей по его улучшению Выявлять корневые причины проблем с качеством данных и тесно работать с участниками процесса: владельцами данных и распорядителями для решения возникающих проблем Определять единый стандартизованный процесс решения проблем с данными от идентификации до разрешения Непосредственно участвовать в процессе определения модели управления качества данных Создавать образовательные инструменты/курсы и писать документацию для поддержки внутренних пользователей Создавать и поддерживать коммуникационный план об изменениях в области по работе с данными, основных изменениях Совместно работать с распорядителями, владельцами данных, владельцами продуктов данных и инженерами для разработки и внедрения передовых методов обеспечения качества данных Выполнять статистические тесты на больших наборах данных для определения качества и целостности данных Лидировать процесс разработки и внедрения инструмента по управлению качеством данных Участвовать в исследованиях данных для выявления проблем и исключений в данных, а также процессах их очистки Соблюдать лучшие практики анализа и сбора данных Быть в курсе событий и тенденций в области анализа качества данных. Мы ожидаем: Опыт лидирования процессов по управлению качеством данных Знание методологий и принципов управления качеством Отличные аналитические способности Понимание принципов разработки КХД Продвинутые навыки решения проблем Знание лучших практик анализа данных Хорошие коммуникативные навыки Хороший письменный и разговорный английский Мы предлагаем: Конкурентоспособную заработную плату и систему бонусов. Ежегодный пересмотр заработной платы (с учетом рыночной ситуации и индивидуальной результативности сотрудника). Страхование жизни и здоровья сотрудника, страхование для выезда за рубеж, 100% оплата больничного листа, страхование от потери трудоспособности. Корпоративную пенсионную программу. Дополнительную оплачиваемую неделю к отпуску после 5 лет работы в компании. нтересную динамичную работу, возможности для профессиональной реализации и карьерного роста. Возможность перенять более чем столетнюю экспертизу в управлении бизнесом.",Английский — B2 — Средне-продвинутый,Марс,"Москва, Сокол, Ленинградский проспект, 72к1"
8003,72563146,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы открыли офис в Омске! У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура • Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных • Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности: Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования: Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем Возможность работы в аккредитованной Т-компании Работу в офисе. График работы — гибридный Платформу обучения и развития Тинькофф Апгрейд. Курсы, тренинги, вебинары и базы знаний. Поддержка менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Компенсацию такси и 50% затрат на спорт от стоимости абонемента Компенсацию обедов. А если захотите перекусить, на каждом этаже есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,Работа с базами данных,ETL,Базы данных,DWH,СУБД,Databases",Тинькофф,"Омск, улица Фрунзе, 1к4"
8039,77723413,Системный аналитик Big Data,з/п не указана,1–3 года,"Полная занятость,полный день","АО «ЭнергосбыТ Плюс» - является крупнейшей энергоснабжающей организацией. С 2010 года ""Энергосбыт Плюс"" взял курс на цифровизацию и развитие Т по всем ключевым направлениям (автоматизация ключевых бизнес процессов на базе биллинговых и учетных систем, конгнитивные помощники, системы анализа данных, CRM-системы и т.п.). Предполагается, что построение цифровой инфраструктуры внутри компании не только позволит усовершенствовать бизнес-процессы, но и поможет клиентам чувствовать себя комфортно в городской среде. Мы находимся в поисках: Системного аналитика Big Data Мы предлагаем: Работа с интересными и нестандартными задачами Трудоустройство с первого дня работы в соответствии с ТК РФ Полностью официальная заработная плата Дополнительное медицинское страхование, включая стоматологию Ежегодная индексация заработной платы Годовая премия по результатам работы прошлого года Обучение и помощь в период адаптации (наставничество, внутреннее корпоративное обучение) Возможность профессионального и карьерного роста График работы: пятидневная рабочая неделя Возможность работать в режиме Home officе Основные задачи: Сбор требования, разработка технического задания, ввод в эксплуатацию, тестирование, мониторинг работы микросервисов, постановка задач для устранения проблем, написание паспортов систем Мы ожидаем от Вас: Знания методологии хранилищ данных Знание нормальных форм и проектирование в нотации DFD Опыт подготовки сложных скриптов (SQL, Python (sqlalchemy)) Опыт сбора требований и написания технической документации Опыт создания функциональных схем (Visio) Опыт работы в микросервисной архитектуре Опыт работы с CI/CD инструментами Присоединяйтесь, будем зажигать города вместе!","Python,Linux,SQL,MS Visio,Обучение и развитие,DFD",ЭнергосбыТ Плюс,
8046,78960127,Data-инженер (стрим еСпортс),з/п не указана,3–6 лет,"Полная занятость,полный день","MTS Digital — это инновационное подразделение МТС, которое работает над созданием экосистемы цифровых сервисов, мобильными приложениями, продуктами в финтехе, стриминге, гейминге, «облаках», AI и других направлениях.  Мы расширяем команду, которая занимается разработкой универсальной UGC платформы для развития инструментов стриминга и новых видео-форматов для блогеров, и ищем Data инженера.  Что предстоит делать: работать с представлениями данных, OLAP и различными BI-Аналитическими системами формировать отчеты, аналитические справки и презентации для продуктовой аналитики составлять дашборды, отчеты, выборки в рамках продуктовых задач формировать требования к источникам данных в рамках продуктовых задач. Наши ожидания: опыт работы с базами данных, умение писать сложные запросы, опыт создания дашбордов опыт обработки и структурирования данных опыт работы с DWH, MDM и комплексными хранилищами данных умение работать с Grafana, Clickhouse, Redash, PostgreSQL умение получать прямой доступ к данным умение описывать структуры данных, документирование данных умение работать со сложными аналитическими запросами в БД, знать язык SQL, читать и понимать процедуры написанные на pl\sql, pl\pgsql умение формировать выгрузки из БД, на основании тех. задания, сформированного дата-аналитиком, умение автоматизировать регулярные процессы в соответстии с требованями бизнеса Что мы предлагаем: собственную платформу MTS Ocean для получения Т-ресурсов, а это значит, что деплой, мониторинг, observability - не будут для вас проблемой, вы сможете сосредоточиться на фичах профессиональные гильдии инженеров по направлениям, чтобы поддерживать друг друга и обмениваться опытом внутреннюю площадку TechTalks для обмена опытом, дискуссий, развития навыков самопрезентации участие во внешних IT конференциях. Мы выступаем на HighLoad++, DataFest, Mobius, Test Driven Conf, Joker, DevOps, Матемаркетинг и даже проводим собственную конференцию по архитектуре Hello, conference! полезные курсы и вебинары в корпоративном университете и электронные библиотеки. А еще: медицинскую страховку с 1 месяца со 100% покрытием расходов, включая стоматологию, страхование жизни и здоровья в поездках за рубеж. Можно застраховать родственников с корпоративной скидкой доступ к сервису «Понимаю»: онлайн-консультации с психологом, юристом, экспертом по финансам или ЗОЖ корпоративный и командный психолог в офисе и массажный кабинет единую подписку МТС Premium — KION light в онлайн-кинотеатре KION, сервис МТС Music, 30 дней бесплатного пользования подпиской OZON Premium скидки и предложения от партнеров на фитнес, занятия английским и прочее.","Работа с базами данных,PostgreSQL,ClickHouse,Olap (online analytical processing),База данных: Olap,DWH,BI,OLAP",МТС,
8051,76413771,Менеджер по внедрению продуктов больших данных (Big Data),з/п не указана,1–3 года,"Полная занятость,полный день","Ваши будущие задачи: Взаимодействие со всеми функциями компании для конкретизации потребностей в продуктах больших данных. Вовлечение внутренних заказчиков в развитие продуктов, поддержка функций во внедрении продуктов в деятельность подразделений. Управление продуктовыми направлениями в роли Product Owner – контроль сроков, рисков, ресурсов Оценка перспектив и экономического эффекта от новых продуктов или от изменения существующих продуктов, приоритизация ресурсов по задачам, исходя из потенциального эффекта. Сбор обратной связи по продуктам – учет выручки, работа с удовлетворенностью заказчиков Подготовка презентаций для руководства и заказчиков по внедряемым продуктам и перспективам развития. Чтобы стать кандидатом, нужно: Опыт управления проектами – не менее 3х лет. Опыт работы с Agile (Scrum, Kanban) в роли Customer, Product owner или Team Lead – не менее 1 года. Опыт развития продуктов как конкурентное преимущество. Опыт работы в Контент-провайдере или Банке. Опыт работы в Телекоме как конкурентное преимущество. Хороший опыт проведения презентаций для внутренних и внешних заказчиков, опыт работы в пресейле как плюс. Опыт работы с контрагентами, понимание процессов документооборота. Опыт внедрения или развития хранилищ данных Понимание предметной области телеком оператора (бизнес-процессы обслуживания и продаж, техника и технологии сотовой связи, OSS/BSS-системы и пр.) Умение понимать потребности внутренних и внешних бизнес-заказчиков, управление ожиданиями и сроками Мотивация на результат, а не на процесс – четкое понимание целей, соблюдение сроков запуска и планов по выручке Сильные коммуникативные навыки, умение мотивировать и объединять матричную команду на проектную работу Базовое понимание основ и принципов скоринга и машинного обучения для взаимодействия с командой аналитиков, трансляции результатов бизнес-заказчикам Понимание предметной области работы с хранилищами данных (КХД, Hadoop, ETL). Плюсы для вас: нтересная работа в быстроразвивающейся компании Уникальная возможность работы с большим разнообразием аналитических задач Бесплатное прохождение курсов на одной из основных обучающих онлайн платформ Посещение специализированных конференций, в том числе и зарубежных Уникальная система обучения для каждого сотрудника на основе индивидуальных планов развития Возможность один день в неделю работать из дома Релокационный пакет при переезде из другого города Витаминно-фруктовой заряд по вторникам Так как офис очень просторный, есть возможность доехать до коллег на самокате Зеленый свет для новых идей и предложений: мы часто делаем то, на что другие не отваживаются Возможности профессионального и карьерного роста ндексируемая заработная плата, годовые бонусы Полное соответствие ТК РФ Расширенная медицинская страховка в России и за пределами страны - даже для любителей черных горнолыжных трасс Компенсация затрат на мобильную связь Дополнительные материальные выплаты (пособия при рождении ребенка, вступлении в брак и т.п.) Компенсация занятий спортом через год работы Современный офис класса ""А"" с развитой инфраструктурой (магазины, кафе, фитнес и т.д.) в 5-ти минутах пешком от метро Румянцево","Agile Project Management,Развитие продаж,Presale,OSS,BSS,DWH,Hadoop,ETL,Scrum",Tele2,
8055,78977724,Специалист по защите данных/Data Protection Officer в Яндекс Go,з/п не указана,3–6 лет,"Полная занятость,полный день","Современные сервисы в процессе работы собирают значительные объёмы данных, например, для обучения рекомендательных систем, продуктовой аналитики, анализа ошибок в приложениях, улучшения пользовательского опыта. Yandex Go заботится о приватности и защите пользовательских данных. Мы ищем человека, который усилит это направление. Что нужно делать: улучшать политики обработки и хранения приватных данных и внедрять их в различных сервисах совместно с командами безопасности разрабатывать best practices по работе с приватными данными повышать осведомлённость сотрудников придумывать новые технические подходы к защите данных, внедрять их вместе с командами разработки развивать и поддерживать процессы take out отвечать за соблюдение регуляторных требований, в частности 152-ФЗ и GDPR развивать механизмы дифференциальной приватности контролировать внедрение и соблюдение политик работы с данными. Мы ждем, что вы: хотите глубоко погружаться в процессы работы с данными участвовали в крупных инфраструктурных проектах понимаете GDPR знаете английский. Условия: сильная команда, с которой можно расти сложные задачи для сервисов с миллионами пользователей возможность влиять на процесс и результат зарплата на уровне рынка и выше премии каждые полгода для всех, кто успешно прошёл ревью расширенная программа ДМС: оплата 80% стоимости ДМС для супругов и детей гибкий график работы.","Знание английского языка,DPO,Data Protection Officer,персональные данные,Английский — B1 — Средний",Яндекс,
8060,78962457,Senior/ Team Lead Data Scientist в ML-команду,з/п не указана,1–3 года,"Полная занятость,полный день","Наша команда занимается построением ML моделей. При реализации кейсов и проведении пилотов находится множество инсайтов, которые помогают делать процессы эффективнее. Для развития этих инсайтов ищем коллегу, в обязанности которого будет входить нахождение решений на стыке ML и классической аналитики Перед командой стоят следующие вызовы: - Прогнозные и причинно-следственные модели - Аудио аналитика телефонных разговоров и записей взаимодействия с клиентами. В том числе перевод аудио в текст, вычленение эмоциональной подоплёки, определения лжецов - Текстовая аналитика записей. В том числе конспект разговоров, вычленение необходимых сущностей, определение лжецов - Гео аналитика клиентов. В том числе где и когда контактировать - Оптимизация бизнес процессов с использованием инструментов process mining Обязанности Фулл стек DS От идей до оценки эффективности готового продукта. Работа ведётся при регулярном общении с бизнес-заказчиком. Управление командой проекта DS Требования Владение алгоритмами работы с табличными пространственными данными, временными рядами, аудио, текстами, гео процессами (опыт от 2 лет совокупно) Python3, включая стек библиотек для работы с машинным обучением Общением с бизнесом по проектам машинного обучения, ориентацией на бизнес результат sql, jupyter, pycharm, git, jira, confluence Будет плюсом опыт управления проектами, в которых участвует несколько команд Условия комфортный офис на Кутузовском проспекте с тренажерным залом, коворкинг-пространствами и кафе полный рабочий день, но гибкий график работы (можно выбрать режим начала работы в промежутке 7:00 - 10:30) ДМС, программы лояльности для сотрудников (льготное кредитование, предложения экосистемы Сбера) комьюнити data-people, множество программ профессионального обучения (курсы, тренинги, конференции, семинары).",,Сбер для экспертов,
8061,78959480,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Мы находимся в поиске Data Engineer, который будет заниматься развитием направлений: ""Цифровая аналитика"", ""Антифрод"", "" Платформа DataLake"". Ваши задачи: Реализация ETL в Hadoop (с помощью Airflow). Работа с различными источниками данных: Oracle, MS SQL, API личных кабинетов, микросервисы. Батч и стримы с помощью PySpark и Kafka. Подготовка витрин для анализа (Hive + Spark + SQL). Наш стек: Ванильный hadoop Kafka, Spark, AirflowClickHouse Jira Confluence GitLab. Мы ждем от будущих коллег: Уверенное владение Python. Опыт использования эко-системы Hadoop: HDFS, Apache AirFlow, Hive, Kafka,Spark. Знание SQL. Опыт работы с реляционными базами данных (Oracle).","Python,Kafka,Spark","Компания «СПОРТМАСТЕР», Sportmaster Lab",
8062,67996104,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Мы находимся в поиске Data Engineer, который будет заниматься развитием направлений: ""Цифровая аналитика"", ""Антифрод"", "" Платформа DataLake"". Ваши задачи: Реализация ETL в Hadoop (с помощью Airflow). Работа с различными источниками данных: Oracle, MS SQL, API личных кабинетов, микросервисы. Батч и стримы с помощью PySpark и Kafka. Подготовка витрин для анализа (Hive + Spark + SQL). Наш стек: Ванильный hadoop Kafka, Spark, AirflowClickHouse Jira Confluence GitLab. Мы ждем от будущих коллег: Уверенное владение Python. Опыт использования эко-системы Hadoop: HDFS, Apache AirFlow, Hive, Kafka, Spark. Знание SQL. Опыт работы с реляционными базами данных (Oracle).","Python,Kafka,Spark","Компания «СПОРТМАСТЕР», Sportmaster Lab",
8074,78941888,Системный аналитик Big Data,з/п не указана,1–3 года,"Полная занятость,полный день","щем аналитика в команду, которая занимается развитием продукта Супермаркет Данных. Супермаркет Данных является частью инфраструктуры рабочего места D-People (Data Scientist, Data Engineer). Позволяет найти и получить данные Банка для исследования и промышленных процессов в режиме self-service. Мы разрабатываем единственную платформу по поиску и заказу данных No vendor lock на нашем рынке. У нас несколько десятков интеграций с различными системами, современные стандарты построения архитектуры продукта, и амбициозные планы по развитию. Все это делает работу в команде продукта интересной и нескучной, а также дает возможности для развития профессиональных навыков. Наш техстек: TypeScript, React, Apollo, Formik, Jest, React Testing Library, Node.js, PostgreSQL, Mocha, Chai, ElasticSearch, Logstash, Kibana, Grafana, Docker, OpenShift Обязанности: постановка задач на разработку на основе бизнес и функциональных требований документирование разработанной функциональности формализация контрактов взаимодействия между сервисами подготовка инструкций для сопровождения. Требования к кандидату: опыт работы в роли бизнес или системного аналитика понимание принципов микросервисной архитектуры знание нотаций описания процессов – UML, BPMN (в первую очередь диаграммы Sequence, ER) опыт описания интеграций через Rest, SOAP, GraphQL, очереди сообщений (RabbitMQ, Kafka) опыт написания SQL-запросов Будет плюсом: опыт работы на продуктах с микросервисной архитектурой знакомство с GraphQL и Apollo знакомство с Docker, Kubernetes, OpenShift знакомство с ElasticSearch, Logstash, Kibana, Grafana Условия работы: режим работы офис \ удаленка стабильный оклад и социальная поддержка сотрудников расширенный ДМС с первого дня работы для сотрудников и льготная медицинская страховка для близких бесплатная подписка СберПрайм +, скидки на продукты компаний партнеров: СберМаркет, Delivery Club, Самокат, СберЕаптека и других корпоративная пенсионная программа корпоративное обучение за счет компании реферальная программа для сотрудников: можно пригласить в команду знакомых профессионалов и получить денежное вознаграждение.","BPMN,REST,GraphQL,SQL,UML",Сбер. IT,"Самара, Алабинская, проспект Ленина, 17"
8076,77770273,Менеджер проектов Big Data,з/п не указана,3–6 лет,"Полная занятость,полный день","Чем предстоит заниматься Управлять созданием аналитических продуктов: ML моделей, витрин данных а также бизнес-процессов, в которых они должны работать Отвечать за целевое видение продукта, план и финансовый результат Работать с бизнес подразделениями для формирования приоритетных гипотез использования данных в бизнесе Участвовать в разработке стратегии аналитики и использования данных в компании, включая формирование списка возможных направлений, оценка эффекта и приоритизация работ Управлять процессом поддержки бизнеса в сложных разовых аналитических задачах Работать с подрядчиками по предоставлению дополнительных источников данных, инструментов аналитики, разработке или доработке бизнес-систем Что для этого нужно меет опыт работы в роли менеджера/руководителя проектов или тимлида в области анализа данных Умеет внедрять результаты аналитики и алгоритмы в бизнес-процессы Умеет управлять командой, ставить задачи и мотивировать на результат Эффективно коммуницирует ка уровне команды, подразделения, заказчиков и высшего менеджмента Понимает, что такое MVP и A/B тесты Умеет и хочет работать руками: собрать презентации по своему направлению, посчитать финкейс, вести бэклог гипотез и актуальный план работ, проанализировать результаты пилотов Дополнительным плюсом будет опыт разработки рекомендательных моделей и моделей NBA, а так же, опыт работы в направлении целевого маркетинга B2C","Управление проектами,MS PowerPoint,Анализ данных,Бизнес-анализ,Аналитическое мышление,Продуктовая аналитика,Проведение пилотов,Таргетированные коммуникации,Тестирование разных алгоритмов и выбор оптимального,ML,A/B тесты","МегаФон, IT","Москва, Маяковская, Новослободская, Чеховская, Оружейный переулок, 41"
8083,78625975,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","RUTUBE - Крупнейший российский видеохостинг, где собраны различные категории видео: премьерные выпуски шоу и сериалов, прямые эфиры телеканалов, фильмы и мультфильмы, контент видеоблогеров. Мы стремимся сделать лучший видеосервис на базе высокотехнологичных решений, исследований и аналитики, который позволит смотреть качественный лицензионный контент, адаптированный под каждого пользователя. Сейчас нам требуется Senior Data Science, способный быстро погрузиться в новые задачи и усилить нашу команду. Что ты будешь делать: Полный цикл обучения ML моделей, включая подготовку данных для разметки и внедрение моделей в продакшн Разработка CV/NLP/Speech моделей в следующих бизнес-направлениях: Рекомендации: фильтрация контента, развитие инструментов ранжирования и персонализации, механизмов валидации Модерация: анализ видео и комментариев на предмет наличия нарушений авторских прав, откровенного контента, рекламы казино и т.д. Поиск: усовершенствование механизмов поиска с целью выдачи более релевантных результатов Speech-To-Text для транскрибации видео и автогенерации субтитров Взаимодействие с заряженными владельцами продуктов (рекомендации, модерация, поиск) в целях формирования бэклога и развития ML направления для достижения бизнес-результатов Рисерч по использованию SOTA методов (трансформеры для задач обработки текста, речи и видео) Анализ данных, формулировка гипотез и дизайн экспериментов Поиск путей улучшения качества работы текущих моделей Возможность влиять на реальный результат. Что ты уже умеешь: Высшее образование в областях: математика, физика, информатика Знания классического и нейросетевого ML Знания современных технологий компьютерного зрения (CNN, YOLO, U-Net, ViT) и/или методов обработки естественных языков (Word2Vec, fasttext, RNN, трансформеры) Практический опыт работы с PyTorch или TensorFlow Уверенный Python, Linux, SQL, Git Коммуникабельность, умение находить компромиссы и аргументировано отстаивать свою точку зрения Уверенный английский для изучения научной литературы. Будет плюсом: Опыт работы с поисковыми движками Опыт работы с Docker и K8s Опыт использования решений для взаимодействия с backend (PostgreSQL/kafka/rest api/rabbit mq и т.п.). Что мы предлагаем: Опыт работы над крупнейшем видеосервисом страны Работу в команде профессионалов и творческих людей Достойный уровень дохода (обсуждается индивидуально с каждым кандидатом) Мы оформим ДМС не дожидаясь окончания испытательного срока Фрукты, овощи, вкуснейший кофе каждый день Гибкое начало рабочего дня (гибридный формат 2-3 дня в офисе) Уютный офис в шаговой доступности от метро Сокол БЦ Алкон.","Python,SQL,Git,Linux,Математическая статистика,PostgreSQL,PyTorch,NLP,Kafka,Bash,Docker,Machine Learning,RabbitMQ,Tensorflow,Word2Vec",Rutube,"Москва, Аэропорт, Красный Балтиец, Сокол, Ленинградский проспект, 72к4"
8084,67996407,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы находимся в поиске Senior Data Engineer, который будет заниматься развитием направлений: ""Цифровая аналитика"", ""Антифрод"", "" Платформа DataLake"". Ваши задачи: Реализация ETL в Hadoop (с помощью Airflow) Работа с различными источниками данных: Oracle, MS SQL, API личных кабинетов, микросервисы Батч и стримы с помощью PySpark и Kafka Подготовка витрин для анализа (Hive + Spark + SQL). Наш стек: Ванильный hadoop Kafka, Spark, AirflowClickHouse Jira Confluence GitLab. Мы ждем от будущих коллег: Уверенное владение Python Опыт использования эко-системы Hadoop: HDFS, Apache AirFlow, Hive, Kafka,Spark Знание SQL Опыт работы с реляционными базами данных (Oracle).","Data Engineer,Python,SQL,Hadoop,ORACLE","Компания «СПОРТМАСТЕР», Sportmaster Lab",
8085,67996119,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы находимся в поиске Senior Data Engineer, который будет заниматься развитием направлений: ""Цифровая аналитика"", ""Антифрод"", "" Платформа DataLake"". Ваши задачи: Реализация ETL в Hadoop (с помощью Airflow) Работа с различными источниками данных: Oracle, MS SQL, API личных кабинетов, микросервисы Батч и стримы с помощью PySpark и Kafka Подготовка витрин для анализа (Hive + Spark + SQL). Наш стек: Ванильный hadoop Kafka, Spark, AirflowClickHouse Jira Confluence GitLab. Мы ждем от будущих коллег: Уверенное владение Python Опыт использования эко-системы Hadoop: HDFS, Apache AirFlow, Hive, Kafka,Spark Знание SQL Опыт работы с реляционными базами данных (Oracle).","Data Engineer,Python,SQL,Hadoop,ORACLE","Компания «СПОРТМАСТЕР», Sportmaster Lab",
8089,76391976,Data Scientist на проект «Синтез речи» (remote),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Кто мы? Наша компания основана Сбером в 2013 году. Четыре года назад под брендом VS Robotics мы запустили новое направление в сфере речевых технологий. С использованием отечественного ПО наша команда создает на базе AI технологичные продукты, которые помогают сокращать расходы на коммуникации с клиентами, повышают эффективность рабочих процессов и легко адаптируются под любые направления бизнеса. Наши флагманские продукты: робот-оператор, система речевой аналитики, распознавание речи и голосовой скоринг применяются в крупнейших компаниях России и СНГ. Сегодня мы являемся аккредитованной IT-компанией и входим в перечень системообразующих организаций, ведущих деятельность в сфере информационных технологий. По итогам 2020 и 2021 года по версии портала Cnews мы входим в ТОП-3 крупнейших игроков России в области AI. Мы не похожи на других, поскольку не просто идем в ногу со временем, но и стараемся его опередить, воплощая инновационные решения во всем: от продуктов и услуг до способов управления бизнес-процессами. В VS Robotics можно смело предлагать идеи и реализовывать их совместно с командой, применяя лучшие практики Scrum и Agile. Мы ставим перед собой самые амбициозные задачи и уже сейчас создаем продукты, которые в скором времени удивят мир. Мы ищем сотрудника, который: меет опыт работы в Data Science не менее трех лет Уверенное владеет Python, опыт не менее трех лет меет опыт работы с библиотеками глубокого обучения (PyTorch) Понимает работу и сферу применения нейронный сетей Владеет английским языком для чтения и обработки технической документации Работает на Linux и использует git, dvc Будет большим плюсом: Хорошая математическая подготовка Опыт создания TTS: Tacotron, FastSpeech, FastPitch, HiFiGAN, Lpcnet др. Опыт извлечения / подготовки данных / ETL Опыт имплементации научных статей Знание основ SQL Опыт работы с Jupyter notebook Опыт работы с регулярными выражениями (regexp) Что предстоит делать? Поддержка текущего решения TTS (text-to-speech) для голосовых ассистентов RnD в области TTS Организация оценки моделей с помощью crowd platforms Взаимодействие со смежными подразделениями Что мы предлагаем? Конкурентная заработная плата и годовая премия Оформление согласно ТК РФ, выплаты 5 и 20 числа каждого месяца Пятидневка с «короткой» пятницей, по согласованию с руководителем возможен гибкий график работы или дистанционный Рабочий ноутбук Культура открытости, наставничества и взаимопомощи Работа строится по Agile-схеме с двухнедельными спринтами Сложные и интересные задачи в собственных highload-проектах, работа с современным востребованным стеком Возможность предлагать идеи и развивать экспертизу в сфере AI и Big Data Обмен опытом на совместных синках с лидами экспертизы Возможность «пощупать» новые технологии и прокачать скиллы Участие во внешних мероприятиях, включая конференции, митапы Обучение в Корпоративном университете Сбера за счёт компании Доступ к Виртуальной школе Сбера 24/7 Карьерные перспективы в рамках компании и экосистемы Сбера Выгодные программы кредитования и вкладов в Сбере Льготная ипотека, в т.ч. рефинансирование СберКарта с бесплатным обслуживанием и кэшбэком до 10% бонусами СберСпасибо Доступ в СберКлуб: корпоративные скидки и дисконт-программы от партнеров экосистемы Сбера Бесплатная подписка «СберПрайм+» (Окко, Сбермобайл, Звук, Delivery, СберМаркет, СберМегаМаркет и т.д.) ДМС, включая стоматологию и телемедицину, скидка 80% по ДМС для родственников Страхование от несчастных случаев Скидка в СберСтрахование Корпоративная пенсионная программа Скидки на онлайн изучение английского языка Скидки на посещение фитнес клуба World Сlass & UFC GYM для сотрудников и их родственников Активная корпоративная жизнь команды, награды, подарки Для кандидатов с локацией в Москве доступен комфортный офис (МЦК / м. Кутузовская): тренажерный зал, оpen-space, кухня, кофемашина и т.д. Присоединяйтесь к команде VS Robotics!","RND,Python,Linux,Git,SQL,PyTorch,Data Science,Нейронные сети,ETL",АБК,
8096,78529466,Руководитель отдела (Master data management),з/п не указана,3–6 лет,"Полная занятость,полный день","Mediascope – исследовательская компания, которая работает на стыке медиа и IТ. Почти 30 лет мы анализируем аудиторию телевидения, интернета, радио и прессы, создаем уникальные аналитические продукты, которыми пользуются более 1000 российских медиа, рекламных агентств и компаний-рекламодателей. Наша задача – создавать и поддерживать индустриальные стандарты работы с данными на рынке медиа и рекламы, а также развивать медиаисследования в России.  Мы являемся аккредитованной IТ-компанией и входим в ТОП-15 работодателей России в категории «средние компании» по версии рейтинга hh.ru. Нам важно сохранять высокий темп развития компании, и мы стремимся, чтобы качество наших продуктов и нашей работы продолжало расти. щем в команду профессионала, который выстроит процесс управления НС (RDM) на платформе Ataccama для управления НС в Mediascope Data Platform, а также наберет сотрудников в свой отдел. Роль будет совмещать в себе проектирование архитектуры, управление проектами и аналитику. Чем предстоит заниматься Анализ, унификация, нормализация НС Компании в мастер системах компании Разработка подходов и методов работы по нормализации и структуризации больших массивов данных Ведение и преобразование существующей архитектуры классификации данных Ведение дорожной карты \ стратегии развития классификации данных Разработка шаблонов наименований для унификации, нормализации данных Участие в архитектурном комитете, взаимодействие с аналитиками, разработчиками и коллегами из бизнес-подразделений Разработка документации, регламентирующей работу с данными Построение работы отдела, набор сотрудников в команду Что для этого потребуется Обладать опытом проектирования DWH Опыт применения Spark SQL и Pyspark в целях формирования наборов данных и их обработки Опыт анализа больших массивов данных Будет плюсом опыт работы с платформой Attacama Навык анализа технической документации Мы предлагаем Возможность выбирать комфортный формат работы – офис, удалёнка или гибрид, гибкое начало рабочего дня Конкурентную белую зарплату Официальное оформление, гарантию соблюдения трудового кодекса РФ, стабильную выплату заработной платы Расширенную медицинскую страховку (включая стоматологию). Работа в Mediascope – это Сложные и нестандартные задачи. Погружайтесь в работу с данными в индустриях, где происходит все самое интересное: Медиа, Реклама, Web, Mobile. Современные технологии и эффективные подходы к работе. Применяйте актуальные инструменты для успешной работы. Непрерывное развитие. Получайте новые знания на профильных конференциях, обменивайтесь опытом с коллегами-экспертами и участвуйте в еженедельных образовательных митапах компании. Профессиональные и открытые коллеги. Работайте в команде сильных специалистов, основа которой - открытость, человечность, доверие, экологичность общения. Откликайтесь, и давайте обсудим все детали вакансии!","Python,SQL,Аналитические исследования,Аналитическое мышление,Архитектура,Анализ данных,Системный анализ",Mediascope,"Москва, Марьина Роща, Савёловская, улица Двинцев, 12к1Б"
8107,78911120,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы ищем Data Engineer, готового присоединиться к нашей команде для работы над проектом Рейтинга поставщиков. Вам предстоит: Спроектировать архитектурное решение Проводить расчеты и аналитику по данным Администрировать инструменты и обеспечивать качество данных Заниматься созданием витрин Строительство DWH: проектирование, оптимизация, мониторинг. Мы ждем, что вы: меете опыт работы DE от 2-х лет Работали с Greenplum, Clickhouse, PostgreSQL Хорошо знаете Python и SQL, имеете опыт оптимизации запросов Знакомы с оркестрацией ETL на Airflow или аналогах. Мы предлагаем: Удаленный или гибридный формат работы Конкурентную заработную плату спользование современного технологического стека Максимум возможностей для профессиональной самореализации.","Python,ClickHouse,PostgreSQL",WILDBERRIES,
8109,78899851,Senior Data-аналитик в команду развития отчетности для Operations банка,з/п не указана,3–6 лет,"Полная занятость,полный день","Operations в Райффайзен Банке отвечает за работу ключевых функций: транзакции, банкоматы, поддержка кредитного процесса. Наша команда обеспечивает домен Operations данными, статистикой и аналитикой для принятия правильных стратегических и операционных решений. Мы активно разрабатываем, создаем и развиваем отчетность во всех сферах деятельности Operations. Это включает в себя анализ систем и процессов банка, развитие и расширение DWH, построение и обогащение аналитических витрин данных, а так же построение правильной архитектуры отчетности на всех уровнях. Работа в нашей команде позволит тебе присоединиться к коллективу профессионалов, объединённых общей идеей проявить свои навыки и способности получить поддержку коллег и профессиональный рост. Чем предстоит заниматься: автоматизировать отчетность, предлагать идеи по улучшению метрик анализировать данные из различных систем и источников внутри банка проводить EDA: видеть в цифрах не “сухую статистику”, а уметь извлекать новые знания и презентовать их проектировать витрины данных собирать, обрабатывать и документировать требования пользователей и бизнес-заказчиков с учетом технологической архитектуры сопровождать процесс разработки отчетности на всех этапах, тестировать и проводить UAT выполненных доработок участвовать в 3-ей линии поддержки пользователей, разбирать инциденты и исправлять ошибки. Ожидания от экспертизы и опыта: владение SQL на высоком уровне (join-ы, агрегация, CTE, оконные функции) умение пользоваться методами статистического анализа, знание теории вероятностей и математической статистики опыт работы с BI-инструментами (PowerBI, SuperSet, DataLens, Tableau), хранилищами и озерами данных (DWH / Data Lake) развитые аналитические навыки, способность приоритизировать задачи желание брать инициативу в свои руки и достигать результата аккуратность, ответственность, коммуникабельность английский язык на уровне чтения технической документации. Будет плюсом: владение Python и знакомство с основными библиотеками для аналитики (pandas, numpy, scipy, sklearn, matplotlib) знания принципов построения управленческой и операционной отчетности опыт работы с большими объемами данных из разнообразных источников. Мы предлагаем: гибридный или полностью удаленный формат работы работа со стеком технологий BigData, а так же с классическим RDBMS дружелюбный коллектив – команда с атмосферой открытости и взаимопомощи комфортная среда для развития и возможность активно участвовать в принятии важных решений социальный пакет, включающий ДМС, страхование выезжающих за рубеж и не только льготное кредитование, программа корпоративных скидок и не только профессиональные обучающие курсы и конференции, а так же своя Т-академия доплату за 14 дней в году по больничному листу до оклада (после испытательного срока) доплату к отпускам, оформленным в январе и мае 3 оплачиваемых отгула в год.",,Райффайзен Банк,
8114,78889723,Head of Data Analytics,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Подготовка, валидация архитекторы решений, связанных с продвинутой аналитикой и управлением данными. Проведение бизнес-анализа задачи, предложение путей решения. Разработка и руководство разработкой AA/ML алгоритмов для решения бизнес-задач. Разработка и руководство разработкой приложений, необходимых для цифровой трансформации. Наставничество для текущей команды продвинутой аналитики, формирование направлений развития Требования: Высшее математическое, техническое (информационные технологии) AA/ML, Python, SQL, базы данных, Excel Опыт работы непосредственно с моделями ML и их продвижением в бизнесе Условия: Работа в постоянно растущей и развивающейся компании Самостоятельность в принятии решений и реализации идей Участие в проектах федерального масштаба, участие в международных запусках Конкурентную заработную плату по результатам интервью и KPI по итогам выполнения планов Возможности обучения по самым разным направлениям Комфортабельный офис в Бизнес-центре ""Арма"", метро Курская.","Работа в команде,MS PowerPoint,Анализ данных,Аналитическое мышление,C++,Английский — B1 — Средний",ГЛОРЯ ДЖНС. Офис,
8116,78887135,Data Architect,з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Участие в разработке и внедрении методологии и процессов управления данными с учетом лучших и регуляторных практик DAMA DMBOK Обеспечение внедрения и согласования процессов Data Governance с политиками и регламентами Data Office Участие в работах по включению в периметр Data Governance процессов согласно приоритетам организации Разработка правил (методологии) формирования и ведения моделей архитектуры данных Разработка подхода для внедрения доменной архитектуры данных Компании Разработка и актуалиазация концептуальной, логической и физической моделей архитектуры данных Компании Формирование требований к инструментам автоматизации процессов Data Governance и их последующее внедрение Data Lineage / Data Provenance – подготовка требований, выбор и внедрение инструментов, разработка методологий отслеживания жизненного цикла данных, каталогизация Осуществление контроля соответствия моделей архитектуры данных и приложений Управление метаданными: каталог доступных источников, таблиц, витрин, моделей данных и отчетов, историю происхождения данных Обеспечение совместного ведения/развития, актуализации и использования бизнес-глоссария и каталога данных Пользовательский портал по данным: поиск объектов данных, владельцев, ролей, наборов данных, просмотр актуальных цепочек происхождения и правил по качеству данных Анализ инцидентов и проблем в межсистемной интеграции на уровне сущностей и атрибутов, поиск корневых причин посредством архитектуры данных Управление внутренними коммуникациями. Требования: Опыт в Data Governance/архитектуре или аналитике DWH/развития и сопровождения систем управления данными (MDM, Metadata Management и DQ) Опыт проектирования бизнес, логической и физической моделей данных. Понимание задач, решаемых каждым видом модели Знание методов и инструментов моделирования архитектуры данных Опыт написания методологических и регламентирующих документов Понимание основных методологий проектирования и ведения корпоративной архитектуры (TOGAF, Zachman и другие). Опыт применения данных методологий рассматривается как преимущество Знание национальных и международных стандартов в области управления данными и/или качества данных (СТ РК, ЕТ, ГОСТ, ISO) Опыт участия в качестве архитектора во внедрении и/или поддержке корпоративных хранилищ данных/систем Знание принципов управления данными, жизненного цикла данных, data lineage Понимание основных принципов и паттернов проектирования микросервисной архитектуры Опыт внедрения и сопровождения каталога данных, портала знаний и бизнес глоссария Навыки структурирования информации и упрощения, викификации знаний Языки SQL и Python: опыт работы с ETL-инструментами, умение читать сложные SQL-запросы и писать простые, умение автоматизировать рутинные действия в Python Навыки бизнес-анализа, использование UML/ARIS/BPMN. Что мы предлагаем: Медицинское страхование Внутреннее и внешнее обучение Служебная мобильная связь Участие в программе годовых бонусов Корпоративное предложение фитнес услуг Ежегодный отпуск 28 календарных дней Бесплатная подписка MyBook Новый современный офис в центре города Гибридный формат работы.",,Мобайл Телеком-Сервис (Объединенная Компания Tele2/ALTEL),
8117,77818891,Data Scientist middle+/senior (Транскодинг),з/п не указана,3–6 лет,"Полная занятость,полный день","Сейчас в Okko создается новый продукт – Видеоплатформа. Это B2B-инструмент для работы с видеоконтентом. Ключевое значение для разработки продукта имеют обработка видео (транскодинг) и оптимизация процессов, связанных с ней. В команду транскодинга мы ищем человека, который сможет сформировать и вывести ML-решения для улучшения продукта, а также найдет баланс между математическими способами решения задач и ML. Обязанности: исследование применимости различных алгоритмов в рекомендательной системе и в системах с применением компьютерного зрения моделирование входных данных интеграция исследованных моделей в системах проведение экспериментов с созданными моделями автоматизация процессов подготовки данных оптимизация потребления ресурсов сервисами, а также повышение утилизации ресурсов и применения ML интеграция сервисов с распределенными системами (Базы данных, Очереди). Требования: высшее техническое/математическое образование знание математической статистики и высшей математики критичны для решения наших задач умение инициализировать новое направление от идеи и построения инфраструктуры до вывода решения в прод для конечных пользователей знание основ статистики понимание классических ML-алгоритмов способность анализировать статьи и имплементировать описываемые алгоритмы базовые знания о Сomputer Vision знание Python желателен опыт работы с видео, изображениями, с рекомендательными системами. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,Machine learning,Сomputer Vision",Okko,"Москва, Баррикадная, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с13"
8118,78887882,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","СберЗдоровье - аккредитованная IT-компания, крупнейшая в России Digital Health платформа, объединяющая различные сервисы цифровой медицины. Сервис начал свою работу в 2012 году под брендом DocDoc. Мы помогли миллионам людей получить помощь и продолжаем повышать качество медицинских услуг. Об IT в цифрах: 3 бизнес-направления 15+ команд (каждая наша команда кросс-функциональная, 7-12 человек, включает в себя QA, DevOps, аналитиков, архитекторов, Web/Mobile разработчиков и конечно же своего PM) 250+ IT специалистов (devops, manual/auto QA, web/mobile devs, backend devs, аналитики и архитекторы) из 40+ городов Чтобы система была безопасней, а наши пользователи — счастливей, мы открыли вакансию DevSecOps. Почему у нас интересно? Потому, что у нас современный и востребованный продукт. Цели и задачи (на любой вкус): Выбрать целевую БД и построить хранилище данных Vertica / Greenplum / Citus / что-то другое Разобраться с CDC — думаем про Debezium DV2.0 / Anchor / Гибрид DataOps / MLOps — затащить лучшие инструменты и практики Airflow + DBT + Great Expectations + DVC + MLFlow + label studio или любой другой стек в рамках здравого смысла Каталог данных / Data Discovery / Data Lineage Datahub / Amundsen / Marquez / другое отличное решение Архитектура и имплементация своего click+event stream решения Snowplow / Rudderstack / Jitsu / другое отличное решение Что надо уметь: Опыт 2+ года в роли DE с похожими задачами Отличные знания Python и SQL Уверенные знания и опыт по нескольким пунктам из списка: Модели хранилищ данных: плюсы, минусы, подводные камни Airflow / Prefect / Dagster DBT / что-то схожее Great Expectations / другие DQ либы MLFlow / Kubeflow и DVC Kafka и Spark / Flink Vertica / Greenplum / Citus / Clickhouse Что тебе может дать СберЗдоровье: Возможность развития в команде ведущей MedTech-компании России. Свободный выбор рабочего формата: удалённый внутри страны или гибридный в Москве. Офис на набережной рядом с метро «Автозаводская». Корпоративное медицинское решение в любом городе страны со стоматологией и психологами. Поддерживаем активный образ жизни: выбирай виды спорта по душе (корпоративные команды, компенсация абонемента). Оплата профильного обучения и конференций. Скидки и бенефиты от наших партнёров. Оплачиваемые курсы английского языка. Льготная ипотека. Приятное дополнение: Всегда поддержим, если ты захочешь посетить профильные конференции, и, тем более, выступить на них. Мы общаемся на “ты”, не любим бюрократию и всегда помогаем друг другу.","Работа с базами данных,DataOps,MLOps,Airflow,Python,MS SQL,Prefect,Dagster,Great Expectations,MLFlow,Kubeflow,DVC,Kafka,Spark,Flink,Vertica,Greenplum,Citus,ClickHouse",СберЗдоровье,
8119,78886145,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Разработка, поддержка и оптимизация ETL/ELT процессов на Oracle Data Integrator Разработка и поддержка витрин данных в интересах аналитиков/datascience Обеспечение доступности данных в регламентные сроки Оптимизация SQL запросов Оптимизация структуры данных Обработка ошибок и поддержание качества данных в хранилище Реализация обмена данными в гетерогенных средах средствами Python/Airflow Поддержание документации по процессам ETL/ELT, сущностям и объектам DWH в актуальном состоянии Требования: Уверенное владение SQL и PL/SQL Чтение и понимание плана запроса Чтение и понимание чужих скриптов Опыт оптимизации запросов на больших объемах данных (от 100M строк в запросе) Желательно опыт работы с Oracle Data Integrator и/или Apache Airflow Опыт реализации высокопроизводительного извлечения/загрузки данных средствами Python. Что мы предлагаем: Медицинское страхование Внутреннее и внешнее обучение Служебная мобильная связь Участие в программе годовых бонусов Корпоративное предложение фитнес услуг Ежегодный отпуск 28 календарных дней Бесплатная подписка MyBook Новый современный офис в центре города Гибридный формат работы.",,Мобайл Телеком-Сервис (Объединенная Компания Tele2/ALTEL),
8121,77772446,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","щем коллегу, который энергично погрузится в тонкости работы экосистемы данных в Okko и поможет в решении таких задач как: внедрение ETL-процессов на Airflow создание витрин данных участие в построении DWH участие в проектировании модели данных администрирование существующих BI-инструментов. Требования: уверенное знание SQL знание Python умение организовывать ETL-процессы опыт построения DWH опыт проектирования модели данных опыт работы с большими объемами данных умение работать в командной строке Unix-систем. Что мы используем: Presto/Trino, Impala, ClickHouse, PostgreSQL, SberCloud Python и основные ML библиотеки: Pandas, NumPy, SciPy, Scikit-Learn BI среду Splunk. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,ETL,DWH",Okko,"Санкт-Петербург, Беговая, улица Савушкина, 126Б"
8125,77772473,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","щем коллегу, который энергично погрузится в тонкости работы экосистемы данных в Okko и поможет в решении таких задач как: внедрение ETL-процессов на Airflow создание витрин данных участие в построении DWH участие в проектировании модели данных администрирование существующих BI-инструментов. Требования: уверенное знание SQL знание Python умение организовывать ETL-процессы опыт построения DWH опыт проектирования модели данных опыт работы с большими объемами данных умение работать в командной строке Unix-систем. Что мы используем: Presto/Trino, Impala, ClickHouse, PostgreSQL, SberCloud Python и основные ML библиотеки: Pandas, NumPy, SciPy, Scikit-Learn BI среду Splunk. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,ETL,DWH",Okko,"Москва, Баррикадная, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с13"
8130,78887598,Senior Data Analyst (Департамент противодействия мошенничеству),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы управляем мошенническим риском в розничном портфеле Хоум Кредита на всех этапах кредитного процесса - от фронта до мониторинга выдач и решаем очень сложную задачу, но мега-интересную задачу – определить на стадии заявки ""того самого"" мошенника. Команда большая, ждем того, кто вольется в нашу активную жизнь в коллективе и принесет свежие идеи, знания, мнения и вложит свою часть умений в выполнение амбициозных задач. ЧЕМ ВЫ БУДЕТЕ ЗАНМАТЬСЯ: Анализировать и принимать решение о том, какие инструменты противодействия мошенничеству являются эффективными Придумывать новые модели и ставить задачи DS на разработку Оценивать влияние на портфель тех или иных инициатив Определять каких аналитических витрин не хватает и разрабатывать их прототип/ставить задачу на разработку ЧТО ВАМ ДЛЯ ЭТОГО НЕОБХОДМО: Технический бэкграунд , высокий уровень знаний в области математической статистики Опыт работы с портфелем в розничных рисках Опыт в моделировании и постановке задач для DS SQL на высоком уровне (оконные функции, макросы) Python (pandas, numpy) Опыт работы с экосистемой Hadoop (HDFS, Hive, Spark) as a plus Опыт работы в антифрод проектах, как плюс Опыт управления командой от 2-3 человек, как плюс МЫ ПРЕДЛАГАЕМ: Фиксированный оклад + система премирования Социальный пакет Офис: м. Белорусская Команда, открытая самым смелым идеям Внутренние программы обучения и развития Высокий уровень ответственности и возможность самостоятельно принимать решения Атмосфера, где легко оставаться собой: минимум формализма, открытые коммуникации и отсутствие дресс-кода","MS SQL,Hadoop,Python,Hive,Spark,ML,Моделирование,Математический анализ",Банк Хоум Кредит,"Москва, Белорусская, Правды, 8 к.1"
8131,77327271,"Business Development Manager (BI, Data Governance \ Data Management)",з/п не указана,3–6 лет,"Полная занятость,полный день","Компания «нфосистемы Джет» — одна из 10 крупнейших Т-компаний в России и СНГ. Наша команда разработки за год выполняет более 300 проектов в области DevOps, Big Data, Data Lake, Machine Learning, CRM, лояльности, клиентского опыта и интеграционных решений. Среди клиентов лидеры ритейла (М.Видео, X5 Retail Group, Детский Мир), крупнейшие банки (Сбербанк, ЮниКредит Банк, НСПК, РСХБ), промышленность (НЛМК) и др.  что важно – в нашей команде нет утомительной бюрократии и сложной иерархии. У нас принято общаться друг с другом на «ты», не теряя при этом взаимного уважения. Чем вы будете заниматься: Развитием продаж продуктов и услуг Центра – хранилища и озера данных, BI системы, интеграционные шины и решения класса Data Governance \ Data Management. Формирование долгосрочных отношений с существующими заказчиками: поддержание коммуникаций с ключевыми сотрудниками Заказчика выявление степени удовлетворенности Заказчика качеством и результатами работ выявление новых потребностей в автоматизации, IT – трансформации и консалтинге помощь в идентификации и расчете бизнес – выгод от изменений мониторинг тендерных процедур, инициированных заказчиком управление пресейловыми активностями. 3. Выстраивание отношений с новыми заказчиками: поиск новых заказчиков (нетворкинг, лиды от вендора, лиды по итогам мероприятий и профессиональных встреч и т.д.) поиск контактов и налаживание коммуникаций презентация компании, продуктов и услуг выявление потребности по предлагаемым услугам 4. Управление пресейловыми активностями: проработка потребностей Заказчика совместно с техническими специалистами и аналитиками подготовка команды к встречам с заказчиком (цель встречи, желаемые результаты встречи, перечень вопросов, роли, акценты, дополнительные установки) постановка задачи техническим службам на формирование оценок и подготовку технического описания решения привлечение смежных центров Компании для работы с комплексными заявками (инфраструктура и сетевые решения, Б и сервисный центр) обсуждение с техническими специалистами Заказчика реализуемости потребностей, вариантов технических решений, выработка итоговых предложений подготовка ТКП, проведение встреч и конференций по защите ТКП взаимодействие с подрядчиками и смежными подразделениями в рамках пресейла. 5. Внутренний и внешний PR продуктов и услуг центра: проведение презентаций и обучений по продуктам и услугам Центра для Дирекции по продажам подготовка внутренних и внешних маркетинговых материалов участие в стратегических сессиях подразделений по продажам проведение бенчмаркинговых исследований, отслеживание трендов и новостей в области хранилищ данных и Data Governance. 6.Операционные задачи: ведение учета пресейловых активностей в CRM ТЦ подготовка информации по статусам пресейловых активностей и воронке продаж формирование презентационных материалов и шаблонов тендерных документов по существующим и новым продуктам участие в разработке стратегии продаж, управлении воронкой продаж контроль качества оценки и соблюдения внутренних регламентов по пресейловым процедурам. Приходите к нам, если у вас есть: высшее образование опыт работы в IT – интеграторе\вендоре\консалтинговой компании понимание назначения систем DWH, BI, ETL, Data Catalog, Data Quality и прочих использующихся при разработке хранилищ и озер данных, аналитических систем и ситуационных центров знание минимум одной из отраслей - банки, ритейл, производство, страхование умение находить контакты и добиваться встречи с потенциальным клиентом опыт участия в продаже/пресейле IT – продуктов и услуг для Заказчиков федерального уровня опыт ведения переговоров с Заказчиком опыт общения с ключевыми лицами и топ – менеджерами опыт подготовки ТКП на комплексные IT - проекты проактивность коммуникабельность грамотная, поставленная речь умение работать с возражениями: английский язык не ниже Intermediate. Что мы предлагаем: Комфортный офис рядом с м. Савеловская (в шаговой доступности – 5 минут) Гибкое начало рабочего дня. Обычно мы работаем с 10:00 до 18:30 Коллектив открытый, увлеченный своей работой, нет строгой корпоративной культуры Оплата обучения и сертификации в России и за рубежом. Доступ к десятку демолабораторий Открытость в общении с ТОП-менеджментом компании Конкурентный оклад + хорошие бонусы по итогам проектов Возможность изучать английский язык в офисе и по Skyeng Корпоративные скидки на фитнес ДМС для сотрудников и членов их семей Медицинский и массажный кабинеты в офисе Кафе и буфеты на территории офиса, бесплатные завтраки.","нформационные технологии,Управление проектами,Развитие продаж,Проведение презентаций,Ведение переговоров,Подготовка коммерческих предложений,Развитие ключевых клиентов,CRM,Планирование продаж,Внутренние коммуникации,Корпоративные продажи,Английский — B1 — Средний",нфосистемы Джет,"Москва, Савёловская, Большая Новодмитровская, 14 корпус1"
8132,67996131,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы находимся в поиске Senior Data Engineer, который будет заниматься развитием направлений: ""Цифровая аналитика"", ""Антифрод"", "" Платформа DataLake"". Ваши задачи: Реализация ETL в Hadoop (с помощью Airflow) Работа с различными источниками данных: Oracle, MS SQL, API личных кабинетов, микросервисы Батч и стримы с помощью PySpark и Kafka Подготовка витрин для анализа (Hive + Spark + SQL). Наш стек: Ванильный hadoop Kafka, Spark, AirflowClickHouse Jira Confluence GitLab. Мы ждем от будущих коллег: Уверенное владение Python Опыт использования эко-системы Hadoop: HDFS, Apache AirFlow, Hive, Kafka,Spark Знание SQL Опыт работы с реляционными базами данных (Oracle).","Data Engineer,Python,SQL,Hadoop,ORACLE","Компания «СПОРТМАСТЕР», Sportmaster Lab",
8134,78885960,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Участие в разработке и реализации архитектуры Единого Пространства Данных компании Обеспечение доступности данных в регламентные сроки Обеспечение качества данных, разработка и внедрение процессов контроля качества данных Участие в создание среды интеграции данных и пайплайн (конвейеров данных) с помощью инструментов, которые обеспечивают федеративный доступ и объединяют данные из разных источников Участие в разработке, поддержке и оптимизации ETL/ELT процессов Обеспечение разработки и поддержки витрин данных в интересах аналитиков/datascience Оптимизация архитектуры и структуры данных Обеспечение актуальности документации по процессам ETL/ELT,сущностям и объектам DWH. Требования: Опыт самостоятельной разработки ELT процессов на PL/SQL и в промышленных системах ETL/ELT (Oracle Data Intergrator, Informatica, Talend) Экспертное владение SQL Опыт внедрения и эксплуатации распределенных систем хранения и обработки данных Знания и опыт реализации моделей данных Star, Snowflake, Data Vault Знания Python, Java и/или Scala Опыт работы со стеком технологий Hadoop, Spark, Hive, Impala. Что мы предлагаем: Медицинское страхование Внутреннее и внешнее обучение Служебная мобильная связь Участие в программе годовых бонусов Корпоративное предложение фитнес услуг Ежегодный отпуск 28 календарных дней Бесплатная подписка MyBook Новый современный офис в центре города Гибридный формат работы.","Oracle Pl/SQL,ETL/ELT,ODI,DWH,Iron Python,Hadoop,Hive,Impala,Spark",Мобайл Телеком-Сервис (Объединенная Компания Tele2/ALTEL),
8155,78882090,Data Protection Officer,з/п не указана,более 6 лет,"Полная занятость,полный день","Скоринг Бюро (бывш. Equifax) является крупнейшим Бюро кредитных историй в России. Наша компания предоставляет финансовым организациям в Российской Федерации услуги по управлению рисками, аналитики и предотвращению мошенничества, которые необходимы для развития бизнеса, такие как: Создание, обработка и распространение кредитных историй и отчетов по заемщикам Защита конфиденциальной информации Предоставление аналитических услуг для банков и компаний В настоящее время мы ищем DPO в Т департамент, подчинение Т директору. У Вас будет ведущая роль в оценке и формулировании требований к изменениям в информационные системы, во внутренние процессы и процедуры для соответствия требованиям по защите данных. Вы будете выступать контактным лицом по любым запросам, связанным с персональными данными, от всех категорий субъектов данных и регулирующих органов. Какие задачи вас ждут: Обеспечение соблюдения всех соответствующих нормативных актов и требований корпоративной политики, касающихся обработки данных. Разработка, согласование и пересмотр внутренней политики и других локальных нормативных актов в области обработки персональных данных. Внутренние консультации сотрудников всех подразделений по вопросам персональных данных и сопровождение внешних сделок: согласование запросов на передачу данных (контракты, тендерная документация и т.д.), внешних маркетинговых и социальных кампаний, опросов. Обучение и подготовка сотрудников в области защиты персональных данных. Контроль соблюдения оператором и его сотрудников законодательства о персональных данных, в том числе требования к их защите нформирование сотрудников оператора о требованиях к защите персональных данных и о положениях НПА и ЛНА, регулирующих их обработку Организация и (или) контроль процесса приема и обработки запросов субъектов и их представителей. Проведение внутренних проверок за соблюдением нормативов ФЗ-152 на предприятии с составлением и подачей оператору отчетов. Требования: Юридическое образование (опыт сопровождения области ПДн – договора, процессы …) Опыт работы в качестве ответственного за ПДН в организации Опыт проведения аудитов на соответствие требованиям 152-ФЗ Опыт прохождения успешных проверок РКН Условия: трудоустройство по ТК РФ, бессрочный трудовой договор гибридный формат работы: 2 дня офис (м. Комсомольская), 3 дня из дома. годовой бонус ежегодная индексация заработной платы ДМС со стоматологией (софинансирование ДМС для супругов и детей) страхование жизни от несчастных случаев Фитнес в нашем БЦ (софинансирование) возможность изучения английского языка за счёт компании в офисе корпоративные мероприятия и подарки для сотрудников и членов семей транспортная доступность: м. Комсомольская (7-10 минут пешком).","data protection officer,152-ФЗ,ПДн",Бюро кредитных историй Скоринг Бюро,"Москва, Комсомольская, Каланчевская улица, 16с1"
8161,78857147,Data engineer (junior +),з/п не указана,1–3 года,"Полная занятость,полный день","Привет, к себе в команду ищем инженера по аналитике больших данных. Формат работы: гибридный/удаленный только по РФ. Какие задачи необходимо решать: Создание витрин данных с помощью Oracle PL/SQL. Разработка витрин данных, содержащих информацию о B2B-клиентах МегаФона и их абонентах Автоматизация сбора и обработки данных с помощью Python Майнинг данных с помощью Python (парсинг сайтов, работа с API, предобработка) Выполнение ad-hoc запросов по выгрузкам данных и аналитике Взаимодействие со специалистами подразделения и отраслевыми экспертами для загрузки и предоставления данных, для разработки и поддержания гибкой архитектуры Для решения этих задач требуется: Уверенное знание Oracle SQL Опыт работы с распределенной системой Hadoop приветствуется Опыт автоматизации и обработки данных на Python Опыт работы с Git","Python,Oracle Pl/SQL,Hadoop","МегаФон, IT","Москва, Маяковская, Новослободская, Чеховская, Оружейный переулок, 41"
8167,78852846,Data Engineer Lead / Дата инженер,от 300 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Мы - аккредитованная IT-компания «Сеть партнерств». В июле 2021 наша команда запустила флагманский продукт – подписку «Огонь», ogon.ru Это первая на рынке мультиподписка с собственным мобильным приложением. На данный момент в подписку входят предложения более чем от 45 партнёров, включая ""VK Музыка + Wink и другие сервисы"".  Для реализации RoadMap на 2023 приглашаем в команду Lead Data Engineer Что предстоит делать: Взаимодействие с внешними и внутренними коллегами с целью определения способов интеграций систем Участие в проектировании архитектуры аналитического контура Менторство над менее опытными коллегами, в том числе постановка задач Реализация наиболее сложных компонентов платформы Вникать в суть проектов. Написание документации по проделанной работе Определение и реализация метрик работы сервисов и пайплайнов обработки данных Постановка их на мониторинг и передача в поддержку Код-ревью. Приемка задач. Валидация выполняемых работ на момент соответствия целевой архитектуре Лидировать процессы построения корпоративного хранилища данных Влиять на внутренние процессы и используемый стек технологий Стек технологий: · Python · ClickHouse, PostgreSQL, Kafka · Prometheus + Grafana · Kubernetes + Docker · Gitlab · Nifi, Tableau · JupyterHub · Influx db Что ожидаем увидеть: Опыт промышленной разработки на python в части работы с данными от 3-х лет Навыки коммуникации с заказчиками и контрагентами Понимание принципов работы data science проектов Опыт работы с Nifi, Airflow, PostgreSQL, ClickHouse Умение писать сложные sql-запросы Понимание принципов работы с аналитическими и транзакционными базами данных Желателен опыт руководства Что мы предлагаем: Проект с финансовой поддержкой крупных инвесторов нновационные сложные продукты В команде: разработчики, продуктовые аналитики, бизнес-аналитики, системные аналитики, тестировщики - обеспечивают высокий уровень результата и профессионализм команды Белая заработная плата + бонусы в течение года до +30% к окладу Гибридный формат работы: удаленно + из офиса (м. Калужская) ДМС расширенный Увеличенный размер отпуска - 31 день","Python,SQL,PyTorch,PostgreSQL,Git,Kafka,Tableau,ClickHouse,NLP,ETL,Big Data,Data Analysis,Machine Learning,Теория вероятностей,Docker,Linux,Машинное обучение",Сеть Партнерств,"Москва, Калужская, Калужско-Рижская линия, метро Калужская"
8174,78848653,Старший data engineer,з/п не указана,1–3 года,"Полная занятость,полный день","КОМПАНЯ «АЙ-ТЕКО» - ведущий российский системный интегратор и поставщик информационных технологий для корпоративных заказчиков. Активно действует на рынке IT России с 1997 года, входит в ТОП-400 крупнейших российских компаний, ТОП-10 крупнейших IT-компаний России. В связи с активным развитием внутренних проектов в компании открыта вакансия DATA ENGINEER. ОПСАНЕ: Проведение аналитики и разработки программного обеспечения с целью создания Т-решения в рамках создания платформы автоматизации процессов производства компонета Commission для ПАО ""ВымпелКом"" ТРЕБОВАНЯ: • Проработал от 1 года и более в таких областях как: коммуникационные технологии, безопасность, маркетинг и продажи, финансы. • Знает SQL на высоком уровне (в т. ч. DDL, табличные выражения, оконные функции) • Работал с Hive, PostgreSQL • Умеет разрабатывать ETL процессы Spark на Scala (потоковая обработка как преимущество) • Пользовался AirFlow или другими оркестраторами – Oozie, Luigi, ну или cron • Может что-то написать на Python – в объеме чтобы пользоваться AirFlow или еще круче • меет опыт потоковой разработки конвейеров данных в NiFi или Flink • нтересуется Flink, пробовал применять его в проектах • Умеет проектировать базы данных (знает Data Vault 2.0 например) • Понимает принципы работы реляционных СУБД и HDFS • меет представление о колоночных и NoSQL СУБД • Понимает подходы к работе с качеством данных • Применяет системный подход к работе, думает о конечной бизнес-задаче, мыслит логически, уделяет внимание деталям ТПОВЫЕ ЗАДАЧ: • Анализ требований к витринам данных (взаимодействие с владельцем продукта, BI-разработчиками, data scientist-ами) • Поиск и исследование источников данных для последующей интеграции • Оценка пригодности, качества исходных данных • Разработка ETL процессов на Spark • Оркестрация ETL процессов в Airflow • Проектирование баз данных • Создание конвейеров данных NiFi ТРЕБОВАНЯ К ЗНАНЮ СТЕКА ТЕХНОЛОГЙ: • Экосистема Hadoop – HDFS, YARN, Hive, HBase • ETL-процессы – Spark (Scala) • Потоковая обработка – NiFi, Flink • Брокер сообщений – Kafka • Оркестрация ETL процессов – Airflow • СУБД – PostgreSQL, Greenplum, Aerospike, Oracle, SQL Server • CI/CD – GitLab МЫ ПРЕДЛАГАЕМ: Работу в стабильной компании, ""белую"" заработную плату Оформление в соответствии с ТК РФ с первого дня работы Расширенный социальный пакет: ДМС (включая стоматологию), корпоративные скидки на посещение фитнес-клубов, футбольная и волейбольная секции Профессиональное обучение и развитие Яркая и насыщенная корпоративная жизнь Снабжаем всей необходимой современной техникой: мощный ноут привезут прямо в день оформления  ОТКЛКАЙСЯ =) ЖДУ КОГДА ВМЕСТЕ ПОРАДУЕМСЯ ТВОЕМУ ОФФЕРУ)",,Ц АЙ-ТЕКО,
8177,78828382,Менеджер центра методологии и популяризации data science,з/п не указана,1–3 года,"Полная занятость,полный день","Наша команда занимается разработкой методологических документов, регламентирующих разработку моделей в Банке, проводит аналитические исследования, организует мероприятия и конференции с целью популяризации искусственного интеллекта и машинного обучения. Если тебе интересно развиваться в области AI/ML, присоединяйся к нам! Обязанности Мониторинг и анализ международного опыта в области AI/ML Подготовка справок, презентаций и др. материалов Участие в подготовке бизнес-описаний и проектировании процессов в ARIS Разработка обучающих материалов по методологии для AI Сommunity Банка Участие в организации различных мероприятий по AI тематике, в т.ч. одной из крупнейших конференций AI Journey Формирование ТЗ/БТ, подготовка приказов/распоряжений для проведения активностей и пр. Требования Опыт работы аналитиком/методологом более 2х лет Знание мировых трендов ведущих технологических лидеров в области AI-технологий Знание международных стандартов и практик моделирования Опыт описания бизнес-процессов и проектирования процессов в ARIS Опыт организации мероприятий, направленных на развитие AI-функции Опыт формирования ТЗ/БТ, подготовки внутренней документации по проектам и пр. Умение работать с информацией (поиск, сбор, анализ из различных источников) Опыт подготовки аналитических материалов и презентаций Навыки ведения деловой переписки и переговоров Условия Фиксированный оклад + годовой бонус Современный Agile-офис, Кутузовский 32: спортзал, зоны отдыха, приятная атмосфера ДМС с первого дня Обучение, семинары, тренинги, конференции, корпоративная библиотека Возможность развития и участия в data science сообществе Сбербанка (более 600 DS банка)",,Сбер для экспертов,
8197,78859330,Enterprise Data Architect (Germany),з/п не указана,3–6 лет,"Полная занятость,полный день","Наш партнер, известный немецкий ритейлер, ищет Архитектора корпоративных данных. Работа на полную ставку (от 38 до 45 часов в неделю) в районе Дюссельдорфа, Германия (возможна частичная работа из дома). Компания обеспечивает релокацию в Германию из-за рубежа. Мы позаботимся о вашей визовой заявке и переезде в Германию. Ваши члены семьи (супруг, дети до 18 лет) также получат визу. О компании: Работа команды Data&Analytics направлена на создание на основе данных добавленной стоимости для компании и ее клиентов по всему миру. Сотрудники участвуют в международных проектах и разрабатывают индивидуальные решения в области данных и аналитики для своих бизнес- и IT-команд. Команда поддерживает другие функции в принятии важных решений на основе надежных данных и современным методов аналитики. Ваши обязанности: Разработка, создание и поддержка корпоративных логических моделей данных и словарей данных Сотрудничество с заинтересованными сторонами в бизнес- и IT-сообществах для определения и документирования требований к данным и метаданным (физическим и логическим) Контроль и обеспечение безупречного функционирование каталога данных Владение IT-приложением каталога данных, обеспечение внедрения разработанных решений Координация разработки коннекторов и сканеров метаданных Предоставление поддержки третьего уровня и помощь в анализе и устранении сбоев сервиса Требуемые квалификации: 5+ лет опыта работы в области архитектуры данных с акцентом на моделирование данных и управление метаданными Владение инструментами моделирования данных Знание и практический опыт работы с платформами каталога данных, такими как Collibra или Informatica Знание API-платформ и стратегий интеграции данных Умение координировать разработку программного обеспечения, структурированное мышление и навыки решения проблем Свободное владение английским языком в устной и письменной форме (минимальный уровень С1) Опыт работы с SAP (как дополнительное преимущество) Преимущества: Пакет релокации Конкурентоспособная заработная плата и пакет льгот Дружелюбная рабочая среда с возможностями для личностного и профессионального роста Работа с передовыми технологиями и проектами в области машинного обучения и искусственного интеллекта Гибкий график работы и возможности удаленной работы Доступ к программам непрерывного обучения и развития Если вас заинтересовало описание позиции - подавайте заявку и отправляйте дополнительную информацию с сопроводительном письме","Английский язык,Моделирование,Architecture,Анализ данных,Английский — C1 — Продвинутый",Transparent Hiring,
8203,78821349,Data Engineer в команду Search Quality,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы — команда качества поиска Авито. Мы создаем, внедряем и следим за качеством алгоритмов ранжирования объявлений, оптимизируя сценарии для десятков миллионов покупателей, продавцов и клиентов Авито. Разрабатываем пайплайны обработки данных для внедрения моделей машинного обучения, проектируем принципы разделения трафика и имплементируем их в наших алгоритмах. В своей работе мы собираем данные об объявлениях и пользовательской активности из разных источников, обогащаем и строим на их основе общедоступные агрегаты и модели. Наш кластер Apache Spark ежедневно обрабатывает события от десятков миллионов активных пользователей. Он постоянно поставляет данные в продуктовые сервисы, а также является аналитической платформой для нескольких десятков аналитиков поиска, вертикалей и монетизации. Наш вызов — дать аналитикам и инженерам максимально удобные инструменты и интеграции с имеющимися данными, при этом не забывая о их качестве и постоянных запросах на увеличение нагрузки, как от бизнеса, так и от растущей аудитории. Вам предстоит: разрабатывать новые и поддерживать существующие продукты в составе кросс-функциональной команды заниматься развитием существующей BigData-платформы с упреждением растущей нагрузки от новых задач и данных (90% задач связаны со Spark) создавать новые сервисы на Python и улучшать уже существующие продвигать лучшие практики и делиться с командой своим опытом предлагать новые подходы и тут же пробовать их в продакшене с реальными данными. Мы ждём, что вы: знаете и умеете писать на Python или Java/Scala (с переходом на Python) глубоко понимаете экосистему Hadoop/Spark/Hive и связанных продуктов имеете опыт работы с данными/решали аналитические задачи умеете администрировать Linux системы на базовом уровне не боитесь нестандартных решений. Будет здорово, если вы: имеете опыт работы с Apache Airflow, знаете принципы построения пайплайнов разрабатывали бэкенд приложения на Flask/Asyncio/Django/другом Python фреймворке или Golang разбираетесь в инфраструктуре Apache Kafka писали стриминговые приложения на Apache Flink/Spark использовали в своей работе для администрирования оркестраторы кластеров (Ansible, SaltStack, Puppet и др.) умеете и любите писать тесты, знаете подходы TDD, BDD собирали CI/CD решения, умеете работать с Docker работали с кластерными СУБД (Vertica, Clickhouse, Sphinx, Trino и др.). Работа у нас — это: интересные и важные задачи на очень большом проекте передовые технологии и подходы, возможность пробовать новое опытные и заинтересованные коллеги, готовые оказать поддержку возможность приносить пользу миллионам пользователей, реализуя решения, основанные на данных личный бюджет на обучение, который можно тратить на книги, курсы и конференции забота о здоровье: с первого дня у вас будет ДМС со стоматологией, в офисе принимают терапевт и массажист возможность работать удаленно и по желанию посещать комфортный офис в Москве или Санкт-Петербурге.","Python,Hadoop,Spark,Linux,Big Data,Java",АВТО ТЕХ: разработка,
8206,76703124,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","ЧЕМ ВЫ БУДЕТЕ ЗАНМАТЬСЯ: Сбор, обработка и парсинг ""сырых"" данных Поддержка и развитие корпоративного хранилища данных Определение потребностей и требований бизнес-пользователей Управление потоками данных Организация работы с большими данными Создание витрин данных Управление данными и распределение на слои (горячие, холодные) Написание SQL-запросов для получения данных Написание ТЗ для DevOps, DevSecOps, DataOps Развитие стандарта по управления данными. ЭТА РАБОТА ДЛЯ ВАС, ЕСЛ МЕЕТЕ: Опыт проектирования и разработки архитектуры БД Опыт работы c MPP системами (Greenplum) Опыт разработки Python и Java/Scala Опыт разработки сложных SQL запросов Опыт работы с ETL инструментами Опыт построения отчетности Опыт работы с нереляционными БД Понимание специфики работы с персональными данными. ПРЕМУЩЕСТВОМ БУДЕТ: Опыт в качестве DE или аналитика данных Знание принципов гибкого подхода MLOps Опыт работы с docker, k8s, kafka. ЖДЁМ ВАШЕ РЕЗЮМЕ!","Архитектура БД,MPP,Python,Java/Scala,SQL,MLOps",АЛРОСА нформационные технологии,"Москва, Новокузнецкая, Павелецкая, Третьяковская, Озерковская набережная, 30"
8209,78851285,DataSec Team Lead,з/п не указана,3–6 лет,"Полная занятость,полный день","Безопасность — часть нашего бизнеса, поэтому мы создаем продукты, следуя принципу security by design. Мы открыты и защищаем не только себя, но и партнеров. Мы ищем людей, которые болеют за идею безопасности и хотят расти в профессии. Если вы готовы предлагать смелые решения, применять нестандартные подходы и добиваться результата, ждем вас в команде. Требования Опыт работы в области информационной безопасности от 3-х лет Опыт работы с системами аналитики и различными базами данных (большой плюс) Опыт разработки или чтения кода на Python/Go (большой плюс) Опыт управления командой от 3-х человек Что нужно будет делать Выстраивать процесс безопасного Data Warehouse Управлять проектной командой data security Участвовать в стратегическом развитии и операционном управлении подразделения Обеспечивать безопасность инфраструктуры инструментов аналитики Обеспечивать безопасность взаимодействия с базами данных, модель управления доступом и аудит Обеспечивать контроль доступа к данным и построение процессов контролируемой передачи данных Внедрять процессы санитайзинга чувствительных данных во внутренних системах Повышать культуру безопасности данных Мы предлагаем Работу в офисе у метро «Водный стадион». График работы — гибридный Платформу обучения и развития Тинькофф Апгрейд. Курсы, тренинги, вебинары и базы знаний. Поддержка менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Бесплатный фитнес-зал Tinkoff Sport. Тренируйтесь, посещайте групповые программы, грейтесь в сауне и участвуйте в спортивных турнирах Бесплатные обеды в Tinkoff Cafe. А если захотите перекусить, на каждом этаже есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","Data Analysis,Базы данных",Тинькофф,"Москва, Водный стадион, Головинское шоссе, 5"
8211,76693962,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","ЧЕМ ВЫ БУДЕТЕ ЗАНМАТЬСЯ: Сбор, обработка и парсинг ""сырых"" данных Поддержка и развитие корпоративного хранилища данных Определение потребностей и требований бизнес-пользователей Управление потоками данных Организация работы с большими данными Создание витрин данных Управление данными и распределение на слои (горячие, холодные) Написание SQL-запросов для получения данных Написание ТЗ для DevOps, DevSecOps, DataOps Развитие стандарта по управления данными. ЭТА РАБОТА ДЛЯ ВАС, ЕСЛ МЕЕТЕ: Опыт проектирования и разработки архитектуры БД Опыт работы c MPP системами (Greenplum) Опыт разработки Python и Java/Scala Опыт разработки сложных SQL запросов Опыт работы с ETL инструментами Опыт построения отчетности Опыт работы с нереляционными БД Понимание специфики работы с персональными данными. ПРЕМУЩЕСТВОМ БУДЕТ: Опыт в качестве DE или аналитика данных Знание принципов гибкого подхода MLOps Опыт работы с docker, k8s, kafka. ЖДЁМ ВАШЕ РЕЗЮМЕ!","Архитектура БД,MPP,Python,Java/Scala,SQL,MLOps",АЛРОСА нформационные технологии,"Москва, Новокузнецкая, Павелецкая, Третьяковская, Озерковская набережная, 30"
8242,72673144,Data engineer / Разработчик DWH / ETL developer,з/п не указана,1–3 года,"Полная занятость,полный день","Media Instinct Group приглашает на работу высококвалифицированных специалистов, которые заинтересованы в интересных и нестандартных задачах, профессиональном росте и дружном коллективе. Сейчас мы приглашаем кандидатов на позицию Data engeneer / разработчика DWH. Media Instinct Group - группа специализированных агентств, оказывающих следующие услуги из области медиасервиса: стратегическое и тактическое планирование, медиабаинг, исследования, аналитика и комплексные digital-услуги. По данным AdIndex и Recma Media Instinct Group входит в ТОП 3 крупнейших агентств РФ. Универсальная Сервисная Компания (УСК) - является ключевым сервисным партнером, в том числе осуществляет подбор сотрудников для Media Instinct Group. Основные задачи: разработка процедур загрузки данных из внешних и внутренних источников (преимущественно REST API), prefect разработка и модификация БД с целью загрузки данных из внешних и внутренних источников, Microsoft SQL Server организации витрин данных для аналитиков с помощью data build tool (dbt) составление технической документации по разрабатываемым витринам данных коммуникация внутри команды. Что мы хотим видеть у Вас: Опыт работы от 2-х лет в похожей роли / с похожим функционалом Свободное знание SQL: процедуры, аналитические функции Знание деталей реализации СУБД: план запроса, физические виды соединений, хинты, секционирование, индексы, строковое и колоночное хранение Знание принципов и подходов к моделированию баз данных Опыт языка программирования Python Опыт командной разработки (Jira, Confluence, Git). Будет плюсом опыт работы с инструментами: prefect dbt liquibase BigQuery Условия: Работа в стабильной и динамичной компании Перспективы профессионального и личностного роста Оформление согласно ТК РФ, белая ЗП Социальный пакет (ДМС, фитнес) Работа в команде профессионалов 5/2, фулл-тайм, гибридный или удалённый формат работы Офис расположен в 5 минутах ходьбы от м. Молодежная.","SQL,Python",Media Instinct Group,"Москва, Молодежная, Ярцевская улица, 19"
8249,78786481,"Senior Data Scientist (""Платформа экспериментов"")",з/п не указана,3–6 лет,"Полная занятость,полный день","A/B эксперименты – ключевой инструмент для принятия решений в компании Okko. Все гипотезы мы проверяем через эксперименты. Сейчас наш бизнес довольно быстро растёт, растёт и количество запускаемых экспериментов, которые нужно качественно и быстро анализировать. Во многом от того, насколько точно будут проанализированы эксперименты, зависят принимаемые решения и, как следствие, будущее нашего бизнеса. Если ты понимаешь, что соответствуешь требованиям и веришь в то, что вместе мы сможем построить лучшую платформу экспериментов на рынке СНГ, откликайся на вакансию! Обязанности: улучшение текущего процесса проведения экспериментов аналитическая разработка новой платформы моделирования, сплитования, мониторинга и оценки экспериментов поддержка и развитие новой платформы моделирования, сплитования, мониторинга и оценки экспериментов повышать общий уровень культуры экспериментирования в компании. Что мы используем: Python (sklearn, seaborn, numpy, scipy, statsmodels) ClickHouse, PostgreSQL, Redis, etc. Airflow, FlaskAPI/FastAPI Bitbucket, Jira, Confluence. Требования: знание математической статистики и A/B тестирования уверенное владение и опыт разработки на Python уверенное владение SQL опыт в классическом ML бизнес-ориентированное мышление. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,ML",Okko,"Москва, Баррикадная, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с13"
8254,78786488,"Senior Data Scientist (""Платформа экспериментов"")",з/п не указана,3–6 лет,"Полная занятость,полный день","A/B эксперименты – ключевой инструмент для принятия решений в компании Okko. Все гипотезы мы проверяем через эксперименты. Сейчас наш бизнес довольно быстро растёт, растёт и количество запускаемых экспериментов, которые нужно качественно и быстро анализировать. Во многом от того, насколько точно будут проанализированы эксперименты, зависят принимаемые решения и, как следствие, будущее нашего бизнеса. Если ты понимаешь, что соответствуешь требованиям и веришь в то, что вместе мы сможем построить лучшую платформу экспериментов на рынке СНГ, откликайся на вакансию! Обязанности: улучшение текущего процесса проведения экспериментов аналитическая разработка новой платформы моделирования, сплитования, мониторинга и оценки экспериментов поддержка и развитие новой платформы моделирования, сплитования, мониторинга и оценки экспериментов повышать общий уровень культуры экспериментирования в компании. Что мы используем: Python (sklearn, seaborn, numpy, scipy, statsmodels) ClickHouse, PostgreSQL, Redis, etc. Airflow, FlaskAPI/FastAPI Bitbucket, Jira, Confluence. Требования: знание математической статистики и A/B тестирования уверенное владение и опыт разработки на Python уверенное владение SQL опыт в классическом ML бизнес-ориентированное мышление. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,ML",Okko,"Санкт-Петербург, Беговая, улица Савушкина, 126Б"
8267,78754744,Архитектор в МТС Аналитику (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Архитектора на продукт ""МТС Аналитика"" Описание продукта: МТС Аналитика - это единая аналитическая платформа для анализа поведения пользователей в web и app приложениях экосистемы МТС. Наша цель – эффективная рекламная атрибуция, обогащенные Big Data полезные данные о когортах, кросс-продуктовый пользовательский путь и LTV пользователя и продукта, сдобренные собственным UI для визуализации метрик и командной работы. Обязательно: опыт работы в области информационных технологий от пяти лет (системный аналитик, разработчик, devops, архитектор) понимание особенностей работы и практический опыт использования batch и streaming обработки данных опыт проектирования API интерфейсов и интеграционного взаимодействия (знание паттернов понимание и умение применять архитектурные паттерны знание и понимание принципов реализации систем мониторинга IT-инфраструктуры (Prometheus, Grafana, ELK) понимание технологий виртуализации, контейнеризации (k8s, docker и др.) практический опыт планирования нагрузки, организации отказоустойчивых схем работы сложных информационных систем (в т.ч. гео-распределенных систем) Желательно: опыт коммерческой разработки на java, знание фреймворков, паттернов участие в разработке платформ web-аналитики участие в разработке платформ real-time-bidding Что предстоит делать? формировать концепцию построения и развития Платформы в соответствии с функциональными и нефункциональными требованиями к Платформе проектировать общую архитектуру Платформы, архитектуру компонентов, интеграционное взаимодействие компонентов и внешних систем и платформ компании планировать развитие инфраструктуры под органический рост/изменение ландшафта взаимодействовать со смежными подразделениями (Б, юр. отделом и т.п.) поддерживать в актуальном состоянии архитектурную документацию Платформы Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем оборудование. Есть ли обучение? Локальные и международные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой.","Архитектура,Аналитическое мышление,Анализ данных,Prometheus,Grafana,Docker",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
8271,77599910,Senior DevOps engineer на продукт МТС Аналитика (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data в МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior DevOps engineer на продукт МТС Аналитика Описание продукта: МТС Аналитика – это единая аналитическая платформа для анализа поведения пользователей в web и app приложениях экосистемы МТС. Наша цель – эффективная рекламная атрибуция, обогащенные Big Data полезные данные о когортах, кросс-продуктовый пользовательский путь и LTV пользователя и продукта, сдобренные собственным UI для визуализации метрик и командной работы. Мы ищем DevOps инженера, которые поможет нам развивать платформу. Обязательно: опыт работы с python или go опыт работы с реляционными и нереляционными базами данных: работа под нагрузкой, репликация, резервирование, профилирование опыт работы с веб-серверами и балансировщиками нагрузки опыт работы с системами управления конфигурацией, инструментами CI/CD и Git понимание работы сети (IP/TCP/HTTP), умение диагностировать и решать проблемы понимание работы docker опыт работы с kubernetes опыт администрирования java приложений опыт работ по настройке и внедрению средств мониторинга микросервисной архитектуры и средств защиты информации в инфраструктуре непрерывной разработки в соответствии с концепциями SDLC и DevOps опыт внедрения, развития и поддержки инструментов информационной безопасности в архитектуре и процессах непрерывной разработки/доставки микросервисов (CI/CD), средств контроля качества кода умение выявлять архитектурные недочеты и риски в планируемой и реализованной инфраструктуре Что предстоит делать? обеспечивать оснащение необходимыми мониторингами, графиками и CI/CD для новых и/или существующих компонентов платформы развертывать кластера хранилищ данных и очередей сообщений масштабировать всю систему в связи с постоянно растущей нагрузкой автоматизировать ручную работу чтобы не тратить время на рутину внедрять новые и развивать существующих практик DevOps внутри команд разработки формировать требования безопасности и внедрять корпоративные инструменты безопасной разработки осваивать и внедрять новые методики и инструменты DevOps Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой.","CI/CD,Python,Go,Git",МТС,
8285,78711110,Data scientist (Управление рисками корпоративных клиентов),з/п не указана,1–3 года,"Полная занятость,полный день","Мы — амбициозная и дружная команда, ежедневно исследующая данные корпоративных клиентов Сбербанка. Наши модели – двигатель не имеющих аналогов в России продуктов в сфере управления рисками корпоративных клиентов. Сводная статистика о нас: Мы решаем задачи по 8 основным направлениям (от монументального ПВР до всеобъемлющих графов и молодого и амбициозного ESG) 95% наших моделей разрабатываются с применением облачных технологий Мы придерживаемся единого стандарта работы, используем JIRA/Confluence/BitBucket, у нас есть единый бэклог 25% нашей команды имеют западное образование и опыт работы в странах Европы Мы сотрудничаем с передовыми ВУЗами в 3-ёх городах России Просрочка по кредитному продукту на основе наших моделей стремится к 0. В команде с заказчиками мы: Погружаемся в предметную область Прорабатываем постановку задачи щем и исследуем данные Выбираем оптимальные методы моделирования Разрабатываем и верифицируем модели Готовим отчеты о разработке и презентуем результаты Мониторим модели Наслаждаемся результатом. В рамках работы над задачей мы будем: Разрабатывать и улучшать инструменты для машинного обучения (внутренние наработки, библиотеки) спользовать прогнозное моделирование, чтобы оптимизировать бизнес риск метрики Работать в команде с портфельными менеджерами, чтобы понять нужды бизнеса и предложить возможные решения Разрабатывать модели машинного обучения Разрабатывать архитектуру пилотов для тестирования гипотез Прокачивать коллег и развиваться самим. Качественные факторы кандидатов с высоким Feature important: Диплом в области компьютерных наук, статистики, прикладной математики или другой релевантной области Опыт работы от 3х лет с одной или несколькими СУБД: Oracle, MS SQL, Teradata либо СУБД стэка Bigdata Опыт работы с хранилищами данных от 1го года Опыт работы в роли аналитика с функцией подготовки выгрузки данных для заказчика Сильные компетенции в области реляционных СУБД и хранилищ данных: Глубокое понимание статистических подходов и методов (регрессия, свойства распределений, оценка максимального правдоподобия, проверка гипотез и их правильное использование) и опыт их применения Знания и опыт применения алгоритмов машинного обучения (GLM/Regression, Trees, Random Forest, Boosting), а также знание их преимуществ, недостатков и ограничений Приветствуется знание принципов работы нейронных сетей и опыт использования библиотек для их обучения (Keras/PyTorch/TensorFlow) Знание Python и основных DS библиотек Отличные знания английского языка (устный и письменный) как преимущество Опыт в распределённых/параллельных вычислениях с помощью следующих технологий: Hadoop, Spark, Dask и другие как преимущество А ещё у нас есть: Развитая IT архитектура. Мощный GPU кластер, возможность расчётов на суперкомпьютере top30 в мире Работа над передовыми задачами в банковском секторе Постоянное развитие: обучающие курсы от лучших университетов и компаний (МФТ, ВШЭ, NVIDIA и другие), участие в международных конференциях Большую сильную команду Развитое DS community.",,Сбер. Data Science,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
8289,71930796,Руководитель Data Science,з/п не указана,1–3 года,"Полная занятость,полный день","Чем предстоит заниматься: • Управление разработкой Data science проектов и ML-продуктов, проектами анализа данных, доведение до продакшн алгоритмов машинного обучения и продвинутой аналитики • Погружение в специфику бизнеса омниканальной ювелирной сети • Кросс-функциональное взаимодействие (бизнес-подразделения) и коммуникации внутри подразделения (разработчики, архитекторы данных, бизнес-аналитик, data governance). • Развитие команды аналитиков данных: найм, обучение, развитие • Создание и поддержка уже созданных проектов по прогнозированию спроса и продаж, персональные рекомендации для покупателей, маркетинговая аналитика, кластеризация ассортимента и т.д. • Управление проектами продвинутой аналитики от идеи до внедрения в продакшн Наши ожидания: • От 2-х лет опыта работы в DS и ML • Опыт управления командой DS • Знания и опыт в области машинного обучения • Владение языком программирования Python и знание основных библиотек (matplotlib, pandas, seaborn, numpy, scipy) • Понимание алгоритмов работы и инструментов обработки больших массивов данных (Hadoop, MapReduce, Spark) • Умение работать с реляционными базами данных (SQL/MSSQL/PostgreSQL) и навык написания SQL- запросов • Аналитический склад ума и желание развиваться в направлении, связанном с  • Опыт в реализации реальных проектов в области DS и моделирования в качестве ведущего аналитика/руководителя группы/тим-лида • Способность выдвигать и проверять исследовательские гипотезы, объяснять и представлять результаты Мы гарантируем: • Высокую заработную плату • Гибкий подход ко времени начала рабочего дня • Работа в команде профессионалов • нтересные и масштабные проекты в компании-лидере на ювелирном рынке России • Работу в современном офисном центре класса А (БЦ «Зенит-Плаза», м. Щукинская/Строгино, 10 минут на корпоративном автобусе","Python,SQL,PostgreSQL,Анализ данных,Hadoop",SUNLIGHT/САНЛАЙТ,"Москва, Мякинино, Павшино, Строгино, Щукинская, улица Маршала Прошлякова, 30"
8292,78711069,Senior Data scientist (Управление рисками корпоративных клиентов),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы — амбициозная и дружная команда, ежедневно исследующая данные корпоративных клиентов Сбербанка. Наши модели – двигатель не имеющих аналогов в России продуктов в сфере управления рисками корпоративных клиентов. Сводная статистика о нас: Мы решаем задачи по 8 основным направлениям (от монументального ПВР до всеобъемлющих графов и молодого и амбициозного ESG) 95% наших моделей разрабатываются с применением облачных технологий Мы придерживаемся единого стандарта работы, используем JIRA/Confluence/BitBucket, у нас есть единый бэклог 25% нашей команды имеют западное образование и опыт работы в странах Европы Мы сотрудничаем с передовыми ВУЗами в 3-ёх городах России Просрочка по кредитному продукту на основе наших моделей стремится к 0. В команде с заказчиками мы: Погружаемся в предметную область Прорабатываем постановку задачи щем и исследуем данные Выбираем оптимальные методы моделирования Разрабатываем и верифицируем модели Готовим отчеты о разработке и презентуем результаты Мониторим модели Наслаждаемся результатом. В рамках работы над задачей мы будем: Разрабатывать и улучшать инструменты для машинного обучения (внутренние наработки, библиотеки) спользовать прогнозное моделирование, чтобы оптимизировать бизнес риск метрики Работать в команде с портфельными менеджерами, чтобы понять нужды бизнеса и предложить возможные решения Разрабатывать модели машинного обучения Разрабатывать архитектуру пилотов для тестирования гипотез Прокачивать коллег и развиваться самим. Качественные факторы кандидатов с высоким Feature important: Диплом в области компьютерных наук, статистики, прикладной математики или другой релевантной области Опыт работы от 3х лет с одной или несколькими СУБД: Oracle, MS SQL, Teradata либо СУБД стэка Bigdata Опыт работы с хранилищами данных от 1го года Опыт работы в роли аналитика с функцией подготовки выгрузки данных для заказчика Сильные компетенции в области реляционных СУБД и хранилищ данных: Глубокое понимание статистических подходов и методов (регрессия, свойства распределений, оценка максимального правдоподобия, проверка гипотез и их правильное использование) и опыт их применения Знания и опыт применения алгоритмов машинного обучения (GLM/Regression, Trees, Random Forest, Boosting), а также знание их преимуществ, недостатков и ограничений Приветствуется знание принципов работы нейронных сетей и опыт использования библиотек для их обучения (Keras/PyTorch/TensorFlow) Знание Python и основных DS библиотек Отличные знания английского языка (устный и письменный) как преимущество Опыт в распределённых/параллельных вычислениях с помощью следующих технологий: Hadoop, Spark, Dask и другие как преимущество А ещё у нас есть: Развитая IT архитектура. Мощный GPU кластер, возможность расчётов на суперкомпьютере top30 в мире Работа над передовыми задачами в банковском секторе Постоянное развитие: обучающие курсы от лучших университетов и компаний (МФТ, ВШЭ, NVIDIA и другие), участие в международных конференциях Большую сильную команду Развитое DS community.",,Сбер. Data Science,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
8295,77591792,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы собираем команду, которая будет заниматься разработкой платформы клиентских данных (CDP) с нуля. Для построения Customer Data Platform мы планируем использовать СУБД Greenplum и ClickHouse. Наша идея - создать платформу клиентских данных, которая будет помогать всем без исключения людям в компании делать их работу проще и эффективнее. Наша цель - превратить хаос в порядок, автоматизировать рутинные задачи и подготовить данные для удобного анализа и аргументированного принятия бизнес-решений, будь то решение о стратегии компании по отношению к клиентам или о развитии конкретного продукта. Подразделение Core-разработки будет заниматься написанием ядра платформы, разработкой фреймворков и инструментов, которые в дальнейшем помогут системным аналитикам просто и быстро загружать данные в платформу, а пользователям - эффективно использовать его и узнавать информацию о данных не только внутри CDP, но и за его пределами. Ты будешь писать те самые механизмы, которые являются сердцем платформы. Для воплощения этой идеи мы ищем людей по-настоящему влюбленных в инженерию данных. СТЭК: Database Systems: ClickHouse, GreenPlum DataFlow/ETL: Airflow, DBT Continuous Integration: Gitlab CI IssueTracking/KnowledgeBase: Jira, Confluence. ТЕБЕ ПРЕДСТОТ: Создание и доработка фреймворков, обеспечивающих загрузку данных в клиентскую платформу данных. МЫ ОЖДАЕМ, ЧТО ТЫ: меешь опыт промышленного программирования на Python меешь опыт создания архитектуры потоков данных и инструментов для управления ими Знаешь SQL как родной язык меешь опыт работы с Airflow меешь продвинутые навыки работы с Git меешь опыт покрытия кода unit-тестами Понимаешь принципы работы СУБД. БУДЕТ ЗДОРОВО, ЕСЛ ТЫ: меешь опыт работы с DBT, MPP-системами (ClickHouse, GreenPlum), Django, Flask/FastApi. В МТС Финтех тебя ждет культура творчества и идей: мы всегда ищем новые решения, задаем тренды и не боимся быть не похожими, постоянная прокачка экспертизы, профессиональное развитие и свобода действовать и нести ответственность за результат. А еще: Достойная заработная плата Аgile-культура: продуктовые команды, Scrum и Kanban, демо-дни, внутренние митапы и таунхоллы Доступ к корпоративной библиотеке Alpina, Корпоративный Университет и программы развития Отсутствие дресс-кода, гибкий формат работы Специальный тариф на мобильную связь для тебя и близких и предложения от партнеров банка и МТС Забота о тебе и твоей семье: ДМС со стоматологией, сессиями с психологом и госпитализацией, страхование от несчастных случаев и болезней 24/7 и страхование выезжающих за рубеж. К ДМС можно подключить детей и родственников. А еще доступ к телемедицине BestDoctor Мы за спорт: вместе тренируемся в MTS Running Club. Ты можешь присоединиться к корпоративным спортивным командам и занятиям йогой Поддержка сотрудников: программа материальной помощи в различных жизненных ситуациях.","Python,SQL,Git,Atlassian Confluence,Atlassian Jira",МТС Банк,
8298,77963503,Senior QA engineer на продукт МТС Аналитика (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data в МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior QA engineer на продукт МТС Аналитика МТС Аналитика – это единая аналитическая платформа для анализа поведения пользователей в web и app приложениях экосистемы МТС Наша цель – эффективная рекламная атрибуция, обогащенные Big Data полезные данные о когортах, кросс-продуктовый пользовательский путь и LTV пользователя и продукта, сдобренные собственным UI для визуализации метрик и командной работы Мы ищем Senior QA engineer, который поможет нам с «нуля» создать и развивать платформу. У нас вы сможете принять участие в разработки event-based архитектуры платформы, поработать с streaming технологиями, технологиями Big Data, in-memory базами данных и аналитическими хранилищами Для автоматизации тестирования используем: Python, PyTest, Allure Report/Allure TestOps, Selenium, Appium. Для нагрузочного тестирования - Locust Наши преимущества: Опытные и отзывчивые коллеги, которые готовы ответить на любые вопросы Платформа создается с «нуля», никакого легаси Сложный и большой проект, в котором можно многому научиться Возможность получить опыт в тестировании и автоматизации тестов различных видов систем (UI, Back, Mobile, BigData) Обязательно: Опыт от 3х лет в QA Опыт разработки или автоматизации тестов на Python, либо желание перейти на Python Опыт тестирования и автоматизации тестов Web и Mobile (native или гибридных) продуктов Опыт работы с Appium, Appium Inpector, Android SDK Опыт работы с системами непрерывной интеграции Опыт работы с Docker, docker-compose Владение SQL на базовом уровне (select с подзапросами, join, группировками) Знание систем контроля версий Git Знание основ Linux и навыки работы с командной строкой Что предстоит делать? Развивать фреймворк автоматизации тестов Web UI и Mobile компонентов платформы на интеграционном и e2e уровне Участвовать в релизном процессе и ручное прохождение тестов business-critical функционала, если по каким-то причинам их не удалось автоматизировать Проводить интеграционное тестирование с продуктами смежных команд Документировать найденные ошибки в системе баг-трекинга, контроль их исправления Контролировать тестовое покрытие и актуализация тестовой документации в TMS (Allure TestOps) Проводить нефункциональные виды тестирования (нагрузочное, отказоустойчивости) Что вы найдете в команде Big Data? Стек: для автоматизации тестирования используем: Python, PyTest, Allure, Selenium (там, где есть UI), Aquas (внутренний фреймворк для автоматизации тестов ETL), для нагрузочного тестирования - Locust, Jmeter Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16” MacBook Pro или Dell на выбор. Есть ли обучение? Конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: Первичный созвон с HR HR + тех. интервью с лидом направления Собеседование с PO и командой, вы бор кандидатом проекта","Тестирование,Python,Pytest,SQL,Mobile,Web,Selenium,Docker,Allure,Appium,Android SDK",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
8302,77445276,Middle Data Scientist (Аналитическая обработка данных),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Компания MagnitTech— это опытная команда IT, которая создает экосистему современных цифровых продуктов Магнит: доставка продуктов, лекарств, инструменты для обеспечения лояльности клиентов, специальные проекты и продукты для внутренних нужд. Чем предстоит заниматься: Развивать инструменты оптимизации регулярного ценообразования Развивать модели прогнозирования регулярных продаж Проводить А/Б тесты и анализировать большие данные Осуществлять постановку технических задач на изменение подсистем, разработки новых инструментов аналитики Создавать концепт, тестировать и внедрять инструменты аналитики. Мы ожидаем: Знание классических ML-алгоритмов и нейросетей Опыт проведения АБ-тестов и уверенное знание статистики Опыт работы с большим объемом данных Уверенное владение стандартным стеком python-библиотек (sklearn, pandas, numpy, matplotlib, LightGBM и т.д.) Уверенное знание SQL. Мы предлагаем: Работу в максимально уютном и современном офисе в Москве или в Краснодаре, или удаленно График работы 5/2 с гибким началом Конкурентоспособную заработную плату Мы любим учиться! А компания всегда поддерживает и способствует профессиональному развитию специалиста Корпоративную технику для успешной и удобной работы Дружескую атмосферу и поддержку команды профессиональных и активных коллег Корпоративные скидки и программы лояльности от наших партнеров.","Python,SQL,A/B тесты,ML","МАГНТ, Розничная сеть",
8313,78663639,Senior Data Scientist в Scoring Platform (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior Data Scientist в Scoring Platform Описание продукта: Продукт “Скоринг” - выявление потенциальных дефолтников и мошенников (фродеров) в банках, МФО и на интернет-площадках с помощью ML-моделей. Мы создаем скоринговую платформу, которая должна сократить и упростить путь от сбора данных до получения нашим клиентом вероятностной оценки в виде сервиса в личном кабинете. Обязательно: углубленное знание математической статистики, теории вероятности и ML методов анализа данных опыт в области промышленного применения методов DS от 3 лет уверенное владение Python, PySpark, SQL понимание принципов MLOps, навыки работы с Git английский язык на уровне, позволяющем читать профессиональную литературу Что предстоит делать? строить модели для внешних клиентов в предметных областях: банковские и не банковские риски, различные виды мошенничества. Формальных ограничений по методам моделирования нет создавать библиотеки python с ML инструментами, релевантными для DS и экспериментов аналитиков, в т.ч. autoML Стек технологий: Python, MLFlow, Hadoop, airflow, gitlab Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные и международные конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Python,MLFlow,gitlab,airflow,Hadoop,PySpark,SQL,Математическая статистика,теория вероятности",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
8318,77407716,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Мы находимся в поиске Data Engineer, который будет заниматься развитием направлений: ""Цифровая аналитика"", ""Антифрод"", "" Платформа DataLake"". Ваши задачи: Реализация ETL в Hadoop (с помощью Airflow). Работа с различными источниками данных: Oracle, MS SQL, API личных кабинетов, микросервисы. Батч и стримы с помощью PySpark и Kafka. Подготовка витрин для анализа (Hive + Spark + SQL). Наш стек: Ванильный hadoop Kafka, Spark, AirflowClickHouse Jira Confluence GitLab. Мы ждем от будущих коллег: Уверенное владение Python. Опыт использования эко-системы Hadoop: HDFS, Apache AirFlow, Hive, Kafka,Spark. Знание SQL. Опыт работы с реляционными базами данных (Oracle).","Python,Kafka,Spark","Компания «СПОРТМАСТЕР», Sportmaster Lab",
8321,78662110,Junior Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Мы собираем команду, которая будет заниматься разработкой платформы клиентских данных (CDP) с нуля. Для построения Customer Data Platform мы планируем использовать СУБД Greenplum и ClickHouse. Наша идея - создать платформу клиентских данных, которая будет помогать всем без исключения людям в компании делать их работу проще и эффективнее. Наша цель - превратить хаос в порядок, автоматизировать рутинные задачи и подготовить данные для удобного анализа и аргументированного принятия бизнес-решений, будь то решение о стратегии компании по отношению к клиентам или о развитии конкретного продукта. Подразделение Core-разработки будет заниматься написанием ядра платформы, разработкой фреймворков и инструментов, которые в дальнейшем помогут системным аналитикам просто и быстро загружать данные в платформу, а пользователям - эффективно использовать его и узнавать информацию о данных не только внутри CDP, но и за его пределами. Ты будешь писать те самые механизмы, которые являются сердцем платформы. Для воплощения этой идеи мы ищем людей по-настоящему влюбленных в инженерию данных. СТЭК: Database Systems: ClickHouse, GreenPlum DataFlow/ETL: Airflow, DBT Continuous Integration: Gitlab CI IssueTracking/KnowledgeBase: Jira, Confluence. ТЕБЕ ПРЕДСТОТ: Создание и доработка фреймворков, обеспечивающих загрузку данных в клиентскую платформу данных. МЫ ОЖДАЕМ, ЧТО ТЫ: меешь опыт промышленного программирования на Python меешь опыт создания архитектуры потоков данных и инструментов для управления ими Знаешь SQL меешь опыт работы с Airflow меешь навыки работы с Git Понимаешь принципы работы СУБД. В МТС Финтех тебя ждет культура творчества и идей: мы всегда ищем новые решения, задаем тренды и не боимся быть не похожими, постоянная прокачка экспертизы, профессиональное развитие и свобода действовать и нести ответственность за результат. А еще: Достойная заработная плата Аgile-культура: продуктовые команды, Scrum и Kanban, демо-дни, внутренние митапы и таунхоллы Доступ к корпоративной библиотеке Alpina, Корпоративный Университет и программы развития Отсутствие дресс-кода, гибкий формат работы Специальный тариф на мобильную связь для тебя и близких и предложения от партнеров банка и МТС Забота о тебе и твоей семье: ДМС со стоматологией, сессиями с психологом и госпитализацией, страхование от несчастных случаев и болезней 24/7 и страхование выезжающих за рубеж. К ДМС можно подключить детей и родственников. А еще доступ к телемедицине BestDoctor Мы за спорт: вместе тренируемся в MTS Running Club. Ты можешь присоединиться к корпоративным спортивным командам и занятиям йогой Поддержка сотрудников: программа материальной помощи в различных жизненных ситуациях.","Python,SQL,Git,Atlassian Confluence,Atlassian Jira,ClickHouse,Airflow",МТС Банк,
8322,77645744,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы создаем платформу процессной аналитики – Sber Process Mining. Process Mining – это подход, позволяющий из сырых event-логов реконструировать процесс, найти в нем неэффективности и предложить план действий по улучшению. Наша задача – сделать аналитику простой, быстрой и красивой – в том числе с помощью BI, AI, ML. Наша команда ищет крутого инженера данных в команду разработки платформы SberPM. Задачи: участие в разработке ядра системы анализа процессов разработка переиспользуемых трансформаций данных и пайплайнов разработка self-service инструментов обработки данных для пользователей разработка и проектирование модели данных. Мы ожидаем: опыт работы в качестве инженера данных от 3 лет опыт работы с Airflow, NiFi или др. оркестраторами ETL процессов владение SQL на уровне native speaker уверенное знание Python знание основ ООП, теории алгоритмов, структур данных знание теории построения хранилищ данных любознательность, широкий кругозор, желание изучать новые технологии, исследовательский склад ума. Будет плюсом: пользователь Unix shell: базовые команды для работы с файлами и процессами опыт работы с брокерами сообщений опыт работы с Docker, Kubernetes опыт работы с Big Data стеком, ClickHouse. Мы предлагаем: конкурентная заработная плата: оклад + бонусы масштабные и интересные задачи в agile команде комфортный офис на м. Кутузовская, Сбербанк Agile Home социальный пакет: ДМС, страхование от несчастных случаев, льготное кредитование бесплатный тренажерный зал и спортивные групповые занятия дисконт-программы от компаний партнеров: фитнес, страхование, туризм обучение и тренинги профессиональный и позитивный коллектив.",,Сбер. IT,
8329,78642657,Data Scientist (MyTracker),з/п не указана,1–3 года,"Полная занятость,полный день","Отдел Предиктивной аналитики внутри трекера решает широкий спектр задач от развития собственной маркетинговой антфирод-системы (Fraud Scanner) до создания системы персонализированных офферов (Personalize). Мы создаем продукты и прогнозы начиная от идеи до ее реализации в интерфейсе MyTracker. Задачи: R&D и анализ данных (поиск корреляций, зависимости, работа с аномалиями, представление результатов и прочее), построение и реализация алгоритмов машинного обучения представление результатов R&D в понятном для команды виде анализ поступающего графика на наличие аномалий и построение предиктивных моделей для работы антифрод-алгоритмов имплементация моделей для работы в production, разработка мониторингов и оповещений по работе моделей. Требования: опыт решения реальных задач с применением алгоритмов машинного обучения (задачи регрессии, классификации, ранжирования) в production и их поддержка опыт работы в команде с 3+ ML-специалистами математика, теория вероятностей, матстатистика опыт в программировании на Python (знание основных конструкций языка, умение разбираться в чужом коде, знания ООП) стек Python (pandas/scipy/catboost/sklearn). Будет плюсом: SQL диалект Clickhouse разработка антифрод-систем умение проводить A/B-тесты Linux и Bash.","Python,Анализ данных,Machine learning,Linux,Bash,Git,SQL,Clickhouse",VK,"Москва, Аэропорт, Ленинградский проспект, 39с79"
8330,78668027,"Big Data Engineer (Spark, Hadoop)",з/п не указана,3–6 лет,"Полная занятость,полный день","Нашему будущему коллеге предстоит работать над проектом: OMNI-дашборды - системой визуализации отчетности для покрытия потребности в аналитических инструментах для высшего и среднего менеджмента Компании. Работать над развитием Корпоративного Хранилища Данных (Hadoop), которое является основным источником данных для этого проекта. Также, в работе у команды проект по переезду с google analytics на Snowplow. Через несколько месяцев мы планируем проект по развитию Больших данных клиентской аналитики. Цель проекта – реализовать уникальную систему по работе с клиентскими данными ПАО ""Детский мир"" на основе используемых компонентов и стэка технологий и программного обеспечения компании. По итогам проекта в компании появится единый источник непротиворечивой и консистентной информации для принятия управленческих решений. Мы ищем эксперта с высокой ролью ответственности на проекте, умеющего самостоятельно и в команде принимать решение по архитектуре и реализации. Наш стек: последние версии Apache Spark и Apache Airflow Hadoop 3 Docker, Kubernetes GitLab для CI/CD Что нужно делать? создавать Spark ETL pipeline для загрузки данных в HDFS и преобразования данных на HDFS обсуждать с аналитиками алгоритмы преобразования данных, переводить SQL от аналитиков в Spark API участвовать в code review проектировать и создавать архитектуру проекта и адаптировать ее под новые требования выстраивать процессы CI/CD, мониторинга, взаимодействовать с командой DevOps заниматься созданием и развертыванием REST-сервисов на базе Spring Kotlin заниматься развертыванием вспомогательной инфраструктуры (Airflow, Zeppelin, Spark History/Thrift Server) в Kubernetes Заниматься созданием Streaming job Наши ожидания: знания SQL опыт работы с Docker обязателен понимание жизненного цикла разработки ПО, культуры CI/CD опыт создания и оптимизации Spark batch jobs, Scala API (PySpark не используется) Опыт разработки на Java (kotlin) Spring Service опыт работы с Airflow, умение создавать DAG'и, состоящие из Task и Sensor Будет плюсом: опыт работы с Kubernetes, Helm опыт работы с Kafka, Nifi, Spark Streaming любые открытые инструменты для Streaming опыт работы с GitLab CI/CD проектирование сбора/визуализации метрик с использованием Prometheus/Grafana Мы предлагаем: Официальное оформление в соответствии с ТК РФ стандартный трудовой договор (П,ГПХ не делаем), официальная аккредитация IT компании (выписки по форме от генерального сотрудникам делаем, помогаем сотрудникам с отсрочкой). Разноплановые и нестандартные задачи, уникальный опыт, отсутствие легаси Продуктовая команда, отсутствие бюрократии и длительных согласований, заинтересованный в результате бизнес Высокий уровень оклада + годовая премия График работы 5/2, гибкое начало рабочего времени, возможна частично-удаленная/или полностью удаленная работа на выбор, офис Москва м/мцк/мцд Окружная. Можно работать из другой страны до 180 дней. Расширенный полис ДМС Скидка на продукцию компании Выдаем современные макбуки","Spark,Hadoop,Kafka,Kubernetes,Java",Детский Мир,
8333,77478896,Data Engineer (Greenplum),до 350 000 руб. на руки,3–6 лет,"Полная занятость,гибкий график","щем дата-инженера в Точку. Мы — финтех-компания, создаём онлайн-банк и другие сервисы для предпринимателей и предприятий. Тебе предстоит работать в команде, которая строит инфраструктуру для работы с данными в Точке. Наши пользователи — продвинутые аналитики со знанием SQL и Python и разработчики сервисов на основе данных.  Мы переезжаем с Oracle на Greenplum, поэтому ищем высококвалифицированных дата инженеров с опытом работы с Greenplum и Hadoop. Плюсом будет аналогичный опыт миграции.  Как мы работаем Сейчас у нас есть хранилище на Oracle, Hadoop и Clickhouse, система потоковой обработки на Kafka, Streamsets, Airflow, а также набор самописных сервисов на Python. Что делать Выстраивать конвейеры данных от источников до конечного хранилища. Проектировать архитектуру core-слоя и создавать витрины данных. Находить узкие места, оптимизировать запросы и ETL-процессы. Ты подойдёшь, если Есть опыт работы дата-инженером от 3-х лет. Умеешь работать с классическими базами: PostgreSQL и Oracle. Отлично разбираешься в устройстве MPP баз данных (Greenplum, Clickhouse), знаешь их особенности и можешь самостоятельно выбирать архитектурные паттерны, связанные с этими особенностями. Знаешь Python на уровне, достаточном для обработки данных (PySpark в т.ч.). Есть опыт работы с экосистемой Hadoop, понимаешь, какие есть подсистемы, их плюсы и минусы, в каких местах инфраструктуры использовать, а в каких не стоит. Умеешь работать с различными ETL-инструментами. В приоритете — Airflow и DBТ. Будет преимуществом Умеешь работать с Kafka и Debezium. Есть опыт работы в Unix-системах. Периодически мы сами разворачиваем что-нибудь под свои нужды. Есть опыт работы с Docker и Kubernetes. Есть навыки командной разработки с использованием Gitlab, настройки CI/CD пайплайнов. Что ждёт тебя в Точке Официальная зарплата до 350 000 . Точная сумма зависит от твоих навыков и ожиданий — обсудим их на собеседовании. Пятидневная рабочая неделя с гибким началом и окончанием дня. Удалёнка или любой офис Точки в городах присутствия. Наши офисы — это продуманные опенспейсы, где есть индивидуальные места для работы, зоны отдыха и кухни с кофе и перекусами. Ты можешь самостоятельно выбрать, где работать — ходить в офис необязательно. Понятная система развития и роста по грейдам. Бесплатное обучение: ты сможешь ездить на IT-конференции, митапы и хакатоны и проходить курсы за счёт компании. А ещё пользоваться нашей библиотекой и платформой с онлайн-курсами. Бесплатная страховка здоровья со стоматологией и корпоративный психолог. Активная корпоративная жизнь: мы проводим спортивные марафоны, гастрономические вечера, музыкальные лайвы и многое другое. Мы ценим твоё время, поэтому не затягиваем процесс собеседования и сделаем пре-оффер в течение 24 часов.","Oracle Pl/SQL,DWH,Hadoop,Greenplum,ORACLE,ETL,Clickhouse",Точка,
8335,77478896,Data Engineer (Greenplum),до 350 000 руб. на руки,3–6 лет,"Полная занятость,гибкий график","щем дата-инженера в Точку. Мы — финтех-компания, создаём онлайн-банк и другие сервисы для предпринимателей и предприятий. Тебе предстоит работать в команде, которая строит инфраструктуру для работы с данными в Точке. Наши пользователи — продвинутые аналитики со знанием SQL и Python и разработчики сервисов на основе данных.  Мы переезжаем с Oracle на Greenplum, поэтому ищем высококвалифицированных дата инженеров с опытом работы с Greenplum и Hadoop. Плюсом будет аналогичный опыт миграции.  Как мы работаем Сейчас у нас есть хранилище на Oracle, Hadoop и Clickhouse, система потоковой обработки на Kafka, Streamsets, Airflow, а также набор самописных сервисов на Python. Что делать Выстраивать конвейеры данных от источников до конечного хранилища. Проектировать архитектуру core-слоя и создавать витрины данных. Находить узкие места, оптимизировать запросы и ETL-процессы. Ты подойдёшь, если Есть опыт работы дата-инженером от 3-х лет. Умеешь работать с классическими базами: PostgreSQL и Oracle. Отлично разбираешься в устройстве MPP баз данных (Greenplum, Clickhouse), знаешь их особенности и можешь самостоятельно выбирать архитектурные паттерны, связанные с этими особенностями. Знаешь Python на уровне, достаточном для обработки данных (PySpark в т.ч.). Есть опыт работы с экосистемой Hadoop, понимаешь, какие есть подсистемы, их плюсы и минусы, в каких местах инфраструктуры использовать, а в каких не стоит. Умеешь работать с различными ETL-инструментами. В приоритете — Airflow и DBТ. Будет преимуществом Умеешь работать с Kafka и Debezium. Есть опыт работы в Unix-системах. Периодически мы сами разворачиваем что-нибудь под свои нужды. Есть опыт работы с Docker и Kubernetes. Есть навыки командной разработки с использованием Gitlab, настройки CI/CD пайплайнов. Что ждёт тебя в Точке Официальная зарплата до 350 000 . Точная сумма зависит от твоих навыков и ожиданий — обсудим их на собеседовании. Пятидневная рабочая неделя с гибким началом и окончанием дня. Удалёнка или любой офис Точки в городах присутствия. Наши офисы — это продуманные опенспейсы, где есть индивидуальные места для работы, зоны отдыха и кухни с кофе и перекусами. Ты можешь самостоятельно выбрать, где работать — ходить в офис необязательно. Понятная система развития и роста по грейдам. Бесплатное обучение: ты сможешь ездить на IT-конференции, митапы и хакатоны и проходить курсы за счёт компании. А ещё пользоваться нашей библиотекой и платформой с онлайн-курсами. Бесплатная страховка здоровья со стоматологией и корпоративный психолог. Активная корпоративная жизнь: мы проводим спортивные марафоны, гастрономические вечера, музыкальные лайвы и многое другое. Мы ценим твоё время, поэтому не затягиваем процесс собеседования и сделаем пре-оффер в течение 24 часов.","Oracle Pl/SQL,DWH,Hadoop,Greenplum,ORACLE,ETL,Clickhouse",Точка,
8339,78642657,Data Scientist (MyTracker),з/п не указана,1–3 года,"Полная занятость,полный день","Отдел Предиктивной аналитики внутри трекера решает широкий спектр задач от развития собственной маркетинговой антфирод-системы (Fraud Scanner) до создания системы персонализированных офферов (Personalize). Мы создаем продукты и прогнозы начиная от идеи до ее реализации в интерфейсе MyTracker. Задачи: R&D и анализ данных (поиск корреляций, зависимости, работа с аномалиями, представление результатов и прочее), построение и реализация алгоритмов машинного обучения представление результатов R&D в понятном для команды виде анализ поступающего графика на наличие аномалий и построение предиктивных моделей для работы антифрод-алгоритмов имплементация моделей для работы в production, разработка мониторингов и оповещений по работе моделей. Требования: опыт решения реальных задач с применением алгоритмов машинного обучения (задачи регрессии, классификации, ранжирования) в production и их поддержка опыт работы в команде с 3+ ML-специалистами математика, теория вероятностей, матстатистика опыт в программировании на Python (знание основных конструкций языка, умение разбираться в чужом коде, знания ООП) стек Python (pandas/scipy/catboost/sklearn). Будет плюсом: SQL диалект Clickhouse разработка антифрод-систем умение проводить A/B-тесты Linux и Bash.","Python,Анализ данных,Machine learning,Linux,Bash,Git,SQL,Clickhouse",VK,"Москва, Аэропорт, Ленинградский проспект, 39с79"
8340,77478897,Data Engineer (Greenplum),до 350 000 руб. на руки,3–6 лет,"Полная занятость,полный день","щем дата-инженера в Точку. Мы — финтех-компания, создаём онлайн-банк и другие сервисы для предпринимателей и предприятий. Тебе предстоит работать в команде, которая строит инфраструктуру для работы с данными в Точке. Наши пользователи — продвинутые аналитики со знанием SQL и Python и разработчики сервисов на основе данных.  Мы переезжаем с Oracle на Greenplum, поэтому ищем высококвалифицированных дата инженеров с опытом работы с Greenplum и Hadoop. Плюсом будет аналогичный опыт миграции.  Как мы работаем Сейчас у нас есть хранилище на Oracle, Hadoop и Clickhouse, система потоковой обработки на Kafka, Streamsets, Airflow, а также набор самописных сервисов на Python. Что делать Выстраивать конвейеры данных от источников до конечного хранилища. Проектировать архитектуру core-слоя и создавать витрины данных. Находить узкие места, оптимизировать запросы и ETL процессы. Ты подойдёшь, если Есть опыт работы дата-инженером от 3-х лет. Умеешь работать с классическими базами (PostgreSQL, Oracle). Отлично разбираешься в устройстве MPP баз данных (Greenplum, Clickhouse), знаешь их особенности и можешь самостоятельно выбирать архитектурные паттерны, связанные с этими особенностями. Знаешь Python на уровне, достаточным для обработки данных (PySpark в т.ч.). Есть опыт работы с экосистемой Hadoop, понимаешь какие есть подсистемы их плюсы и минусы, в каких местах инфраструктуры использовать, а в каких не стоит. Умеешь работать с различными ETL инструментами (Airflow и DBT в приоритете, но не ограничиваемся ими). Будет преимуществом Умеешь работать с Kafka и Debezium. Есть опыт работы в Unix системах (мы периодически сами разворачиваем что-нибудь под наши нужды). Приходилось работать с Docker и Kubernetes. Есть навыки командной разработки с использованием Gitlab, настройки CI/CD пайплайнов. Что ждёт тебя в Точке Официальная зарплата до 350 000 . Точная сумма зависит от твоих навыков и ожиданий — обсудим их на собеседовании. Пятидневная рабочая неделя с гибким началом и окончанием дня. Удалёнка или любой офис Точки в городах присутствия. Наши офисы — это продуманные опенспейсы, где есть индивидуальные места для работы, зоны отдыха и кухни с кофе и перекусами. Ты можешь самостоятельно выбрать, где работать — ходить в офис необязательно. Понятная система развития и роста по грейдам. Бесплатное обучение: ты сможешь ездить на IT-конференции, митапы и хакатоны и проходить курсы за счёт компании. А ещё пользоваться нашей библиотекой и платформой с онлайн-курсами. Бесплатная страховка здоровья со стоматологией и корпоративный психолог. Активная корпоративная жизнь: мы проводим спортивные марафоны, гастрономические вечера, музыкальные лайвы и многое другое. Мы ценим твоё время, поэтому не затягиваем процесс собеседования и сделаем пре-оффер в течение 24 часов.","Oracle Pl/SQL,DWH,Hadoop,Greenplum,ORACLE,ETL,Clickhouse",Точка,
8353,77470908,Middle/Senior Data Scientist [команда Content],з/п не указана,1–3 года,"Полная занятость,полный день","СберМаркет — технологический онлайн-сервис, который помогает делать покупки не выходя из дома. СберМаркет был создан на основе стартапа Instamart, присоединившегося к экосистеме Сбера в сентябре 2019 года. Наша миссия: экономить время, энергию и деньги людей для чего-то более важного. СберМаркет это: один из лидеров рынка e-grocery в России рост в 11 раз год к году передовые технологии и собственная разработка возможность задавать тренды в своей профессии и быть первопроходцем классная команда и открытая корпоративная культура быстрый рост и самостоятельное управление проектами конкурентная зарплата и надежность Мы хотим, чтобы клиент мог заказать продукты и товары с доставкой через нашу платформу из своих любимых магазинов, поэтому сотрудничаем уже с более 60 федеральными и региональными ретейлерами. Среди наших партнеров крупнейшие торговые сети: METRO, ЛЕНТА, АШАН, О'КЕЙ, Твой Дом и многие другие. Сегодня мы работаем на одном из самых крупных и динамичных потребительских рынков. В СберМаркете по-прежнему живы дух, скорость и независимость стартапа. В то же время мы располагаем силой и мощью крупнейшей в России экосистемы Сбера. Мы находимся в поиске Middle/Senior Data Scientist в команду Content. Отдел Контента в СберМаркете отвечает за наполнение сайта. DS-команда помогает автоматизировать процесс разработки карточки товара: с момента ее создания до момента отображения в каталоге.  Что предстоит делать: Развивать модель Out-of-stock модель. Мы уже выкатили первую версию, получив значимый прирост GMV. Хотим повысить интерпретируемость модели и превратить технологию в полноценный продукт для ритейлеров Оптимизировать работу контент-отдела Развивать алгоритм мэтчинга для предотвращения создания дублей в базе. Мы уже выкатили первую версию с использованием трансформеров в прод, но хотим значимо улучшить top-1 accuracy модели для полного отказа от человеческой работы Улучшать алгоритм автозаполнения карточки товара Улучшать алгоритм обработки изображений товаров. Необходимо ускорить процесс создания фото для карточки товара - первый этап фотопродакшна это удалить фон от основного товара. Что мы ждём от кандидата: Знание алгоритмов ML Решал задачи NLP / Graph analysis Опыт от 2х лет выкатки в прод Умение делать итерации в разработке моделей A/B тесты - знание стат. критериев, антипаттернов, умение сформулировать гипотезу и придумать дизайн теста под эту гипотезу Уверенное владение git, CI/CD, docker, k8s Самостоятельно может подготовить данные для анализа/моделей (SQL, hive, spark) Разработка простых архитектурных решений. Будет плюсом, если ты: Владеешь PyTorch меешь опыт применения BERT-like моделей Наш стэк: Пишем на Python и SQL Данные храним в ClickHouse, S3 Прототипируем в Jupyter, успешные эксперименты переносим на Airflow + Kubernetes Микросервисы разрабатываем на Python + GRPC, разворачиваем на собственной PaaS (Kubernetes, Gitlab CI, Helm, Prometheus) Аналитику, дашборды, мониторинги строим в Tableau, Metabase, Grafana. Что мы предлагаем: Смешанный формат: можно работать из офиса в Москве (Садовническая улица, 9А) или удаленно Соц.пакет — ДМС, спорт, промокоды на заказ продуктов или билеты в отпуск Предоставляем технику для работы на ваш выбор Команда: Мы стараемся нанимать тех, с кем нам хорошо, поэтому работой дело не ограничивается Вместе мы занимаемся спортом, ездим на шашлыки, ходим на внешние хакатоны, играем в настолки, ну и бары, куда же без них Возможности для роста и развития: Сбермаркет активно развивается и растет, что дает возможности роста горизонтально, вертикально и диагонально Внешнее и внутреннее менторство. Если вы знаете классного эксперта и хотите обсудить ваш рабочий проект, это приветствуется и финансируется Бюджет на обучение Поддержка участия в хакатонах - команда из опытных хакатонщиков, days off, сервера Корпоративная культура: Открытость: мы умеем давать обратную связь корректно и вовремя Свобода и ответственность: мы верим, что выдающийся результат достижим при максимальной свободе в принятии решений Fail fast: ошибки это “ок”, для инноваций они необходимы, главное не повторять одни и те же и быстро тестировать гипотезы А еще: Мы не работаем ""в стол"", мы сами отвечаем за полный цикл жизни гипотезы - от рисерча в ноутбуке до выкатки на продакшн Мы уделяем большое внимание обучению сотрудников, поэтому в нашей knowledge base можно найти много интересных курсов, книг и записей конференций Мы сами участвуем в конференциях, как спикеры Проводим внутренние митапы и дискуссионные клубы Не боимся экспериментировать с новыми решениями и технологиями У нас Pet friendly офис. Отправляй своё резюме и становись частью огромной дружной команды!","Python,SQL,Git,Tableau,Spark,A/B тесты,Обработка изображений,Алгоритмы,Обработка фото",СберМаркет,
8355,78618459,Data аналитик,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Разработка автоматизированной управленческой отчетности. Анализ банковского рынка. Анализ финансовых показателей банка и построение прогноза таких показателей. Участвовать в разработке и реализации планов развития и усовершенствования работы управления. Рассмотрение поступающей корреспонденции, принятие по ней соответствующих решений, подготовка предложений и ответов на письма и запросы филиалов, Национального банка и других учреждений. Взаимодействие с органами государственного управления, коммерческими банками, субъектами хозяйствования, подразделениями Национального банка по решению вопросов, входящих в компетенцию управления. Требования: Высшее экономическое образование. Стаж работы в банковской системе не менее 2 (двух) лет. Знание законодательных и иных нормативно-правовых актов в сфере банковской деятельности. Знание принципов организации финансовой работы коммерческого банка. Навыки работы с соответствующими программными продуктами, прикладными электронными программами банка и другими техническими средствами, необходимыми для работы. Отсутствие отрицательных характеристик с предыдущих мест трудовой деятельности. Умение составлять на должностном уровне официальные письма и отвечать на административные запросы. Умение рационально использовать рабочее время, пунктуальность, исполнительность, коммуникабельность. Условия: Устройство согласно ТК КР. Пятидневная рабочая неделя. Полный социальный пакет.","Высшее образование,Взаимодействие с контрольными органами,Анализ текущих финансовых показателей,Высокая ответственность",БАКАЙ БАНК,
8358,73139690,Data scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Требования: Высшее техническое или физико-математическое образование. Релевантный опыт в сфере от 4 лет. Знание классического Machine Learning, матстатистики. Опыт использования стека DS на Python: Numpy, Pandas, SciPy, визуализация (Matplotlib, Plotly). Теоретические/практические знания Deep Learning: полносвязные, свёрточные, рекуррентные, сети. Будет плюсом понимание работы автоэнкодеров, GAN, трансформеров Опыт обучения ML-моделей: Постановка задачи, выбор архитектуры модели, метрики качества и т.д. Опыт разработки на Python, опыт работы с различными форматами и хранилищами данных. Будет преимуществом: Опыт в Fullstack разработке. Призовое место в соревновании Kaggle. Знание алгоритмов и структур данных. Что предстоит сделать: Лидирование проектов, постановка задач команде и контроль их выполнения Проведение исследований и создание ML/DL моделей Предварительная обработка и анализ данных Разработка архитектуры решений Генерация и тестирования гипотез в рамках воронки исследований и разработок Экспериментирование со state-of-the-art методами машинного обучения Оценка и интерпретация результатов экспериментов, подготовка выводов для бизнес-заказчика. Участие в реализаций, как клиентской, так и серверной стороны прототипов решений Примеры задач: предиктивная и описательная аналитика, NLP , CV а также решения других прикладных задач в области Supply Chain Условия: Официальное оформление График работы 5/2, рассматривается удаленный и гибридный формат работы ДМС и социальный пакет Возможность профессионального роста и развития в рамках Компании","Python,SQL,Machine Learning,Pandas,Deep Learning,алгоритмы",Газпром нефть,
8359,77556769,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы создаем платформу процессной аналитики – Sber Process Mining. Process Mining – это подход, позволяющий из сырых event-логов реконструировать процесс, найти в нем неэффективности и предложить план действий по улучшению. Наша задача – сделать аналитику простой, быстрой и красивой – в том числе с помощью BI, AI, ML. Наша команда ищет крутого инженера данных в команду разработки платформы SberPM. Задачи: участие в разработке ядра системы анализа процессов разработка переиспользуемых трансформаций данных и пайплайнов разработка self-service инструментов обработки данных для пользователей разработка и проектирование модели данных. Мы ожидаем: опыт работы в качестве инженера данных от 3 лет опыт работы с Airflow, NiFi или др. оркестраторами ETL процессов владение SQL на уровне native speaker уверенное знание Python знание основ ООП, теории алгоритмов, структур данных знание теории построения хранилищ данных любознательность, широкий кругозор, желание изучать новые технологии, исследовательский склад ума. Будет плюсом: пользователь Unix shell: базовые команды для работы с файлами и процессами опыт работы с брокерами сообщений опыт работы с Docker, Kubernetes опыт работы с Big Data стеком, ClickHouse. Мы предлагаем: конкурентная заработная плата: оклад + бонусы масштабные и интересные задачи в agile команде комфортный офис на м. Кутузовская, Сбербанк Agile Home социальный пакет: ДМС, страхование от несчастных случаев, льготное кредитование бесплатный тренажерный зал и спортивные групповые занятия дисконт-программы от компаний партнеров: фитнес, страхование, туризм обучение и тренинги профессиональный и позитивный коллектив.","Python,SQL,ООП,Big Data,Анализ данных",Сбер. IT,"Москва, Кутузовский проспект, 32"
8368,77593363,Аналитик проверок DataQuality,з/п не указана,3–6 лет,"Полная занятость,полный день","МТС Финтех – одно из ключевых направлений развития Группы МТС. Мы развиваем цифровые финансовые продукты и сервисы на стыке банкинга и телекома. Основа МТС Финтех – МТС Банк – стабильный цифровой банк с фокусом на мобильное приложение и финансовые сервисы нового поколения. В команду Центра Управления Данными (Data Governance) требуется специалист с глубоким знанием языка запросов SQL на вакансию Разработчик проверок DataQuality Любишь работать с данными? Умеешь писать сложные запросы, работать с технической документаций. Тогда эта вакансия для тебя! Какие ЗАДАЧ предстоит решать: Разрабатывать контроли качества данных (ККД) на базе существующих решений (In-house инструмент ККД на базе СУБД Oracle, фреймворк расчета метрик ККД на Python) Взаимодействовать с заказчиками контролей на этапе постановки требований Производить аудит существующих контролей на предмет актуальности и корректности Формировать описание по реализуемым проверкам. МЫ ОЖДАЕМ: Уверенное знание языка SQL запросов (опыт работы с различными вариантами SQL-диалекта будет преимуществом, в порядке очередности Oracle SQL, PostgreSQL, MS SQL). Опыт написания сложных запросов (более 10 таблиц), с бизнес-логикой. Практический опыт использования аналитических и оконных функций. Умение писать и оптимизировать собственный код для обеспечения максимальной производительности запросов при сниженном потреблении ресурсов. Умение писать процедуры и функции (в приоритете Oracle PL/SQL) Умение анализировать больших объемы данных Умение писать техническую документацию МЫ ПРЕДЛАГАЕМ: Работу в современной надежной цифровой компании Достойную заработную плату Комфортный и стильный офис в двух минутах от м. Технопарк Отсутствие дресс-кода, гибкий формат работы Корпоративное кафе «Мечта» и отличный кофе на первом этаже БЦ Аgile-культура: продуктовые команды, Scrum и Kanban, демо-дни, внутренние митапы и таунхоллы Забота о вас и вашей семье: ДМС со стоматологией, сессиями с психологом и госпитализацией, страхование от несчастных случаев и болезней 24/7 и страхование выезжающих за рубеж. К ДМС можно подключить детей и родственников. А еще доступ к телемедицине BestDoctor и врач в офисе Специальный тариф на мобильную связь и предложения от партнеров банка и МТС Мы за спорт: вместе тренируемся в MTS Running Club, в офисе есть бесплатный тренажерный зал. Вы можете присоединиться к корпоративным спортивным командам и занятиям йогой Доступ к корпоративной библиотеке Alpinа, корпоративный университет МТС и программы развития Поддержка сотрудников: программа материальной помощи в различных жизненных ситуациях.","ORACLE,DataQuality,Python,контроли качества данных,качество данных,ККД,СУБД Oracle,Oracle Pl/SQL",МТС Банк,
8394,78580878,Data Engineer (Мy Tracker),з/п не указана,1–3 года,"Полная занятость,полный день","Группа предиктивной аналитики находится в поисках middle data engineer, который не боится новых вызовов и готов придумывать и внедрять новые способы решения задач.  Стек: Python, Prometheus, Clickhouse, MySQL, Redis, Airflow, Linux и Bash. Задачи: написание кода для работы в production разработка мониторингов и оповещений по работе моделей разработка платформы для запуска ML-моделей разработка сопутствующих скриптов (архивация старых данных, сервисы для работы с другими командами, сбор и хранение данных). Требования: опыт работы со стеком: Python, Prometheus, Clickhouse, MySQL, Redis, Airflow, Linux и Bash опыт поддержки уже готовой платформы на микросервисной архитектуре и внедрение новых подходов/фреймворков в production опыт работы в команде с Data-science специалистами умение разработки нового сервиса с нуля (разработка структуры, оценка аппаратных характеристик, имплементация решения, документация к решению, поддержка работоспособности и мониторинг работы).","MySQL,Python,ClickHouse,Linux,Bash",VK,
8398,77472379,Middle/Senior Data Scientist (RecSys),з/п не указана,3–6 лет,"Полная занятость,полный день","СберМаркет — технологический онлайн-сервис, помогающий делать покупки не выходя из дома. СберМаркет был создан на основе стартапа Instamart, присоединившегося к экосистеме Сбера в сентябре 2019 года. Наша миссия: экономить время, энергию и деньги людей для чего-то более важного. СберМаркет это: Один из лидеров рынка e-grocery в России Рост в 11 раз год к году Передовые технологии и собственная разработка Возможность задавать тренды в своей профессии и быть первопроходцем Классная команда и открытая корпоративная культура Быстрый рост и самостоятельное управление проектами Конкурентная зарплата и надежность. Мы хотим, чтобы клиент мог заказать продукты и товары с доставкой через нашу платформу из своих любимых магазинов, поэтому сотрудничаем уже с более 60 федеральными и региональными ретейлерами. Среди наших партнеров крупнейшие торговые сети: METRO, ЛЕНТА, АШАН, О'КЕЙ, Твой Дом и многие другие. Мы работаем на одном из самых крупных и динамичных потребительских рынков. СберМаркет-это дух, скорость и независимость стартапа, а так же сила и мощь крупнейшей в России экосистемы Сбера. Команда RecSys существует 2 года. За это время мы успели: с нуля создать ключевые рекомендательные алгоритмы и в честном А/В-тесте значимо победить рекомендации от внешнего вендора пройти непростой путь от offline до online рекомендаций проверить в А/В-тестах множество гипотез по улучшению рекомендательных алгоритмов для всего сервиса запустить в А/В-тест проект персонализации UI приложения и многое другое. Кроме того, мы сами занимаемся разработкой и развитием рекомендательной платформы, сами катим свои модели в продакшн и сами отвечаем за стабильность работы сервиса рекомендаций. Что предстоит делать: зучать статьи в поисках лучших подходов к созданию рекомендаций в фудтехе Выдвигать гипотезы по улучшению существующих алгоритмов рекомендаций, а также придумывать новые по запросу от бизнеса Проверять гипотезы на данных Обучать ML-модели Запускать А/В-тесты. Что ждем от тебя? Для кандидатов уровня Middle и выше: совокупный опыт работы в ML от 2-х лет умение сделать качественный EDA и донести результаты до команды уверенное владение Python и базовые знания SQL практический опыт работы с ML (в частности, опыт работы с алгоритмами CF и ранжирования) опыт полного цикла внедрения моделей (сбор данных, обучение и оценка модели, проведение А/Б-тестов) самостоятельность, проактивность и умение декомпозировать при решении задач. Для кандидатов уровня Senior и выше: предыдущий опыт работы в сфере нформационного поиска/RecSys/NLP/E-commerce на позиции уровня Middle и выше практический опыт проектирования ML-систем. Будет плюсом, если ты: Знаешь, как правильно готовить алгоритмы бустинга и разрабатывать для них жгущие факторы меешь опыт работы с нейронными сетями меешь опыт работы, связанный с выкатками на продакшн Умеешь писать надежный и эффективный продакшн-код на Python. Наш стэк: Пишем на Python и SQL Данные храним в ClickHouse, S3 Прототипируем в Jupyter, успешные эксперименты переносим на Airflow + Kubernetes Микросервисы разрабатываем на Python + GRPC, разворачиваем на собственной PaaS (Kubernetes, Gitlab CI, Helm, Prometheus) Аналитику, дашборды, мониторинги строим в Tableau, Metabase, Grafana. Что мы предлагаем? Удаленный формат: Гибкое время начала дня Белая заработная плата Сильная команда коллег с kaggle grand и просто мастерами, выпускниками ШАДа Предоставляем всё необходимое оборудование для работы Развитие и рост (внешнее и внутреннее менторство, семинары, курсы, тренинги, внутреннее обучение) Поддержка участия в хакатонах - команда из опытных хакатонщиков, days off, сервера.","Python,SQL,Машинное обучение,ML",СберМаркет,
8402,77471529,Lead Data Scientist (Operations),з/п не указана,более 6 лет,"Полная занятость,полный день","СберМаркет — технологический онлайн-сервис, помогающий делать покупки не выходя из дома. СберМаркет был создан на основе стартапа Instamart, присоединившегося к экосистеме Сбера в сентябре 2019 года. Наша миссия: экономить время, энергию и деньги людей для чего-то более важного. СберМаркет это: Один из лидеров рынка e-grocery в России Рост в 11 раз год к году Передовые технологии и собственная разработка Возможность задавать тренды в своей профессии и быть первопроходцем Классная команда и открытая корпоративная культура Быстрый рост и самостоятельное управление проектами Конкурентная зарплата и надежность. Мы хотим, чтобы клиент мог заказать продукты и товары с доставкой через нашу платформу из своих любимых магазинов, поэтому сотрудничаем уже с более 60 федеральными и региональными ретейлерами. Среди наших партнеров крупнейшие торговые сети: METRO, ЛЕНТА, АШАН, О'КЕЙ, Твой Дом и многие другие. Мы работаем на одном из самых крупных и динамичных потребительских рынков. СберМаркет-это дух, скорость и независимость стартапа, а так же сила и мощь крупнейшей в России экосистемы Сбера.  Мы ищем тимлида в ML-команду Operations Операции - сердце бизнеса. DS-команда операций работает на проектах, которые повышают операционную эффективность и помогают бизнесу стать прибыльным. Что предстоит делать: Управлять командой от 5 до 10 человек Развивать команду через процессы, принятые в компании: 1-1, feedback sessions, ПР, perfomance review Повышать операционную эффективность бизнеса за счет ML Определять направление развития ML в операциях Создавать квартальные планы совместно с продактом команды. Планировать спринты Участвовать в code review. Что ждем от тебя? Совокупный опыт работы в ML от 5 лет, в том числе опыт управления командой от 1 года Предыдущий опыт в сфере E-commerce на Senior/Lead позиции Опыт работы с задачами операционной части бизнеса (supply/demand balance, dispatch, surge и другие) Умеешь говорить на одном языке с бизнесом Любишь погружаться в бизнес-процессы и оптимизировать их с помощью математики Умеешь писать код на Python эффективно (может отличить O(n) от O(n^2)) Наш стэк: Пишем в основном на Python, прототипируем в Jupyter, успешные эксперименты переносим на Airflow+Kubernetes Микросервисы разрабатываем на Python+GRPC, разворачиваем на собственной PaaS (Kubernetes,Gitlab CI,Helm, Prometheus) Аналитику, дашборды, мониторинги строим в Tableau, Metabase, Grafana. Что мы предлагаем? Удаленный формат работы: Гибкое время начала дня Белая заработная плата Сильная команда коллег с kaggle grand и просто мастерами, выпускниками ШАДа Предоставляем всё необходимое оборудование для работы Развитие и рост (внешнее и внутреннее менторство, семинары, курсы, тренинги, внутреннее обучение) Поддержка участия в хакатонах - команда из опытных хакатонщиков, days off, сервера.","Обучение и развитие,Машинное обучение,Системное мышление,ML,Математика",СберМаркет,
8405,78575624,Архитектор Data,от 270 000 руб. на руки,не требуется,"Полная занятость,удаленная работа","В крупный проект на срок от 3-х месяцев на удалёнку требуется Архитектор Обязанности: Аналитическая часть - Cогласование и уточнение требований к системе копирования - Cогласование и уточнение требований к системе трансформации OLAP кубов SAS Разработка - Разработка архитектуры системы копирования данных SAS - Разработка архитектуры системы трансформации OLAP кубов SAS - Настройка тестовой центральной ETL среды и тестовой MPP Greenplum - Модуль копирования таблиц в staging по добавленным заданиям SAS (transport_worker_mpp.sas) - Модуль управления (добавления) заданиями (add_copy_tasks.sas) - Процесс перенос таблиц Staging в конечные таблицы хранилища (loopJob.sas) - Процесс создания view на основе мета данных для интеграции c SAS EG (MPPGenerateViews.sas) - Разработка модуля трансформации OLAP кубов SAS в плоские таблицы - Реализация ETL-процесса c копированием таблиц SAS - Оптимизация производительности - Проведение нагрузочного тестирования - Адаптация разработанного функционала для переноса на продуктивный стенд Документация - Разработка приемо-сдаточной документации - Согласование результатов на тестовом стенде - Участие в приемо-сдаточных испытаниях Требования: Опыт работы с базами данных в качестве аналитика/разработчика от пяти лет - Опыт участия в проектах по созданию и развитию DWH - Опыт разработки OLAP-кубов - Понимание принципов разработки с помощью ETL инструментария - Опыт разработки высоконагруженных систем - Опыт разработки логической и физической моделей данных - Понимание предметной области Телеком - Понимание нюансов работы платформ - Teradata, SAS, Greenplum (особенности DDL,DML,PL/SQL)",,АБП,"Москва, Софийская набережная, 34"
8406,78562766,Data аналитик (Продажи и обслуживание вне отделений),з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: подготовка бизнес-требований на витрины и отчётность для IT взаимодействие с командой проекта, мониторинг статуса, помощь в аналитике построение аналитических отчётов (таблицы в БД + визуальная часть) тестирование и приёмка результатов проекта исследование данных в БД (Hadoop/GreenPlum) ad-hoc запросы Требования: Опыт работы в аналитике данных и построении отчётности в крупной организации (желательно в банке) от 2 лет Знание базовых принципов построения хранилищ данных Знание SQL на уровне сложных запросов (будут задачи) Желательно: Общее представление о банковских продуктах ФЛ Умение работать с AirFlow Умение строить OLAP отчётность (кубы) Знание Python Знание любого BI инструмента визуализации (PowerBI, Tableau, Qlik и т.п.) Опыт работы с Hadoop и GreenPlum","Python,Big Data,Power BI,OLAP,MS SQL,SQL,PowerBI,Hadoop,Аналитическое мышление,Аналитические исследования,Анализ данных,Работа с базами данных,Работа с банками,Jira,Работа с большим объемом информации","ннотех, Группа компаний",
8409,77471270,Lead Data Scientist (RecSys),з/п не указана,более 6 лет,"Полная занятость,полный день","СберМаркет — технологический онлайн-сервис, помогающий делать покупки не выходя из дома. СберМаркет был создан на основе стартапа Instamart, присоединившегося к экосистеме Сбера в сентябре 2019 года. Наша миссия: экономить время, энергию и деньги людей для чего-то более важного. СберМаркет это: Один из лидеров рынка e-grocery в России Рост в 11 раз год к году Передовые технологии и собственная разработка Возможность задавать тренды в своей профессии и быть первопроходцем Классная команда и открытая корпоративная культура Быстрый рост и самостоятельное управление проектами Конкурентная зарплата и надежность. Мы хотим, чтобы клиент мог заказать продукты и товары с доставкой через нашу платформу из своих любимых магазинов, поэтому сотрудничаем уже с более 60 федеральными и региональными ретейлерами. Среди наших партнеров крупнейшие торговые сети: METRO, ЛЕНТА, АШАН, О'КЕЙ, Твой Дом и многие другие. Мы работаем на одном из самых крупных и динамичных потребительских рынков. СберМаркет-это дух, скорость и независимость стартапа, а так же сила и мощь крупнейшей в России экосистемы Сбера. щем тимлида в ML-команду рекомендательных систем. Команда RecSys существует 2 года. За это время мы успели: с нуля создать ключевые рекомендательные алгоритмы и в честном А/В-тесте значимо победить рекомендации от внешнего вендора пройти непростой путь от offline до online рекомендаций проверить в А/В-тестах множество гипотез по улучшению рекомендательных алгоритмов для всего сервиса запустить в А/В-тест проект персонализации UI приложения и многое другое. Кроме того, мы сами занимаемся разработкой и развитием рекомендательной платформы, сами катим свои модели в продакшн и сами отвечаем за стабильность работы сервиса рекомендаций. Что предстоит делать: Управлять командой от 3 до 5 человек Развивать команду через процессы, принятые в компании: 1-1, feedback sessions, ПР, perfomance review Растить денежные метрики СберМаркета и повышать пользовательский опыт путём улучшения рекомендательных алгоритмов на основе имеющейся экспертизы Определять направление развития ML-компоненты рекомендательной платформы Создавать квартальные планы совместно с продактом команды. Планировать спринты Участвовать в code review. Что ждем от тебя? Совокупный опыт работы в ML от 5 лет, в том числе опыт управления командой от 1 года Предыдущий опыт в сфере нформационного поиска/RecSys/NLP/E-commerce на Senior/Lead позиции Опыт полного цикла внедрения моделей (сбор данных, обучение и оценка модели, проведение А/Б-тестов) Практический опыт проектирования ML-систем Опыт работы, связанный с выкатками на продакшн Уверенное владение Python и SQL. Будет плюсом, если ты: меешь опыт работы с нейронными сетями Умеешь писать надежный и эффективный продакшн-код на Python. Наш стэк: Пишем на Python и SQL Данные храним в ClickHouse, S3 Прототипируем в Jupyter, успешные эксперименты переносим на Airflow + Kubernetes Микросервисы разрабатываем на Python + GRPC, разворачиваем на собственной PaaS (Kubernetes, Gitlab CI, Helm, Prometheus) Аналитику, дашборды, мониторинги строим в Tableau, Metabase, Grafana. Что мы предлагаем? Удаленный формат работы Гибкое время начала дня Белая заработная плата Сильная команда коллег с kaggle grand и просто мастерами, выпускниками ШАДа Предоставляем всё необходимое оборудование для работы Развитие и рост (внешнее и внутреннее менторство, семинары, курсы, тренинги, внутреннее обучение) Поддержка участия в хакатонах - команда из опытных хакатонщиков, days off, сервера.","Python,Машинное обучение,Алгоритмы",СберМаркет,
8410,78561927,Data engineer (Устройства самообслуживания),з/п не указана,3–6 лет,"Полная занятость,полный день","В команду по клиентской аналитике и геомоделированию, требуется Data Engineer для проектирования и разработки витрин данных, а также оперативного обеспечения DS, DA команды выборками из различных информационных систем и баз данных.  Обязанности:  Проведение анализа данных в части поведения клиента при использовании физической сети Банка (отделения, банкоматы), построение гипотез, определение ключевых признаков в данных, грамотное формирование выводов и визуализация результатов Поиск, сбор, группировка и обработка данных из внешних и внутренних источников для выполнения поставленных задач Разработка алгоритмических и математических решений для анализа крупных наборов данных Документирование процессов обработки данных Взаимодействие с заказчиками, внутренними подразделениями Требования:  Высшее техническое образование (желательно прикладная математика, анализ данных) Уверенное владение SQL: сложные запросы, аналитические функции, понимание физической реализации join’ов, оптимизация производительности запросов Знание Python, опыт работы с библиотеками для анализа данных Jira, Confluence Понимание принципов анализа данных, проверки гипотез, поиска взаимосвязей и интерпретации результатов в бизнес-логике Умение работать со статистическими приложениями и программами визуализации данных Будет плюсом: Опыт работы с Big data стеком: Hadoop, Hive, Impala, Spark","Python,SQL,ETL,СУБД,Математическое моделирование,Математический анализ,Аналитическое мышление,Hadoop,PostgreSQL,Математический склад ума,Большие данные","ннотех, Группа компаний",
8411,77536408,Data Engineer (группа машинного обучения),з/п не указана,1–3 года,"Полная занятость,полный день","Наша команда внутри AdTech разрабатывает инструменты работы с большими данными, упрощающие жизнь DS и аналитиков. В центре внимания — обучение и применение большого количества моделей ранжирования и классификации в Hadoop-кластере, результаты работы моделей применяются при подборе рекламы и позволяют улучшать его качество на различных этапах (таргетинги, пре-ранк объявлений, новые признаки для моделей real-time-подбора и т.д.). Задачи: развитие системы автоматизации жизненного цикла ML-моделей и обработки больших данных для повышения качества подбора рекламы и смежных задач проектирование, разработка и поддержка инструментов для создания надежных пайплайнов данных исследование и интеграция новых источников для построения различных витрин признаков, используемых в ML-моделях. Требования: знание классических алгоритмов и структур данных уверенное владение Python/SQL, написание качественного кода опыт работы с Hadoop (HDFS, Spark, Hive) навыки работы с bash, git, linux, docker. Будет плюсом: опыт работы с luigi/airflow знание Java/Scala опыт работы с Kafka знание классических ML-моделей.","SQL,Python,Hadoop,Airflow,Spark,Hive,Linux","VK, ВКонтакте","Москва, Аэропорт, Ленинградский проспект, 39с79"
8413,77432992,Data Engineer junior +,з/п не указана,1–3 года,"Полная занятость,полный день","Мы стремимся к большему, и нам нужен Data Engineer junior + Чем предстоит заниматься: Сбором, обработкой и подготовкой данных с множества источников данных Оркестрацией расчетных джоб в airflow Организацией хранения данных в Hadoop Разработкой скриптов на Python Мы ожидаем, что ты: Знаешь инструменты разработки: Python, SQL Работал в ОС Linux Преимуществом будут: Опыт работы в аналитике больших данных от 1 года Владение современными методами машинного обучения Высокая обучаемость Мы предлагаем: Трудоустройство в аккредитованную Т компанию Достойную твоего профессионального уровня заработную плату (уровень вознаграждения обсуждается индивидуально по результатам интервью) Годовую премию по результатам деятельности, дополнительную материальную мотивацию (премии от руководителя) Качественная программа ДМС со стоматологией с первого месяца работы услуги телемедицины, консультации психолога, страхование жизни и здоровья в том числе за границей, льготные условия страхования для близких и возможность расширить перечень клиник по опции Flexible benefits Неограниченный доступ к образовательному контенту на портале знаний от корпоративного университета Подписка на лучшие электронные библиотеки с подборками IT-литературы (и не только) Собственный центр профессионального развития, в котором проводятся комплексные программы обучения hard skills Внутренние демодни, коуч-дни, питчи – то, что поможет продвигать и совершенствовать проекты и собственные идеи Корпоративные скидки для изучения английского языка в малых группах онлайн и офлайн Регулярные карьерные марафоны, индивидуальные карьерные консультации и планы развития Общение вне рабочих рамок – независимо от того, в каком городе ты работаешь! От участия в корпоративных спортивных сообществах до онлайн-экскурсий и неформальных встреч в формате Random coffee  В «Газпром нефть» ты можешь: • Получить уникальный профессиональный опыт • Создавать смелые проекты с нуля и наблюдать за их влиянием на целую отрасль • Быть вместе с теми, кого вдохновляют сверхсложные задачи • Сочетать несколько ролей, быть частью нескольких команд или участвовать в кросс-функциональных командах • спользовать возможности компании-лидера для своей самореализации и убедиться, что любой профессиональный опыт важен • Быть среди тех, кто создает первую в России цифровую платформу для управления промышленной компанией нового поколения","Python,MS SQL,Linux",Газпром нефть,
8417,76291841,DWH разработчик / DWH инженер / Data Engineer,от 110 000 руб. до вычета налогов,1–3 года,"Полная занятость,полный день","iSpring - продуктовая Т компания. С 2001 года мы разрабатываем софт для создания онлайн-курсов и управления обучением в корпоративном сегменте (eLearning). В команде 500+ человек, 7 офисов в России и 3 за рубежом Наши основные продукты - iSpring Suite, конструктор онлайн курсов, и iSpring Learn, платформа для управления онлайн обучением (LMS) занимают лидерские позиции в своих сегментах на глобальном рынке. Также мы предоставляем образовательный контент и услуги по обучению и внедрению под маркой «Академия iSpring». щем сильного нженера по данным, который поможет нам с развитием, поддержкой и управлением Data Warehouse для аналитики. Обязанности: Разработка ETL процессов, обеспечивающих загрузку, очистку и сохранение данных в хранилище данных (DWH) Взаимодействие с внутренним заказчиком с целью сбора требований Участие в проектировании архитектуры системы Подготовка данных для разработки конкретных моделей, установление связей в данных из разных источников, очистка данных, выделение выборок, создание витрин данных для аналитики Автоматизация типовых операций в хранилище Разработка инструментов обеспечения Data Quality: сверка данных с источником, контроль целостности данных между витринами, контроль на критичные выбросы в данных Написание внутренней технической документации.  Что необходимо для работы: Опыт разработки и оптимизации аналитических SQL запросов Понимание принципов работы реляционных БД и построения хранилищ данных Понимание теории ETL-процессов и опыт работы с ETL-процессами Уверенные знания языка Python (pandas), Понимание принципов проектирования DWH (денормализация данных, таблицы с Фактами и змерениями, структуры Звезда и Снежинка, Data Vault) Высшее техническое образование Плюсом будет: Опыт разработки корпоративных хранилищ данных (DWH) Опыт работы с Docker, Kubernetes, Ansible, Apache Airflow Опыт работы с MySQL, MS SQL, MS SQL Server Analysis Services, или с другой реляционной базой данных (разработка хранилищ данных или написание запросов) Опыт построения архитектуры баз данных и архитектуры приложений Опыт работы с колоночными базами данных Опыт работы с SQL Server Integration Services (или другими промышленными ETL-инструментами) Знание языка MS T-SQL (объединения, обобщенные выражения, оконные функции) Опыт работы аналитиком Условия: Энергичная, живая команда, свобода действий, быстрый цикл согласований и возможность прямого контакта с владельцем компании Регулярные тренинги в рамках развития управленческой команды компании Оформление в соответствии с ТК РФ с предоставлением всех предусмотренных законом социальных гарантий Оклад + премия без ограничения сверху Расширенный пакет ДМС: амбулаторная помощь, помощь на дому, стоматологические услуги Современный офис 6500 кв.м в центре Йошкар-Олы Бочки варенья, корзины печенья, пуфики, фруктики или всё как принято в Т-компаниях :) Кто мы С 2001 года создаём высокотехнологичные Т-продукты для глобального рынка. Наша миссия - создавать возможности для развития: чтобы наши клиенты и сотрудники могли реализовывать свои мечты и жить достойно. Команда iSpring ждёт тех, кому важно стремиться к совершенству, жить полной жизнью, верить в мечту и быть настоящим. Главный офис iSpring находится в Йошкар-Оле. Это комфортный, экологичный, красивый город в Поволжье с развитой Т-индустрией. Также есть офисы в Санкт-Петербурге, Москве, Владивостоке, Казани и Краснодаре. Вместе с нашими программными продуктами мы развиваем три больших оффлайновых проекта в области Т-образования. Познакомьтесь с ними, чтобы узнать нас лучше: Детская компьютерная школа нфосфера Т-лицей нфотех нститут iSpring - бакалавриат по IT специальностям.","DWH,MS SQL,Аналитическое мышление,Работа с базами данных,SQL,ETL,Docker,Kubernetes,Data Vault,Python,Apache Airflow",iSpring,
8418,76291842,DWH разработчик / DWH инженер / Data Engineer,от 110 000 руб. до вычета налогов,1–3 года,"Полная занятость,полный день","iSpring - продуктовая Т компания. С 2001 года мы разрабатываем софт для создания онлайн-курсов и управления обучением в корпоративном сегменте (eLearning). В команде 500+ человек, 7 офисов в России и 3 за рубежом Наши основные продукты - iSpring Suite, конструктор онлайн курсов, и iSpring Learn, платформа для управления онлайн обучением (LMS) занимают лидерские позиции в своих сегментах на глобальном рынке. Также мы предоставляем образовательный контент и услуги по обучению и внедрению под маркой «Академия iSpring». щем сильного нженера по данным, который поможет нам с развитием, поддержкой и управлением Data Warehouse для аналитики. Обязанности: Разработка ETL процессов, обеспечивающих загрузку, очистку и сохранение данных в хранилище данных (DWH) Взаимодействие с внутренним заказчиком с целью сбора требований Участие в проектировании архитектуры системы Подготовка данных для разработки конкретных моделей, установление связей в данных из разных источников, очистка данных, выделение выборок, создание витрин данных для аналитики Автоматизация типовых операций в хранилище Разработка инструментов обеспечения Data Quality: сверка данных с источником, контроль целостности данных между витринами, контроль на критичные выбросы в данных Написание внутренней технической документации.  Что необходимо для работы: Опыт разработки и оптимизации аналитических SQL запросов Понимание принципов работы реляционных БД и построения хранилищ данных Понимание теории ETL-процессов и опыт работы с ETL-процессами Уверенные знания языка Python (pandas), Понимание принципов проектирования DWH (денормализация данных, таблицы с Фактами и змерениями, структуры Звезда и Снежинка, Data Vault) Высшее техническое образование Плюсом будет: Опыт разработки корпоративных хранилищ данных (DWH) Опыт работы с Docker, Kubernetes, Ansible, Apache Airflow Опыт работы с MySQL, MS SQL, MS SQL Server Analysis Services, или с другой реляционной базой данных (разработка хранилищ данных или написание запросов) Опыт построения архитектуры баз данных и архитектуры приложений Опыт работы с колоночными базами данных Опыт работы с SQL Server Integration Services (или другими промышленными ETL-инструментами) Знание языка MS T-SQL (объединения, обобщенные выражения, оконные функции) Опыт работы аналитиком Условия: Энергичная, живая команда, свобода действий, быстрый цикл согласований и возможность прямого контакта с владельцем компании Регулярные тренинги в рамках развития управленческой команды компании Оформление в соответствии с ТК РФ с предоставлением всех предусмотренных законом социальных гарантий Оклад + премия без ограничения сверху Расширенный пакет ДМС: амбулаторная помощь, помощь на дому, стоматологические услуги Современный офис 6500 кв.м в центре Йошкар-Олы Бочки варенья, корзины печенья, пуфики, фруктики или всё как принято в Т-компаниях :) Кто мы С 2001 года создаём высокотехнологичные Т-продукты для глобального рынка. Наша миссия - создавать возможности для развития: чтобы наши клиенты и сотрудники могли реализовывать свои мечты и жить достойно. Команда iSpring ждёт тех, кому важно стремиться к совершенству, жить полной жизнью, верить в мечту и быть настоящим. Главный офис iSpring находится в Йошкар-Оле. Это комфортный, экологичный, красивый город в Поволжье с развитой Т-индустрией. Также есть офисы в Санкт-Петербурге, Москве, Владивостоке, Казани и Краснодаре. Вместе с нашими программными продуктами мы развиваем три больших оффлайновых проекта в области Т-образования. Познакомьтесь с ними, чтобы узнать нас лучше: Детская компьютерная школа нфосфера Т-лицей нфотех нститут iSpring - бакалавриат по IT специальностям.","DWH,MS SQL,Аналитическое мышление,Работа с базами данных,SQL,ETL,Docker,Kubernetes,Data Vault,Python,Apache Airflow",iSpring,
8443,77361870,Senior Finance Data Analyst Департамента финансовой отчётности и контроля,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Создание структуры данных для BI-tool, разработка дэшбордов Анализ бизнес-процессов и технических потоков данных для выявления проблем с качеством данных, а также потенциальных рисков возникновения таких проблем Разработка аналитических расчетов на SQL / Python Разработка решений «легкой автоматизации» (RPA, макросы, OLAP-кубы и другие инструменты) Участие в стратегическом проекте по развитию аналитического DWH Актуализация моделей данных для поддержания дэшбордов и аналитических расчетов в актуальном состоянии Участие в разработке и автоматизация предиктивных и статистических моделей Требования: Основное образование - Техническое / Математическое / Финансовое Дополнительное образование - Аналитик данных Сфера: аналитик данных, написание SQL-запросов и создание структуры данных для BI-tool Профессиональные компетенции: знание SQL на продвинутом уровне и опыт оптимизации запросов знание Python и опыт работы с BI-tool (Tableau, Power BI, ORACLE BI) понимание основных принципов разработки хранилищ данных опыт работы в сфере управления данными/качества данных, понимание основных характеристик качества данных и типовых причин проблем с качеством данных Личностные компетенции: Навыки профессионального общения Умение самостоятельно находить пути решения, аккуратно и быстро выполнять задачи, планировать своё и чужое время Помощь в оптимизации наших бизнес-процессов – от улучшения качества данных до автоматизации бизнес-операций Умение работать в команде Знание языков (укажите уровень владения): узбекский - Хорошо или свободно русский - Хорошо или свободно английский - Не ниже upper-intermediate Знание компьютерных программ: Excel, Power BI, SQL, Python, будет преимуществом опыт работы с BI-tool (Tableau, Power BI, ORACLE BI) Опыт с ML моделями – как преимущество Дополнительные требования базовые знания о банковских продуктах и основных процессах Условия: Комфортное рабочее место Корпоративное обучение Бесценный опыт трансформации Возможность карьерного развития 24 дня оплачиваемого отпуска","Python,SQL,Английский язык,Tableau,MS PowerPoint",Xalq Banki,
8445,78135303,Руководитель проектов в Data Office,з/п не указана,3–6 лет,"Полная занятость,полный день","Data Office появился пару лет назад. Наша команда: • строит хранилище данных для VK • запустила Data Portal как отдельный сервис для удобного взаимодействия с данными основные наши пользователи — маркетологи, менеджеры продуктов, аналитики, дата-сайентисты • провела десятки обучающих мероприятий для менеджеров и аналитиков • организовала сообщества DS/ML и Analytics и объединила дата-сайентистов и аналитиков всех продуктов VK • провела сотни A/B-тестов и продуктовых исследований.  Каждый день мы работаем с огромными объёмами данных (50 петабайт), используем современный стек технологий (Spark, Airflow, Presto, Vertica, ClickHouse) и разрабатываем современные дата-сервисы, которые помогают развиваться каждому продукту в компании.  За год наша команда выросла в пять раз. Основные функциональные направления нашей работы: • Data Analytics, • Data Engineering, • Data Science, • Product&Service Development. щем специалиста, который будет тесно работать с аналитиками, дата-сайентистами, менеджерами продуктов и маркетологами. Вам предстоит: • проводить исследования и искать с помощью данных точки роста во всех продуктах VK • сделать данные понятными, интерпретируемыми и полезными для поиска инсайтов. У нас интересно, потому что: • мы анализируем данные и выдвигаем, разрабатываем и тестируем гипотезы по улучшению продуктовых метрик в продуктах • вы сможете узнать, как устроены все продукты VK, поработать с их данными и реализовать с нуля новые проекты. Мы ожидаем, что вы: • работали аналитиком, бизнес-аналитиком, менеджером дата-продуктов • хорошо знаете SQL • выстраивали проактивную аналитику • обладаете опытом дизайна и анализа A/B-тестов, применяли теорию вероятности и статистику • визуализировали данные • понимаете и применяете основные метрики интернет-продуктов (ARPAU, LTV, retention, churn) • работали с хранилищами данных, понимаете базовую архитектуру данных. Будет плюсом знание Python. Приглашаем специалиста, который сможет посещать офис в Москве или Санкт-Петербурге, работать в комбинированном режиме. Ждём ваших откликов. Удачи!",,"VK, ВКонтакте",
8446,78135302,Руководитель проектов в Data Office,з/п не указана,3–6 лет,"Полная занятость,полный день","Data Office появился пару лет назад. Наша команда: • строит хранилище данных для VK • запустила Data Portal как отдельный сервис для удобного взаимодействия с данными основные наши пользователи — маркетологи, менеджеры продуктов, аналитики, дата-сайентисты • провела десятки обучающих мероприятий для менеджеров и аналитиков • организовала сообщества DS/ML и Analytics и объединила дата-сайентистов и аналитиков всех продуктов VK • провела сотни A/B-тестов и продуктовых исследований.  Каждый день мы работаем с огромными объёмами данных (50 петабайт), используем современный стек технологий (Spark, Airflow, Presto, Vertica, ClickHouse) и разрабатываем современные дата-сервисы, которые помогают развиваться каждому продукту в компании.  За год наша команда выросла в пять раз. Основные функциональные направления нашей работы: • Data Analytics, • Data Engineering, • Data Science, • Product&Service Development. щем специалиста, который будет тесно работать с аналитиками, дата-сайентистами, менеджерами продуктов и маркетологами. Вам предстоит: • проводить исследования и искать с помощью данных точки роста во всех продуктах VK • сделать данные понятными, интерпретируемыми и полезными для поиска инсайтов. У нас интересно, потому что: • мы анализируем данные и выдвигаем, разрабатываем и тестируем гипотезы по улучшению продуктовых метрик в продуктах • вы сможете узнать, как устроены все продукты VK, поработать с их данными и реализовать с нуля новые проекты. Мы ожидаем, что вы: • работали аналитиком, бизнес-аналитиком, менеджером дата-продуктов • хорошо знаете SQL • выстраивали проактивную аналитику • обладаете опытом дизайна и анализа A/B-тестов, применяли теорию вероятности и статистику • визуализировали данные • понимаете и применяете основные метрики интернет-продуктов (ARPAU, LTV, retention, churn) • работали с хранилищами данных, понимаете базовую архитектуру данных. Будет плюсом знание Python. Приглашаем специалиста, который сможет посещать офис в Москве или Санкт-Петербурге, работать в комбинированном режиме. Ждём ваших откликов. Удачи!",,"VK, ВКонтакте",
8476,77341231,Data Engineer / ETL-аналитик/-разработчик,з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Разработка архитектуры хранилища данных, с учётом требований по визуализации (DataFlow) Реализация хранилища данных из разрозненных систем-источников. Подготовка витрин данных для дальнейшей визуализации в BI системах. Построение и поддержка интеграций данных между различными системами. Выстраивание процесса валидации данных. Постановка задач администраторам по развёртке, мониторингу нагрузке баз данных. Оптимизация запросов. Составление технической документации по разрабатываемым витринам данных Валидация проектных решений, предлагаемых подрядными организациями Контроль работы команды подрядчика по направлению Коммуникация внутри команды (в том числе посредством систем заявок и управления задачами) Требования: Образование высшее (желательное, но не обязательное) Уверенные знания SQL middle+ (PostgreSQL, Clickhouse) наличие специальных сертификатов о прохождении курсов. Опыт работы от 5-ти лет в похожей роли / с похожим функционалом Свободное знание SQL: процедуры, аналитические функции Знания и опыт администрирования PostgreSQL, Clickhouse Опыт командной разработки (например, Itilium, Kanban, Confluence, SVN). Умение выстраивать коммуникации в команде разработчиков, аналитиков, руководителей проектов Желание разбираться с данными из сложных источников и находить возможности для оптимизации Предпочтительно опыт работы с Visiology, Форсайт, Luxms BI и другими отечественными BI системами Предпочтительно опыт интеграции BI с 1С MS Visio Английский (на уровне работы с технической документацией) Условия: Официальное трудоустройство Достойный уровень заработной платы Соблюдение ТК РФ в полном объеме ДМС, корпоративная мобильная связь Офис: ст. метро ""Маяковская"" (шаговая доступность от метро)","Visiology,QL middle+,SQL,DataFlow,BI,1С,MS Visio,Kanban,Аналитика,разработчик",Независимая нефтегазовая компания,"Москва, 1-я Тверская-Ямская улица, 5"
8486,78499239,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы - команда инженеров, которая занимается развитием и поддержкой корпоративного хранилища данных в Лаборатории Касперского. В команде в течение 6-ти лет развивалось и поддерживалось DWH на стеке Microsoft (MS SQL Server, SSIS, T-SQL, C#). За это время в команде хорошо выстроили все процессы: постановка задач, ревью, автотесты (.Net + tSqlt), CI на базе Azure DevOps, мониторинг на базе Prometheus/Grafana/SCOM. Текущий стек технологий не позволяет решить весь спектр имеющихся задач, и в данный момент мы расширяем архитектуру, добавляя новый слой - DataLake на базе Hadoop и Hive, а также переходим на Spark и Airflow для загрузки данных в DataLake. В команде есть системные аналитики, кто работает с требованиями и взаимодействует с бизнес-пользователями, и архитектор, который помогает с проектированием и реализацией. Так что разработчики могут сфокусироваться на инженерных задачах. Вам предстоит: Разработка батч и стриминговых пайплайнов по загрузке данных в DataLake и DWH (Airflow, Hive, Spark) Совместно с командой и архитектором развивать подходы к обработке данных в DataLake Внедрение модели данных на основе DataVault и создание библиотеки по генерации пайплайнов на основе метаданных нтеграция с корпоративной шиной на базе Kafka и RabbitMQ Разработка автотестов на процессы загрузки данных Разработка мониторингов качества данных. Мы ожидаем от Вас: Отличное знание SQL и опыт оптимизации запросов. Плюс, опыт работы с MS SQL Server Понимание принципов работы БД и построения хранилищ данных (Кимбалл, DataVault) Опыт работы с Hadoop стеком (Hive, Spark) Опыт разработки на Python Опыт работы с Airflow и ETL-инструментами Опыт работы с Kafka/RabbitMQ. Непрерывное профессиональное развитие, к примеру: изучение новых языков программирования, онлайн курсы, контрибьюты в открытые проекты, чтение книг, блогов, подкасты и т.д. Будет плюсом: Опыт работы с MS SQL Server (партиционирование, колоночные индексы) и MS SSIS Опыт работы с Docker, Kubernetes Опыт работы с Prometheus, Grafana",,Лаборатория Касперского,
8490,77342356,Системный администратор Linux (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","В команде Big Data мы стремимся сделать единую точку аналитики в VK и сейчас рады пригласить в команду системного администратора Linux, с которым мы смогли бы это сделать еще быстрее и успешнее. Мы планируем доработать и улучшить существующие сервисы, внедрить их как экосистему в большинство проектов внутри VK. Наш стек — это Hadoop, Kafka, Spark, Clickhouse, Postgres. Часть сервисов написана на Python, деплоятся в Kubernetes с использованием GitLab CI и Puppet. Мы автоматизируем различные сценарии для удобной работы с данными. Для аналитики используются данные размером десятки петабайтов. Готовы обсуждать любой формат работы: дистанционный, гибрид, офис. Задачи: администрирование приложений стека Hadoop (HDFS, Hive, YARN, Spark, Hue) и сервисов вокруг (FreeIPA, Jupyter, KVM) администрирование распределенных БД (Vertica, Clickhouse) внедрение дистрибутива Hadoop, разработанного в VK аудит и анализ существующих инсталляций Hadoop создание документации и инструкций. щем в опыте коллеги: опыт администрирования Linux (у нас Centos) опыт работы с Configuration Management инструментами (Puppet/Ansible/Salt) опыт написания скриптов автоматизации (Bash/Python). Будет плюсом: опыт работы с git опыт работы с виртуализацией опыт работы с Vanilla Hadoop опыт настройки и эксплуатации нескольких кластеров Hadoop, объединенных в федерацию опыт интеграции LDAP/Kerberos с приложениями стека Hadoop (HDFS, Hive, YARN) опыт работы с Docker, Kubernetes опыт работы с Apache Kafka.","Ansible,Bash,Hadoop,Администрирование,Linux,Puppet,Git","VK, Технический департамент","Москва, Аэропорт, Ленинградский проспект, 39с79"
8491,78446978,Руководитель центра монетизации Big Data,з/п не указана,3–6 лет,"Полная занятость,полный день","SIMBLE – это IT-продукт для управления автостраховкой, помогающий не переплачивать, а страховать авто только тогда, когда это действительно необходимо. Совместно с нашими партнёрами мы создали сервис доступного и справедливого страхования по законам IT: с персональными тарифами и гибкими настройками полисов. Мы решаем сложные задачи на стыке аналитики данных, пользовательского опыта и новых бизнес-моделей, чтобы страхование стало доступным для всех. Приглашаем в команду Simble эксперта с подтверждёнными компетенциями по развитию и коммерциализации больших данных (Big Data). В Ваши непосредственные обязанности будет входить создание стратегий по поиску (майнингу), изучению, обработке и запуску коммерческих проектов вокруг больших данных, которые аккумулирует наша компания. В процессе взаимодействия Simble с пользователями у нас появляются и хранятся различные дата-сеты, например, данные с мобильной телематики, данные о поездках по автомобильным дорогам, данные об авто и страхователях, данные из открытых внешних источников. Одной из основных задач успешного кандидата станет создание цифровых профилей клиентов на основе хранящихся и новых данных для дальнейшего создания персонализированных страховых тарифов, специальных предложений, маркетинга и т.д. деальный кандидат должен фундаментально разбираться в техниках анализа данных, уметь выявлять ключевые бизнес-идеи и обладать креативностью в разработке стратегий монетизации больших данных. Успешный опыт монетизации данных и коммерческих проектов в этой области является значительным плюсом для кандидата. Руководитель центра монетизации Big Data будет фокусироваться на выявлении потенциальных рынков для данных Simble и на выстраивании партнёрских взаимоотношений для монетизации этих данных с компаниями -лидерами своих индустрий. Руководитель центра монетизации Big Data имеет опыт создания моделей машинного обучения, искусственного интеллекта, обработки больших данных и может самостоятельно реализовывать эти модели и эффективно взаимодействовать с выделенными командами разработки, data-scientists с целью быстрого получения финансового результата для компании. Что нужно будет делать: Проводить маркетинговые исследования для определения потенциальных отраслей и рынков для наших данных. Сотрудничать с кросс-функциональными командами для разработки стратегий монетизации на основе полученных из данных идей. Строить и поддерживать отношения с потенциальными партнёрами в различных отраслях. Вести переговоры и заключать соглашения с партнёрами о лицензионном использовании наших данных. Разрабатывать и внедрять процессы управления и предоставления данных партнёрам. Следить за тенденциями в отрасли и новыми аналитическими техниками. Разрабатывать стратегии ценообразования для соглашений о лицензионном использовании наших данных. Что нам важно: Диплом бакалавра и выше в предметной области (например, статистика, Computer Science, Data Science). Подтвержденный опыт в анализе данных и способность работать с большими данными. Сильные аналитические и проблемно-ориентированные навыки. Отличные коммуникационные навыки и умение выстраивать сотрудничество. Опыт в разработке стратегий монетизации данных. Опыт в коммерческих переговорах и заключении соглашений по лицензионному использованию данных. Знание различных отраслей и областей потенциального применения больших данных, включая, но не ограничиваясь, банковские, розничным и страховым секторами. Опыт работы с инструментами визуализации данных (например, Tableau, PowerBl) является плюсом. Мы предлагаем: Работа в аккредитованной IT-компании. Конкурентная заработная плата. Комбинированный формат работы: 4 дня в офисе, пятница-удаленно. Оформление по ТК РФ. Работа в просторном офисе в центре рядом с парком, где можно прогуляться в обеденное время. Дружную команду, нацеленную на бизнес-результат и Клиента.",,Simble,"Москва, Выставочная, Улица 1905 года, Краснопресненская набережная, 12"
8492,77321671,Владелец продукта (продукты Data Science),з/п не указана,3–6 лет,"Полная занятость,полный день","Чем вам предстоит заниматься Управление проектами/портфелем проектов Data Science по направлению оптимизации производства (улучшение технологического режима, предиктивная диагностика оборудования, повышение качества продукции). Организация ритуалов разработки. Взаимодействие с бизнес-заказчиком. Подбор и управление командой разработки в рамках ритуалов Agile. Управление сроками/ресурсами/дорожной картой проекта. Управление мотивацией команды и Заказчика. Организация внутреннего финансирования инициатив. Что мы ожидаем от вас: Высшее образование по направлению Т, программирование, математики, кибернетики. Понимание Agile методологии и роли Владельца продукта. Опыт работы в качестве Владельца продукта – от 2 лет, с подтвержденным опытом успешного создания продуктов. Технологический бэкграунд – опыт работы в роли аналитика данных, Data Scientist. Опыт работы в проектах Big Data, понимание методов машинного обучения. Развитые аналитические и коммуникативные способности. Умение принимать решения в условиях неопределенности. Приветствуется опыт создания и управления собственным бизнесом. Что мы предлагаем: Работа в аккредитованной Т-компании со всеми преимуществами. Гибридный формат работы (график обсуждается индивидуально в зависимости от роли). Заработная плата по результатам собеседования, премии за эффективную работу и результат. Действительно нестандартные задачи, которые требуют креатива и новых подходов, мы работаем в реальном секторе, наши пользователи - реальные люди. Современный стек и гибкие методологии разработки, работа в команде высококлассных профессионалов из разных технологических областей. Возможность обучения и участия в жизни IT-сообщества: большой выбор курсов в нашем корпоративном университете, посещение митапов, конференций. Корпоративные льготы: ДМС, льготное страхование родственников, большой выбор внутренних спортивных секций, скидки на абонементы сети World Class.","Data science,Agile",Сибур,
8506,76274433,Data Scientist Middle/Senior (Моделирование RnD),з/п не указана,3–6 лет,"Полная занятость,полный день","Вместе с нами ты будешь: Работать с данными для обучения моделей (текст и звук) Заниматься выгрузкой данных из корпоративного хранилища Подготавливать данные для разметки Дорабатывать и запускать скрипты тестирования Подготавливать манифесты для обучения моделей Обучать модели – запуск обучения, подбор гиперпараметров, контроль хода обучения тоговое тестирование Подготавливать скрипты применения моделей для передачи в эксплуатацию Задачи – классификация, кластеризация текстов, в том числе задачи речевой аналитики, распознавание речи, сентимент - анализ, идентификация спикера Какие знания и навыки для нас важны: высшее физико-математическое / техническое образование основы математического анализа, линейной алгебры, методов оптимизации, теории вероятностей и математической статистики основы машинного обучения и методов анализа данных основы стандартного стека: python + sklearn, pandas, numpy, scipy, matplotlib, pytorch, tensorflow. знакомство с основными архитектурами нейронных сетей знания SQL, git, bash, docker, conda опыт самостоятельного решения задач с выбором архитектуры и дообучением НС опыт участия в проектах по машинному обучению Является преимуществом: наличие github опыт написания кода в прод призовые места в хакатонах, соревнованиях по машинному обучению","Python,Моделирование,Big Data","ннотех, Группа компаний",
8523,78381736,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Контур — экосистема для бизнеса. Каждая четвертая компания в стране решает бизнес-задачи, используя наши сервисы. Мы автоматизируем документооборот, бухгалтерию и отчетность. Делаем эти процессы простыми и быстрыми, а сервисы — удобными для клиента.  Data Science в Контуре помогает оптимизировать внутренние процессы и добавляет ценности в продукты. Например, чат-бот Сирена экономит около 25% времени консультантов техподдержки в чатах, а технология распознавания речи обрабатывает тысячи лет записей в год. Мы постоянно следим за прогрессом в технологиях и разрабатываем новые методы и алгоритмы, чтобы сделать инновации доступными для использования в продуктах и процессах компании. В Центре искусственного интеллекта представлены разные роли: есть дата сайентисты, разработчики и аналитики данных, девопсы, QA-специалисты, системные аналитики, проджекты и продакт-менеджеры. Свое железо (V100/A100) и асессорская служба позволяют нам не ограничивать себя при работе с чувствительными данными, а также крутая инфраструктурная команда создает, улучшает и развивает инструменты MLOps на любой вкус от ресерча до прода. Мы ищем Senior Data Scientist в направление оптимизации процессов продаж и маркетинга. Нам нужен человек, который разовьет направление продаж и маркетинга с точки зрения машинного обучения: составит дорожную карту применения Data Science в процессах продаж согласует с бизнесом и приоритизирует сам проверит и доведет до продакшена гипотезы, и, как результат, повысит эффективность продаж и маркетинга. Примеры задач, которые уже решали Речевая аналитика (после ASR): оценка эффективности работы менеджеров по продажам на основании анализа текста звонков. Работа с конверсией: оценка вероятности оплаты клиентом счета по сделке по набору параметров. Что ожидаем от вас Опыт работы в аналогичной роли от двух лет. Опыт решения задач и понимание работы алгоритмов NLP и Classic ML. Умение общаться на языке заказчика, погружаться в продуктовый контекст. Умение работать в команде. Опыт декомпозиции, приоритизации больших задач. Опыт доведения задач до продакшена. Желательно иметь опыт доведения задачи от формулировки на языке бизнеса до прода (от начала до конца) работы с высокой неопределенностью: прокапывание проблематики, осознанный выбор решения. Технологии Python, SQL. GitLab. Docker, Kubernetes, AirFlow. Classic ML, языковые модели (BERT etc.). Мы предлагаем Зарплата зависит от ваших технических знаний и навыков. Пересматриваем ее два раза в год. Нам важно, чтобы вам было комфортно: непринципиально, где вы находитесь и во сколько начинаете рабочий день, главное – выполненные задачи. Умеем работать в команде, находясь в разных точках мира (Таллин, Ташкент, Астана, Лимассол, Екатеринбург, Москва и т. д.). Мы поддерживаем участие в конференциях, митапах и обучающих проектах. Наши деврелы помогут написать статью на Хабр, снять видео или подготовиться к выступлению на конференции. У нас сильное инженерное сообщество: регулярно проводим техническую конференцию КонфУР, обмениваемся опытом между командами, проводим дизайн-ревью с экспертами в разных технологиях. Всегда найдется, с кем посоветоваться. А еще у нас есть инженерный совет. Он придумывает и реализует проекты, которые улучшают жизнь инженеров в компании. Максимум горизонтальных связей в коллективе, чтобы быстрее договариваться и решать рабочие задачи. Присоединяйтесь :)","NLP,Machine Learning,Python,Data Science",Контур,
8527,73118539,Senior Data Engineer (Search),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы в поиске сильных DE в уютную команду, которая развивает мультиплатформенный аудиосервис на благо слушателя. Сейчас мы движемся от централизованной работы с данными в монолитных командах к платформенно-продуктовой парадигме (DataMesh) и нам предстоит большая работа по созданию этой самой платформы. Чем нужно будет заниматься? поддержка и написание etl-процессов для наполнения индексов в elasticsearch оптимизация запросов выгрузки данных/поисковых запросов в контакте с аналитиками работа с индексами (создание, настройка) активное участие в группе по настройке и сопровождению кластеров Elastic. А вот это нужно уметь: знание Python (std_lib, GIL, magic methods) опыт создания ETL\ELT-процедур знание SQL (индексы, оконные функции) практический опыт работы с Hadoop, PySpark, AirFlow. Опыт работы с Elasticsearch: понимание принципов работы умение диагностировать проблемы опыт написания запросов (полнотекстовый поиск, агрегации, скрипты сортировки). Работа должна быть в удовольствие, поэтому ты получаешь: все преимущества работы в аккредитованной IT-компании возможность делать продукт, который вдохновляет, приносит пользу и которым пользуются миллионы возможность работать удаленно или в гибридном графике, выбирать начало и окончание рабочего дня, брать дополнительные дни отпуска а если ты выбираешь работу в офисе - стильное рабочее пространство рядом с м. Кутузовская (7 минут от метро и МЦК) ДМС со стоматологией с первого рабочего дня для тебя и для твоего питомца заботу о психологическом здоровье и компенсацию затрат на платформе «Ясно» полезные завтраки и перекусы в офисе каждый день занятия в офисном спортзале, йогу и фитнес, компенсацию затрат на спорт оплату участия в конференциях и помощь в подготовке выступлений, скидки на изучение английского, доступ к корпоративным обучающим ресурсам возможность делиться новостями и экспертизой с коллегами на ежемесячных митапах и внутренних мероприятиях вечеринки с артистами в офисе и проходки на их концерты! Приходи в Звук слушать музыку, жить музыкой, творить музыку. Не работа, а удовольствие!","Python,SQL,Hadoop,AirFlow,PySpark,Elasticsearch",Звук,"Москва, Кутузовская, Кутузовская, Парк Победы, Студенческая, Поклонная улица, 3"
8535,69614008,Senior Data Engineer (DataPlatform team),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы в поиске сильных DE в уютную команду, которая развивает мультиплатформенный аудиосервис на благо слушателя. Сейчас мы движемся от централизованной работы с данными в монолитных командах к платформенно-продуктовой парадигме (DataMesh) и нам предстоит большая работа по созданию этой самой платформы. Чем нужно будет заниматься? участвовать в трансформации ETL из родного overnight batching в модный молодёжный realtime streaming разрабатывать self-service инструменты платформы данных для реализации DataMesh интегрировать хранилища, каталог данных, dbt, CDC движок, DQ, мониторинги обучать младших коллег, помогать аналитикам, продвигать лучшие практики работы с данными. А вот это нужно для работы: релевантный опыт работы от 2-х лет опыт создания ETL-процедур опыт работы с batch обработкой данных знание Python, SQL практический опыт работы с Hadoop, Spark, AirFlow, Presto знакомство с kubernetes и опыт его использования в работе. Будет плюсом: опыт работы со stream обработкой данных знание Scala, опыт работы с Kafka и Flink навыки работы с CDC опыт внедрения инструментов контроля качества данных опыт создания self-service инструментов и платформенных решений навыки успешного взаимодействия c data science командой. Работа должна быть в удовольствие, поэтому ты получаешь: все преимущества работы в аккредитованной IT-компании возможность делать продукт, который вдохновляет, приносит пользу и которым пользуются миллионы возможность работать удаленно или в гибридном графике, выбирать начало и окончание рабочего дня, брать дополнительные дни отпуска а если ты выбираешь работу в офисе - стильное рабочее пространство рядом с м. Кутузовская (7 минут от метро и МЦК) ДМС со стоматологией с первого рабочего дня для тебя и для твоего питомца заботу о психологическом здоровье и компенсацию затрат на платформе «Ясно» полезные завтраки и перекусы в офисе каждый день занятия в офисном спортзале, йогу и фитнес, компенсацию затрат на спорт оплату участия в конференциях и помощь в подготовке выступлений, скидки на изучение английского, доступ к корпоративным обучающим ресурсам возможность делиться новостями и экспертизой с коллегами на ежемесячных митапах и внутренних мероприятиях вечеринки с артистами в офисе и проходки на их концерты! Приходи в Звук слушать музыку, жить музыкой, творить музыку. Не работа, а удовольствие!","Python,Spark,SQL,Hadoop,AirFlow,Presto",Звук,"Москва, Кутузовская, Кутузовская, Парк Победы, Студенческая, Поклонная улица, 3"
8547,72211424,Senior Data engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы находимся в поиске Ведущего Data engineer'a, который будет заниматься развитием направлений: ""Цифровая аналитика"", ""Антифрод"", "" Платформа DataLake"". Ваши задачи: Реализация ETL в Hadoop (с помощью Airflow) Работа с различными источниками данных: Oracle, MS SQL, API личных кабинетов, микросервисы Батч и стримы с помощью PySpark и Kafka Подготовка витрин для анализа (Hive + Spark+ SQL) Наш стек: Ванильный hadoop Kafka Spark Airflow ClickHouse Jira ,Confluence GitLab Мы ждем от будущих коллег: Уверенное владение Python Опыт использования эко-системы Hadoop: HDFS, Apache AirFlow, Hive, Kafka,Spark Знание SQL Опыт работы с реляционными базами данных (Oracle)","Data Engineer,Python,SQL,Hadoop,ORACLE","Компания «СПОРТМАСТЕР», Sportmaster Lab",
8564,78358402,Middle/Senior Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Мы «КОРУС Консалтинг» - IT компания, предоставляем услуги по IT-консалтингу и автоматизации бизнес-процессов. мена всех наших заказчиков тебе точно известны - это крупнейшие игроки на российском рынке. А нас на сегодняшний день уже больше 1000 человек. Наш Департамент аналитических решений (ДАР) погружен во все современные направления в области работы с данными: внедрение BI-систем и систем аналитической отчетности проектирование хранилищ и витрин данных разработка в области продвинутой аналитики и больших данных применение прикладных продуктов с использованием Machine Learning внедрение решений в области управлениям данными (Data Governance, Data Quality). О проекте: для иностранной ритейл компании мы разрабатываем облачные хранилища данных и аналитические решения на облачных платформах, помогаем нашему заказчику изменять бизнес-процессы путем использования аналитики. Сейчас мигрируем все проекты на Yandex.Cloud. Наш текущий стек: Python, Spark, Hive, AirFlow как оркестратор, Yandex.Cloud. щем к себе в команду Middle/ Senior Data Engineer. Основные задачи: Формировать комплексные системы интеграции витрин данных Hadoop с использованием PySpark + AirFlow. Разрабатывать и оптимизировать ETL процессы. Погрузиться в специфику Yandex.Cloud (можем предоставить обучение). В работе поможет: Опыт разработки на Python от 2-х лет. Опыт разработки приложений с использованием инструментария экосистемы Hadoop (Spark Streaming, Hbase, Spark SQL, Kafka, Hive, Impala, Hue и т.д.) от 2-х лет. Опыт работы с любым ETL инструментом от 1 года (Airflow в приоритете). Опыт написания запросов для анализа и преобразования данных (на любой реляционной СУБД). Будет плюсом: Опыт работы с облачными платформами (Yandex.Cloud, MS Azure, AWS). Что мы можем предложить: Заработная плата: состоит из оклада и бонуса за выполнение проекта. Знаем рынок, готовы обсуждать оклад индивидуально по итогам тех. собеседования. Оформляем официально в штат компании. Гибкое начало рабочего дня - не смотрим на отработанные часы, смотрим на результат. Удаленный формат работы или гибридный график по желанию (удаленка/офис в Москве, Санкт-Петербурге или Ярославле). ндивидуальный план развития: подбираем задачи для роста экспертизы, выделяем бюджет на обучение, предоставляем курсы и программы обучения (в т.ч. английскому языку), предоставляем обратную связь, регулярно обсуждаем развитие. Полис ДМС, корпоративные тарифы на фитнес и др. Открытая корпоративная культура: каждый может предложить идею и получить возможности для ее реализации, мы помогаем друг другу, часто и весело проводим корпоративы. Минимум бюрократии и отчётов, а совещания только по необходимости и с чёткой программой. Приходи к нам в команду, будем вместе создавать крутые и полезные вещи!","Python,Hadoop,Hive,SQL,ETL,AWS,Spark,AirFlow,PostgreSQL",КОРУС Консалтинг,
8574,74291242,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура • Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных • Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем Возможность работы в аккредитованной Т-компании Работу в офисе. График работы — гибридный Платформу обучения и развития Тинькофф Апгрейд. Курсы, тренинги, вебинары и базы знаний. Поддержка менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Компенсацию такси и 50% затрат на спорт от стоимости абонемента Компенсацию обедов. А если захотите перекусить, есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,Работа с базами данных,ETL,Базы данных,DWH,СУБД,Databases",Тинькофф,"Нижний Новгород, Горьковская, Алексеевская улица, 10"
8576,69199016,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем Возможность работы в аккредитованной Т-компании Работу в офисе. График работы — гибридный Профессиональное развитие. Вы получите доступ к библиотеке с технической литературой, тренингами и мастер-классами для сотрудников Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Компенсацию такси, парковки и 50% затрат на спорт от стоимости абонемента Компенсацию обедов. А если захотите перекусить, на каждом этаже есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,ETL,Greenplum",Тинькофф,"Пермь, улица Куйбышева, 95Б"
8578,72856913,Business Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Описание: У нас в DWH очень много данных: 6000 объектов, 200 тб в Greenplum и 2 пт в Hadoop. С данными активно работают более 3000+ аналитиков в бизнес командах. На стороне команды DWH созданы инструменты, которые позволяют аналитику не зависеть от etl разработчика и самостоятельно собирать данные для своих задач. Сейчас мы ищем экспертов sql, готовых помогать аналитикам оптимально работать с данными. Наша инфраструктура Greenplum / Hadoop / Clickhouse в качестве ядра обработки данных Собственные решения на базе Apache Zeppelin, Apache Airflow и Apache Flink в качестве инструментов трансформации данных для аналитиков (selfservice etl) Мы не требуем знания этих инструментов от кандидатов. Наша задача сделать инструменты работы с данными максимально удобными и доступными. Но нам важно, чтобы кандидат на эту позицию имел большой опыт работы с данными. Обязанности: Быть экспертом по данным: помогать аналитикам в решении вопросов с источниками данных, моделью данных DWH Разрабатывать витрины в помощь аналитикам Выступать заказчиком для разработки витрин в смежных командах Оптимизировать существующие запросы Внедрять и развивать культуру написания оптимальных запросов Требования: Высшее техническое образование Опыт работы с базами данных в качестве разработчика от 1 года Свободное владение SQL Опыт проектирования объектов БД на основании бизнес требований Понимание теории СУБД и ETL-процессов Знакомство с ETL-инструментами будет плюсом Мы предлагаем Возможность работы в аккредитованной Т-компании Работу в офисе. График работы — гибридный Платформу обучения и развития Тинькофф Апгрейд. Курсы, тренинги, вебинары и базы знаний. Поддержка менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Компенсацию такси и 50% затрат на спорт от стоимости абонемента Компенсацию обедов. А если захотите перекусить, есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","SQL,Hadoop,Работа с базами данных,ETL,Базы данных,DWH",Тинькофф,"Челябинск, улица Кирова, 159"
8580,78300280,Data Scientist senior,з/п не указана,3–6 лет,"Полная занятость,полный день","Вам предстоит участвовать в развитии система фрод-мониторинга Сбербанка, которая обеспечивает защиту клиентов банка во всех каналах обслуживания от мобильных приложений и покупок в интернет до визитов клиентов в офисы. Эта система признана одной из лучших в мире: 17th Annual 2021 Cyber Security Global Excellence Awards winners. Fraud Prevention GOLD WINNER - SberBank Anti-Fraud System Fraud Prevention Editor’s Choice – SberBank Наша команда принимает активное участие в развитии этой системы и сосредоточена на разработке и внедрении AI-моделей по выявлению мошенничества. Вам предоставляется уникальная возможность поработать с действительно большими объемами данных, широким перечнем передовых технологий и сделать значимый вклад в борьбу с мошенничеством в стране. Вы будете участвовать в развитии система форд-мониторинга Сбербанка, которая обеспечивает защиту клиентов банка во всех каналах обслуживания от мобильных приложений и покупок в интернет до визитов клиентов в офисы. Обязанности Разработка и развитие моделей и алгоритмов противодействия мошенничеству: скоринг транзакций для выявления фрода/«отмывания» средств, оценка риска сущностей (клиенты, устройства и пр.), анализ и выявление связей, транзакционных аномалий и пр. Мониторинг и регулярный контроль качества работающих в пром. моделей Анализ доступных источников данных и информации в них, оценка качества для решения задач Обсуждение задач и методов их решения совместно с фрод-аналитиками и бизнес-заказчиками, формулирование гипотез и их проверка Построение воспроизводимых и переиспользуемых решений для работы с данными и моделями Взаимодействие с командами инженеров и участие в интеграции решений в промышленную эксплуатацию Требования Хорошие знания Python 3 Опыт работа с Pandas, SQL, Spark/PySpark, Hive и др. инструментами для анализа малых и больших данных Опыт использования ML библиотек и алгоритмов на Python (xgboost/lightgbm/catboost, sklearn, …), понимание особенностей и границ применимости Знание мат. статистики и теории вероятностей, линейной алгебры, математического анализа Опыт внедрения ML решений в бизнес процессы и доведение их до прома, последующий мониторинг Хорошее понимание методов машинного обучения с точки зрения математики и умение адаптировать их под конкретные задачи Опыт работы с Git Опыт работы с Linux Знание английского языка (чтение документации и статей) Будет плюсом: Знание Scala Знание одного из фреймворков DeepLearning (Keras/Tensorflow/PyTorch) Опыт автоматизации пайплайнов работы с данными (Airflow и др.), а также ML-пайплайнов (DVC и др.) Опыт работы с AutoML Условия Молодая и активная команда, состоящая преимущественно из DS и DE. Наличие мощного кластера и сред разработки, включая GPU Возможность поработать с действительно большими объемами данных и сделать значимый вклад в борьбу с мошенничеством в стране",,Сбер для экспертов,
8587,78271756,Системный аналитик на продукт МТС Аналитика (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Системного Аналитика на продукт МТС Аналитика Описание продукта: МТС Аналитика – это единая аналитическая платформа для анализа поведения пользователей в web и app приложениях экосистемы МТС. Наша цель – эффективная рекламная атрибуция, обогащенные Big Data полезные данные о когортах, кросс-продуктовый пользовательский путь и LTV пользователя и продукта, сдобренные собственным UI для визуализации метрик и командной работы. Мы ищем талантливых системных аналитиков, которые помогут нам создать и развивать платформу. Платформа создается с «нуля», никакого легаси. Обязательно: опыт работы системным аналитиком от 3-х лет знание принципов API взаимодействий (REST, GraphQL), очередей сообщений и т.п. опыт интеграции технических систем (требования / постановка задач / приёмка) опыт работы с бизнес-требованиями опыт составления и согласования системных требований и проектной документации уверенные навыки SQL знание математической статистики Что предстоит делать? участвовать в анализе работы платформы, предлагая полезные решения проектировать интеграционные решения внутри платформы и с внешними сервисами снижать time to market команды разработки – помогая с анализом и детализацией требований взаимодействовать со смежными командами внутри МТС помогая им воспользоваться результатами платформы сбор и анализ требований от внутренних и внешних заказчиков разрабатывать проектную и техническую документацию Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16” MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","SQL,Python,Spark,Big Data,ClickHouse",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
8591,78270914,Старший эконометрист в центр маркетинговой аналитики (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Старшего эконометриста в центр маркетинговой аналитики Описание продукта: В задачи нового Центра маркетинговой аналитики в Big Data входит помощь маркетинговым командам экосистемы принимать решения на основе больших данных и развитие, поддержка инструмента для оценки эффектов от инвестиций в маркетинг. Обязательно: от 2-х лет опыта в построении эконометрических моделей знание Python / R на уровне уверенного пользователя, самостоятельное написание кода (не только встроенные библиотеки) знание основ эконометрики, статистики, дискретной математики знание методов визуального представление данных аналитические способности. Способность видеть и выделять неочевидное, ставить гипотезы и находить и объяснять зависимости в данных высшее образование в области математической статистики, математических методов в экономике, data science Что предстоит делать? разрабатывать эконометрические модели для описания и прогнозирования бизнес и маркетинговых KPIs бренда, оценивать работу маркетингового микса и прогнозирования оценивать ROМI на основе созданных моделей строить и презентовать рекомендации внутреннему заказчику на основе созданных эконометрических моделей оптимизировать маркетинговый микс (в тч глубокая оптимизация online и offline медиамикса и бюджета рекламных кампаний) создавать сценарное моделирование. скать зоны роста KPI на основе моделируемой среды собирать, очищать, обрабатывать и верифицировать данные, верифицировать модели Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Python,R,эконометрика,Математическая статистика,дискретная математика,BI",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
8593,78272278,Senior Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Объединенное Кредитное Бюро – крупнейшее Бюро кредитных историй в России. Небольшой спойлер: мы не выдаем кредиты, мы храним и обрабатываем крупнейший в России массив данных о кредитных историях. Наш уникальный ресурс – самая большая база данных, в которой более 560 миллионов кредитных историй, и мы уделяем большое внимание не только количеству данных, но и качеству их обработки. Мы помогаем нашим частным клиентам контролировать свою кредитную историю и получать лучшие финансовые предложения, а компаниям – принимать взвешенные решения и оценивать риски на основе аналитики данных. Роль: Постоянное совершенствования аналитических механизмов, используемых в розничных продуктах ОКБ (создание и прокачка умных мозгов «под капотом» наших сервисов) Построение новых аналитических методов для внедрения в бизнес-процессы розничного бизнеса. Функции: Построение скоринговых моделей различной направленности, используя любые самые новые методы, без каких-либо ограничений со стороны регулирующих органов Разработка методов классификации пользователей по их интересу к определенным продуктам Разработка гипотез, грамотное формирование выборок для проверок этих гипотез, а потом составление итогового решения по данной гипотезе с использованием различных известных статистических тестов Разработка и улучшение текущих рекомендательных систем. Требования: Опыт работы не менее одного года в области аналитики и моделирования Уверенный уровень работы с реляционными СУБД и корпоративными хранилищами данных – SQL (Oracle, MSSQL, PostgreSQL) Уверенный уровень работы с Python для анализа данных и обучения предиктивных моделей Опыт разработки и внедрения регрессионных и классификационных алгоритмов обучения, знание их преимуществ, недостатков и ограничений Знание статистики и теории вероятности Опыт работы с git Опыт работы с PyCharm. Плюсами будут: Опыт разработки моделей в финансовом секторе или рекламном секторе Знание других алгоритмических языков для анализа данных Способность написать свои алгоритмы, а также оценивать их сложность Уметь писать Python-код, соответствующий PEP8 стандарту Успешное участие в соревнованиях по машинному обучению Профильное технической образование. Мы предлагаем: В ОКБ хранится ~600 млн. кредитных историй – это уникальная огромная база знаний о финансовых предпочтениях, финансовой жизни людей на протяжении последних 18 лет, так что будет на чём строить модели и статистические решения любой направленности Возможность создать любой аналитический инструмент с минимальной документацией и бюрократией Уникальный опыт по разработке нестандартных моделей с учётом пользовательского опыта и ожиданий Модели не уходят «в стол», а результат работы виден всем сразу в промышленной среде Дружный профессиональный коллектив, который заточен под решения проблем «здесь и сейчас» Достойную твоего профессионального уровня зарплату и годовой бонус Современную технику для комфортной работы Заботу о здоровье: оформим полис ДМС со стоматологией, дадим 3 дополнительных дня к отпуску, компенсируем затраты на абонемент в зал По-настоящему дружескую атмосферу: поддерживаем, когда вы приводите своих друзей, и выплачиваем реферальный бонус.","Python,SQL,PostgreSQL,Анализ данных,ORACLE,Git",ОКБ,"Москва, Павелецкая, Павелецкая, Таганская, Шлюзовая набережная, 4"
8595,78262889,Project Manager (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","IT-компания Selecty в активном поиске Project Manager (Big Data) в крупную промышленную компанию. Что предстоит делать: Управлять проектами по разработке ПО на базе данных и алгоритмов машинного обучения (фокус на предиктивной аналитике промышленных активов) Выявлять потребности бизнеса, формирование и тестирование гипотез, определение задач и ТЗ Управлять разработкой, тестированием и внедрением проектов Проводить различных исследовательских интервью с ключевыми стейкхолдерами Подготавливать презентации и других материалов Управлять командой (дата- аналитики, бизнес-аналитики, разработчики) Что нам важно: Знание стека технологий в области предсказательной аналитики и систем поддержки принятия решений Опыт в управлении внутренними продуктами / коммерческими продуктами в сфере Big Data и технологий  Умения выявлять потребности бизнеса, собрать продукт, оценить требуемые ресурсы, обосновать коммерческую целесообразность и поставить грамотное техническое задание Опыт управления командой Комфортные условия и полезные бонусы: Полная занятость, график работы 5/2 Возможность гибридного графика Полный соц. пакет, ДМС Конкурентный уровень заработной платы (оклад + квартальная премия) Кандидатам из других регионов, предоставляется релокационный пакет. Ждем тебя в команде!","Управление проектами,Agile Project Management,Big Data",Selecty,
8597,78300370,Data Scientist – Senior/Chief,з/п не указана,более 6 лет,"Полная занятость,полный день","Вам предстоит участвовать в развитии система фрод-мониторинга Сбербанка, которая обеспечивает защиту клиентов банка во всех каналах обслуживания от мобильных приложений и покупок в интернет до визитов клиентов в офисы. Эта система признана одной из лучших в мире: 17th Annual 2021 Cyber Security Global Excellence Awards winners. Fraud Prevention GOLD WINNER - SberBank Anti-Fraud System Fraud Prevention Editor’s Choice – SberBank Наша команда принимает активное участие в развитии этой системы и сосредоточена на разработке и внедрении AI-моделей по выявлению мошенничества. Вам предоставляется уникальная возможность поработать с действительно большими объемами данных, широким перечнем передовых технологий и сделать значимый вклад в борьбу с мошенничеством в стране. Обязанности Руководство по нескольким направлениям, участие в формировании стратегии развития AI-инициатив, разработка целей и road map их достижений Обсуждение задач и методов их решения совместно с фрод-аналитиками и бизнес-заказчиками, формулирование гипотез и их проверка Взаимодействие с командами инженеров и участие в интеграции решений в промышленную эксплуатацию Разработка и развитие моделей и алгоритмов противодействия мошенничеству: скоринг транзакций для выявления фрода/«отмывания» средств, оценка риска сущностей (клиенты, устройства и пр.), анализ и выявление связей, транзакционных аномалий и пр. Мониторинг и регулярный контроль качества работающих в пром. моделей Анализ доступных источников данных и информации в них, оценка качества для решения задач Построение воспроизводимых и переиспользуемых решений для работы с данными и моделями Требования Успешные внедрения ML решений в бизнес-процессы и доведение их до прома, практический опыт их последующего мониторинга и развития Опыт руководством гурппы DS/DE от 3х человек Опыт автоматизации пайплайнов работы с данными (Airflow и др.), а также ML-пайплайнов (DVC и др.) Хорошие знания Python 3 Большой практический опыт работа с Pandas, SQL, Spark/PySpark, Hive и др. инструментами для анализа малых и больших данных Большой практический опыт использования ML библиотек и алгоритмов на Python (xgboost/lightgbm/catboost, sklearn, …), понимание особенностей и границ применимости Знание одного из фреймворков DeepLearning (Keras/Tensorflow/PyTorch) Знание мат. статистики и теории вероятностей, линейной алгебры, математического анализа Хорошее понимание методов машинного обучения с точки зрения математики и умение адаптировать их под конкретные задачи Опыт работы с Git Опыт работы с Linux Знание английского языка (чтение документации, статей, просмотр видео) Будет плюсом: Опыт работа в сфере противодействия мошенничеству/AML Знание Scala Опыт работы с AutoML-инстурментами Условия Молодая и активная команда, состоящая преимущественно из DS и DE. Наличие мощного кластера и сред разработки, включая GPU Возможность поработать с действительно большими объемами данных и сделать значимый вклад в борьбу с мошенничеством в стране",,Сбер для экспертов,
8602,78265072,Преподаватель по курсу Data Science,з/п не указана,1–3 года,"Частичная занятость,полный день","Бруноям — это школа аналитики, программирования, дизайна и маркетинга. За 11 лет мы создали множество офлайн и онлайн курсов и обучили более 16 000 человек. Наши преподаватели – действующие практики с большим опытом работы в своей сфере. У нас много планов, большие амбиции и огромная любовь к тому, что мы делаем.  на данный момент мы ищем Преподавателя по курсу Data Science, для ведения учебных групп в выходные дни. Задачи, с которыми необходимо будет работать: Проведение очных занятий в нашей Школе в выходные дни Проверка домашних заданий Общение со слушателями в чате группы. Необходимые навыки: Опыт работы от 1,5 лет Знание Python, NumPy, pandas, SQL и основных моделей Machine Learning Опыт работы с разными типами данных и нейронными сетями Аналитические способности, умение обобщать, систематизировать информацию Внимательность, точность, пунктуальность, самостоятельность, ответственность. Что мы предлагаем: Обучение преподаванию (с нами ты станешь профессионалом в преподавании) Удобный график работы. Сейчас мы ищем специалиста, готового работать в дневные часы (Суббота и Воскресенье с 14:00 -19:00) Комфортный офис в самом центре Петербурга (м. Сенная/ Cпасская/ Садовая) Заработная плата – 660 руб. /час Профессиональный рост. Возможность прокачать свои навыки выступлений и передачи информации Отсутствие бюрократии (мы общаемся на ты) Заботливые коллеги (поможем тебе адаптироваться и влиться в команду) Доступ к нашим курсам.","Python,Pandas,Numpy,Machine Learning,Data Analysis,Аналитическое мышление",Бруноям,"Санкт-Петербург, Спасский переулок, 14/35"
8609,73828260,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Эта вакансия предполагает обязательную релокацию из России и Беларуси с возможностью работы в одном из наших офисов в рландии, Португалии, Кипре, Сербии, Черногории, Армении, Казахстане, либо удаленно из других стран. В игры Playrix уже играют миллионы людей ежедневно. Чтобы это число превратилось в миллиард, мы активно вкладываемся в создание мощной автоматизированной системы по работе с креативами на рекламных каналах. Наша команда занимается разработкой и поддержкой программных продуктов для извлечения, трансформации, выгрузки и анализа данных. Объем данных в нашем Data Lake больше 2.5 петабайт: маркетинговые метрики, игровые события, параметры операционной деятельности. Мы делаем всё возможное, чтобы не возникало ни малейших сомнений в полноте, актуальности и достоверности информации, которую мы предоставляем. Особое внимание уделяем скорости обработки и качеству данных. Это позволяет нам принимать верные решения относительно развития наших игр! В нашу команду ищем Senior Data Engineer, готового развивать наши продукты. Наши задачи подготовка источников данных для заказчика - маркетинг и игровая аналитика разработка конвейера поставки данных в виде DAG процессов для Airflow/Luigi внедрение моделей прогнозирования и ML в продакшен интеграция с сервисами партнеров для получения данных от них построение процессов data quality для новых и имеющихся источников. Наш стек Наш основной язык программирования — Python. Для доступа к данным используем SQL. Datalake построен на S3, Parquet и Hive. В качестве DWH используем Redshift/PostgreSQL. Работаем в облачной инфраструктуре AWS. спользуем решения мейнстримовых вендоров (Databricks, MonteCarlo, DBT). Практикуем serverless подход работы с ресурсами и горизонтальное масштабирование, используем предиктивные модели. Уделяем внимание рефакторингу и кода, и архитектуры. Для CI/CD процесса используем TeamCity. Мы ожидаем технический бэкграунд в Python от 5 лет: навык проектирования фреймворков и библиотек, умение читать и анализировать код, опыт профилирования и оптимизации производительности/масштабируемости опыт разработки data-driven приложений, выбора технического стека и субд навыки работы с популярными DE/ML фреймворками: airflow, pandas, sqlalchemy, tensorflow, mlflow навыки написания и оптимизации SQL запросов, умение работать с планами запросов, опыт работы с хранилищами разных архитектур: mpp, columnar, relation, hadoop, in-memory опыт разработки в распределённых средах. Будет плюсом понимание работы облачных сервисов или знание стека AWS знание предметной области маркетинга опыт управления командой от 2 лет (6+ человек). Мы предлагаем Заботу о здоровье Компенсируем онлайн-сессии с психологом, открываем для вас и ваших детей ДМС со стоматологией и лечением от COVID-19. Организуем вакцинацию для тех, кому это важно. Спорт и фитнес Поддерживаем здоровый образ жизни и компенсируем покупку любых спортивных абонементов, подписку на фитнес-приложение или участие в марафонах. Заботу о благополучии Сохраняем 100% зарплату во время отпуска или больничного без лишних справок. А для особых случаев предоставим дополнительные выходные. Удобное рабочее место У нас есть все для комфортной работы, где бы вы не находились. В офисах — зоны отдыха и горячее питание, для удаленных сотрудников — доставка современной техники. Развитие и обучение Оплачиваем участие в профильных конференциях и курсах, регулярно проводим внутренние буткемпы и стажировки. А для личного развития предлагаем доступ к тысячам книг в онлайн-библиотеке и скидки на курсы английского языка. Мероприятия и мерч Конкурсы, спортивные челленджи, вечеринки, хакатоны и внутренние офлайн-ивенты для команд — каждый год мы проводим сотни мероприятий по всему миру. Социальные проекты Запускаем благотворительные проекты и поддерживаем идеи сотрудников в конкурсе грантов.","SQL,Python,MS SQL,PostgreSQL,Airflow,Luigi,Базы данных",Playrix,
8610,73828477,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","В игры Playrix уже играют миллионы людей ежедневно. Чтобы это число превратилось в миллиард, мы активно вкладываемся в создание мощной автоматизированной системы по работе с креативами на рекламных каналах. Наша команда занимается разработкой и поддержкой программных продуктов для извлечения, трансформации, выгрузки и анализа данных. Объем данных в нашем Data Lake больше 2.5 петабайт: маркетинговые метрики, игровые события, параметры операционной деятельности. Мы делаем всё возможное, чтобы не возникало ни малейших сомнений в полноте, актуальности и достоверности информации, которую мы предоставляем. Особое внимание уделяем скорости обработки и качеству данных. Это позволяет нам принимать верные решения относительно развития наших игр! В нашу команду ищем Senior Data Engineer, готового развивать наши продукты. Наши задачи подготовка источников данных для заказчика - маркетинг и игровая аналитика разработка конвейера поставки данных в виде DAG процессов для Airflow/Luigi внедрение моделей прогнозирования и ML в продакшен интеграция с сервисами партнеров для получения данных от них построение процессов data quality для новых и имеющихся источников. Наш стек Наш основной язык программирования — Python. Для доступа к данным используем SQL. Datalake построен на S3, Parquet и Hive. В качестве DWH используем Redshift/PostgreSQL. Работаем в облачной инфраструктуре AWS. спользуем решения мейнстримовых вендоров (Databricks, MonteCarlo, DBT). Практикуем serverless подход работы с ресурсами и горизонтальное масштабирование, используем предиктивные модели. Уделяем внимание рефакторингу и кода, и архитектуры. Для CI/CD процесса используем TeamCity. Мы ожидаем технический бэкграунд в Python от 5 лет: навык проектирования фреймворков и библиотек, умение читать и анализировать код, опыт профилирования и оптимизации производительности/масштабируемости опыт разработки data-driven приложений, выбора технического стека и субд навыки работы с популярными DE/ML фреймворками: airflow, pandas, sqlalchemy, tensorflow, mlflow навыки написания и оптимизации SQL запросов, умение работать с планами запросов, опыт работы с хранилищами разных архитектур: mpp, columnar, relation, hadoop, in-memory опыт разработки в распределённых средах. Будет плюсом понимание работы облачных сервисов или знание стека AWS знание предметной области маркетинга опыт управления командой от 2 лет (6+ человек). Мы предлагаем Комфортные условия Работайте удаленно из любой точки мира. Мы гибко подходим к вопросам релокации и помогаем с переездом. Заботу о здоровье Компенсируем онлайн-сессии с психологом, открываем для вас и ваших детей ДМС со стоматологией и лечением от COVID-19. Организуем вакцинацию для тех, кому это важно. Спорт и фитнес Поддерживаем здоровый образ жизни и компенсируем покупку любых спортивных абонементов, подписку на фитнес-приложение или участие в марафонах. Заботу о благополучии Сохраняем 100% зарплату во время отпуска или больничного без лишних справок. А для особых случаев предоставим дополнительные выходные. Удобное рабочее место У нас есть все для комфортной работы, где бы вы не находились. В офисах — зоны отдыха и горячее питание, для удаленных сотрудников — доставка современной техники. Развитие и обучение Оплачиваем участие в профильных конференциях и курсах, регулярно проводим внутренние буткемпы и стажировки. А для личного развития предлагаем доступ к тысячам книг в онлайн-библиотеке и скидки на курсы английского языка. Мероприятия и мерч Конкурсы, спортивные челленджи, вечеринки, хакатоны и внутренние офлайн-ивенты для команд — каждый год мы проводим сотни мероприятий по всему миру. Социальные проекты Запускаем благотворительные проекты и поддерживаем идеи сотрудников в конкурсе грантов.","SQL,Python,MS SQL",Playrix,
8614,73828476,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","В игры Playrix уже играют миллионы людей ежедневно. Чтобы это число превратилось в миллиард, мы активно вкладываемся в создание мощной автоматизированной системы по работе с креативами на рекламных каналах. Наша команда занимается разработкой и поддержкой программных продуктов для извлечения, трансформации, выгрузки и анализа данных. Объем данных в нашем Data Lake больше 2.5 петабайт: маркетинговые метрики, игровые события, параметры операционной деятельности. Мы делаем всё возможное, чтобы не возникало ни малейших сомнений в полноте, актуальности и достоверности информации, которую мы предоставляем. Особое внимание уделяем скорости обработки и качеству данных. Это позволяет нам принимать верные решения относительно развития наших игр! В нашу команду ищем Senior Data Engineer, готового развивать наши продукты. Наши задачи подготовка источников данных для заказчика - маркетинг и игровая аналитика разработка конвейера поставки данных в виде DAG процессов для Airflow/Luigi внедрение моделей прогнозирования и ML в продакшен интеграция с сервисами партнеров для получения данных от них построение процессов data quality для новых и имеющихся источников. Наш стек Наш основной язык программирования — Python. Для доступа к данным используем SQL. Datalake построен на S3, Parquet и Hive. В качестве DWH используем Redshift/PostgreSQL. Работаем в облачной инфраструктуре AWS. спользуем решения мейнстримовых вендоров (Databricks, MonteCarlo, DBT). Практикуем serverless подход работы с ресурсами и горизонтальное масштабирование, используем предиктивные модели. Уделяем внимание рефакторингу и кода, и архитектуры. Для CI/CD процесса используем TeamCity. Мы ожидаем технический бэкграунд в Python от 5 лет: навык проектирования фреймворков и библиотек, умение читать и анализировать код, опыт профилирования и оптимизации производительности/масштабируемости опыт разработки data-driven приложений, выбора технического стека и субд навыки работы с популярными DE/ML фреймворками: airflow, pandas, sqlalchemy, tensorflow, mlflow навыки написания и оптимизации SQL запросов, умение работать с планами запросов, опыт работы с хранилищами разных архитектур: mpp, columnar, relation, hadoop, in-memory опыт разработки в распределённых средах. Будет плюсом понимание работы облачных сервисов или знание стека AWS знание предметной области маркетинга опыт управления командой от 2 лет (6+ человек). Мы предлагаем Комфортные условия Работайте удаленно из любой точки мира. Мы гибко подходим к вопросам релокации и помогаем с переездом. Заботу о здоровье Компенсируем онлайн-сессии с психологом, открываем для вас и ваших детей ДМС со стоматологией и лечением от COVID-19. Организуем вакцинацию для тех, кому это важно. Спорт и фитнес Поддерживаем здоровый образ жизни и компенсируем покупку любых спортивных абонементов, подписку на фитнес-приложение или участие в марафонах. Заботу о благополучии Сохраняем 100% зарплату во время отпуска или больничного без лишних справок. А для особых случаев предоставим дополнительные выходные. Удобное рабочее место У нас есть все для комфортной работы, где бы вы не находились. В офисах — зоны отдыха и горячее питание, для удаленных сотрудников — доставка современной техники. Развитие и обучение Оплачиваем участие в профильных конференциях и курсах, регулярно проводим внутренние буткемпы и стажировки. А для личного развития предлагаем доступ к тысячам книг в онлайн-библиотеке и скидки на курсы английского языка. Мероприятия и мерч Конкурсы, спортивные челленджи, вечеринки, хакатоны и внутренние офлайн-ивенты для команд — каждый год мы проводим сотни мероприятий по всему миру. Социальные проекты Запускаем благотворительные проекты и поддерживаем идеи сотрудников в конкурсе грантов.","SQL,Python,MS SQL",Playrix,
8616,77273541,Специалист MDM (Master Data Management),з/п не указана,3–6 лет,"Полная занятость,полный день","ЗАО ""АДВН Смарт Фэктори"" - один из мировых лидеров в создании и внедрении прорывных, революционных инноваций в сегменте рынка наукоемкого рентгеновского оборудования медицинского назначения, неразрушающего контроля и обеспечения безопасности Приглашаем на постоянную работу специалиста MDM (Master Data Management) КРУГ ЗАДАЧ: проведение анализа требований структурных подразделений к мастер-данным и формирование консолидированных требований к составу мастер-данных и их ведению разработка функциональных требований и алгоритмов формирования мастер-данных сбор и формализация знаний об источниках данных для мастер-данных взаимодействие с внешними организациями – поставщиками данных ведение централизованных реестров мастер-данных Уучастие в разборе инцидентов в отношении мастер-данных ведение каталога данных в отношении мастер-данных оказание методологической поддержки структурным подразделениям по работе с мастер-данными ТРЕБОВАНЯ: высшее-техническое образование (IT, экономическое, математическое) опыт работы в сфере управления данными – не менее 3 лет знание принципов профилирования, стандартизации, очистки, обогащения и дедупликации данных (MDM) знание методологической основы процессов выверки, нормализации и контроля качества данных, методик классификации и кодирования опыт анализа данных инструментами класса BI, навыки работы с БД, знание SQL приветствуется опыт работы с системами класса MDM, прикладными системами ведения мастер-данных приветствуется опыт формирования функциональных и технических требований, опыт управления инцидентами в сфере IТ, опыт тестирования программных продуктов МЫ ПРЕДЛАГАЕМ: работу в крупной инновационной компании международного уровня возможность применить свои знания и навыки, приобрести новый опыт дружный коллектив единомышленников профессиональный рост полный соцпакет конкурентную заработную плату график работы: 8:40-17:00 (сб, вс - выходные дни) доставка служебным транспортом к месту работы от ст. м. Могилёвская, либо на автобусе №9, №61 месторасположение офиса: Новодворский сельсовет, 116 (СЭЗ Шабаны) ЖДЕМ ВАШХ ОТКЛКОВ  ЗВОНКОВ!","BPMN,Бизнес-аналитик,ПО,Анализ данных,Автоматизация бизнес-процессов,Разработка ТЗ,MDM,Master Data Management,SQL,BI",Адвин Смарт Фэктори,"Минский район, Могилевская"
8617,75782775,Lead Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Эта вакансия предполагает обязательную релокацию из России и Беларуси с возможностью работы в одном из наших офисов в рландии, Португалии, Кипре, Сербии, Черногории, Армении, Казахстане, либо удаленно из других стран. В игры Playrix уже играют миллионы людей ежедневно. Чтобы это число превратилось в миллиард, мы активно вкладываемся в создание мощной автоматизированной системы по работе с креативами на рекламных каналах. Наша команда занимается разработкой и поддержкой программных продуктов для извлечения, трансформации, выгрузки и анализа данных. Объем данных в нашем Data Lake больше 2.5 петабайт: маркетинговые метрики, игровые события, параметры операционной деятельности. Мы делаем всё возможное, чтобы не возникало ни малейших сомнений в полноте, актуальности и достоверности информации, которую мы предоставляем. Особое внимание уделяем скорости обработки и качеству данных. Это позволяет нам принимать верные решения относительно развития наших игр! В нашу команду ищем Lead Data Engineer, готового развивать наши продукты. Наши задачи подготовка источников данных для заказчика - маркетинг и игровая аналитика разработка конвейера поставки данных в виде DAG процессов для Airflow/Luigi внедрение моделей прогнозирования и ML в продакшен интеграция с сервисами партнеров для получения данных от них построение процессов data quality для новых и имеющихся источников. Наш стек Наш основной язык программирования — Python. Для доступа к данным используем SQL. Datalake построен на S3, Parquet и Hive. В качестве DWH используем Redshift/PostgreSQL. Работаем в облачной инфраструктуре AWS. спользуем решения мейнстримовых вендоров (Databricks, MonteCarlo, DBT). Практикуем serverless подход работы с ресурсами и горизонтальное масштабирование, используем предиктивные модели. Уделяем внимание рефакторингу и кода, и архитектуры. Для CI/CD процесса используем TeamCity. Мы ожидаем технический бэкграунд в Python от 5 лет: навык проектирования фреймворков и библиотек, умение читать и анализировать код, опыт профилирования и оптимизации производительности/масштабируемости опыт разработки data-driven приложений, выбора технического стека и субд навыки работы с популярными DE/ML фреймворками: airflow, pandas, sqlalchemy, tensorflow, mlflow навыки написания и оптимизации SQL запросов, умение работать с планами запросов, опыт работы с хранилищами разных архитектур: mpp, columnar, relation, hadoop, in-memory опыт разработки в распределённых средах. Будет плюсом понимание работы облачных сервисов или знание стека AWS знание предметной области маркетинга опыт управления командой от 2 лет (6+ человек). Мы предлагаем Заботу о здоровье Компенсируем онлайн-сессии с психологом, открываем для вас и ваших детей ДМС со стоматологией и лечением от COVID-19. Организуем вакцинацию для тех, кому это важно. Спорт и фитнес Поддерживаем здоровый образ жизни и компенсируем покупку любых спортивных абонементов, подписку на фитнес-приложение или участие в марафонах. Заботу о благополучии Сохраняем 100% зарплату во время отпуска или больничного без лишних справок. А для особых случаев предоставим дополнительные выходные. Удобное рабочее место У нас есть все для комфортной работы, где бы вы не находились. В офисах — зоны отдыха и горячее питание, для удаленных сотрудников — доставка современной техники. Развитие и обучение Оплачиваем участие в профильных конференциях и курсах, регулярно проводим внутренние буткемпы и стажировки. А для личного развития предлагаем доступ к тысячам книг в онлайн-библиотеке и скидки на курсы английского языка. Мероприятия и мерч Конкурсы, спортивные челленджи, вечеринки, хакатоны и внутренние офлайн-ивенты для команд — каждый год мы проводим сотни мероприятий по всему миру. Социальные проекты Запускаем благотворительные проекты и поддерживаем идеи сотрудников в конкурсе грантов.","SQL,Python,MS SQL,PostgreSQL,Airflow,Luigi,Базы данных",Playrix,
8620,75783349,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","В игры Playrix уже играют миллионы людей ежедневно. Чтобы это число превратилось в миллиард, мы активно вкладываемся в создание мощной автоматизированной системы по работе с креативами на рекламных каналах. Наша команда занимается разработкой и поддержкой программных продуктов для извлечения, трансформации, выгрузки и анализа данных. Объем данных в нашем Data Lake больше 2.5 петабайт: маркетинговые метрики, игровые события, параметры операционной деятельности. Мы делаем всё возможное, чтобы не возникало ни малейших сомнений в полноте, актуальности и достоверности информации, которую мы предоставляем. Особое внимание уделяем скорости обработки и качеству данных. Это позволяет нам принимать верные решения относительно развития наших игр! В нашу команду ищем Senior Data Engineer, готового развивать наши продукты. Наши задачи подготовка источников данных для заказчика - маркетинг и игровая аналитика разработка конвейера поставки данных в виде DAG процессов для Airflow/Luigi внедрение моделей прогнозирования и ML в продакшен интеграция с сервисами партнеров для получения данных от них построение процессов data quality для новых и имеющихся источников. Наш стек Наш основной язык программирования — Python. Для доступа к данным используем SQL. Datalake построен на S3, Parquet и Hive. В качестве DWH используем Redshift/PostgreSQL. Работаем в облачной инфраструктуре AWS. спользуем решения мейнстримовых вендоров (Databricks, MonteCarlo, DBT). Практикуем serverless подход работы с ресурсами и горизонтальное масштабирование, используем предиктивные модели. Уделяем внимание рефакторингу и кода, и архитектуры. Для CI/CD процесса используем TeamCity. Мы ожидаем технический бэкграунд в Python от 5 лет: навык проектирования фреймворков и библиотек, умение читать и анализировать код, опыт профилирования и оптимизации производительности/масштабируемости опыт разработки data-driven приложений, выбора технического стека и субд навыки работы с популярными DE/ML фреймворками: airflow, pandas, sqlalchemy, tensorflow, mlflow навыки написания и оптимизации SQL запросов, умение работать с планами запросов, опыт работы с хранилищами разных архитектур: mpp, columnar, relation, hadoop, in-memory опыт разработки в распределённых средах. Будет плюсом понимание работы облачных сервисов или знание стека AWS знание предметной области маркетинга опыт управления командой от 2 лет (6+ человек). Мы предлагаем Комфортные условия Работайте удаленно из любой точки мира. Мы гибко подходим к вопросам релокации и помогаем с переездом. Заботу о здоровье Компенсируем онлайн-сессии с психологом, открываем для вас и ваших детей ДМС со стоматологией и лечением от COVID-19. Организуем вакцинацию для тех, кому это важно. Спорт и фитнес Поддерживаем здоровый образ жизни и компенсируем покупку любых спортивных абонементов, подписку на фитнес-приложение или участие в марафонах. Заботу о благополучии Сохраняем 100% зарплату во время отпуска или больничного без лишних справок. А для особых случаев предоставим дополнительные выходные. Удобное рабочее место У нас есть все для комфортной работы, где бы вы не находились. В офисах — зоны отдыха и горячее питание, для удаленных сотрудников — доставка современной техники. Развитие и обучение Оплачиваем участие в профильных конференциях и курсах, регулярно проводим внутренние буткемпы и стажировки. А для личного развития предлагаем доступ к тысячам книг в онлайн-библиотеке и скидки на курсы английского языка. Мероприятия и мерч Конкурсы, спортивные челленджи, вечеринки, хакатоны и внутренние офлайн-ивенты для команд — каждый год мы проводим сотни мероприятий по всему миру. Социальные проекты Запускаем благотворительные проекты и поддерживаем идеи сотрудников в конкурсе грантов.","SQL,Python,MS SQL",Playrix,
8621,76168231,Data/ML engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы запускаем амбициозный проект CVM в компании с ""0"" и ищем профессионалов в продвинутую команду! CVM - это системная работа с клиентской базой, на основании персонализированных предложений (учитывающих потребности клиентов), которые создаются с использованием продвинутой аналитики и нацелены на повышение долгосрочной ценности клиента (LTV) через повышение частоты покупок, размера средней корзины или предотвращение оттока. Нашему будущему коллеге предстоит работать над развитием Корпоративного Хранилища Данных (Hadoop), которое является основным источником данных для этого проекта. Мы ищем эксперта с высокой ролью ответственности на проекте, умеющего самостоятельно и в команде принимать решение по архитектуре и реализации. Что нужно делать? Проектирование, разработка и поддержка витрины данных для целей маркетинговых промо-кампаний Операционализация моделей машинного обучения от команды DS Техническая поддержка запуска кампаний (включая автоматизацию формирования контента) Разработка алгоритмов выгрузки, обработки, хранения данных (ETL) из разных систем, интеграция с внешними системами Автоматизация процессов обновления данных и запуска промо-кампаний Разработка правил и процедур контроля качества данных Наш стек: последние версии Apache Spark и Apache Airflow Zeppelin Hadoop 3 Kafka Docker, Kubernetes GitLab для CI/CD Наши ожидания: Знания SQL Понимание жизненного цикла разработки ПО, культуры CI/CD Опыт создания и оптимизации Spark batch jobs Опыт разработки на Java (kotlin) Spring Service опыт работы с Airflow, умение создавать DAG'и, состоящие из Task и Sensor Отличное понимание устройства и принципов проектирования БД Опыт участия в проектах построения DWH и Data Lake в роли ETL-разработчика – от 2 лет Умение писать чистый поддерживаемый код и техническую документацию Опыт работы с Docker Будет плюсом: Понимание технологий DevOps, опыт работы с CI/CD-инструментами. Опыт работы с Hadoop Опыт работы с Kubernetes Опыт работы с современными брокерами и очередями сообщений Опыт работы с Nifi Математическое\инженерное образование (Ведущие вузы) Условия: Официальное оформление в соответствии с ТК РФ, полная стабильность Отсутствие бюрократии и плоская организационная структура Возможность вносить коррективы в процессы, в архитектуру и лояльный бизнес, постоянные коммуникации, возможность на равных обсуждать бизнес-фичи на стадии формирования Действительно высокий уровень дохода, оклад + годовая премия, полностью ""белый"". Гибкое начало работы, но 5/2, полный день. Возможен частично-удаленный формат работы. Офис- м/мцд Окружная или корп.транспорт 7 минут от м.Петровско-Разумовская. . Хорошее техническое оснащение, никаких проблем с доступами на удаленной работе Расширенный полис ДМС До 20% скидка на продукцию компании Мы являемся официальной IT компанией в РФ (льготная ипотека, отсрочка от армии). ндексация дохода","Python,SQL,Big Data,Linux,Hadoop",Детский Мир,
8623,75959346,Lead Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","В игры Playrix уже играют миллионы людей ежедневно. Чтобы это число превратилось в миллиард, мы активно вкладываемся в создание мощной автоматизированной системы по работе с креативами на рекламных каналах. Наша команда занимается разработкой и поддержкой программных продуктов для извлечения, трансформации, выгрузки и анализа данных. Объем данных в нашем Data Lake больше 2.5 петабайт: маркетинговые метрики, игровые события, параметры операционной деятельности. Мы делаем всё возможное, чтобы не возникало ни малейших сомнений в полноте, актуальности и достоверности информации, которую мы предоставляем. Особое внимание уделяем скорости обработки и качеству данных. Это позволяет нам принимать верные решения относительно развития наших игр! В нашу команду ищем Lead Data Engineer, готового развивать наши продукты. Наши задачи подготовка источников данных для заказчика - маркетинг и игровая аналитика разработка конвейера поставки данных в виде DAG процессов для Airflow/Luigi внедрение моделей прогнозирования и ML в продакшн интеграция с сервисами партнеров для получения данных от них построение процессов data quality для новых и имеющихся источников. Наш стек Наш основной язык программирования — Python. Для доступа к данным используем SQL. Datalake построен на S3, Parquet и Hive. В качестве DWH используем Redshift/PostgreSQL. Работаем в облачной инфраструктуре AWS. спользуем решения мейнстримовых вендоров (Databricks, MonteCarlo, DBT). Практикуем serverless подход работы с ресурсами и горизонтальное масштабирование, используем предиктивные модели. Уделяем внимание рефакторингу и кода, и архитектуры. Для CI/CD процесса используем TeamCity. Мы ожидаем технический бэкграунд в Python от 5 лет: навык проектирования фреймворков и библиотек, умение читать и анализировать код, опыт профилирования и оптимизации производительности/масштабируемости опыт разработки data-driven приложений, выбора технического стека и субд навыки работы с популярными DE/ML фреймворками: airflow, pandas, sqlalchemy, tensorflow, mlflow навыки написания и оптимизации SQL запросов, умение работать с планами запросов, опыт работы с хранилищами разных архитектур: mpp, columnar, relation, hadoop, in-memory опыт разработки в распределённых средах. Будет плюсом понимание работы облачных сервисов или знание стека AWS знание предметной области маркетинга опыт управления командой от 2 лет (6+ человек). Мы предлагаем Заботу о здоровье Компенсируем онлайн-сессии с психологом, открываем для вас и ваших детей ДМС со стоматологией и лечением от COVID-19. Организуем вакцинацию для тех, кому это важно. Спорт и фитнес Поддерживаем здоровый образ жизни и компенсируем покупку любых спортивных абонементов, подписку на фитнес-приложение или участие в марафонах. Заботу о благополучии Сохраняем 100% зарплату во время отпуска или больничного без лишних справок. А для особых случаев предоставим дополнительные выходные. Удобное рабочее место Для удаленных сотрудников — доставка современной техники. Развитие и обучение Оплачиваем участие в профильных конференциях и курсах, регулярно проводим внутренние буткемпы и стажировки. А для личного развития предлагаем доступ к тысячам книг в онлайн-библиотеке и скидки на курсы английского языка. Мероприятия и мерч Конкурсы, спортивные челленджи, вечеринки, хакатоны и внутренние офлайн-ивенты для команд — каждый год мы проводим сотни мероприятий по всему миру. Социальные проекты Запускаем благотворительные проекты и поддерживаем идеи сотрудников в конкурсе грантов.","SQL,Python,MS SQL,PostgreSQL,Airflow,Luigi,Базы данных",Playrix,
8628,75782776,Lead Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Эта вакансия предполагает обязательную релокацию из России и Беларуси с возможностью работы в одном из наших офисов в рландии, Португалии, Кипре, Сербии, Черногории, Армении, Казахстане, либо удаленно из других стран. В игры Playrix уже играют миллионы людей ежедневно. Чтобы это число превратилось в миллиард, мы активно вкладываемся в создание мощной автоматизированной системы по работе с креативами на рекламных каналах. Наша команда занимается разработкой и поддержкой программных продуктов для извлечения, трансформации, выгрузки и анализа данных. Объем данных в нашем Data Lake больше 2.5 петабайт: маркетинговые метрики, игровые события, параметры операционной деятельности. Мы делаем всё возможное, чтобы не возникало ни малейших сомнений в полноте, актуальности и достоверности информации, которую мы предоставляем. Особое внимание уделяем скорости обработки и качеству данных. Это позволяет нам принимать верные решения относительно развития наших игр! В нашу команду ищем Lead Data Engineer, готового развивать наши продукты. Наши задачи подготовка источников данных для заказчика - маркетинг и игровая аналитика разработка конвейера поставки данных в виде DAG процессов для Airflow/Luigi внедрение моделей прогнозирования и ML в продакшен интеграция с сервисами партнеров для получения данных от них построение процессов data quality для новых и имеющихся источников. Наш стек Наш основной язык программирования — Python. Для доступа к данным используем SQL. Datalake построен на S3, Parquet и Hive. В качестве DWH используем Redshift/PostgreSQL. Работаем в облачной инфраструктуре AWS. спользуем решения мейнстримовых вендоров (Databricks, MonteCarlo, DBT). Практикуем serverless подход работы с ресурсами и горизонтальное масштабирование, используем предиктивные модели. Уделяем внимание рефакторингу и кода, и архитектуры. Для CI/CD процесса используем TeamCity. Мы ожидаем технический бэкграунд в Python от 5 лет: навык проектирования фреймворков и библиотек, умение читать и анализировать код, опыт профилирования и оптимизации производительности/масштабируемости опыт разработки data-driven приложений, выбора технического стека и субд навыки работы с популярными DE/ML фреймворками: airflow, pandas, sqlalchemy, tensorflow, mlflow навыки написания и оптимизации SQL запросов, умение работать с планами запросов, опыт работы с хранилищами разных архитектур: mpp, columnar, relation, hadoop, in-memory опыт разработки в распределённых средах. Будет плюсом понимание работы облачных сервисов или знание стека AWS знание предметной области маркетинга опыт управления командой от 2 лет (6+ человек). Мы предлагаем Заботу о здоровье Компенсируем онлайн-сессии с психологом, открываем для вас и ваших детей ДМС со стоматологией и лечением от COVID-19. Организуем вакцинацию для тех, кому это важно. Спорт и фитнес Поддерживаем здоровый образ жизни и компенсируем покупку любых спортивных абонементов, подписку на фитнес-приложение или участие в марафонах. Заботу о благополучии Сохраняем 100% зарплату во время отпуска или больничного без лишних справок. А для особых случаев предоставим дополнительные выходные. Удобное рабочее место У нас есть все для комфортной работы, где бы вы не находились. В офисах — зоны отдыха и горячее питание, для удаленных сотрудников — доставка современной техники. Развитие и обучение Оплачиваем участие в профильных конференциях и курсах, регулярно проводим внутренние буткемпы и стажировки. А для личного развития предлагаем доступ к тысячам книг в онлайн-библиотеке и скидки на курсы английского языка. Мероприятия и мерч Конкурсы, спортивные челленджи, вечеринки, хакатоны и внутренние офлайн-ивенты для команд — каждый год мы проводим сотни мероприятий по всему миру. Социальные проекты Запускаем благотворительные проекты и поддерживаем идеи сотрудников в конкурсе грантов.","SQL,Python,MS SQL,PostgreSQL,Airflow,Luigi,Базы данных",Playrix,
8631,78265355,Data Engineer (HR платформа),з/п не указана,3–6 лет,"Полная занятость,полный день","Команда HR Аналитики ищет дата инженера для развития аналитических продуктов внутри флагманской HR Платформы СБЕРа – Пульс. Мы работаем с HR данными СБЕРа и внешнего рынка: ETL (получаем данные от поставщиков, организуем контракты, контролируем и проверяем качество) методология (в тесной коммуникации с продуктовыми командами Аналитики работаем над созданием методологии и формированием алгоритмов расчета показателей) разработка потоков и витрин данных предоставление рассчитанных данных конечным потребителям. Основные технологии и используемые решения: SQL Yandex СlickHouse PostgreSQL Kafka Обязанности повышение качества данных оптимизация и рефакторинг существующих ETL процессов и SQL запросов обеспечение SLA по времени наших решений улучшение time to market производства витрин участие в продуктовых задачах команды. Требования опыт работы в направлениях DWH/ETL опыт работы с MPP базами: Greenplum / Vertica / Clickhouse знание SQL и навыки оптимизации запросов комплексное понимание работы аналитических систем. Условия работа в лучшем офисе страны по версии Best Office Awards 2022 и в шаговой доступности от ст. Кутузовская (метро и МЦК) стабильный оклад и социальная поддержка сотрудников расширенный ДМС с первого дня и льготное страхование для близких корпоративное обучение за счет компании бесплатную подписку СберПрайм+ и скидки на продукты компаний-партнеров мощное железо, дополнительные мониторы и всё, что нужно для продуктивной работы многофункциональный спортивный зал (бесплатно).",,Сбер. IT,
8639,77236315,Senior Data/ML engineer,з/п не указана,не требуется,"Полная занятость,полный день","Мы запускаем амбициозный проект CVM в компании с ""0"" и ищем профессионалов в продвинутую команду! CVM - это системная работа с клиентской базой, на основании персонализированных предложений (учитывающих потребности клиентов), которые создаются с использованием продвинутой аналитики и нацелены на повышение долгосрочной ценности клиента (LTV) через повышение частоты покупок, размера средней корзины или предотвращение оттока. Нашему будущему коллеге предстоит работать над развитием Корпоративного Хранилища Данных (Hadoop), которое является основным источником данных для этого проекта. Мы ищем эксперта с высокой ролью ответственности на проекте, умеющего самостоятельно и в команде принимать решение по архитектуре и реализации. Что нужно делать? Проектирование, разработка и поддержка витрины данных для целей маркетинговых промо-кампаний Операционализация моделей машинного обучения от команды DS Техническая поддержка запуска кампаний (включая автоматизацию формирования контента) Разработка алгоритмов выгрузки, обработки, хранения данных (ETL) из разных систем, интеграция с внешними системами Автоматизация процессов обновления данных и запуска промо-кампаний Разработка правил и процедур контроля качества данных Наш стек: последние версии Apache Spark и Apache Airflow Zeppelin Hadoop 3 Kafka Docker, Kubernetes GitLab для CI/CD Наши ожидания: Знания SQL Понимание жизненного цикла разработки ПО, культуры CI/CD Опыт создания и оптимизации Spark batch jobs Опыт разработки на Java (kotlin) Spring Service опыт работы с Airflow, умение создавать DAG'и, состоящие из Task и Sensor Отличное понимание устройства и принципов проектирования БД Опыт участия в проектах построения DWH и Data Lake в роли ETL-разработчика – от 5 лет Умение писать чистый поддерживаемый код и техническую документацию Опыт работы с Docker Будет плюсом: Понимание технологий DevOps, опыт работы с CI/CD-инструментами. Опыт работы с Hadoop Опыт работы с Kubernetes Опыт работы с современными брокерами и очередями сообщений Опыт работы с Nifi Математическое\инженерное образование (Ведущие вузы) Условия: Официальное оформление в соответствии с ТК РФ, полная стабильность Отсутствие бюрократии и плоская организационная структура Возможность вносить коррективы в процессы, в архитектуру и лояльный бизнес, постоянные коммуникации, возможность на равных обсуждать бизнес-фичи на стадии формирования Действительно высокий уровень дохода, оклад + годовая премия, полностью ""белый"". Гибкое начало работы, но 5/2, полный день. Возможен частично-удаленный / удаленный формат работы. Офис- м/мцд Окружная или корп.транспорт 7 минут от м.Петровско-Разумовская. . Хорошее техническое оснащение, никаких проблем с доступами на удаленной работе Расширенный полис ДМС До 20% скидка на продукцию компании Мы являемся официальной IT компанией в РФ (льготная ипотека, отсрочка от армии). ндексация дохода",,Детский Мир,"Москва, Окружная, Окружная, Петровско-Разумовская, 3-й Нижнелихоборский проезд, 3с6"
8681,78233444,Менеджер по развитию партнёрского канала Data Platform (сквозная аналитика) в Yandex Cloud,з/п не указана,3–6 лет,"Полная занятость,полный день","Облачный бизнес — одно из приоритетных направлений развития Яндекса на ближайшие годы. Yandex Cloud — это облачная платформа, которую используют тысячи компаний и предпринимателей, от небольших частных технических специалистов до крупных международных корпораций. Продуктовая группа Data Platform — самое быстро растущее продуктовое направление Yandex Cloud. Мы ежегодно демонстрируем кратный рост по выручке, количеству новых клиентов, среднему чеку заказчиков, числу развёрнутых кластеров идоли партнёрского бизнеса. Прямо сейчас мы ищем гибкого и проактивного менеджера по работе с партнёрами, который усилит команду Data Platform, и сможет выступить экспертом при запуске и развитии партнёров с фокусом на сквозную и продуктовую аналитику. Эта роль совмещает в себе продуктовое видение в партнёрском канале и классический партнёрский менеджмент, поэтому вам пригодится не только опыт продаж проектных решений в корпоративном сегменте и работа с партнёрами, но и хорошая технологическая база и понимание рынка аналитических решений, особенно в части сквозной и продуктовой аналитики. Что нужно делать: формировать стратегии продуктового и технологического развития партнёрского канала в направлении Data Platform. К нему относятся Managed Service for ClickHouse, Greenplum, Spark, Yandex DataLens и другие сервисы развивать технологический опыт и знания партнёров в различных сегментах, искать новые аудитории совместно с командой рекрутинга партнёров формировать собственный партнёрский портфель для дальнейшего развития с фокусом на партнёров с сервисной моделью бизнеса развивать и сопровождать бизнес Yandex Cloud в портфеле выделенного списка фокусных партнёров: проводить встречи с руководством, обучать и мотивировать менеджеров по продажам, организовывать трёхсторонние встречи с заказчиками, разрабатывать стратегию развития технологических компетенций, консультировать и заниматься операционной поддержкой, взаимодействовать с партнёром (готовить pipeline review, QBR, sync-ups с аккаунт-менеджерами Yandex Cloud), заниматься совместным маркетинговым планированием, координировать и помогать партнёрам с привлечением внутренних ресурсов различных подразделений Yandex Cloud заниматься бизнес-планированием и контролем основных метрик, выполнять планы по продажам через партнёрскую сеть работать с командами продукта, продаж и маркетинга для повышения эффективности и обеспечения кратного роста бизнеса: организовывать партнёрские конференции, офлайн-мероприятия для повышения узнаваемости бренда и лояльности компаний, создавать целевые оферы с партнёрами искать новые бизнес-возможности с привлечением внутренних ресурсов подразделений Яндекса. Мы ждем, что вы: занимались прямыми или партнёрскими продажами проектных решений компаниям корпоративного сегмента разбираетесь в российском и зарубежных рынках технологий сквозной и продуктовой аналитики, знаете ключевых поставщиков, особенности продуктов и конкурентные отличия понимаете бизнес-модели партнёров, которые занимаются проектами и консалтингом в области сквозной аналитики готовы постоянно развиваться и изучать новые технологии умеете вести переговоры на уровне CEO/CTO/CPO/CBDO знаете английский язык не ниже уровня Intermediate. Условия: сильная команда, с которой можно расти сложные задачи для сервисов с миллионами пользователей возможность влиять на процесс и результат зарплата на уровне рынка и выше компенсация оплаты питания расширенная программа ДМС, оплата 80% стоимости ДМС для супругов и детей спортзал, тренажёрный зал, йога в офисе гибкий график парковка.",,Яндекс,"Москва, Парк культуры, Парк культуры, улица Льва Толстого, 16"
9243,79173353,Machine learning/data science engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Innowise Group на рынке с 2007 года. За это время наша команда реализовала 600+ проектов для 200+ заказчиков из 30+ стран мира — и эти показатели постоянно растут.  Каждый год мы растем в 2 раза. Для тебя это возможность интенсивно развиваться, пробовать себя в разных направлениях и технологиях, стать ментором и реализовывать свои самые смелые карьерные ожидания.  Основа нашего успеха — крутая команда. У нас сформировалось профессиональное комьюнити, которое поможет тебе расти, общаться с экспертами и поддерживать компетенции на высоком уровне.  Уверены, что ты сможешь усилить нашу команду! Наши ожидания: Опыт работы с Python Понимание жизненного цикла проекта ML (от преобразования бизнес-потребностей в проблемы ML до предоставления полезных моделей в производство), знакомство с лучшими практиками разработки Data Science Опыт работы со следующими инструментами: Tensorflow, Keras, Sklearn, PyTorch, Caffe, Numpy, Pandas и др. Опыт работы с базами данных SQL и знакомство с обработкой данных OLAP Знание как классического ML, так и/или современных подходов глубокого обучения для RecSys, Forecasting, NLP, CV Знакомство с облачной средой: GCP, AWS, Azure Уровень владения английским языком B1+. Будет плюсом: Участие в профильных соревнованиях вроде Kaggle Опыт решения задач CV, NLP Опыт работы с инструментами проектирования данных и MLOps: Spark (PySpark), Airflow, Dask, DVC, MLFlow и др. Мы предлагаем:  Обучение и развитие: Большой пул разноплановых проектов в таких сферах, как FinTech, Medicine, Entertainment, eCommerce, Gaming, Artificial Intelligence и пр. Минимум легаси короткий бенч Широкий стек технологий, возможность перехода между ними ндивидуальные карты роста и регулярный пересмотр условий (роли на проекте, уровня ЗП) Подготовку к собеседованиям с зарубежными заказчиками на английском языке.  Рабочая среда: Гибридный формат работы (в офисе/дома) Просторные и комфортные рабочие места Подробный онбординг: знакомство с командой, процессами и правилами, экскурсия по офису, welcome card Уютные кухни, игровые комнаты, коворкинги, лаунж-зоны.  Дополнительные бонусы: Добровольное медицинское страхование Cкидки у компаний-партнеров (от пиццерий и книжных до магазинов бытовой техники).  Если ты ищешь реальные возможности реализовать себя, управлять профессиональным и карьерным ростом – будем рады видеть тебя в нашей дружной команде!",,Innowise Group / Фабрика инноваций и решений,
9245,78448054,"Специалист/нженер (AI, Data Scientist, Big Data, Machine learning, Нейронные сети, ChatGPT)",з/п не указана,3–6 лет,"Полная занятость,гибкий график","ПК ЛДЕРГРУПП – это успешная и динамичная команда профессионалов, реализующая проекты в области проектирования линейных объектов по всей территории России в качестве Генерального проектировщика. Условия: Персональный график работы (офис, удаленно, гибридный). Любая форма трудоустройства (Официально, ГПХ, Самозанятость). Уровень оплаты обсуждается индивидуально. Территориально: ст.м. Киевская офис класса А (в пешей доступности). Возможность участвовать в реализации новых уникальных проектов на базе . Профессиональный творческий коллектив. Задачи: Аналитика рынка AI-сервисов под бизнес-задачи кампании. Проведение тестирований на основе технологий искусственного интеллекта (-Сервисов). Подготовка протоколов и результатов исследований. Разработка и внедрение актуальных технологий AI для оптимизации бизнес-процессов Компании. Подбор и координация работы подрядчиков-разработчиков систем -Сервисов. Требования: Профильное высшее образование и навыки работы с разными языками программирования. Знание техник и алгоритмов AI (Data Scientist, Big Data, Machine learning, Нейронные сети, ChatGPT). Практический опыт разработки и внедрения программных продуктов. Опыт управления внутренними и внешними командами разработчиков.",,ПК ЛидерГрупп,
9259,78937079,Data Engineer (Machine Learning),з/п не указана,1–3 года,"Полная занятость,полный день","Описание проекта Наша agile-команда создает информационную платформу в интересах Департамента Глобальных Рынков (ДГР) одного из крупнейших Банков. ДГР – предоставляет корпоративным и розничным клиентам широкий спектр продуктов и услуг на локальных и зарубежных финансовых рынках. Этот бизнес потребляет и порождает огромное количество данных, которые должны обрабатываться c целью: • поддержки регулярных бизнес-операций • проведения Ad hoc анализа • подготовки регулярной аналитической / управленческой отчетности • разработки моделей машинного обучения, направленных на решение широкого спектра прикладных задач прогнозирования, классификации, кластеризации, выявления поведенческих паттернов и отклонений от них, сентимент-анализ и т.д. Разрабатываемая нами информационная платформа – высоконагруженное решение, призванное обеспечить достижение всех этих целей. Текущий инструментальный стек платформы: Python, Java, Informatica PowerCenter, Kafka, AirFlow, InfluxDB, kdb+, OneTick, MS SQL, PostgreSQL, MongoDB, Grafana, Qlik Sense, Kibana, ELK, OpenShift, Python ML/DL libraries, PySpark, TensorFlow Основные задачи сотрудника на данной позиции Проектирование и разработка потоков для загрузки данных в хранилище Проектирование и разработка слоев детальных данных Проектирование и разработка корпоративной аналитической платформы (ПКАП) Системная разработка, поддержка и оптимизация ETL-процессов Применение и ансамблирование ML моделей Поддержка промышленной эксплуатации разработанных решений Поддержание технической документации в актуальном состоянии Обязательные навыки Опыт работы с любой промышленной ETL-системой Опыт применения и ансамблирование ML моделей от 1-го года Опыт работы с популярными РСУБД (Greenplum, Teradata, Oracle, PostrgeSQL) Знание SQL, PL/SQL или PL/pgSQL Знакомство с экосистемой Hadoop Желательные навыки Опыт промышленной разработки на Python Опыт работы с CI/CD решениями на базе Jenkins и Bitbucket/Git Опыт работы с Data Vault Знание основ администрирования ОС Linux Условия Официальное оформление в аккредитованную IT-компанию Система ДМС Есть собственный учебный центр с тренингами по языкам программирования, soft skills, карьерному росту и другие Участие в крупных отраслевых мероприятиях Корпоративные скидки от компаний-заказчиков и многое другое","Greenplum,PostrgeSQL,SQL,Hadoop,DWH,ETL,ML,PL/SQL,Teradata,Machine Learning",IBS,
9262,76827021,Data Scientist / ML нженер,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Stellar Labs,"Москва, Белорусская, Белорусская, Лесная улица, 43"
9263,78386771,Middle+ Data Scientist,от 160 000 до 200 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","AgentApp — платформа для бизнеса, которая позволяет запустить продажи страховок со своего сайта или моб. приложения для клиентов со всей страны. Над продуктом работает единая команда разработчиков, аналитиков, маркетологов, а также экспертов в страховом бизнесе. 200 000 000р.+ — ежемесячный объем продаж через платформу. AgentApp — активно развивающийся стартап, позволяющий сотрудникам быстро развиваться профессионально и прокачивать скиллы. Наш продукт интегрирован в моб.приложения Сбербанк, OZON, ВТБ, МТС, Райффайзен, Газпром и имеет аудиторию свыше 70 млн пользователей. Мы находимся в поиске крутого специалиста, который поможет развивать наш Big Data проект! Что нужно будет делать: Разработка моделей скоринга Построение упрощенной модели по характеристикам авто и данным об убытках за пару лет Разработка моделей сегментации клиентов на основании их профилей и анализа их поведения. Мониторинг текущих показателей, обеспечением чистоты входящих данных, улучшением текущих моделей. Разработка инструментов мониторинга сследование тенденций и технологий в сфере Data Science, AI и Machine Learning с целью их последующего применения. Ждем от кандидата: Опыт подготовки неструктурированных данных для обучения модели (feature engineering) Прикладной опыт выведения моделей в продакшн Навык работы с базами данных: владение SQL / Hive / Hadoop / SQL Alchemy Опыт реализации классических ML-моделей: регрессия, классификация, кластеризация, понижение размерности данных Навыки Python-разработчика: работа с файлами - прочитать/записать, работа с АП http-сервисов через xml / json (SOAP/REST). Опыт работы с python-библиотеками (logging, yaml, xml, json, requests, threading) + ORM (sqlalchemy, ponyORM, tortoise) + навыки в ООП (работа через классы). Этапы интервью: 1. HR интервью (30 мин). Знакомство с вакансией. 2. Техническое интервью с CTO и тимлидом. (1-2 часа) 3. Знакомство с СЕО (30 мин) 4. Оффер. С нас: Работа над инновационном продуктом, который востребован на рынке Стабильная зарплата с потенциальными бонусами и регулярной индексацией Удаленная работа (при необходимости использование офиса в пешей доступности от ст.м. Василеостровская и ст.м. Спортивная (СПб)) Прокачка скиллов по запросу или по необходимости (курсы, книжки, семинары) Официальное трудоустройство.","SQL,Python,Базы данных,Big Data,ML",Remokate,
9266,79245437,Senior Data scientist / Machine learning engineer (команда рекомендаций и машинного обучения),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы применяем алгоритмы машинного обучения к рекомендациям контента. Не просто берем готовые решения, но и создаем собственные, пригодные к работе в условиях высоких нагрузок и больших данных. Помимо классического ML, мы используем deep learning и байесовские методы. Типичный пример нашего проекта — система, которая на ходу учится определять перспективность нового контента и аудиторию, среди которой он будет наиболее востребован. щем специалиста, который будет вместе с нами разрабатывать рекомендательную систему, искать возможности для роста и формировать планы по развитию продукта. Вам предстоит: • математически формулировать бизнес-задачи • использовать огромное количество разных данных • создавать гипотезы по улучшению сервиса, внедрять их и проверять работоспособность в офлайне, а в случае удачи искать способы реализации • проводить A/B-тесты и анализировать результаты экспериментов. У нас интересно, потому что вы сможете поработать с разнообразными state-of-the-art решениями в области рекомендательных систем, например: • с продвинутыми методами матричной факторизации для извлечения информации из истории просмотров и поиска • построением текстовых эмбеддингов • методами reinforcement learning • SNA-техниками для анализа социального графа • разработками big data и аналитикой поверх стека Apache Spark • product science для инсайтов и генерирования продуктовых гипотез • анализом границ применимости моделей, техниками explanation для понимания работы моделей и их специфик. Мы ожидаем, что вы: • имеете отличную математическую и алгоритмическую подготовку • знаете методы машинного обучения и умеете грамотно их использовать • работали с рекомендательными системами или интересуетесь ими • уверенно владеете Python, Java или Scala, а также любым из диалектов SQL. Будет плюсом, если вы: • умеете работать с фреймворками big data — Spark, Hadoop • знакомы с байесовскими методами машинного обучения. Приглашаем кандидата, который сможет посещать офис в Санкт-Петербурге или работать в гибридном графике. Ждем ваших откликов. Удачи!","Python,Java,Hadoop,Big Data,Spark,SCALA","VK, ВКонтакте","Санкт-Петербург, Гостиный двор, Невский проспект"
9268,77899629,Senior NLP Engineer / Data Scientist,до 370 000 руб. на руки,3–6 лет,"Полная занятость,полный день","КБЕР-РОМ — это неформальная обстановка, крутые Т-проекты в области медиаиндустрии и продукты, конкурирующие с лидерами рынка! У нас есть команда, которая создает ML решения, аналогов которых нет на рынке! Спроси себя, хочешь ли ты: обрабатывать миллионы видео со стримминговых сервисов предоставлять пользователям релевантный контент искать структуры в неструктурированных данных бороться за каждую миллисекунду скорости делать продукт, который сделает лучше пользовательский опыт. Наша команда растет и мы ищем Senior NLP Engineer / Data Scientist. Наш стек: Lang: Python/Go/C++ ML: Torch, CatBoost и многое другое =)  DB: PostgreSQL, GreenPlum, Mongo, ClickHouse, Redis, OpenSearch Queue: Rabbit, Kafka Orchestration: K8s DevOps: Docker, ArgoCD, Helm Services: AirFlow, SuperSet, ML-Flow, Git-Lab Log: ELK (под OpenSearch стек) Monitoring: Grafana, Prometheus. С чем можно будет поработать: Работа с большими данными и высокой нагрузкой С Machine Learning сервисами, которые приносят людям пользу =)  Общение с экспертами в области разработки и ML из разных областей. Чем предстоит заниматься: Разрабатывать модели NLP и IR сследовать текстовые данные UGC Строить и внедрять Pipeline-ы обработки текстовых данных нтегрировать модели в сервисы. Что ожидаем от Вас: Знание и применение базовых и ML алгоритмов Опыт построение NLP сервисов от постановки бизнес задачи до внедрения сервиса в Production Опыт разработки и внедрения моделей NLP в Production сервисы от 3х лет Знание и применение Python в Production от 3х лет Опыт работы с большими данными Применение в Production DL моделей Умение определить, где нужен DL, а где достаточно регулярки =)  Навыки работы с SQL и NoSQL базами данных. Будет плюсом: Опыт работы с Docker и K8s Умение работы с ML-Ops подходами Успешные внедрения в высоко-нагруженных проектах Публикации в NLP. Бенефиты: Мы - аккредитованная в Минцифрах IT-компания Оформление по ТК РФ, конкурентная заработная плата График работы 5\2, гибкое начало дня до 11 утра (возможен гибридный график работы или удаленка) ДМС со стоматологией и госпитализацией в классных клиниках Профессиональное обучение и конференции Стильный просторный лофт на территории Трехгорной мануфактуры. Тебе предстоит легкая 10 минутная пешая прогулка через парки от метро 1905 года и Краснопресненская Сhill Lounge с пятой плойкой и капсулой для сна с массажем Современное топовое оборудование, мощные ноутбуки Комфортная кухня с вкусным кофе, чаем, какао, орешками, фруктами, снэками и прочими ништяками Холодильник с колой и энергетиками По пятницам в офисе пицца, роллы или грузинская кухня Годовая подписка на топовый онлайн кинотеатр. Минусы: Очень много интересных и сложных задач Будут спрашивать результаты работы Нет возможности работы из-за границы.","Python,Go,C++,Torch,CatBoost,PostgreSQL,GreenPlum,MongoDB,ClickHouse,Redis,OpenSearch,RabbitMQ,Kafka,K8s,Docker,ArgoCD,Helm,AirFlow,SuperSet,ML-Flow,Git-Lab,ELK,Grafana,Prometheus",КБЕР-РОМ,"Москва, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с27"
9276,71322369,Data Scientist Middle/Senior,з/п не указана,3–6 лет,"Полная занятость,полный день","Responsibilities: Collaborate with business partners to develop novel ways to meet objectives utilizing cutting edge techniques and tools Effectively communicate the analytics approach and how it will meet and address objectives to business partners Advocate and educate on the value of data driven decision making focusing on the “how and why” of solving problems Lead analytic approaches, integrating work into applications and tools with data engineers, business leads, analysts and developers Create repeatable, interpretable, dynamic and scalable models that are seamlessly incorporated into analytic data products Engineer features by using their business acumen to find new ways to combine disparate internal and external data sources Share their passion for Data Science with broader enterprise community identify and develop long-term processes, frameworks, tools, methods and standards Collaborate, coach, and learn with a growing team of experienced Data Scientists Stay connected with external sources of ideas through conferences and community engagements Domain Expertise: Bachelor’s degree required Graduate degree in quantitative discipline and demonstrated Data Science skill set, plus 3+ years work experience Must have Python or R proficiency working with DataFrames Must have proficiency writing complex SQL queries Must have proficiency with Machine Learning to solve clustering, classification, regression, anomaly detection, simulation and optimization problems on large scale data sets Must have proven ability to merge and transform disparate internal & external data sets together to create new features Advanced time series forecasting understanding – from classical linear approaches to ML ones Understanding the key business metrics and its application to ML models Experience with sophisticated data cleansing approaches & robust models Proficiency validating the current approaches and understanding the improvement area Experience with Big Data technologies preferred — Hadoop, Spark, H20.ai, Cloud AI platforms, containerization Experience with supporting deployment, monitoring, maintenance and enhancement of models desired Experience with data visualization tools preferred — Power BI, Tableau, R Shiny, Plotly, etc. Experience with AB testing preferred We offer: Competitive salary Advanced benefits package (annual bonus, health insurance, mobile compensation, partial fitness compensation, 3-year saving plan) Professional development and career growth Ability to take part in digital transformation in a large company","Python,Machine Learning,SQL,Big Data,Data science",Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
9278,78552507,Data Engineer (senior),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Анабар – система аналитики и управления продажами для продавцов на маркетплейсах. Продукт запустили Петр Марков (ex-Яндекс, ex-Циан) и Павел Тарасов (ex-Альфа-Банк, ex-Циан) в июле 2020. У нас есть довольные клиенты, выручка и мы удваиваемся по всем ключевым бизнес-метрикам каждый квартал. Количество продавцов на маркетплейсе удваивается каждый год + большинство из них работает сразу на нескольких маркетплейсах (Wildberries, Озон, Shopee). Т. е. на рынке много клиентов (и становится больше), у них много денег (и становится больше) и у них много проблем (и становится больше по мере усложнения самих маркетплейсов). деальная смесь, чтобы построить успешную компанию. Компанию делают люди, поэтому мы набираем команду единомышленников, которая сможет сделать лучший продукт на рынке. У нас уже есть сильные навыки Павла Тарасова в Machine Learning, команда разработки (которая тоже растет). Сейчас нам нужен middle-senior data engineer. Непосредственным руководителем будет Павел Тарасов (сооснователь). В Циан Павел построил и возглавлял департамент Machine Learning, поэтому ты будешь в хорошей компании и сможешь многому научиться. Можешь посмотреть выступление Павла Нам нужен человек, который умеет: - Создавать batch и streaming pipeline-ы обработки данных - Разруливание зависимостей потоков данных - Оптимизация SQL запросов - Тестирование и мониторинг качества данных  Тебе нужно будет делать: - Обрабатывать данные парсинга и создавать стабильные пайплайны с хорошей очисткой данных и контролем качества - нтегрироваться с api маркетплейсов и создавать витрины на основе данных площадок и парсинга Что мы ищем в тебе: - Отличное знание SQL - Знание python на уровне senior разработчика - Хотя бы одно из, лучше все: athena/presto, spark, clickhouse, Trino - Опыт работы с большими массивами данных Желательно: - Опыт решения аналитических задач - Работа с luigi/airflow - Опыт работы с облачным стеком - Опыт работы с hadoop стеком Что мы предлагаем:  - Конкурентоспособную “белую” зарплату - Дистанционную работу по Московскому времени (работать можно из любой точки мира) - Участие в превращении старт-апа в большую компанию - Погружение в быстрорастущую индустрию e-commerce - Быстрый рост навыков (нужно будет делать быстро много нового, это большая нагрузка и быстрый рост)","SQL,Python,ClickHouse,Hadoop,Анализ данных",ANABAR,
9279,79021402,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","By joining KAZ Minerals as a Data scientists, you will: Solve the most complex and practical tasks of the Metals and Mining industry, the key economy sector of Kazakhstan, with immediate impact on operations. The industry has been accumulating enormous operational data, but lagging behind using these data for an educated decision making based on the power of advanced analytics and artificial intelligence Take part in building a Digital and Analytics arm of the most advanced M&M company in Kazakhstan, creating impact-oriented culture without bureaucracy. KAZ Minerals is aiming to become the most innovative and digitally driven mining companies in Kazakhstan, and have started the development of artificial intelligence solution to optimize its production. The company plans to build the team of best data scientists, who would like to lead this direction Implement advanced analytics solution might require some business trips to the Operations sites in Eastern and Northern parts of Kazakhstan, where you will be working with the experienced international and local miners and metallurgists Job duties: Develop complex models and algorithms that drive innovation throughout the organization. This may include improving on-time performance, network planning, etc. Conduct advanced statistical and other analysis to provide actionable insights, identify trends, and measure performance Provide coaching and insight on analytic approaches and can objectively weigh trade-offs of different analytic methods Guide data engineering efforts to ensure alignment with future data science needs Provide guidance to business leaders and data engineering function highlighting data integrity risks Collaborate with analytics engineers to implement and deploy scalable solutions Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders Skills and qualification requirements: BS/MS in computer science, statistics, economics, mathematics, ops research or related technical discipline 2+ year of experience as a data analyst and/or data scientist Knowledge of machine learning, statistics, optimization, or related field Experience with Python is required Experience with SQL, Pandas, Numpy, SciPy, Scikit-learn, xgboost Experience with BI and visualization tools is a plus Experience in the Metals and Mining industry is a plus Professional attitude and service orientation superb team player Good written and verbal communication skills along with strong desire to work in cross-functional teams","Python,Data Mining,SQL,Machine Learning,Data Science,Numpy",KAZ Minerals Management,
9281,73328814,Associate Professor - Data Science&AI (eng),з/п не указана,3–6 лет,"Полная занятость,полный день","The Faculty of Computer Science and Engineering of Innopolis University invites high-caliber Associate Professors and who can teach in English (the language of instruction). Specifically, we are looking for candidates whose research/teaching interests and expertise are in one of the following fields: DATA SCIENCE: 1. Designing, Creating and Managing large volumes of data 2. Identifications of Pattern in the Data 3. Visualisation Tools 4. Creating Mathematical Models AI (Knowledge): 1. Expert Systems 2. Fuzzy Logic 3. Evolutionary Computation 4. Reinforcement Learning 5. Theory of Machine Learning and Neural Nets AI (Fields): 1. Natural Language Processing 2. Speech 3. Vision 4. Healthcare 5. Finance Required Qualifications: PhD degree in one of the above mentioned fields of expertise 2+ years of Assistant Professorship record of published papers in A* conferences Compensations and benefits: The initial appointment is 3-years with expectation for renewal with benefits, including the low taxation level of Russia (max.15%), 56 days of annually paid vacations, paid health care coverage, relocation, housing allowance, school/kindergarten. Responsibilities: Up to 120 academic hours of frontal teaching theory+practice rich courses typically distributed in 4 courses per year, leading high quality research, advising and mentoring students, contributing to community services and other activities related to developing and maintaining the intellectual and cultural environment of the University. Typical workload distribution: teaching - 40%, research - 40%, service - 20%. How to apply: Please kindly submit the minimum application pack via the form at the foot of the Careers section on our website: cover letter, CV (with Scopus and Google Scholar profiles links, links for the videos of public talks or lectures, if any), research statement and teaching statement, scans of BS, MS, PhD, Habilitation certificates along with the transcripts. Additionally, three referees should send a recommendation letter via the same form.","Information Technology,Fluent English,Research,Public Speaking,Machine Learning,Data Mining,Writing Articles",Университет ннополис,
9285,71354549,Chief Data Scientist / DS Team Lead,з/п не указана,3–6 лет,"Полная занятость,полный день","Responsibilities: Collaborate, coach, and learn with a growing team of experienced Data Scientists and Data Trainees Collaborate with business partners to develop novel ways to meet objectives utilizing cutting edge techniques and tools Share passion for Data Science with broader enterprise community identify and develop long-term processes, frameworks, tools, methods and standards Effectively communicate the analytics approach and how it will meet and address objectives to business partners Advocate and educate on the value of data driven decision making focusing on the “how and why” of solving problems Lead analytic approaches, integrating work into applications and tools with data engineers, business leads, analysts and developers Create repeatable, interpretable, dynamic and scalable models that are seamlessly incorporated into analytic data products Engineer features by using their business acumen to find new ways to combine disparate internal and external data sources Domain Expertise: Bachelor’s degree required, in quantitative discipline and demonstrated Data Science skill set 4+ years work experience, 1+ year work experience as a team lead Python or R proficiency working with DataFrames and proficiency writing complex SQL queries Proficiency with Machine Learning to solve clustering, classification, regression, anomaly detection, simulation and optimization problems on large scale data sets Proven ability to merge and transform disparate internal & external data sets together to create new features Experience with Big Data technologies preferred — Hadoop, Spark, H20.ai, Cloud AI platforms, containerization Experience with supporting deployment, monitoring, maintenance and enhancement of models preferred Experience with data visualization tools preferred — Tableau, R Shiny, Plotly, etc. We Offer: Competitive salary Advanced benefits package (annual bonus, health insurance, mobile compensation, partial fitness compensation, 3-year saving plan) Professional development and career growth Ability to take part in digital transformation in a large company","Python,Machine Learning,SQL,Big Data,Spark,Data Analysis,Teambuilding,ML",Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
9287,73328509,Assistant Professor - Data Science&AI (eng),з/п не указана,1–3 года,"Полная занятость,полный день","The Faculty of Computer Science and Engineering of Innopolis University invites highly promising Assistant Professors who have recently graduated or are close to graduation (completion expected in Spring 2023) and who can teach in English (the language of instruction). Specifically, we are looking for candidates whose research/teaching interests and expertise are in one of the following fields: DATA SCIENCE: 1. Designing, Creating and Managing large volumes of data 2. Identifications of Pattern in the Data 3. Visualisation Tools 4. Creating Mathematical Models AI (Knowledge): 1. Expert Systems 2. Fuzzy Logic 3. Evolutionary Computation 4. Reinforcement Learning 5. Theory of Machine Learning and Neural Nets AI (Fields): 1. Natural Language Processing 2. Speech 3. Vision 4. Healthcare 5. Finance Required Qualifications: PhD degree in one of the above mentioned fields of expertise depth of expertise at least in one of the above mentioned areas experience of being a Teaching Assistant strong record of published papers in flagship journals or conferences practical and presentations skills Compensations and benefits: The initial appointment is 3-years with expectation for renewal with benefits, including the low taxation level of Russia (max.15%), 56 days of annually paid vacations, paid health care coverage, relocation, housing allowance, school/kindergarten. Responsibilities: Up to 120 academic hours of frontal teaching theory+practice rich courses typically distributed in 4 courses per year, leading high quality research, advising and mentoring students, contributing to community services and other activities related to developing and maintaining the intellectual and cultural environment of the University. Typical workload distribution: teaching - 40%, research - 40%, service - 20%. How to apply: Please kindly submit the minimum application pack via the form at the foot of the Careers section on our website: cover letter, CV (with Scopus and Google Scholar profiles links, links for the videos of public talks or lectures, if any), research statement and teaching statement, scans of BS, MS, PhD, Habilitation certificates along with the transcripts. Additionally, three referees should send a recommendation letter via the same form.","Information Technology,Fluent English,Research,Public Speaking,Machine Learning,Data Mining,Writing Articles",Университет ннополис,
9289,78579913,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","B2B CLTV - это проект, который позволяет прогнозировать, управлять пожизненной ценностью B2B-клиентов на основе анализа данных и построения моделей машинного обучения (Machine Learning) Обязанности: Анализ требований к витринам данных (взаимодействие с владельцем продукта, BI-разработчиками, data scientist-ами) Поиск и исследование источников данных для последующей интеграции Оценка пригодности, качества исходных данных Разработка ETL процессов на Spark Оркестрация ETL процессов в Airflow Проектирование баз данных Создание конвейеров данных NiFi. Требования: Знание SQL на высоком уровне (в т. ч. DDL, табличные выражения, оконные функции) Опыт работы с Hive, PostgreSQL Умение разрабатывать ETL процессы Spark на Scala (потоковая обработка как преимущество) Опыт AirFlow или другие оркестраторы – Oozie, Luigi, ну или cron Знаете Python Опыт потоковой разработки конвейеров данных в NiFi или Flink нтересуетесь Flink, пробовали применять его в проектах Умеете проектировать базы данных (знает Data Vault 2.0 например) Понимаете принципы работы реляционных СУБД и HDFS меете представление о колоночных и NoSQL СУБД Понимаете подходы к работе с качеством данных Стек и технологии Экосистема Hadoop – HDFS, YARN, Hive, HBase ETL-процессы – Spark (Scala) Потоковая обработка – NiFi, Flink Брокер сообщений – Kafka Оркестрация ETL процессов – Airflow СУБД – PostgreSQL, Greenplum, Aerospike, Oracle, SQL Server CI/CD – GitLab. Условия: ДМС + стоматология после испытательного. Удаленный формат работы на всей территории. Корпоративная мобильная связь. Оплата обучения по квалификации. Билайн академия.",,билайн: Контактные центры,
9290,73328547,Assistant Professor - Data Science&AI (eng),з/п не указана,1–3 года,"Полная занятость,полный день","The Faculty of Computer Science and Engineering of Innopolis University invites highly promising Assistant Professors who have also recenlty graduated or are close to graduation and who can teach in English (the language of instruction). Specifically, we are looking for candidates whose research/teaching interests and expertise are in one of the following fields: DATA SCIENCE: 1. Designing, Creating and Managing large volumes of data 2. Identifications of Pattern in the Data 3. Visualisation Tools 4. Creating Mathematical Models AI (Knowledge): 1. Expert Systems 2. Fuzzy Logic 3. Evolutionary Computation 4. Reinforcement Learning 5. Theory of Machine Learning and Neural Nets AI (Fields): 1. Natural Language Processing 2. Speech 3. Vision 4. Healthcare 5. Finance Required Qualifications: PhD degree in one of the above mentioned fields of expertise depth of expertise at least in one of the above mneitoned areas experience of being a Teaching Assistant strong record of published papers in flagship journals or conferences paractical and presentations skills Compensations and benefits: The initial appointment is 3-years with expectation for renewal with benefits, including the low taxation level of Russia (max.15%), 56 days of annually paid vacations, paid health care coverage, relocation, housing allowance, school/kindergarten. Responsibilities: Up to 120 academic hours of frontal teaching theory+practice rich courses typically distributed in 4 courses per year, leading high quality research, advising and mentoring students, contributing to community services and other activities related to developing and maintaining the intellectual and cultural environment of the University. Typical workload distribution: teaching - 40%, research - 40%, service - 20%. How to apply: Please kindly submit the minimum application pack via the form at the foot of the Careers section on our website: cover letter, CV (with Scopus and Google Scholar profiles links, links for the videos of public talks or lectures, if any), research statement and teaching statement, scans of BS, MS, PhD, Habilitation certificates along with the transcripts. Additionally, three referees should send a recommendation letter via the same form.","Information Technology,Fluent English,Research,Public Speaking,Machine Learning,Data Mining,Writing Articles",Университет ннополис,
9293,73328680,Associate Professor - Data Science&AI (eng),з/п не указана,3–6 лет,"Полная занятость,полный день","The Faculty of Computer Science and Engineering of Innopolis University invites high-caliber Associate Professors and who can teach in English (the language of instruction). Specifically, we are looking for candidates whose research/teaching interests and expertise are in one of the following fields: DATA SCIENCE: 1. Designing, Creating and Managing large volumes of data 2. Identifications of Pattern in the Data 3. Visualisation Tools 4. Creating Mathematical Models AI (Knowledge): 1. Expert Systems 2. Fuzzy Logic 3. Evolutionary Computation 4. Reinforcement Learning 5. Theory of Machine Learning and Neural Nets AI (Fields): 1. Natural Language Processing 2. Speech 3. Vision 4. Healthcare 5. Finance Required Qualifications: PhD degree in one of the above mentioned fields of expertise 2+ years of Assistant Professorship record of published papers in A* conferences Compensations and benefits: The initial appointment is 3-years with expectation for renewal with benefits, including the low taxation level of Russia (max.15%), 56 days of annually paid vacations, paid health care coverage, relocation, housing allowance, school/kindergarten. Responsibilities: Up to 120 academic hours of frontal teaching theory+practice rich courses typically distributed in 4 courses per year, leading high quality research, advising and mentoring students, contributing to community services and other activities related to developing and maintaining the intellectual and cultural environment of the University. Typical workload distribution: teaching - 40%, research - 40%, service - 20%. How to apply: Please kindly submit the minimum application pack via the form at the foot of the Careers section on our website: cover letter, CV (with Scopus and Google Scholar profiles links, links for the videos of public talks or lectures, if any), research statement and teaching statement, scans of BS, MS, PhD, Habilitation certificates along with the transcripts. Additionally, three referees should send a recommendation letter via the same form.","Information Technology,Fluent English,Research,Public Speaking,Machine Learning,Data Mining,Writing Articles",Университет ннополис,
9296,78961342,ML Research Engineer/Data Science Engineer,з/п не указана,1–3 года,"Полная занятость,удаленная работа","MY.GAMES is a leading European publisher and developer headquartered in Amsterdam, with over one billion registered users worldwide. War Robots, Hustle Castle, Rush Royale, Left to Survive, Tacticool, and many other games were developed and produced by MY.GAMES. The company creates and publishes games for PC, consoles, and mobile devices. We have more than a dozen game development studios united under MY.GAMES, as well as MGVC, a global game investment company. The global MY.GAMES and MGVC partner network comprises over 40 studios. Our studios are professional teams with their own unique atmosphere. We’re united by a common passion: transforming our enthusiasm and talent into fabulous games. We create engaging products which captivate millions of people all over the world. What you’ll do: Prepare and analyze in-game and advertising data Build ML models for predicting ""monetary"" events, striking a compromise between performance (both learning and prediction) and accuracy Develop strategies/distributed systems for optimal budget spending Analyze and build ML models and heuristic approaches to cut off fraudulent traffic Analyze user history from ad auctions using the unsupervised approach Conduct A/B tests for model versions What you need to succeed: Basic algorithmic training: knowledge of basic algorithms and data structures, as well as their implementation in standard libraries Strong knowledge of Python, ability to write testable codes for production processes, ability to solve analytical and data preparation tasks English for reading technical documentation and analyzing professional articles Knowledge of probability theory, statistics, algebra, numerical and Bayesian methods Experience supporting the full life cycle of models, including analyzing raw data, generating hypotheses, creating models, conducting experiments, and introducing the results in production Experience applying ML algorithms practically: linear algorithms (linear and logistic regression, etc.), compositional algorithms (random forest, gradient boosting, etc.) Nice to have: Knowledge of Factorization machines, SVD decomposition, and unsupervised approaches Knowledge of Python libraries and basic data science SQL knowledge What we offer: Work remotely from all around the world Collaborative working atmosphere in an internal game dev community that unites more than 40 in-house and partner studios A strong team of specialists across different areas — access unique expertise and professional knowledge Possibility to experiment and work on interesting tasks with ambitious goals — we have all resources to implement new ideas Create great games and win the hearts of players Push the boundaries of the game industry and lead the way forward","Data Science,Python",MY.GAMES,
9303,78889781,Data Engineer (relocation to Germany),з/п не указана,более 6 лет,"Полная занятость,полный день","Our partner, a well-known German online platform, is looking for a Data Engineer Advanced Analytics (m/f/d) to resolve technical data issues, and optimize their data architecture. This is a full-time position in Dusseldorf metropolitan area, Germany (partial work from home is possible). Relocation from abroad is possible. We will take care of your visa application and relocation to Germany. Your family members (spouse, children under 18 years old) will get a visa as well. About the company: In the team, everything revolves around one topic: creating data-based added value for the company and its customers around the world In international projects, they develop customized data & analytics solutions for their business and IT teams They support the entire organization in making important decisions based on reliable data and state-of-the-art analyses Your responsibilities: Design, develop, optimize and maintain squad-specific data architecture and pipelines that adhere to defined ETL and data lake principles Prepare, coordinate and organize the handover of data architecture and pipeline artifacts to the platform team Resolve technical data issues Participate in building data products for Analytics and Data Scientists / Machine Learning Engineers to improve their productivity Mentor data and analytics professionals on data standards and practices Propose and contribute to training and improvement plans regarding analytical data engineering skills, evaluation of new tools for analytical data engineering or data science Educating in machine learning, data science, computer vision, artificial intelligence, statistics, or applied mathematics Required qualifications: At least a Bachelor’s degree in Information Technologies or a related field Experience in data engineering and solutions for cloud computing services in the area of data and analytics Knowledge of SQL and data analytics and experience with at least one programming language (e.g., Python, Scala) Experience in database development and data modeling, ideally with Databricks/Spark and SQL Server DB Knowledge of relational, NoSQL, and cloud database technologies Would be a plus: experience with MS Azure tools such as Data Factory, Event Hub, Databricks, ML, Synapse, Purview. Knowledge of data and analytics, e.g. dimensional modeling, ETL, reporting tools, data governance, data warehousing, and structured and unstructured data Excellent English (at least C1 level) Benefits: Mobile working within Germany incl. equipment and flexible working hours State-of-the-art technologies Attractive remuneration Vacation and Christmas bonus Future-oriented training & development Modular onboarding and an onboarding buddy Health perks Relocation package If you are interested in joining the team as Data Engineer, do not hesitate to apply for the job and send us your CV","SAP MM,Ariba,Procurement,Logistics,SAP MDG,SAP S/4HANA,English,Английский — C1 — Продвинутый",Transparent Hiring,
9305,78852846,Data Engineer Lead / Дата инженер,от 300 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Мы - аккредитованная IT-компания «Сеть партнерств». В июле 2021 наша команда запустила флагманский продукт – подписку «Огонь», ogon.ru Это первая на рынке мультиподписка с собственным мобильным приложением. На данный момент в подписку входят предложения более чем от 45 партнёров, включая ""VK Музыка + Wink и другие сервисы"".  Для реализации RoadMap на 2023 приглашаем в команду Lead Data Engineer Что предстоит делать: Взаимодействие с внешними и внутренними коллегами с целью определения способов интеграций систем Участие в проектировании архитектуры аналитического контура Менторство над менее опытными коллегами, в том числе постановка задач Реализация наиболее сложных компонентов платформы Вникать в суть проектов. Написание документации по проделанной работе Определение и реализация метрик работы сервисов и пайплайнов обработки данных Постановка их на мониторинг и передача в поддержку Код-ревью. Приемка задач. Валидация выполняемых работ на момент соответствия целевой архитектуре Лидировать процессы построения корпоративного хранилища данных Влиять на внутренние процессы и используемый стек технологий Стек технологий: · Python · ClickHouse, PostgreSQL, Kafka · Prometheus + Grafana · Kubernetes + Docker · Gitlab · Nifi, Tableau · JupyterHub · Influx db Что ожидаем увидеть: Опыт промышленной разработки на python в части работы с данными от 3-х лет Навыки коммуникации с заказчиками и контрагентами Понимание принципов работы data science проектов Опыт работы с Nifi, Airflow, PostgreSQL, ClickHouse Умение писать сложные sql-запросы Понимание принципов работы с аналитическими и транзакционными базами данных Желателен опыт руководства Что мы предлагаем: Проект с финансовой поддержкой крупных инвесторов нновационные сложные продукты В команде: разработчики, продуктовые аналитики, бизнес-аналитики, системные аналитики, тестировщики - обеспечивают высокий уровень результата и профессионализм команды Белая заработная плата + бонусы в течение года до +30% к окладу Гибридный формат работы: удаленно + из офиса (м. Калужская) ДМС расширенный Увеличенный размер отпуска - 31 день","Python,SQL,PyTorch,PostgreSQL,Git,Kafka,Tableau,ClickHouse,NLP,ETL,Big Data,Data Analysis,Machine Learning,Теория вероятностей,Docker,Linux,Машинное обучение",Сеть Партнерств,"Москва, Калужская, Калужско-Рижская линия, метро Калужская"
9311,78680130,Data Scientist / ML-инженер,з/п не указана,1–3 года,"Полная занятость,полный день","Медиалогия разрабатывает высоконагруженные системы, которые в режиме реального времени сканируют весь текстовый сегмент нтернета (100+ млн. сообщений в сутки, 1.7 млрд. метрик) и, используя уникальные технологии лингвистического анализа и компьютерного зрения, позволяют осуществлять мгновенный анализ упоминаний наших клиентов в соц.сетях, блогах, форумах и управлять их репутацией. Задачи: Построение и тестирование гипотез Создание моделей для задач NLP и CV Доработка и улучшение существующих моделей Анализ данных из социальных сетей: классификация, кластеризация, выявление аномалий Проведение экспериментов на ""больших данных"" и обработка результатов Требования: Уверенное знание Python и библиотек для работы с данными (numpy, pandas, sklearn, catboost и др.) Умение писать чистый хорошо структурированный код Опыт создания моделей машинного обучения на TensorFlow, PyTorch и др. Умение работать с неструктурированными контентом, правильно оценивать качество моделей Умение работать в команде, хорошие коммуникативные навыки, Желание активно развиваться и браться за самые сложные задачи. Желателен опыт работы с большими данными (Spark, Hadoop) Условия: Белая ЗП, официальное оформление по ТК РФ ДМС с хорошим выбором клиник и международной страховкой Современный офис в 10 мин от м. Дмитровская (БЦ «Савеловский Сити» с массажистом, кикером, турником и PlayStation) или полная удаленка Гибкое начало рабочего дня Возможность посещения профильных мероприятий и карьерное развитие Рядом дизайн-завод Флакон, кафе и магазины.","Python,Adobe Photoshop,Аналитические исследования,Аналитическое мышление,Статистический анализ,Machine Learning,Neural Networks,Deep Learning,Data Science,Data Analysis,Data Mining,Big Data,Анализ данных",Медиалогия,"Москва, Дмитровская, Новодмитровская улица, 2к2"
9312,78730030,Data Engineer/ML Engineer Sber AI lab,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы приглашаем ML Engineer-а в команду медицинских исследований Лаборатории искусственного интеллекта, особое подразделение Сбера, нацеленное на долгосрочные наукоемкие AI проекты. Наша цель не только научные проекты на стыке  и медицины, но и пилотирование/PoC-внедрение разработанных решений в существующие системы. В проектах такой социально-значимой и сложной области как здравоохранение важна каждая деталь, поэтому мы уделяем особое внимание подготовке данных и проработке деталей интеграции. Наша команда состоит из специалистов с опытом работы в известных IT-компаниях, мастеров Kaggle, учёных с публикациями на ведущих конференциях. Обязанности нжинирингом данных/моделей (создание MVP и ML-сервисов / мониторинги / CI/CD / докеризация / интеграция с системами хранения медицинской информации и т.п.) Написанием/автоматизацией пайплайнов / ETL-процессов обработки данных Выкаткой моделей в prod. Требования Высокая техническая грамотность (алгоритмический базис) Понимание основ machine learning и deep learning Хорошее знание Python (в т.ч. опыт работ с какими-то из Python фреймворков по подготовке данных (Pandas, NumPy, SciPy, PySpark) / знание Java/Scala или С++ будут плюсом Знание SQL, опыт работы с распространёнными СУБД (PostgreSQL, MySQL, ClickHouse и т.п.) Scripting (bash/powershell) обязателен, поднимать и настраивать сервера в облачных средах Знание систем контроля версий, опыт коллективный разработки (опыт с системами версионирования данных типа DVC как плюс) Умение анализировать научную литературу, самостоятельно разбираться в незнакомой теме Желание заниматься инженерной и инфраструктурной стороной проблемы. Условия Профессиональный коллектив (где работают грандмастера и мастера Kaggle и лучшие исследователи в AI) Масштабные проекты Акцент на результат Премии по итогу ревью ДМС с первого дня работы.",,Сбер для экспертов,
9314,78685496,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Wialon Hosting servers store 140 terabytes of data, and more than 1 million requests come to them every minute. We are open to expanding our expertise in Data Science, so we are looking for reinforcements in the team. The new colleague will have to work with large arrays of real data, on which the success of numerous companies (from taxi companies to oil corporations) depends. Tasks for you: Working with hypotheses and goals: Construction, validation and implementation of advanced machine learning algorithms in the field of telematics and IoT, for example: detection of anomalies in time series (fuel theft, equipment wear, car theft, etc.) driving quality control transport typification cost optimization in the field of logistics Analysis of large volumes of structured information to identify patterns and build hypotheses. Interaction with product managers and engineers. Help in solving algorithmic problems. Formation of hypotheses / formation of ML backlog. Advice and assistance in the construction of a Data-driven approach in the company as well as the requirements for the formation of DWH. We will appreciate: Python development experience. Strong knowledge of machine learning frameworks: PyTorch, Tensorflow, Keras. Strong knowledge of libraries: scikit-learn, numpy, pandas. Data visualization: bokeh/plotly, matplotlib, seaborn. Experience with big data (Dask, PySpark). Practical experience in the development of AI / ML algorithms Understanding the main ideas and theoretical foundations of machine learning. Analytic mind. Communication skills (the ability to express thoughts clearly and clearly, the ability to listen and hear). Autonomy and learning. Will be an advantage: Experience in API development in Python (FastApi/Django). Experience with MLflow, Airflow, Docker. What we offer: Work in an international company where yet each person matters and where work in a satellite office does not leave you with an isolation feeling Result-driven, friendly, and supportive team - we do an amazing job and are good friends after work Developing a product of excellent quality that makes our world a better place Flexible work options without time and location tracking Social package: professional and business training, individual foreign language training, corporate library, 20 fully covered psychological sessions, team building events, corporate presents, health insurance.  Looking forward to your applications and resumes )","Python,ML,Machine Learning,PyTorch,Numpy,Big Data",Gurtam,"Тбилиси, улица Михаила Тамарашвили, 13"
9316,78405101,Data Scientist / ML-engineer (Middle+) со знание python в проект по искусственному интеллекту,от 150 000 руб. до вычета налогов,1–3 года,"Полная занятость,полный день","Привет! Мы разрабатываем продукт для птицеводческих ферм, основанный на компьютерном зрении и искусственном интеллекте. Наши девайсы работают по всему миру от Тайланда до Латинской Америки и помогают фермерам отслеживать состояние птиц, их вес и процесс роста. Московская команда тесно сотрудничает с командой из Малайзии, ндии и Америки. Мы шагаем широкими шагами и нам в команду нужен дополнительный человек, который бы помогал нам искать закономерности в Big Data, обучать модели, проверять гипотезы и помогать с автоматизацией процессов на python. Требования: - ответственный, думающий человек с быстрым умом аналитического склада - опыт работы DataScience/ML-engineer или опыт коммерческой разработки 2+ года - уверенное знание Python 3.x, SQL-запросов - хорошее знание Git - опыт разработки моделей для работы с табличными данными (временные ряды) - английский уровня B1+ Что предстоит делать: - обучение нейросетей на табличных данных - проверка гипотез (генерация как своих гипотез, так и помощь команде в реализации их идей) AB-тестирование - сбор и анализ датасетов для обучения/тестирования - работа с данными, поиск общих корреляций в разнородных данных, позволяющих повысить точность моделей - выявление и работа с аутлаерами в данных, кластеризация данных - автоматизация подготовки данных к обучению, обучение и деплой модели. Автоматизация ML пайплайна - инцидентные задачи, реагирование на запросы членов международной команды. Будет плюсом: - опыт работы с сервисами AWS & AWS S3 - опыт работы с базами данных PostgresSQL, Mongo DB - Docker, Airflow Что мы предлагаем: - стартаперский дух разработки - молодая веселая команда - погружение в современные технологии искусственного интеллекта, компьютерного зрения и робототехники - возможность попробовать себя в различных направлениях: программирование, анализ данных, обучение нейросетей, компьютерное зрение, робототехника - участие в других различных проектах от разработки ПО до создания роботов - аккредитованная IT-компания. Условия работы: - Полный день в офисе, территориально м. Селигерская. - Удаленная работа возможна, но большую часть времени надо будет находиться в офисе хотя бы на время испытательного срока. - Официальное трудоустройство по ТК РФ.","Python,Machine Learning,Базы данных,PyCharm,SQL,Английский язык,Big Data,AWS,Ответственный подход к работе,Анализ данных,Обучение и развитие,MongoDB,PostgreSQL",ПАВЛН ТЕХНО,"Москва, Селигерская, Дмитровское шоссе, 100с2"
9321,78103204,ML engineer/Data engineer,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Сбер для экспертов,
9324,78579913,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","B2B CLTV - это проект, который позволяет прогнозировать, управлять пожизненной ценностью B2B-клиентов на основе анализа данных и построения моделей машинного обучения (Machine Learning) Обязанности: Анализ требований к витринам данных (взаимодействие с владельцем продукта, BI-разработчиками, data scientist-ами) Поиск и исследование источников данных для последующей интеграции Оценка пригодности, качества исходных данных Разработка ETL процессов на Spark Оркестрация ETL процессов в Airflow Проектирование баз данных Создание конвейеров данных NiFi. Требования: Знание SQL на высоком уровне (в т. ч. DDL, табличные выражения, оконные функции) Опыт работы с Hive, PostgreSQL Умение разрабатывать ETL процессы Spark на Scala (потоковая обработка как преимущество) Опыт AirFlow или другие оркестраторы – Oozie, Luigi, ну или cron Знаете Python Опыт потоковой разработки конвейеров данных в NiFi или Flink нтересуетесь Flink, пробовали применять его в проектах Умеете проектировать базы данных (знает Data Vault 2.0 например) Понимаете принципы работы реляционных СУБД и HDFS меете представление о колоночных и NoSQL СУБД Понимаете подходы к работе с качеством данных Стек и технологии Экосистема Hadoop – HDFS, YARN, Hive, HBase ETL-процессы – Spark (Scala) Потоковая обработка – NiFi, Flink Брокер сообщений – Kafka Оркестрация ETL процессов – Airflow СУБД – PostgreSQL, Greenplum, Aerospike, Oracle, SQL Server CI/CD – GitLab. Условия: ДМС + стоматология после испытательного. Удаленный формат работы на всей территории. Корпоративная мобильная связь. Оплата обучения по квалификации. Билайн академия.",,билайн: Контактные центры,
9326,78935821,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Requirements: 4+ years of data science experience with at least 2 years of experience in retail and CPG domain Proven knowledge and experience of Python and SQL Knowledge of statistics and machine learning (including but not limited to classical ML and time series forecasting, etc.) Proven experience of LightGBM or similar ML libraries (e.g. XGBoost, CatBoost, scikit-learn, ...) is highly desirable Software Engineering experience and experience working on large-scale ML projects highly desirable Great presentation and storytelling skills, proven interpersonal skills. Responsibilities: Support startups with data science research and development. Participate in internal products development. Benefits: Projects in Western Europe and America. Career and professional growth. Product development. Full cycle projects. Corporate-funded training (functional training, foreign languages). Benefits (football, basketball, swimming pool, health insurance, sports compensation, corporate presents and events). Friendly team. Long term full time employment Stable pay (100% official). Flexible working hours Mentor's support and guidance to help you grow as a developer.","Python,Data Mining,MATLAB,Data Analysis,MS SQL,Machine learning,Time Series Analysis,Data Science,Английский — B1 — Средний",LeverX International,
9327,76111917,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Приглашаем в команду Data Engineer'а  Вы нам подходите, если любите настраивать автоматический сбор данных из различных источников, а также бережно следите за их качеством и стабильностью, создавая все возможные алгоритмы мониторинга и уведомления. Какие задачи у Data Engineer'а? Участие в построении корпоративного хранилища данных (BigData) на платформе Microsoft для BI-системы и проектов скусственного интеллекта(DL/ML) Организация автоматизированного сбора данных с внешних и внутренних источников Сохранение данных в DWH согласно правилам Участие в реализации процесса ETL. Связь данных из разных источников, трансформация, подготовка, агрегация данных для анализа Применение скрапинга и парсинга Консультирование Аналитиков BI и DataScientist- потребителей данных Участие в разработке чат ботов для ВК и Телеграмм Прежде всего мы ценим: Навыки программирования на Python(pandas, numpy, selenium, unittest или pytest ) Навыки работы с SQL любого диалекта Понимание технологий интеграции между платформами (API, триггеры, webhook) Знание библиотек для написания парсеров Опыт работы с Git Мы предлагаем: Развитие в команде молодых профессионалов своего дела ндивидуальную программу адаптации и помощь наставника Оформление по ТК РФ и полностью белую заработную плату Один день в неделю работаем на удалёнке Доступ к электронной библиотеке Альпина Сразу после испытательного срока предоставляем ДМС со стоматологией Будь в форме – участвуй в спортивных мероприятиях (Петровский гребной марафон, ЗаБег.РФ, Футбол, Пляжный волейбол и др.)","SQL,Python,Numpy,Git,Machine Learning,DWH,ETL,Pandas,Data Analysis,Big Data,Парсинг",Главстрой Санкт-Петербург,"Санкт-Петербург, Старая Деревня, улица Оптиков, 4"
9331,78271476,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Мы в Space307 разрабатываем международную торговую платформу. Каждый день у нас в онлайне 255 тысяч уникальных пользователей из 100+ стран. У нас плоская структура и нет просто исполнителей. Каждый из нас — спец в своей области, и принцип работы простой: к нам приходят с проблемой, а мы отвечаем решением. Наш проект с большим количеством фич и вся разработка ведется в кросс-функциональных командах. Мы ищем Data Scientist в команду DS Team. ЧТО ПРЕДСТОТ ДЕЛАТЬ?: Работать над моделью Market Mixture Models: строить модели на имеющихся данных, структурировать и валидировать источники данных Работать с data analytics, data engineers с целью разработки устойчивого пайплайна для MMM модели Создавать ML модели для скоринга пользователей (user acquisition), churn prediction, LTV Разрабатывать ML модели, backtesting Тестировать моделей в real-time Создавать методологии и инструменты мониторинга качества и обновления моделей МЫ ОЖДАЕМ, ЧТО ТЫ: меешь 2+ года работы в ML проектах Уверенно владеешь Python и работал с ML библиотеками (sklearn, pandas, numpy, catboost, lightgbm, etc.) Применял ML алгоритмы к табличными данным: понимаешь принципы работы основных ML методов, feature engineering, validation strategy меешь базовое понимание статистики Работал с Linux, bash меешь опыт работы с базами данных: мы активно пользуемся Vertica, Hadoop, MySQL Самостоятельный в формулировании гипотез, дизайне ML решения от постановки задачи до способов валидации. БУДЕТ ПЛЮСОМ: Опыт работы с Time Series, Survival Analysis Опыт работы с графовыми БД Опыт работы с Docker, Flask/FastAPI Опыт дизайна и проведения A/B тестов, Casual Impact. ЧТО ТЕБЯ ЖДЁТ В SPACE307: Комфорт и достойные условия: гибкий график, удалённая работа ворлдвайд и, конечно же, конкурентный уровень заработной платы. Честность, прозрачность и отсутствие бюрократии. Структура, в которой нет «СЕО минус четыре» — мы все равны и каждый отвечает за результат. Мероприятия на любой вкус: тренинги, семинары, конференции, лекции, мастер-классы. А также тимбилдинги и корпоративы, впечатляющие своим масштабом. Хакатоны, марафоны, квесты и турниры: коллеги объединяются в команды, создают крутые идеи и проекты и получают за это не менее крутые призы. Настоящая команда: здесь дают честный фидбэк, приходят на помощь и болеют за результат.","Linux,Bash,ML,Machine Learning,Data Science,Python,Data Analysis,Математическая статистика,Pandas,sklearn",Space307,"Санкт-Петербург, Горьковская, Чкаловская, улица Кропоткина, 1"
9332,78102836,Senior Data Engineer в Sber AI Lab,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Сбер для экспертов,
9333,78179909,Data Engineer,от 190 000 руб. на руки,1–3 года,"Полная занятость,полный день","Мы — букмекерская компания PARI. Мы создаем все условия для того, чтобы любители спорта могли наслаждаться просмотром спортивных событий и заключать пари. PARI обладает внушительным спонсорским портфолио в самых популярных видах спорта и сотрудничает с ведущими российскими федерациями — Союз биатлонистов России, Всероссийская федерация волейбола футбольными клубами: «ПАР НН», «Торпедо», «Ахмат», любительский футбольный клуб «Амкал» хоккейными клубами: «Торпедо», «Северсталь», «Нефтехимик», «Адмирал» и «Витязь». В нашей команде амбассадоров — известные телеведущие Дмитрий Губерниев, Ольга Петрикова, популярные российские ММА-бойцы Петр Ян и Арман Царукян, а также легенда российского футбола Андрей Тихонов и главный регбист страны Василий Артемьев. Мы стремимся войти в топ-3 букмекерских компаний, поэтому нам нужно создать сильную команду для продвижения нашего продукта на российском рынке. НАШ СТЕК: Tableau – как основной инструмент визуализации данных Python+Airflow – как основной инструмент для разработки ETL-процессов Clickhouse – как основной СУБД PostgreSQL. ЧЕМ ПРЕДСТОТ ЗАНМАТЬСЯ: Вывод в прод продуктовых решений Data команды Проектировать, внедрять и постоянно расширять пайплайны данных, выполняя предварительную обработку, очистку и проверку Определение возможностей для автоматизации и улучшения существующих процессов обработки данных, приносящих эффект бизнесу Разработка конвейеров данных ETL / ELT, которые легко поддерживать и контролировать Эффективная работа с несколькими командами для предоставления данный внутрь подразделений. ЧТО ДЛЯ НАС ВАЖНО: Опыт работы с данными от 1 года Связка Airflow + Git Свободное владение Python, который является у нас основным Возможность писать сложный SQL для обработки сырых данных, преобразования, проверки данных Опыт работы с API для сбора или приема данных в пакетном или реальном времени Опыт работы с докером. Будет преимуществом: Опыт работы с облачными решениями, мы в скором времени переходим на облако, будет много новых для команды задач Опыт работы с BI инструментами (Tableau / Power BI/ Metabase) Опыт выкатки в прод Machine learning DE, подразумевающим вывод DS моделей в прод Техническое высшее образование.","Python,SQL,Git,ETL,Визуализация данных,ClickHouse",PARI,
9334,79004050,"Data Scientist, ML (Удаленно)",от 100 000 до 250 000 руб. на руки,1–3 года,"Частичная занятость,удаленная работа","Привет, я Виктор Комаров, основатель чат-бот платформы для автоматизации взаимодействия с клиентами в мессенджерах - IntellectDialog. Мы ищем Data Scientist, ML инженера (с хорошим опытом) на проектную работу (по задачам с почасовой оплатой) с дальнейшим получением доли в компании. Можно работать в удобное для вас время и совмещать с основной работой. Требования: Опыт работы в разработке NLP-приложений и знание инструментов по обработке естественного языка на Python, таких как SpaCy, NLTK, Gensim и т.д. Понимание основных приемов обработки естественного языка, включая способы извлечения ключевых слов, именованных сущностей, анализ синтаксиса, грамматические модели и обработку структурных данных. Опыт работы с такими инструментами, как Tensorflow, PyTorch, NumPy, Pandas, Jupyter Notebook, понимание системы контроля версий (Git). Базовые знания математической статистики и теории вероятности. Глубокое понимание методов для работы с данными и алгоритмов машинного обучения, таких как классификация, кластеризация, регрессия, обработка последовательностей и т.д. Понимание принципов построения диалоговых систем, в том числе умения разрабатывать и применять техники генерации ответов и распознавания речи. Опыт работы с облачной инфраструктурой. Понимание архитектуры и дизайна диалоговых систем с использованием фреймворка на основе правил и/или машинного обучения. Ответственность, коммуникативные навыки для работы в команде. + Желание развиваться и изучать новые инструменты и технологии для оптимизации работы и улучшения результатов. Заинтересовала вакансия? Тогда ждем от Вас отклика и надеемся, что в скором времени Вы присоединитесь к нашей команде IntellectDialog","Data Scientis,ML,Машинное обучение,Machine Learning",нтеллектДиалог,
9335,79004051,"Data Scientist, ML (Удаленно)",от 100 000 до 250 000 руб. на руки,1–3 года,"Частичная занятость,удаленная работа","Привет, я Виктор Комаров, основатель чат-бот платформы для автоматизации взаимодействия с клиентами в мессенджерах - IntellectDialog. Мы ищем Data Scientist, ML инженера (с хорошим опытом) на проектную работу (по задачам с почасовой оплатой) с дальнейшим получением доли в компании. Можно работать в удобное для вас время и совмещать с основной работой. Требования: Опыт работы в разработке NLP-приложений и знание инструментов по обработке естественного языка на Python, таких как SpaCy, NLTK, Gensim и т.д. Понимание основных приемов обработки естественного языка, включая способы извлечения ключевых слов, именованных сущностей, анализ синтаксиса, грамматические модели и обработку структурных данных. Опыт работы с такими инструментами, как Tensorflow, PyTorch, NumPy, Pandas, Jupyter Notebook, понимание системы контроля версий (Git). Базовые знания математической статистики и теории вероятности. Глубокое понимание методов для работы с данными и алгоритмов машинного обучения, таких как классификация, кластеризация, регрессия, обработка последовательностей и т.д. Понимание принципов построения диалоговых систем, в том числе умения разрабатывать и применять техники генерации ответов и распознавания речи. Опыт работы с облачной инфраструктурой. Понимание архитектуры и дизайна диалоговых систем с использованием фреймворка на основе правил и/или машинного обучения. Ответственность, коммуникативные навыки для работы в команде. + Желание развиваться и изучать новые инструменты и технологии для оптимизации работы и улучшения результатов. Заинтересовала вакансия? Тогда ждем от Вас отклика и надеемся, что в скором времени Вы присоединитесь к нашей команде IntellectDialog","Data Scientis,ML,Машинное обучение,Machine Learning",нтеллектДиалог,
9336,76930898,"Data scientist / Machine learning engineer (команда рекомендаций и машинного обучения, ВКонтакте)",з/п не указана,1–3 года,"Полная занятость,гибкий график","Мы применяем алгоритмы машинного обучения к рекомендациям контента. Мы не просто берем готовые решения, но и создаем собственные, пригодные к работе в условиях высоких нагрузок и больших данных. Помимо классического ML, мы используем deep learning и байесовские методы. Типичный пример нашего проекта — система, которая на ходу учится определять перспективность нового контента и аудиторию, среди которой он будет наиболее востребован. щем специалиста, который будет вместе с нами разрабатывать рекомендательную систему, искать возможности для роста и формировать планы по развитию продукта. Вам предстоит: • математически формулировать бизнес-задачи • использовать огромное количество разных данных • создавать гипотезы по улучшению сервиса, внедрять их и проверять работоспособность в офлайне, а в случае удачи искать способы реализации • проводить A/B-тесты и анализировать результаты экспериментов. У нас интересно, потому что вы сможете поработать с разнообразными state-of-the-art решениями в области рекомендательных систем, например: • с продвинутыми методами матричной факторизации для извлечения информации из истории просмотров и поиска • построением текстовых эмбеддингов • методами reinforcement learning • SNA-техниками для анализа социального графа • разработками big data и аналитикой поверх стека Apache Spark • product science для инсайтов и генерирования продуктовых гипотез • анализом границ применимости моделей, техниками explanation для понимания работы моделей и их специфик. Мы ожидаем, что вы: • имеете отличную математическую и алгоритмическую подготовку • знаете методы машинного обучения и умеете грамотно их использовать • работали с рекомендательными системами или интересуетесь ими • уверенно владеете Python, Java или Scala, а также любым из диалектов SQL. Будет плюсом, если вы: • умеете работать с фреймворками big data — Spark, Hadoop • знакомы с байесовскими методами машинного обучения. Приглашаем кандидата, который сможет посещать офис в Санкт-Петербурге или работать в гибридном графике. Ждем ваших откликов. Удачи!","Python,Machine Learning,SQL,SCALA,Hadoop,Spark","VK, Одноклассники",
9337,77536865,Data Scientist Junior/Junior+,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
9340,79004051,"Data Scientist, ML (Удаленно)",от 100 000 до 250 000 руб. на руки,1–3 года,"Частичная занятость,удаленная работа","Привет, я Виктор Комаров, основатель чат-бот платформы для автоматизации взаимодействия с клиентами в мессенджерах - IntellectDialog. Мы ищем Data Scientist, ML инженера (с хорошим опытом) на проектную работу (по задачам с почасовой оплатой) с дальнейшим получением доли в компании. Можно работать в удобное для вас время и совмещать с основной работой. Требования: Опыт работы в разработке NLP-приложений и знание инструментов по обработке естественного языка на Python, таких как SpaCy, NLTK, Gensim и т.д. Понимание основных приемов обработки естественного языка, включая способы извлечения ключевых слов, именованных сущностей, анализ синтаксиса, грамматические модели и обработку структурных данных. Опыт работы с такими инструментами, как Tensorflow, PyTorch, NumPy, Pandas, Jupyter Notebook, понимание системы контроля версий (Git). Базовые знания математической статистики и теории вероятности. Глубокое понимание методов для работы с данными и алгоритмов машинного обучения, таких как классификация, кластеризация, регрессия, обработка последовательностей и т.д. Понимание принципов построения диалоговых систем, в том числе умения разрабатывать и применять техники генерации ответов и распознавания речи. Опыт работы с облачной инфраструктурой. Понимание архитектуры и дизайна диалоговых систем с использованием фреймворка на основе правил и/или машинного обучения. Ответственность, коммуникативные навыки для работы в команде. + Желание развиваться и изучать новые инструменты и технологии для оптимизации работы и улучшения результатов. Заинтересовала вакансия? Тогда ждем от Вас отклика и надеемся, что в скором времени Вы присоединитесь к нашей команде IntellectDialog","Data Scientis,ML,Машинное обучение,Machine Learning",нтеллектДиалог,
9341,79004050,"Data Scientist, ML (Удаленно)",от 100 000 до 250 000 руб. на руки,1–3 года,"Частичная занятость,удаленная работа","Привет, я Виктор Комаров, основатель чат-бот платформы для автоматизации взаимодействия с клиентами в мессенджерах - IntellectDialog. Мы ищем Data Scientist, ML инженера (с хорошим опытом) на проектную работу (по задачам с почасовой оплатой) с дальнейшим получением доли в компании. Можно работать в удобное для вас время и совмещать с основной работой. Требования: Опыт работы в разработке NLP-приложений и знание инструментов по обработке естественного языка на Python, таких как SpaCy, NLTK, Gensim и т.д. Понимание основных приемов обработки естественного языка, включая способы извлечения ключевых слов, именованных сущностей, анализ синтаксиса, грамматические модели и обработку структурных данных. Опыт работы с такими инструментами, как Tensorflow, PyTorch, NumPy, Pandas, Jupyter Notebook, понимание системы контроля версий (Git). Базовые знания математической статистики и теории вероятности. Глубокое понимание методов для работы с данными и алгоритмов машинного обучения, таких как классификация, кластеризация, регрессия, обработка последовательностей и т.д. Понимание принципов построения диалоговых систем, в том числе умения разрабатывать и применять техники генерации ответов и распознавания речи. Опыт работы с облачной инфраструктурой. Понимание архитектуры и дизайна диалоговых систем с использованием фреймворка на основе правил и/или машинного обучения. Ответственность, коммуникативные навыки для работы в команде. + Желание развиваться и изучать новые инструменты и технологии для оптимизации работы и улучшения результатов. Заинтересовала вакансия? Тогда ждем от Вас отклика и надеемся, что в скором времени Вы присоединитесь к нашей команде IntellectDialog","Data Scientis,ML,Машинное обучение,Machine Learning",нтеллектДиалог,
9342,76930898,"Data scientist / Machine learning engineer (команда рекомендаций и машинного обучения, ВКонтакте)",з/п не указана,1–3 года,"Полная занятость,гибкий график","Мы применяем алгоритмы машинного обучения к рекомендациям контента. Мы не просто берем готовые решения, но и создаем собственные, пригодные к работе в условиях высоких нагрузок и больших данных. Помимо классического ML, мы используем deep learning и байесовские методы. Типичный пример нашего проекта — система, которая на ходу учится определять перспективность нового контента и аудиторию, среди которой он будет наиболее востребован. щем специалиста, который будет вместе с нами разрабатывать рекомендательную систему, искать возможности для роста и формировать планы по развитию продукта. Вам предстоит: • математически формулировать бизнес-задачи • использовать огромное количество разных данных • создавать гипотезы по улучшению сервиса, внедрять их и проверять работоспособность в офлайне, а в случае удачи искать способы реализации • проводить A/B-тесты и анализировать результаты экспериментов. У нас интересно, потому что вы сможете поработать с разнообразными state-of-the-art решениями в области рекомендательных систем, например: • с продвинутыми методами матричной факторизации для извлечения информации из истории просмотров и поиска • построением текстовых эмбеддингов • методами reinforcement learning • SNA-техниками для анализа социального графа • разработками big data и аналитикой поверх стека Apache Spark • product science для инсайтов и генерирования продуктовых гипотез • анализом границ применимости моделей, техниками explanation для понимания работы моделей и их специфик. Мы ожидаем, что вы: • имеете отличную математическую и алгоритмическую подготовку • знаете методы машинного обучения и умеете грамотно их использовать • работали с рекомендательными системами или интересуетесь ими • уверенно владеете Python, Java или Scala, а также любым из диалектов SQL. Будет плюсом, если вы: • умеете работать с фреймворками big data — Spark, Hadoop • знакомы с байесовскими методами машинного обучения. Приглашаем кандидата, который сможет посещать офис в Санкт-Петербурге или работать в гибридном графике. Ждем ваших откликов. Удачи!","Python,Machine Learning,SQL,SCALA,Hadoop,Spark","VK, Одноклассники",
9343,77536865,Data Scientist Junior/Junior+,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
9346,52581749,"Senior Consultant, Data Scientist, Technology Group",з/п не указана,3–6 лет,"Полная занятость,полный день","Department: IT Advisory, Astana and Almaty A Senior Data Scientist would typically work, works collaboratively with our business teams and our clients to show the art of the possible and to assess possible value and feasibility of applying data science in order to help solve specific business problems. This could include demoing to prospective clients, developing data strategies, leading feasibility studies, explorative data analysis, delivering minimal viable products or fully fledged projects including putting our models into production either on our own or our client’s environments Requirements: Completed university degree in Computer Science, Statistics, Engineering or similar technical field A combination of one or more of the following (proficient with programming languages like Python, R, Scala, Java, C++ skills in data engineering technologies like Hadoop, HDFS, Spark, Elasticsearch SQL and NoSQL databases) Experience in data, data science, data engineering and/or other technology related capabilities: Experience applying advanced analytical techniques to large and varied data sets, generated and flowing at a rapid rate. Sample techniques include, but are not limited to applied machine learning, NLP, collaborative filtering and recommender systems, neural networks (including recurrent, convolutional), event detection and tracking, graph analytics. Experience with: Generating and test working hypotheses, prepare and analyze historical data, identify patterns from samples for reporting of trends and support Predictive Analytics Leveraging data visualization techniques and tools to effectively demonstrate patterns, outliers and exceptional conditions in the data Creating performance metrics and tracking processes to measure the effectiveness of Data Science solutions Conceptualizing necessary data governance models to support the technical solution and assure the veracity of the data Operating within the exploratory and experimental aspects of Data Science, e.g. to tease out interesting and previously unknown insights from vast pools of data Working collaboratively with other members of the Data Science and Information Architecture teams to innovate and create compelling data-centric stories and experiences Experience in demonstrating data science consultancy skills, e.g. running hypotheses workshops, mentoring more junior team members, preparing reports and presenting data science results. Responsibilities: Build data science assets (aka accelerators’), in line with our global strategy, to ensure we have the platforms and core assets in place to meet market demand. This could also include supporting our continuous improvement process around our own design and development processes e.g. about how we ensure the high quality that our clients require in an efficient manner. As a fast growing highly specialized team, you will be involved in the running and growing of our team, e.g. through coaching colleagues, helping with knowledge management. Support client engagements focused on large data sets and applying advanced analytical techniques, in diverse domains such as retail price optimization, marketing strategies, customer intelligence, financial crime, risk management, smart grids, etc. Develop new, or tailor existing, analytical solutions designed for processing large data sets (e.g. using an Hadoop framework) and by applying advanced analytical techniques (e.g. machine learning, neural networks, NLP, A/B testing, etc.) Develop big data management and data analytics strategies and roadmaps for their implementation Planning and organisation skills so as to work with a team, handle demanding clients and multitask effectively","Java,Python,Data Mining,SCALA,C++,Data Science,NLP,Английский — C1 — Продвинутый",KPMG,
9348,79255519,Data Scientist middle+/senior (Транскодинг),з/п не указана,3–6 лет,"Полная занятость,полный день","Сейчас в Okko создается новый продукт – Видеоплатформа. Это B2B-инструмент для работы с видеоконтентом. Ключевое значение для разработки продукта имеют обработка видео (транскодинг) и оптимизация процессов, связанных с ней. В команду транскодинга мы ищем человека, который сможет сформировать и вывести ML-решения для улучшения продукта, а также найдет баланс между математическими способами решения задач и ML. Обязанности: исследование применимости различных алгоритмов в рекомендательной системе и в системах с применением компьютерного зрения моделирование входных данных интеграция исследованных моделей в системах проведение экспериментов с созданными моделями автоматизация процессов подготовки данных оптимизация потребления ресурсов сервисами, а также повышение утилизации ресурсов и применения ML интеграция сервисов с распределенными системами (Базы данных, Очереди). Требования: высшее техническое/математическое образование знание математической статистики и высшей математики критичны для решения наших задач умение инициализировать новое направление от идеи и построения инфраструктуры до вывода решения в прод для конечных пользователей знание основ статистики понимание классических ML-алгоритмов способность анализировать статьи и имплементировать описываемые алгоритмы базовые знания о Сomputer Vision знание Python желателен опыт работы с видео, изображениями, с рекомендательными системами. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,Machine learning,Сomputer Vision",Okko,"Санкт-Петербург, Беговая, улица Савушкина, 126Б"
9353,79170149,Data Engineer (ETL),з/п не указана,1–3 года,"Полная занятость,полный день","Описание проекта Наша команда создает информационную платформу для решения аналитических и исследовательских задач в области создания продуктов и услуг на мировых финансовых рынках: • торговля валютой, • ценными бумагами, • производными финансовыми инструментами.  Этот бизнес потребляет и порождает огромное количество данных, которые должны обрабатываться c целью:  Разработки витрин данных и моделей машинного обучения,  Подготовки регулярной аналитической и управленческой отчетности,  Поддержки регулярных бизнес-операций,  Проведения Ad hoc анализа.  Разрабатываемая нами информационная платформа – высоконагруженное решение, призванное обеспечить достижение всех этих целей. Основные задачи сотрудника на данной позиции Проектировать и разрабатывать потоки для загрузки данных в хранилище Проектировать и реализовывать слои детальных данных Создавать витрины для отчетности и для моделей машинного обучения Обязательные навыки Знание SQL, PL/SQL или PL/pgSQL Опыт работы с любой промышленной ETL-системой Опыт работы с популярными РСУБД (Greenplum, Oracle, PostrgeSQL) Желательные навыки Опыт работы с CI/CD решениями на базе Jenkins и Bitbucket/Git Опыт работы с хранилищем данных (DWH) Опыт работы с любой промышленной ETL-системой Знакомство с экосистемой Hadoop Готовность работать в рамках формальных процессов Опыт работы с Data Vault Знание основ администрирования ОС Linux Условия Официальное оформление в аккредитованную IT-компанию Система ДМС Есть собственный учебный центр с тренингами по языкам программирования, soft skills, карьерному росту и другие Участие в крупных отраслевых мероприятиях Корпоративные скидки от компаний-заказчиков и многое другое","Greenplum,PostrgeSQL,SQL,Hadoop,DWH,ETL,PL/SQL,Teradata,Machine Learning",IBS,
9371,79244489,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
9373,79244492,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
9374,79244491,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
9378,79045942,Senior Site Reliability Engineer (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Since 2003, Murano has been developing software that simplifies and optimizes the customer's daily work and contributes to the digitalization of key US industries as well. Besides the client projects, the company maintains and develops its product based on the .NET platform: the world’s leading insurance submission, application, and policy management system, which is used by more than half of independent insurance agencies in the United States. Murano's head office locates in Los Angeles, and its team works from different cities and countries worldwide. This vacancy is opened on our outsourcing project. Project of our client produces a complete view of the health customer, to unlock and activate health insights in order to revolutionize health decision-making in real time. Through machine learning and programmatic automation, the company interprets the hard-to-read signals of the health journey to understand the connection points between relevance and engagement. This is achieved by unifying real-time Digital Determinants of Health, offline and clinical data to create a unique and precise view of the health ecosystem that refines, improves and increases its view over time. What you’ll be doing: Deploying, configuring, monitoring and maintaining multiple big data stores, across multiple datacenters. Perform planning, configuration, deployment and maintenance work relevant to the environment. Managing the large-scale Linux infrastructure to ensure maximum uptime. Developing and documenting system configuration standards and procedures. Performance and reliability testing. This may include reviewing configuration, software choices/versions, hardware specs, etc. Advancing our technology stack with innovative ideas and new creative solutions. Who are you: Collaboration is in your DNA. You enjoy contributing to a mutual cause, that is why you know when the team succeeds, you succeed. You are always looking for ways to grow your skills. You are hungry to learn new technologies and share your insights with your team. You like a big picture perspective and also digging into the fine details. You can think strategically but also dive into complex systems and break them down and build them back better. You are a proactive problem solver. You are irked by an unreliable infrastructure and your first instinct is to find ways to fix it. What you'll need: Multi-faceted Alluxio and Hadoop understanding, including the Kerberos, for data storage and Trino, Hive, and Impala for data retrieval. Experience managing Kafka clusters on Linux. Thorough understanding of Linux (we use CentOS in production). Experience administering SQL/NoSQL databases (we use MySQL, PostgreSQL, MongoDB). Any scripting language (Python/Ruby/Shell etc). Understanding of basic networking concepts (TCP/IP stack, DNS, CDN, load balancing). Must be willing and able to East Coast U.S. hours 9am-6pm EST Bonus, but not required: Ability to work with Cassandra cluster from installation through troubleshooting and maintenance. Puppet configuration management tool. Experience with scalable infrastructure monitoring solutions such as Icinga, Prometheus, Graphite, Grafana and ELK. Experience with container technologies such as Docker and Kubernetes. Train/mentor junior-level staff. Experience in AdTech or High-Frequency Trading. Experience with Security-related best practices. Waiting for your CV!",Английский — C1 — Продвинутый,Murano Software,
9380,77949666,Middle Data Scientist (Северсталь Диджитал),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Мы продолжаем развивать наше ML направление в Северсталь Диджитал, наши модели управляют обжиговыми машинами, помогают производить чугун, определяют неисправное оборудование по изображению и данным с датчиков, детектируют поверхностные дефекты листа, управляют скоростью трех ключевых агрегатов на плоском прокате, в том числе с помощью Reinforcement Learning, прогнозируют рыночные цены на сталелитейную продукцию, экономят мазут и электроэнергию. Наш технологический стек включает в себя: Python 3 со стандартными DS пакетами (numpy, pandas, scikit-learn, xgboost/lightgbm Технологии Big Data (Hadoop, Hive, Spark) Git, Graylog, Grafana, Kubernetes, Docker В твои обязанности будет входить: Собирать данные из внутренних баз данных и работать с внешними источниками информации Применять анализ данных и алгоритмы машинного обучения для решения производственных задач Реализация и поддержка end-to-end продакшн решений (в команде с дата-инженером и разработчиком) Тесное общение с технологами на производстве Взаимодействие с заказчиком и презентация продукта Со временем возможно менторство над 1-2 джунами Командировки на производство в г. Череповец ( не более 10%). Тебе нужно уметь: Писать понятный и воспроизводимый код Формулировать и проверять на данных статистические гипотезы Подбирать предпосылки и алгоритм машинного обучения, соответствующие поставленной бизнес-задаче, выбирать метрики и оценивать работу алгоритма Трансформировать бизнес-постановку задачи в математическую формулировку и код Ожидаем: Опыт самостоятельной реализации DS проектов и готовность о них рассказать Опыт дизайна экспериментов и проведения пилотных испытаний Плюсом будет: Опыт работы с промышленными данными Опыт работы с алгоритмами оптимизации (пакеты gurobi/cplex/pulp) Опыт работы с семействами моделей ARIMA-GARCH Участие в ML-соревнованиях Знание Tensorflow/Pytorch. Тебе нужно знать: Python и пакеты нашего стека SQL на уровне запросов средней сложности Теорию вероятностей и математическую статистику Принципы работы алгоритмов машинного обучения (линейная регрессия, логистическая регрессия, деревья решений, случайный лес, градиентный бустинг, нейронные сети и др.) Мы предлагаем: Работу в профессиональной команде, которая готова делиться знаниями и опытом Офис на м. Войковская, МЦК Балтийская или МЦД Красный Балтиец или удаленная работа График работы 5/2 (40 часов в неделю), гибкое начало дня Официальное трудоустройство Корпоративную мобильную связь, медицинскую страховку и страхование жизни Современное рабочее пространство и уютные зоны отдыха Спортзал и велопарковку Оплату дистанционных курсов и участия в профессиональных конференциях.","Python,Tensorflow,SQL,Machine Learning,Git",Северсталь. IT & Digital,
9381,78998578,Data Insight Analytics Expert,з/п не указана,3–6 лет,"Полная занятость,полный день","Your responsibilities: Lead Segmented Execution deployment & value delivery of the use case core features Partner with Commercial managers, Regional Marketing managers, Regional General Sales managers to identify and ensure adaptation of regional specifics Deliver outlets segmentation based on external data sources and drive changes in execution strategy & resources allocation Lead internal advancements of market situation modelling and deriving insights from data analysis Design and implement novel Data Mining/Machine Learning approaches to structure and identify the key business problems that data and analytics can solve Develop and own Power BI reporting & Dashboarding Communicate solutions to non-technical teams Support data inventory and data management processes Requirements: University degree (business, math, economics, finance, statistic, science) English B2+ 3+ years experience of hands-on experience in big data analytics over big data (Data Engineering and Optimization experience) Power BI experienced user or significant experience in other data visualization platform Experience with geospatial data and relevant applications (QGIS etc.) MS Office – deep knowledge incl excel power functions: pivot/query, power point Experience in change management related to Big Data implementation is desirable Exceptional programming skills with Python and/or R Solid knowledge of the Azure Data bricks platform and the overall Azure Cloud environment Solid knowledge of Hadoop, Spark, Hive, Power BI and/or other visualization tools. SQL Server experience – ability to write complex queries We offer: Competitive salary Good opportunities for professional and career growth within great company Flexible working hours: 9.00 - 17.30 (8-16.30, 10-18:30 as the options) Internal educational courses and trainings Social package: Medical insurance, mobile compensation, corporate discounts","Python,Git,Big Data,Английский язык,Hive,Английский — C1 — Продвинутый",Мултон Партнерс,
9383,77949850,Middle Data Scientist (Северсталь Диджитал),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Мы продолжаем развивать наше ML направление в Северсталь Диджитал, наши модели управляют обжиговыми машинами, помогают производить чугун, определяют неисправное оборудование по изображению и данным с датчиков, детектируют поверхностные дефекты листа, управляют скоростью трех ключевых агрегатов на плоском прокате, в том числе с помощью Reinforcement Learning, прогнозируют рыночные цены на сталелитейную продукцию, экономят мазут и электроэнергию. Наш технологический стек включает в себя: Python 3 со стандартными DS пакетами (numpy, pandas, scikit-learn, xgboost/lightgbm Технологии Big Data (Hadoop, Hive, Spark) Git, Graylog, Grafana, Kubernetes, Docker В твои обязанности будет входить: Собирать данные из внутренних баз данных и работать с внешними источниками информации Применять анализ данных и алгоритмы машинного обучения для решения производственных задач Реализация и поддержка end-to-end продакшн решений (в команде с дата-инженером и разработчиком) Тесное общение с технологами на производстве Взаимодействие с заказчиком и презентация продукта Со временем возможно менторство над 1-2 джунами Командировки на производство в г. Череповец ( не более 10%). Тебе нужно уметь: Писать понятный и воспроизводимый код Формулировать и проверять на данных статистические гипотезы Подбирать предпосылки и алгоритм машинного обучения, соответствующие поставленной бизнес-задаче, выбирать метрики и оценивать работу алгоритма Трансформировать бизнес-постановку задачи в математическую формулировку и код Ожидаем: Опыт самостоятельной реализации DS проектов и готовность о них рассказать Опыт дизайна экспериментов и проведения пилотных испытаний Плюсом будет: Опыт работы с промышленными данными Опыт работы с алгоритмами оптимизации (пакеты gurobi/cplex/pulp) Опыт работы с семействами моделей ARIMA-GARCH Участие в ML-соревнованиях Знание Tensorflow/Pytorch. Тебе нужно знать: Python и пакеты нашего стека SQL на уровне запросов средней сложности Теорию вероятностей и математическую статистику Принципы работы алгоритмов машинного обучения (линейная регрессия, логистическая регрессия, деревья решений, случайный лес, градиентный бустинг, нейронные сети и др.) Мы предлагаем: Работу в профессиональной команде, которая готова делиться знаниями и опытом Офис на м. Войковская, МЦК Балтийская или МЦД Красный Балтиец или удаленная работа График работы 5/2 (40 часов в неделю), гибкое начало дня Официальное трудоустройство Корпоративную мобильную связь, медицинскую страховку и страхование жизни Современное рабочее пространство и уютные зоны отдыха Спортзал и велопарковку Оплату дистанционных курсов и участия в профессиональных конференциях.","Python,Tensorflow,SQL,Machine Learning,Git",Северсталь. IT & Digital,
9384,79089818,Senior Data Scientist в направление рекламной платформы RnD (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior Data Scientist в направление рекламной платформы RnD Описание продукта: Рекламная платформа МТС включает в себя: 1. Программатик. DSP платформа, которая подключена ко всем популярным SSP и рекламным сетям. 2. Медиапланировщик. нструмент планирования маркетингового бюджета, определение наилучшего сплита как по основным каналам, так и внутри каналов. 3. Система аналитики. Аналитика трафика и событий. Построение MTA (Multi touch atributuon), сквозная аналитика. Обязательно: глубокое понимание статистических подходов и методов (регрессия, свойства распределений, оценка максимального правдоподобия, проверка гипотез и их правильное использование) и опыт их применения свободное владение основными библиотеками на Python (pandas, numpy, matplotlib, seaborn, etc.) коммерческий опыт применения классических алгоритмов машинного обучения (LR, RF, XGBoost/LGBM/CatBoost), понимание их преимуществ, недостатков и ограничений высокий уровень владения SQL опыт в распределённых/параллельных вычислениях с помощью следующих технологий: Hadoop, Spark, Dask и другие умение общаться с бизнес-заказчиком, объяснять простым языком полученные результаты и процесс работы алгоритма Желательно: опыт работы в медиа, понимание сферы digital рекламы стремление вникнуть в бизнес соответствующей отрасли диплом в области компьютерных наук, статистики, прикладной математики или другой релевантной анализу данных области английский язык (устный и письменный) на уровне Upper Intermediate опыт применения deep learning алгоритмов в NLP, CV направлениях (для подключения к R&D задачам) Что предстоит делать? собирать и обрабатывать данные из хранилищ компании подготавливать витрины данных, необходимые для разработки моделей машинного обучения. Задача частично закрывается data engineering специалистами разрабатывать модели машинного обучения как для MVP проектов, так и решений, выводящихся в production разрабатывать методологии применения различных ML алгоритмов для решения задач команды. подготавливать рекомендации по внедрению методологий и использованию продуктов для внутренних заказчиков компании проводить консультации и обмениваться идеями с младшими специалистами и коллегами по команде Стек технологий: Python, Pandas, Numpy, Matplotlib, Seaborn, LR, RF, XGBoost/LGBM/CatBoost, Hadoop, Spark, Dask. Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные и международные конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Python,SQL,Математическая статистика,Big Data,Machine Learning,NLP,Hadoop,Spark,Pandas,Numpy,Matplotlib,Seaborn",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
9395,78381745,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Контур — экосистема для бизнеса. Каждая четвертая компания в стране решает бизнес-задачи, используя наши сервисы. Мы автоматизируем документооборот, бухгалтерию и отчетность. Делаем эти процессы простыми и быстрыми, а сервисы — удобными для клиента.  Data Science в Контуре помогает оптимизировать внутренние процессы и добавляет ценности в продукты. Например, чат-бот Сирена экономит около 25% времени консультантов техподдержки в чатах, а технология распознавания речи обрабатывает тысячи лет записей в год. Мы постоянно следим за прогрессом в технологиях и разрабатываем новые методы и алгоритмы, чтобы сделать инновации доступными для использования в продуктах и процессах компании. В Центре искусственного интеллекта представлены разные роли: есть дата сайентисты, разработчики и аналитики данных, девопсы, QA-специалисты, системные аналитики, проджекты и продакт-менеджеры. Свое железо (V100/A100) и асессорская служба позволяют нам не ограничивать себя при работе с чувствительными данными, а также крутая инфраструктурная команда создает, улучшает и развивает инструменты MLOps на любой вкус от ресерча до прода. Мы ищем Senior Data Scientist в направление оптимизации процессов продаж и маркетинга. Нам нужен человек, который разовьет направление продаж и маркетинга с точки зрения машинного обучения: составит дорожную карту применения Data Science в процессах продаж согласует с бизнесом и приоритизирует сам проверит и доведет до продакшена гипотезы, и, как результат, повысит эффективность продаж и маркетинга. Примеры задач, которые уже решали Речевая аналитика (после ASR): оценка эффективности работы менеджеров по продажам на основании анализа текста звонков. Работа с конверсией: оценка вероятности оплаты клиентом счета по сделке по набору параметров. Что ожидаем от вас Опыт работы в аналогичной роли от двух лет. Опыт решения задач и понимание работы алгоритмов NLP и Classic ML. Умение общаться на языке заказчика, погружаться в продуктовый контекст. Умение работать в команде. Опыт декомпозиции, приоритизации больших задач. Опыт доведения задач до продакшена. Желательно иметь опыт доведения задачи от формулировки на языке бизнеса до прода (от начала до конца) работы с высокой неопределенностью: прокапывание проблематики, осознанный выбор решения. Технологии Python, SQL. GitLab. Docker, Kubernetes, AirFlow. Classic ML, языковые модели (BERT etc.). Мы предлагаем Зарплата зависит от ваших технических знаний и навыков. Пересматриваем ее два раза в год. Нам важно, чтобы вам было комфортно: непринципиально, где вы находитесь и во сколько начинаете рабочий день, главное – выполненные задачи. Умеем работать в команде, находясь в разных точках мира (Таллин, Ташкент, Астана, Лимассол, Екатеринбург, Москва и т. д.). Мы поддерживаем участие в конференциях, митапах и обучающих проектах. Наши деврелы помогут написать статью на Хабр, снять видео или подготовиться к выступлению на конференции. У нас сильное инженерное сообщество: регулярно проводим техническую конференцию КонфУР, обмениваемся опытом между командами, проводим дизайн-ревью с экспертами в разных технологиях. Всегда найдется, с кем посоветоваться. А еще у нас есть инженерный совет. Он придумывает и реализует проекты, которые улучшают жизнь инженеров в компании. Максимум горизонтальных связей в коллективе, чтобы быстрее договариваться и решать рабочие задачи. Присоединяйтесь :)","NLP,Machine Learning,Python,Data Science",Контур,
9397,78062870,GCP Data Architect/Team Lead,от 5 000 до 6 000 USD на руки,более 6 лет,"Полная занятость,полный день",,,E-book Applications,
9399,78581500,GCP Data Architect/Team Lead,до 6 000 USD на руки,более 6 лет,"Полная занятость,полный день","Мы — консалтинговая компания по разработке программного обеспечения. Работаем с новаторами в области технологий, помогая им воплощать свои идеи в жизнь. В течение 5 лет мы были увлечены разработкой технологий машинного обучения и искусственного интеллекта для управления данными и курирования контента для приложений EdTech, IoT и розничной торговли. Мы ищем архитектора данных GCP/руководителя группы для одного из самых интересных проектов в области биоинформатики, поддерживающего научное сообщество или генетиков, находящихся на передовой генетических исследований одноклеточных. Это роль, где Вы будете использовать свои навыки инженера данных и Google Cloud Platform для разработки и внедрения современной, масштабируемой платформы данных для нашего научного сообщества и проекта Human Cell Atlas.  Мы гарантируем будущему коллеге: Стабильный конкурентоспособный доход Официальное оформление в международную компанию - Consulting Agteement Полностью белую заработную плату, выплачивается без задержек ндексацию заработка График работы 5/2 с плавающим началом рабочего дня Полностью удаленный формат работы из любой точки мира Среду полностью свободную от бюрократии и микроменеджмента нтересные инженерные задачи, которые позволят раскрыть ваш креатив и потенциал Возможность повлиять на продукт на его первых стадиях и стать частью яркой команды настоящих профи своего дела.  Чем предстоит заниматься: Выступать в качестве эксперта в области инженерии данных и технологий данных GCP. Работать с командами клиентов и учеными над проектированием и внедрением моделей данных для транзакционных и больших данных в качестве исходных данных для обработки Machine Learning. Работать с методами Agile и DevOps и подходами к реализации в процессе доставки. Оценивать поддержку новых технологий и специфических для науки случаев использования.  Мы ожидаем от кандидата: Опыт работы в IT проектах от 6 лет. Опыт проектирования и построения конвейеров данных с использованием сервисов GCP, таких как BigQuery, Dataflow, Dataproc, Pub/Sub, Cloud Functions и т.д. Опыт использования Python или Java для обработки данных и написания сценариев Опыт управления командой и руководства членами команды. Практические навыки в области анализа кода, проектирования архитектуры, кодирования и т.д. Английский язык на уровне C1/B2.  Если в этом описании Вы увидели себя, смелее направляйте ваше резюме! (Ссылка на Телеграмм ниже)","Architecture,Administrating Skills,Английский — C1 — Продвинутый,SQL,Python,Java,Machine Learning,Data Science,Data Analysis,Deep Learning,Big Data,Team management,NoSQL,ML,Fluent English,Английский — C1 — Продвинутый",Wanted,
9405,77818891,Data Scientist middle+/senior (Транскодинг),з/п не указана,3–6 лет,"Полная занятость,полный день","Сейчас в Okko создается новый продукт – Видеоплатформа. Это B2B-инструмент для работы с видеоконтентом. Ключевое значение для разработки продукта имеют обработка видео (транскодинг) и оптимизация процессов, связанных с ней. В команду транскодинга мы ищем человека, который сможет сформировать и вывести ML-решения для улучшения продукта, а также найдет баланс между математическими способами решения задач и ML. Обязанности: исследование применимости различных алгоритмов в рекомендательной системе и в системах с применением компьютерного зрения моделирование входных данных интеграция исследованных моделей в системах проведение экспериментов с созданными моделями автоматизация процессов подготовки данных оптимизация потребления ресурсов сервисами, а также повышение утилизации ресурсов и применения ML интеграция сервисов с распределенными системами (Базы данных, Очереди). Требования: высшее техническое/математическое образование знание математической статистики и высшей математики критичны для решения наших задач умение инициализировать новое направление от идеи и построения инфраструктуры до вывода решения в прод для конечных пользователей знание основ статистики понимание классических ML-алгоритмов способность анализировать статьи и имплементировать описываемые алгоритмы базовые знания о Сomputer Vision знание Python желателен опыт работы с видео, изображениями, с рекомендательными системами. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,Machine learning,Сomputer Vision",Okko,"Москва, Баррикадная, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с13"
9416,76491071,Middle+ Data Scientist на продукт Маркетолог (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Data Scientist на продукт Маркетолог Описание продукта: Маркетолог является 2-ым самым крупным В2В продуктом по выручке в МТС. Мы занимаемся не только классическим вариантом телеком-рекламы (sms, mms, обзвон), но также имеем собственную DSP и активно размещаемся в digital каналах. Модели помогают эффективнее таргетироваться на абонентов в различных каналах (dsp, sms, обзвон), тем самым повышая эффективность рекламных кампаний. Обязательно: знание python на продвинутом уровне (ds, ml библиотеки – sklearn/catboost, lgbtm) опыт работы с Docker и AirFlow опыт работы с Hadoop, Apache Spark, SQL сильные теоретические знания ML умение переложить бизнес задачу на язык анализа данных, умение простым языком объяснять сложные вещи, интерпретировать результат (придется работать, как с внешними, так и с внутренними заказчиками) опыт работы в телекоме, маркетинге, рекламе Что предстоит делать? строить модели предсказания поведения пользователя работать с базами данных (проводить проверку и приемку витрин для дальнейшей работы по части ML) документировать процессы и процедуры, связанные с разработкой моделей проводить А/В тесты, дизайн экспериментов, введение культуры проведения A/B тестов в продукте писать ТЗ для инженеров Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Docker,AirFlow,Hadoop,SQL,Machine Learning,Маркетинг,Spark,sklearn,Catboost,ML,Big Data,Python",МТС,
9417,76139031,Senior Data Engineer (Scala),з/п не указана,3–6 лет,"Полная занятость,полный день","MY.GAMES is a leading European publisher and developer headquartered in Amsterdam, with over one billion registered users worldwide. War Robots, Hustle Castle, Rush Royale, Left to Survive, Tacticool, and many other games were developed and produced by MY.GAMES. The company creates and publishes games for PC, consoles, and mobile devices.  We have more than a dozen game development studios united under MY.GAMES, as well as MGVC, a global game investment company. The global MY.GAMES and MGVC partner network comprises over 40 studios.  Our studios are professional teams with their own unique atmosphere. We’re united by a common passion: transforming our enthusiasm and talent into fabulous games. We create engaging products which captivate millions of people all over the world. What you will do: Together with a team of ML engineers, participate in the development of machine learning services for games Improve the reliability and fault tolerance of the recommendations calculation serviceSupport existing ETL processes Participate in the support and improvement of ML services infrastructure Participate in the development of production code in terms of loading and processing data What you need to succeed: Experience with Scala or Java Experience processing large amounts of data in realtime or near realtime Docker knowledge Profound knowledge of SQL Experience with message brokers, such as Kafka, RabbitMQ Ability to optimize data processing and loading Knowledge of Linux, Bash Nice to have: Experience in Python development using OOP concepts Understanding of the Hadoop principles, knowledge of Hive and Spark Experience with Airflow, Kubernetes Experience with Tarantool Knowledge of Lua Understanding of machine learning principles What we offer: Work remotely from all around the world Collaborative working atmosphere in an internal game dev community that unites more than 40 in-house and partner studios A strong team of specialists across different areas — access unique expertise and professional knowledge Possibility to experiment and work on interesting tasks with ambitious goals — we have all resources to implement new ideas Create great games and win the hearts of players Push the boundaries of the game industry and lead the way forward","Java,SCALA,Big Data,hadoop,Spark streaming",MY.GAMES,
9422,78663746,Data Scientist / ML-инженер (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Мы ищем Data Scientist’ов и ML-инженеров в следующие продукты: Рекламная платформа RnD (Senior) В настоящий момент в команде основной фокус бизнес задач приходится на разработку маркетинговых продуктов – применение алгоритмов классификации, регрессии и рекомендательных систем для оптимизации медиа инвестиций. Перечень инициатив очень широкий – от задач стратегического планирования медиа бюджетов до оптимизации биддинговых стратегий в перформанс инструментах. МТС Travel (Senior/Lead) MTS Travel - молодая дочерняя компания МТС, которая создает и развивает сервисы для путешественников по России и миру. Ее цель - стать №1 на рынке онлайн-бронирования отелей в РФ. MTS Big Data помогает сервису создавать и усиливать конкурентные преимущества через работу с большими данными. Рекомендательная Платформа - Строки ( Senior) Команда занимается созданием персональных рекомендаций по жанрам для текстовых и аудио книг. В перспективе планируется сделать лучшие кросс-контентные рекомендательные модели, такие как подбор музыки по ходу прочтения книги, анализ текста книги, выделение облака тегов и эмоциональную окраску текста за счет добавления музыки, соответствующей настроению текста. Scoring Platform (Senior) Мы создаем скоринговую платформу, которая должна сократить и упростить путь от сбора данных до получения нашим клиентом вероятностной оценки в виде сервиса в личном кабинете. Маркетолог (Senior) Маркетолог - self service продукт. Маркетолог является самым крупным В2В продуктом по выручке в МТС. Мы занимаемся не только классическим вариантом телеком-рекламы, но также имеем собственный DCP, каналы, my target. Мы делаем модели, которые помогают клиентам сократить время и улучшить показатели. Обязательно: опыт работы от 2-х лет в области анализа данных и машинного обучения понимание, как работают ML-алгоритмы и не будете тратить время на эксперименты с заведомо плохими решениями понимание, когда нужно остановиться и использовать вместо ML более простые и быстрые подходы у вас продвинутые знания Python, в т.ч. основных ml-библиотек умение делать препроцессинг данных на SQL или PySpark умение работать с git есть базовые навыки работы в Linux/Unix знание минимум один из классических языков C, Java, Scala, C/C++/C# и есть опыт программирования в прошлом опыт вывода ml-решений в продакшн Что предстоит делать? выгружать и готовить/обрабатывать данные (находить аномалии и инсайты) перебирать гиперпараметры ml-моделей, пока кросс-валидация не даст нормальный результат :) дорабатывать ml-модели из стандартных библиотек проверять бизнес гипотезы в offline и готовить дизайн A/B тестов доводить модель до прода совместно с разработчиками Что вы найдете в команде Big Data? Стек технологий: работаем с данными на классическом hadoop-стеке (Spark, Hive) разрабатываем на python3: R&D делаем в Jupyter, продуктивизируем в PyCharm обучаем модели на отдельных мощных машинах с видеокартами Tesla V100 используем собственные разработки для скоринга больших данных и MLFlow для экспериментов храним код в gitlab, CI/CD в Jenkins, процессы запускаем в Airflow Команда: в команде Data Science сейчас 30 человек (во всей Big Data МТС более 300 человек). Все DS поделены на группы со своими лидами - есть группа рекомендательных систем, скоринга и другие. Каждую неделю мы обмениваемся опытом на совместных синках. DS работают в продуктах со своей автономной командой, в которой есть все роли: аналитики, DE, DS, разработчики, девопсы, менеджеры продукта. Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Python,Machine Learning,Data Science,Математическая статистика,Git",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
9423,78668022,Data Engineer/ETL developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Проект: Наша agile-команда создает информационную платформу в интересах Департамента Глобальных Рынков (ДГР). ДГР – предоставляет корпоративным и розничным клиентам широкий спектр продуктов и услуг на локальных и зарубежных финансовых рынках. Этот бизнес потребляет и порождает огромное количество данных, которые должны обрабатываться c целью: • поддержки регулярных бизнес-операций • проведения Ad hoc анализа • подготовки регулярной аналитической / управленческой отчетности • разработки моделей машинного обучения, направленных на решение широкого спектра прикладных задач прогнозирования, классификации, кластеризации, выявления поведенческих паттернов и отклонений от них, сентимент-анализ и т.д. Разрабатываемая нами информационная платформа – высоконагруженное решение, призванное обеспечить достижение всех этих целей. Текущий инструментальный стек платформы: Python, Java, Informatica PowerCenter, Kafka, AirFlow, InfluxDB, kdb+, OneTick, MS SQL, PostgreSQL, MongoDB, Grafana, Qlik Sense, Kibana, ELK, OpenShift, Python ML/DL libraries, PySpark, TensorFlow Обязанности: Проектировать и разрабатывать потоки для загрузки данных в хранилище Проектировать и реализовывать слои детальных данных Проектирование и разработка корпоративной аналитической платформы (ПКАП) Системная разработка, поддержка и оптимизация ETL-процессов Поддержка промышленной эксплуатации разработанных решений Поддержание технической документации в актуальном состоянии Разворачивание ML моделей и проверка работоспособностей Требования: Опыт работы с любой промышленной ETL-системой Знание SQL, PL/SQL или PL/pgSQL Опыт работы с одной из РСУБД (Greenplum, Teradata, Oracle, PostrgeSQL) Опыт работы с ML достаточный, чтобы вписывать созданный ML в ETL систему Опыт работы с Python от 1 года Условия: Наша компания является аккредитованной в Минцифры Современный подход к обучению и развитию сотрудников Конкурентная зп ндивидуальный план развития по итогам регулярных аттестаций В качестве приятных бонусов: ДМС со стоматологией для сотрудников и их родственников, обучение и сертификация, скидки на курсы и фитнес, разговорные клубы на английском языке и др. активности Трудоустройство в штат на бессрочный трудовой договор","SQL,Python,СУБД,ETL,PostgreSQL,Teradata,ML,Greenplum,Oracle Pl/SQL,Machine Learning",IBS,
9435,77856030,GCP Data Architect/Team Lead,от 5 000 до 6 000 USD на руки,более 6 лет,"Полная занятость,полный день","IMPORTANT!!! We need a specialist who is Senior/Lead level and has 6+ years of experience! We need a specialist who is practically fluent (C1/B2) in spoken English! Please do not apply if your skills are lower. Please save your and our time! Thank you! DESCRIPTION We are looking for a GCP Data Architect/Team Lead on one of the most exciting projects in the bioinformatics domain supporting the scientific community or geneticists at the forefront of single-cell genetic research. This is a role where you will use your data engineering and Google Cloud Platform skills to design and implement a modern, scalable data platform for our single-cell scientific community and project Human Cell Atlas. As a GCP Data Architect, you will: Act as a subject matter expert in data engineering and GCP data technologies. Work with client teams and scientists to design and implement data models for transactional and big data environments as an input into Machine Learning processing Work with Agile and DevOps techniques and implementation approaches in the delivery Assess supporting new technologies and science-specific use cases To be successful in this role, you should have: Experience in designing and building data pipelines using GCP services such as BigQuery, Dataflow, Dataproc, Pub/Sub, Cloud Functions etc. Experience in working with SQL and NoSQL databases such as Cloud SQL, Cloud Spanner, Firestore etc. Experience in using Python or Java for data processing and scripting Knowledge of data governance principles and best practices Experience in driving team and guiding team members. Practical skills in code review, architecture design, coding, etc.Experience in driving team and guiding team members. Practical skills in code review, architecture design, coding, etc.","Architecture,Python,SQL,Java,Machine Learning,Data Science,Data Analysis,Deep Learning,Big Data,Team management,Fluent English,NoSQL,ML,Administrating Skills,Английский — C1 — Продвинутый",E-book Applications,
9440,78413803,Менеджер по анализу больших данных (Big data),з/п не указана,1–3 года,"Полная занятость,полный день","Кого мы ищем: В нашу дружную команду BDO мы ищем человека с живым умом и непреодолимым желанием приносить пользу. Если тебе нравится собирать и анализировать информацию, находить зависимости, придумывать улучшения и добиваться результата – у нас все это есть! Что мы предлагаем: Выдвигать и проверять гипотезы, внедрять улучшения, оценивать их эффективность Систематизировать и анализировать полученную информацию Много работы и поле для свершений Работать с командой амбициозных и увлеченных людей Работать в компании, где тебя слышат и ценят твой вклад На практике это значит, что ты будешь решать следующие задачи: Поддержка ключевых направлений: антифрод, качество продаж, гео-отчётность сегментация абонентской базы, исследование пользовательского поведения Оптимизация регулярных процессов: развитие существующих метрик, описание и формирование новых Операционная поддержка бизнес-заказчиков: решение их запросов, развитие успешных кейсов Монетизация внутренних и внешних проектов: разработка методологии, описание, реализация алгоритмов, составление технического задания на автоматизацию Описание требований для привлечения новых продуктивных источников данных, сопровождение процесса внедрения и приёмки Автоматизация проектов под задачи других команд Что для нас важно в тебе: Опыт работы с большими объёмами неструктурированных данных Отличное знание SQL Опыт работы в практических проектах по обработке больших данных в роли Data Science / Data Engineer / Data Analyst Владение Python / R Отличные знания пакета MS Office Не обязательно, но будет очень здорово, если ты: Опыт в телекоме и/или банковской сфере Владение инструментами из стека Hadoop: понимание разницы между Hive и Impala использование в работе Spark / PySpark / Scala Опыт ETL и организации обработки больших потоков данных Практический опыт в data mining, text mining, machine learning Опыт работы с web-crawling и технологиями индексации Опыт разработки БФТ, внедрения продуктов Что есть у нас и чем готовы делиться: Полное соответствие ТК РФ ндексируемая белая заработная плата, годовые бонусы Дополнительное медицинское страхование Компенсация затрат на мобильную связь Дополнительные материальные выплаты (пособия при рождении ребёнка, вступлении в брак и т. п.) Компенсация занятий спортом через год работы Скидки от партнёров Релокационный пакет при переезде из другого города Возможность удалённой работы Бесплатное прохождение курсов на одной из основных обучающих онлайн платформ нтересная работа в стабильной компании Возможности профессионального и карьерного роста Уникальная возможность работы с большим разнообразием аналитических задач Витаминно-фруктовой заряд по вторникам Зеленый свет для новых идей и предложений: мы часто делаем то, на что другие не отваживаются Современный офис класса «А» с развитой инфраструктурой (магазины, кафе, фитнес и т. д.) в пяти минутах пешком от метро Румянцево Так как офис очень просторный, есть возможность доехать до коллег на самокате","Python,Data Mining,SQL,Бизнес-анализ,MS SQL,Hadoop,Teradata,DWH,ORACLE,R,Sas",Tele2,"Новомосковский административный округ, Румянцево, Киевское шоссе, 22-й километр, 6с1"
9445,78381741,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Контур — экосистема для бизнеса. Каждая четвертая компания в стране решает бизнес-задачи, используя наши сервисы. Мы автоматизируем документооборот, бухгалтерию и отчетность. Делаем эти процессы простыми и быстрыми, а сервисы — удобными для клиента.  Data Science в Контуре помогает оптимизировать внутренние процессы и добавляет ценности в продукты. Например, чат-бот Сирена экономит около 25% времени консультантов техподдержки в чатах, а технология распознавания речи обрабатывает тысячи лет записей в год. Мы постоянно следим за прогрессом в технологиях и разрабатываем новые методы и алгоритмы, чтобы сделать инновации доступными для использования в продуктах и процессах компании. В Центре искусственного интеллекта представлены разные роли: есть дата сайентисты, разработчики и аналитики данных, девопсы, QA-специалисты, системные аналитики, проджекты и продакт-менеджеры. Свое железо (V100/A100) и асессорская служба позволяют нам не ограничивать себя при работе с чувствительными данными, а также крутая инфраструктурная команда создает, улучшает и развивает инструменты MLOps на любой вкус от ресерча до прода. Мы ищем Senior Data Scientist в направление оптимизации процессов продаж и маркетинга. Нам нужен человек, который разовьет направление продаж и маркетинга с точки зрения машинного обучения: составит дорожную карту применения Data Science в процессах продаж согласует с бизнесом и приоритизирует сам проверит и доведет до продакшена гипотезы, и, как результат, повысит эффективность продаж и маркетинга. Примеры задач, которые уже решали Речевая аналитика (после ASR): оценка эффективности работы менеджеров по продажам на основании анализа текста звонков. Работа с конверсией: оценка вероятности оплаты клиентом счета по сделке по набору параметров. Что ожидаем от вас Опыт работы в аналогичной роли от двух лет. Опыт решения задач и понимание работы алгоритмов NLP и Classic ML. Умение общаться на языке заказчика, погружаться в продуктовый контекст. Умение работать в команде. Опыт декомпозиции, приоритизации больших задач. Опыт доведения задач до продакшена. Желательно иметь опыт доведения задачи от формулировки на языке бизнеса до прода (от начала до конца) работы с высокой неопределенностью: прокапывание проблематики, осознанный выбор решения. Технологии Python, SQL. GitLab. Docker, Kubernetes, AirFlow. Classic ML, языковые модели (BERT etc.). Мы предлагаем Зарплата зависит от ваших технических знаний и навыков. Пересматриваем ее два раза в год. Нам важно, чтобы вам было комфортно: непринципиально, где вы находитесь и во сколько начинаете рабочий день, главное – выполненные задачи. Умеем работать в команде, находясь в разных точках мира (Таллин, Ташкент, Астана, Лимассол, Екатеринбург, Москва и т. д.). Мы поддерживаем участие в конференциях, митапах и обучающих проектах. Наши деврелы помогут написать статью на Хабр, снять видео или подготовиться к выступлению на конференции. У нас сильное инженерное сообщество: регулярно проводим техническую конференцию КонфУР, обмениваемся опытом между командами, проводим дизайн-ревью с экспертами в разных технологиях. Всегда найдется, с кем посоветоваться. А еще у нас есть инженерный совет. Он придумывает и реализует проекты, которые улучшают жизнь инженеров в компании. Максимум горизонтальных связей в коллективе, чтобы быстрее договариваться и решать рабочие задачи. Присоединяйтесь :)","NLP,Machine Learning,Python,Data Science",Контур,
9446,78381736,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Контур — экосистема для бизнеса. Каждая четвертая компания в стране решает бизнес-задачи, используя наши сервисы. Мы автоматизируем документооборот, бухгалтерию и отчетность. Делаем эти процессы простыми и быстрыми, а сервисы — удобными для клиента.  Data Science в Контуре помогает оптимизировать внутренние процессы и добавляет ценности в продукты. Например, чат-бот Сирена экономит около 25% времени консультантов техподдержки в чатах, а технология распознавания речи обрабатывает тысячи лет записей в год. Мы постоянно следим за прогрессом в технологиях и разрабатываем новые методы и алгоритмы, чтобы сделать инновации доступными для использования в продуктах и процессах компании. В Центре искусственного интеллекта представлены разные роли: есть дата сайентисты, разработчики и аналитики данных, девопсы, QA-специалисты, системные аналитики, проджекты и продакт-менеджеры. Свое железо (V100/A100) и асессорская служба позволяют нам не ограничивать себя при работе с чувствительными данными, а также крутая инфраструктурная команда создает, улучшает и развивает инструменты MLOps на любой вкус от ресерча до прода. Мы ищем Senior Data Scientist в направление оптимизации процессов продаж и маркетинга. Нам нужен человек, который разовьет направление продаж и маркетинга с точки зрения машинного обучения: составит дорожную карту применения Data Science в процессах продаж согласует с бизнесом и приоритизирует сам проверит и доведет до продакшена гипотезы, и, как результат, повысит эффективность продаж и маркетинга. Примеры задач, которые уже решали Речевая аналитика (после ASR): оценка эффективности работы менеджеров по продажам на основании анализа текста звонков. Работа с конверсией: оценка вероятности оплаты клиентом счета по сделке по набору параметров. Что ожидаем от вас Опыт работы в аналогичной роли от двух лет. Опыт решения задач и понимание работы алгоритмов NLP и Classic ML. Умение общаться на языке заказчика, погружаться в продуктовый контекст. Умение работать в команде. Опыт декомпозиции, приоритизации больших задач. Опыт доведения задач до продакшена. Желательно иметь опыт доведения задачи от формулировки на языке бизнеса до прода (от начала до конца) работы с высокой неопределенностью: прокапывание проблематики, осознанный выбор решения. Технологии Python, SQL. GitLab. Docker, Kubernetes, AirFlow. Classic ML, языковые модели (BERT etc.). Мы предлагаем Зарплата зависит от ваших технических знаний и навыков. Пересматриваем ее два раза в год. Нам важно, чтобы вам было комфортно: непринципиально, где вы находитесь и во сколько начинаете рабочий день, главное – выполненные задачи. Умеем работать в команде, находясь в разных точках мира (Таллин, Ташкент, Астана, Лимассол, Екатеринбург, Москва и т. д.). Мы поддерживаем участие в конференциях, митапах и обучающих проектах. Наши деврелы помогут написать статью на Хабр, снять видео или подготовиться к выступлению на конференции. У нас сильное инженерное сообщество: регулярно проводим техническую конференцию КонфУР, обмениваемся опытом между командами, проводим дизайн-ревью с экспертами в разных технологиях. Всегда найдется, с кем посоветоваться. А еще у нас есть инженерный совет. Он придумывает и реализует проекты, которые улучшают жизнь инженеров в компании. Максимум горизонтальных связей в коллективе, чтобы быстрее договариваться и решать рабочие задачи. Присоединяйтесь :)","NLP,Machine Learning,Python,Data Science",Контур,
9448,78358402,Middle/Senior Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Мы «КОРУС Консалтинг» - IT компания, предоставляем услуги по IT-консалтингу и автоматизации бизнес-процессов. мена всех наших заказчиков тебе точно известны - это крупнейшие игроки на российском рынке. А нас на сегодняшний день уже больше 1000 человек. Наш Департамент аналитических решений (ДАР) погружен во все современные направления в области работы с данными: внедрение BI-систем и систем аналитической отчетности проектирование хранилищ и витрин данных разработка в области продвинутой аналитики и больших данных применение прикладных продуктов с использованием Machine Learning внедрение решений в области управлениям данными (Data Governance, Data Quality). О проекте: для иностранной ритейл компании мы разрабатываем облачные хранилища данных и аналитические решения на облачных платформах, помогаем нашему заказчику изменять бизнес-процессы путем использования аналитики. Сейчас мигрируем все проекты на Yandex.Cloud. Наш текущий стек: Python, Spark, Hive, AirFlow как оркестратор, Yandex.Cloud. щем к себе в команду Middle/ Senior Data Engineer. Основные задачи: Формировать комплексные системы интеграции витрин данных Hadoop с использованием PySpark + AirFlow. Разрабатывать и оптимизировать ETL процессы. Погрузиться в специфику Yandex.Cloud (можем предоставить обучение). В работе поможет: Опыт разработки на Python от 2-х лет. Опыт разработки приложений с использованием инструментария экосистемы Hadoop (Spark Streaming, Hbase, Spark SQL, Kafka, Hive, Impala, Hue и т.д.) от 2-х лет. Опыт работы с любым ETL инструментом от 1 года (Airflow в приоритете). Опыт написания запросов для анализа и преобразования данных (на любой реляционной СУБД). Будет плюсом: Опыт работы с облачными платформами (Yandex.Cloud, MS Azure, AWS). Что мы можем предложить: Заработная плата: состоит из оклада и бонуса за выполнение проекта. Знаем рынок, готовы обсуждать оклад индивидуально по итогам тех. собеседования. Оформляем официально в штат компании. Гибкое начало рабочего дня - не смотрим на отработанные часы, смотрим на результат. Удаленный формат работы или гибридный график по желанию (удаленка/офис в Москве, Санкт-Петербурге или Ярославле). ндивидуальный план развития: подбираем задачи для роста экспертизы, выделяем бюджет на обучение, предоставляем курсы и программы обучения (в т.ч. английскому языку), предоставляем обратную связь, регулярно обсуждаем развитие. Полис ДМС, корпоративные тарифы на фитнес и др. Открытая корпоративная культура: каждый может предложить идею и получить возможности для ее реализации, мы помогаем друг другу, часто и весело проводим корпоративы. Минимум бюрократии и отчётов, а совещания только по необходимости и с чёткой программой. Приходи к нам в команду, будем вместе создавать крутые и полезные вещи!","Python,Hadoop,Hive,SQL,ETL,AWS,Spark,AirFlow,PostgreSQL",КОРУС Консалтинг,
9449,78265110,Senior Data Scientist,от 300 000 руб. на руки,3–6 лет,"Полная занятость,полный день",,,Сеть Партнерств,
9454,78347782,Data Analyst,до 4 000 USD на руки,1–3 года,"Полная занятость,полный день","At Neiro.ai we are developing entertainment products using generative AI Why us? We have a strong engineering team (ex-Samsung AI, Yandex, JetBrains, VK, PicsArt, VisionLabs) We have raised money from investors of Looksery and AI Factory (both acquired by Snap for $150M and $166M) We develop state-of-the-art generative AI (Lip-Sync, Text-to-speech, Voice Conversion, Dialogue Engine) and build unique entertainment products More than 500 000 000 video views on TikTok with content generated by our apps Your Responsibility Selection and development of a system for collecting, analyzing, and visualizing product metrics Create a plan for the integration of analytical systems with products Verify the correctness of analytical pipelines with developers Analyzing data from mobile analytics systems based on the user's behavior Own dashboards and maintain analytical pipelines Proactively propose product/marketing changes based on insights from data & setting up experiments Looking for anomalies/patterns/bugs in data and data collection pipelines Product metrics comparison with market benchmarks & competitors Key Qualifications: 1+ years of experience in Data Analyst / Product Analyst / Data Scientist roles Experience setting up mobile analytical systems SQL + Python Experience in A/B testing Excellent knowledge of statistics relevant to product analytics Intermediate analytical, verbal, and written English communication skills Fast learner. You should pick up and run with new workflows quickly Understanding of product metrics, unit economics, and principles of their optimization Proactivity and Autonomy It would be great to have Track record of collaborating with engineers on solving problems What do we offer The ability to understand how entertaining mobile products are built Direct work with C-level. Fast communication between UA/Mobile/Marketing teams. Our products are based on our own Generative AI (Computer Vision, Speech, NLP). Working with us is an excellent opportunity to understand how modern Machine Learning works. Opportunity to become Head of Analytics Salary & stock options to be discussed Remote work or Relocation package to Tbilisi Necessary equipment/software/education Our Process Test assignment HR interview  CEO Interview","Amplitude,Firebase,Google Analytics,Retention,Play Console,SQL,Python,Data Analysis,Английский — C1 — Продвинутый",Botan Investments,
9477,79244493,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
9478,79244487,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
9479,79244488,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
9480,79244494,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
9481,79244490,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
10059,78083054,Project manager Big Data,з/п не указана,3–6 лет,"Полная занятость,гибкий график",,,"Beeline, ТМ",
10604,78447491,Product Owner/Менеджер продукта (Big Data),з/п не указана,1–3 года,"Полная занятость,полный день","Лента — третий по выручке в России ритейлер (>400 млрд. руб. в год). Мы в департаменте BIG DATA Ленты строим внутренние продукты, которые зарабатывают деньги и улучшают опыт наших покупателей. BIG DATA в Ленте создана недавно и растет семимильными шагами, так что у нас есть отличные условия для карьерного и профессионального роста, а также возможность создать коммерческие продукты с высоким value для бизнеса. Мы ищем сильных продакт-менеджеров, которые помогут нам сделать удобные и полезные ML продукты. Тебя ждут следующие задачи: Формировать стратегию развития продукта и Roadmap, защищать перед бизнес заказчиками или стейкхолдерами Моделировать экономику продукта, вести P&L, а также формировать и защищать продуктовую команду для реализации стратегии, участвовать в найме команды Управлять продуктом (или группой продуктов) от этапа бизнес-потребности и MVP до его внедрения в бизнес и монетизации Лидировать продуктовые команды, состоящие из дата-инженеров, бизнес аналитика (-ов), дата-саинтистов Выстраивать взаимодействие с внутренними заказчиками и другими подразделениями Ленты/Севергрупп Выявлять потребности бизнеса, формировать и тестировать гипотезы, декомпозировать бизнес-задачи в задачи и ТЗ для каждого из членов продуктовой команды и участников рабочей группы Объяснять бизнес-логику нового решения по DS направлению бизнес-заказчикам, проводить Demo по продукту Отслеживать и улучшать продуктовые метрики Проводить AB-тесты Мы ожидаем: Подтверждаемый опыт не менее 2х лет в управлении внутренними продуктами / коммерческими продуктами / проектами в сфере IT с применением методологий agile и scrum Приветствуется технический / аналитический бэкграунд Опыт создания и управления дата продуктами (понимание построенияDSмоделей, ML Ops архитектуры, BI систем, хранилищ данных) Умения выявлять потребности бизнеса, собрать продукт, оценить требуемые ресурсы, обосновать коммерческую целесообразность и поставить грамотное техническое задание Умение презентовать результат заказчику, объяснить понятным языком нюансы D Мы предлагаем: ДМС класса Люкс со стоматологией оформление по ТК РФ возможность работать удаленно 100% времени скидка на занятия с репетитором по английскому языку скидки на фитнес, возможность заниматься корпоративным спортом (футбол, волейбол)","Agile Project Management,Scrum,Управление продуктом,Английский язык,Python","Лента, федеральная розничная сеть, IT",
10851,77330018,Data DevOps Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Компания BAUM - с 2010 года специализируется на системах хранения и обработки больших данных. Ведем разработку zero-code платформы прикладного искусственного интеллекта, которая позволяет создавать модели и приложения , без необходимости прямого кодирования В команду разработки платформы прикладного искусственного интеллекта требуется data-engineer ОБЯЗАННОСТ Участие в разработке распределенного вычислительного кластера Настройка Spark, как центрального фреймворка на платформе Настройка load balancer kubernetes для возможности динамически выделять ресурсы пользователю в соответствии с квотами Настройка облака, адаптация стека технологий под наш кластер, настройка БД, сервисов и подов Выделение мощностей на основе конфиг файла от пользователя (разработатьресурс менеджер совместно с питонистами)Мониторинг инфраструктуры, Обновление CI/CD пайплайна Обновление Helm Chart'ов под нужды новых сервисов Написание и обновление Dockerfile'ов Ввод в эксплуатацию новых нод k8s кластера Ввод в строй новых стэйджей и поддержание текущих Работа с БД и их резервным копированием. ТРЕБОВАНЯ Опыт работы с Apache Spark Опыт работы с Apache Spark Streaming Опыт работы с Apache Kafka Опыт работы с kubernetes Опыт работы с MongoDB, PostgreSQL. ПРВЕТСТВУЕТСЯ Опыт разработки с Hadoop или S3 Опыт работы с облачными провайдерами DevOps и MLops концепции. НАШ СТЕК Unix системы Shell Script, JS, Python Apache spark, streaming Apache kafka БД - Postgresql, MySQL, Hbase, MongoDB Виртуализация KVM, Vmware Микросервисы на Docker и Kubernetes Системы мониторинга EFK/ELK, Grafana, Prometheus. УСЛОВЯ Работа в стабильной, динамично развивающейся компании Официальное трудоустройство с первого дня Достойная з/п по результатам собеседования График работы - полная занятость, гибкий график Возможность профессионального и карьерного роста Комфортабельный офис в центре города на Бауманской. Мы лояльны и не обременены бюрократией, так что твоя инициатива всегда в тему.",,BAUM STORAGE,"Москва, Бауманская, Арбатско-Покровская линия, метро Бауманская"
11281,78519105,Data engineer (middle+),до 350 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Наши продукты - AI/ML-решения для крупных банков, ритейла и промышленности: системы предсказания спроса, сервисы персонализации и рекомендательные системы, поисковые системы для крупных ритейлеров и банков. Мы ищем data engineer'а для усиления нашего направления разработки систем прогнозирования спроса на товары в крупнейшем ритейле. Задачи: Разработка и развитие платформы прогнозирования - архитектура и реализация инструментов для построения ML-пайплайнов (подготовка данных, сбор фичей, обучение моделей, применение моделей, ведение ML-экспериментов и т.п.) Помощь коллегам/DS в оптимизации их работающих пайплайнов, проявлять про-активность с предложениями оптимизации Взаимодействие с коллегами/Devops по настройке окружений, деплоя кода, работы с инфраструктурой компании Общение с коллегами/DQ, выяснение деталей наполнения данных, участие в составлении БТ к данным Решение неожиданных проблем с данными, задержками их доставки. Минимальные требования: Уверенные знания Python 3+ (структуры данных, алгоритмы, концепции языка) Уверенные знания SQL: агрегации, джойны, вложенные запросы, индексы, оптимизации запросов Опыт работы с Hadoop, Spark Опыт разворачивания, настройки мониторинга и передача на поддержку разработанных решений. На что ещё смотрим: Опыт работы с Airflow и другими подобными инструментами для запуска регулярных задач Опыт Devops (Docker, Kubernetes, Gitlab-CI, настройка окружения на серверах и др.) Опыт разработки сервисов (Flask, Django, Asyncio и др.) Опыт проектирования высоконагруженных приложений и/или приложений работы с большими данными Будет плюсом опыт использования машинного обучения. У нас: Участие в быстром росте компании, работающей на перспективном AI рынке Возможность удаленное работы в любой точки мира или офис МСК Совместная работа с опытными разработчиками, аналитиками данных, менеджерами, продуктологами Гибкий график работы Оформление ТК РФ или ГПХ (вне рф) ДМС (включая стоматологию) после прохождения испытательного срока Уютный офис в центре Москвы (2 минуты от м. Сухаревская) со всем необходимым для комфортной работы. Особенно актуальное: Мы аккредитованная Т-компания со всеми вытекающими льготами.","Python,Spark,Hadoop,Docker,Kubernetes",Мамаева рина Анатольевна,
11288,79251530,DevOps Engineer в продукт Data River (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data в МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? DevOps Engineer на продукт Data River Описание продукта: Продукт Data River состоит из различных компонентов и сервисов, которые отвечают за потоковую обработку больших данных в режиме реального времени. Часть сервисов входят в состав и образуют основу ЭПМ Гео и платформы DSMP, а другая часть сервисов реализует прочие бизнес-кейсы со сложной логикой. Обязательно: опыт работы с контейнерами и Kubernetes (установка и настройка операторов, написание Helm-чартов) опыт работы с системами мониторинга (Victoria Metrics, Prometheus, Grafana) опыт работы с системами обработки/хранения/визуализации логов (ELK/EFK) опыт разработки и поддержки CI/CD (Gitlab CI, Jenkins) знание стратегий развертывания, навыки тестирования и оптимизации пайплайнов опыт автоматизации инфраструктурных задач (Ansible, Bash/Python) навыки работы с реляционными базами данных (наш технологический стек: PostgreSQL), NoSQL базами данных (наш технологический стек: Aerospike, Redis) навыки управления конфигурациями, поддержки Infrastructure as Code / GitOps (Helm, Ansible, ArgoCD и т.п.) понимание архитектуры сети, навыки диагностики проблем и устранения инцидентов в Production среде, написания Post-mortems знание JVM и опыт сборки/дистрибуции JVM-приложений знание систем контроля версий (Git), навыки управления релизами, опыт проведения Code Review Что предстоит делать? разрабатывать и поддерживать CI/CD пайплайны разрабатывать и поддерживать Helm-чарты обеспечивать бесперебойное функционирование сервисов настраивать мониторинг и алертинг повышать Observability реагировать на события и инциденты, решать инциденты сопровождать процессы разработки автоматизировать рутинные процессы взаимодействовать со смежными командами (ответственными за IaaS, PaaS, SaaS, Unix и др.) Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой.","Kubernetes,Helm,Prometheus,CI/CD,Ansible,Grafana",МТС,
11310,77474066,DevOps Engineer в команду Data Lake,з/п не указана,3–6 лет,"Полная занятость,полный день","Перед командой Data Lake стоит задача развития и поддержки основного компонента современной аналитической платформы данных. Платформа дает возможность быстрой, параллельной и независимой разработки решений прикладных бизнес-задач. щем в команду DevOps-инженера, для поддержки и развития Data Lake, смежных сервисов и внутренних процессов. Наш текущий основной стек: Linux, Docker, Kubernetes, ELK, Zabbix, Prometheus, Grafana, PostgreSQL, Nginx, Gitlab CI/CD, Hadoop (HIVE, HDFS, HBASE, YARN, Ranger), Airflow, Rundeck, Jira, Confluence. Кандидат, успешно прошедший собеседование и присоединившийся к команде Data Lake, будет: обеспечивать работоспособность Data Lake (кластер Hadoop, Airflow), Unix подобных ОС поддерживать и настраивать мониторинг различных систем и инфраструктуры анализировать и оптимизировать производительность различных компонент Data Lake поддерживать в актуальном состоянии имеющуюся инфраструктуру управлять обновлениями, настройками, устранять выявленные уязвимости настраивать и поддерживать процессы и инструменты интеграции Data Lake с системами-источниками и потребителями данных развивать, улучшать процессы CI/CD восстанавливать сервисы Data Lake после сбоев, обрабатывать инциденты документировать разрабатываемые процессы и обучать коллег работе с ними развивать архитектуру системы и внедрять новые технологические решения и сервисы. Требования к кандидатам: опыт администрирования Unix-подобных ОС знания и опыт построения CI/CD-процессов понимание сетевых технологий и основных протоколов: TCP, UDP, HTTP, HTTPS, LDAP, Kerberos, DNS, DHCP базовое знание одного из скриптовых языков: bash, python опыт работы с системой управления конфигурацией понимать принципы работы систем мониторинга опыт разработки сервисов для автоматизаций рутинной работы понимание базовых принципов информационной безопасности обладать экспертизой работы с контейнерными технологиями и оркестрацией навыки работы с Kubernetes опыт администрирования web серверов опыт администрирования баз данных. Будет плюсом: знания в области устройства JVM/JDK навыки развертывания K8s и администрирования на bare metal опыт работы с кластером Hadoop (HDFS, YARN, HIVE, HBASE, Ranger), Livy, Spark, Airflow навыки сбора различных приложений/сервисов из исходников администрирование кластеров БД. Мы обещаем тебе возможность: возможность работать удаленно или в комфортном офисе на м. «Технопарк» с собственным спортзалом и кафе социальный пакет, включающий ДМС, страхование выезжающих за рубеж и не только обмен опытом и знаниями внутри виртуального комьюнити внешнее и внутреннее обучение, участие в профессиональных конференциях и митапах доплата до оклада за 14 дней в году по больничному листу доплата к отпуску в январе и мае 3 оплачиваемых отгула в год скидки от компаний-партнеров и специальные предложения по банковским продуктам. еще десятки льгот и бонусов для сотрудников.","Kubernetes,Bash,Python,CI/CD,Zabbix,Unix,Hadoop",Райффайзен Банк,
11446,78794747,Devops на проект Data lake,з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем DevOps-инженера c функцией Hadoop администрирования на проект банковский проект. Основными задачами которого будет развернуть платформу Data Lake (на базе Hadoop) с нуля, настроить все необходимые компоненты для построения современного стека для работы с данными. Платформа Data Lake: будет являться частью централизованной Data Platform и поможет в стандартизации и автоматизации бизнес-процессов по загрузке и обработке “сырых” данных, обеспечении нужных таблиц в корпоративном реляционном хранилище DWH и развитии Data Science инициатив. Будущие пользователи нашей платформы - это разработчики и аналитики из продуктовых команд, Data Scientiest-ы, которые будут решать прикладные задачи бизнеса. Наш стек: Hadoop (HDFS, YARN, Spark, Hive), Airflow, Bitbucket, Teamcity, Nexus, Jira/Confluence, Ansible, Docker, Grafana/Zabbix. Чем предстоит заниматься: – участвовать в пилоте по разворачиванию Data Lake (Hadoop) – развернуть дистрибутив Hadoop на целевом железе – поддерживать и проводить troubleshooting, тестирование и анализ возникающих issues платформы – настроить репликацию данных между Production и DR площадками – оказывать поддержку разработчикам Data Lake из продуктовых команд – настроить мониторинги по основным сервисам (HDFS, Yarn, Hive, Spark, Kerberos + Ranger, Jupyterhub и др.) – проводить RnD, изучать новое open-source ПО Требования к кандидатам: Опыт работы с одним из дистрибутивов Hadoop (Arenadata, Cloudera и т.д.) Администрирование Hadoop кластеров (Подойдет даже если кандидат хоть как-то пересекался с этим) Опыт администрирования Linux (желательно RHEL, CentOS) Опыт работы с Docker Опыт работы с Ansible Понимание общих принципов построения процессов CI/CD Уверенное знание Python Опыт написания shell-скриптов Как преимущество Знание Java Опыт работы с Nexus, Teamcity Опыт работы с Kubernetes Опыт работы с базами данных (PostgreSQL) Опыт работы с системами мониторинга Zabbix, Grafana, Prometheus Мы предлагаем: Работу в стабильной аккредитованной Т компании, основанной в 1992 году Уровень заработной платы обсуждается ндивидуальный план развития в рамках ежегодной аттестации Удаленный формат работы, никакого физического железа Реализация своих теоретических знаний на практическом боевом проекте Привлекательный соц. пакет: медстраховка для сотрудника и его детей. Доступ к базе корпоративному порталу «среда развития».","Hadoop,PostgreSQL,Kubernetes,TeamCity,Linux,Docker,Ansible,CI/CD,Hive,DevOps,Arenadata",IBS,
11609,78294254,DevOps инженер в команду Analytical Data Platform,з/п не указана,3–6 лет,"Полная занятость,полный день","Перед командой Analytical Data Platform стоит задача развития и поддержки аналитической платформы данных. Платформа дает возможность быстрой, параллельной и независимой разработки решений прикладных бизнес-задач. Мы ищем в команду DevOps-инженера для поддержки и развития сервисов Analytical Data Platform, смежных сервисов и внутренних процессов. Наш текущий основной стек: Linux, Docker, Kubernetes, ELK, Zabbix, Prometheus, Grafana, GreenPlum, PostgreSQL, Nginx, Gitlab CI/CD, Hadoop (HIVE, HDFS, HBASE, YARN, Ranger), Airflow, Rundeck, Jira, Confluence. Чем предстоит заниматься: обеспечивать работоспособность сервисов платформы, Unix-подобных ОС поддерживать и настраивать мониторинг различных систем и инфраструктуры анализировать и оптимизировать производительность различных компонент поддерживать в актуальном состоянии имеющуюся инфраструктуру управлять обновлениями и настройками, устранять выявленные уязвимости развивать, улучшать процессы CI/CD восстанавливать сервисы платформы после сбоев, обрабатывать инциденты документировать разрабатываемые процессы и обучать коллег работе с ними развивать архитектуру системы и внедрять новые технологические решения и сервисы. Наши ожидания: опыт администрирования Unix-подобных ОС знания и опыт построения CI/CD-процессов понимание сетевых технологий и основных протоколов: TCP, UDP, HTTP, HTTPS, LDAP, Kerberos, DNS, DHCP базовое знание одного из скриптовых языков: Bash, Python опыт работы с системой управления конфигурацией понимание принципов работы систем мониторинга опыт разработки сервисов для автоматизаций рутинной работы понимание базовых принципов информационной безопасности опыт работы с контейнерными технологиями и оркестрацией навыки работы с Kubernetes опыт администрирования web-серверов опыт администрирования баз данных. Будет плюсом: знания в области устройства JVM/JDK навыки развертывания K8s и администрирования на bare metal опыт работы с кластером Hadoop (HDFS, YARN, HIVE, HBASE, Ranger), Livy, Spark, Airflow навыки сбора различных приложений/сервисов из исходников опыт администрирования кластеров БД. Мы предлагаем: возможность самостоятельно сформировать гибкий график работы с «удаленкой» и работой в просторном и современном офисе в одной минуте ходьбы от станции метро «Технопарк» профессиональные тренинги и образовательные курсы, лучшие тематические конференции, а также внутрибанковские митапы с приглашенными экспертами возможность влиять на конечный результат и понимать бизнес-логику продуктов корпоративный MacBook ДМС с первого рабочего дня, льготные условия на банковские продукты, а также услуги и товары от компаний-партнеров.","Kubernetes,Docker,DevOps,CI/CD,Grafana,Zabbix,SQL,Bash,Python",Райффайзен Банк,
11687,78771160,DevOps Engineer в продукт Net (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data в МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? DevOps Engineer на продукт Net Описание продукта: Продукт NET является одним из основных источником данных и витрин для инфраструктурных и продуктовых команд BigData, загружая и преобразуя данные из системы мониторинга опорной сети МТС. В области обработки и преобразования данных продукт NET выполняет разработку коммунального инструмента «Streaming Service», позволяющий автоматизировать задачи потоковой обработки данных для внешних команд и сократить T2M разработки. Обязательно: большой опыт разработки и эксплуатации CI/CD пайплайнов (GitlabCI) уверенные знания Docker/K8S и шаблонизаторов Helm понимание принципов работы по методологиям Agile, DevOps, GitOps хорошее знание ОС семейства Linux (RHEL, CentOS/Ubuntu) и опыт администрирования более 3-х лет опыт автоматизации работы с помощью Bash/Python опыт работы с какими-либо SCM (puppet, ansible, chef, saltstack) опыт эксплуатации и/или организации систем мониторинга (Prometheus, Victoria metrics) опыт эксплуатации систем логирования (ELK/EFK) понимание основ построения сетей умение не просто ставить задачи в JIRA, а также осуществлять их сопровождение и доведение до конца Что предстоит делать? участвовать в проектировании компонентов С автоматизировать CI/CD (конфигурирование, сборка, деплой) диагностировать и устранять проблемы, контролировать работоспособность приложений и предупреждать критические ситуации Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой.","GitlabCI,Helm,Docker,Linux,Bash,Python,Prometheus",МТС,
11710,77605879,DevOps Engineer на продукт Data Virtualization (DataOps Platform),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data в МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? DevOps Engineer на продукт Data Virtualization Описание продукта: Команда продукта Data Virtualization разрабатывает единый движок для выполнения SQL запросов к различным базам данных внутри группы компаний МТС. Задача продукта - предоставлять различным группам пользователей выполнять ad-hoc запрос к самым разным СУБД из единого интерфейса! Обязательно: знание JVM и опыт сборки/дистрибуции JVM-приложений (наш технологический стек: Java, Gradle, Spring) навыки построения и обслуживания систем мониторинга (Prometheus, Grafana) и логирования (ELK/EFK), умение определить ключевые метрики качества и производительности сервисов навыки работы с реляционными базами данных и NoSQL базами данных опыт работы с Big Data стеком (наш технологический стек: Kafka, Hadoop, Spark, HBase, Hive), понимание архитектур и назначения Big Data систем Что предстоит делать? поддерживать разработку backend приложений (REST API) настраивать систему мониторинга вокруг продукта автоматизировать разворачивание различных сред продукта участвовать в создании современной платформы больших данных Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой.","JVM,Prometheus,Grafana,SQL,Hadoop,Spark,Kafka",МТС,
11971,78560759,Data Engineer at Orca Security,з/п не указана,3–6 лет,"Полная занятость,полный день","Dive right in. Swim with our pod. At Orca, we believe that in the right environment and with the right team, talent has no boundaries. This team spirit, together with our drive to always aim high (because the cloud is the limit), have quickly earned us unicorn status and turned us into a global cloud security innovation leader. So if you’re ready to join an amazing team of people who inspire each other every day, now is the time to find your place in our pod.  About the role: Orca Security’s Cloud Detection and Response engineering team is growing and looking for a talented Data Infrastructure Engineer to join our global team. Together we will build the next generation of Security products as part of Orca’s one-stop-shop for cloud security solutions. If you’re a team player, looking to be part of a fast-growing, heavily funded startup company, and solve complex technical challenges while using state-of-the-art technologies on a product built from scratch — that’s your chance!  Ready to dive in and swim with our pod?  On a typical day you'll: Be charged with the vital task of developing and improving our data platform that is not only efficient but also at the forefront of innovation You will enable engineers to work with cloud architecture and build a data platform as a service Run complicated systems over Kubernetes to meet the demand and complexity of our enormous scale and handle upcoming challenges using modernized IaC solutions Leveraging the latest technology stack, you have the power to drive real change and make a significant impact on the industry About you: 5+ years of experience in Platform / Devops / Data oriented teams Experience with big data processing engines (Spark, Hadoop) Public cloud experience (AWS) Experience in handling large scale production environments Experience in developing in Golang / Python / Java Strong understanding of Kubernetes internals and patterns Advanced CI/CD development skills Team player mindset Bonus point: Experience with data warehousing, ETL and data integration Experience with workflow management tools (Airflow) Experience with analytical databases (Druid, Snowflake) Benefits of working with us: Work in a highly professional team. Informal and friendly atmosphere in the team Opportunity to attend WeWork coworkings in Warsaw (on demand) Paid vacation - 20 business days per year, 100% sick leave payment 5 sick days per year Equipment provision Inflation-protected wages with regular revision of compensation conditions Partially compensated educational costs (for courses, certifications, professional events, etc.) Medical insurance (after the end of the probationary period) English and Polish courses - 2 times a week (at the pandemic time - remotely) Bright and memorable corporate life: corporate parties 2 times a year, gifts to employees in honor of life events.","Python,Spark,Hadoop,Golang,Kubernetes,AWS,Английский — B1 — Средний",Он Зэ Спот Девелопмент,
11973,78077596,QA engineer в команду разработки Data Office,з/п не указана,3–6 лет,"Полная занятость,полный день",,,"Лента, федеральная розничная сеть, Офис",
11990,76954495,Data Engineer (DWH),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","PETER PARTNER – это молодая продуктовая IT-компания, которая занимается созданием собственных крутых финтех продуктов. Мы – команда профессионалов, готовых помочь с трудной задачей в понедельник утром и классно провести время в пятницу вечером. Придерживаемся agile-подхода. Для нас agile – это не только гибкая методология создания продуктов, но и прозрачность взаимоотношений внутри команды и вовлеченность каждого в общее дело. В нашем активе есть коммерчески успешные продукты. Мы реализовали систему по автоматизации торговли, которая интегрирована с крупными торговыми брокерами. Все продукты компании Peter Partner локализованы на множество языков и ими пользуется свыше 1 млн. человек в странах Азии, Африки и Южной Америки. Также, используя свой опыт в алгоритмах трейдинга мы разработали платформу, которая позволяет управлять активами на ведущих криптовалютных биржах. Мы работаем в технологически-сложной сфере и наша задача – сделать простой и удобный продукт, понятный для каждого. Наша команда развивает и поддерживает инфраструктуру для продуктовой аналитики в Peter Partner. Мы отвечаем за контуры обработки и трансформации данных (ETL), организацию хранения данных (DWH), средства визуализации (BI) и A/B тестирования. Мы в поисках Data-engineer который, также как и мы разделяет data driven подход, знает как искать insights в данных и сможет вывести наши продукты на новый уровень!) Это про тебя? Давай с нами!) ТЕБЕ ПРЕДСТОТ: Создание единого пайплайна обновления отчетности на базе Airflow + Clickhouse + Postgres Создание витрин с разными слоями данных (сырые данные, агрегированные данные, таблицы под отчеты и датасеты для BI), проектирование модели данных исходя из бизнес-требований Подключение и сверка новых источников Performance маркетинга Формирование стратегии по работе с данными с четкой, понятной и описанной структурой Проектирование структуры хранения данных (в том числе бэкапы, сжатие неиспользуемых данных), создание ETL-процессов Выстраивание и поддержка процессов data quality (health-метрики, алерты) Поддержка и развитие инфраструктуры A/B тестирования. НЕОБХОДМЫЕ НАВЫК: Уверенное владение Python. Владение SQL, понимание принципов оптимизации запросов и организации хранения данных Автономность и проактивность в работе - умение находить, подсвечивать и решать проблемные моменты самостоятельно, не дожидаясь задач со стороны Опыт разработки ETL-процессов с применением Airflow Опыт работы с Clickhouse Опыт работы с логированием пользовательских событий (в мобильном приложении) Желание разбираться в бизнес-особенностях данных с которыми предстоит работать. БУДЕТ ПЛЮСОМ: Понимание принципов разработки bi - как преимущество (SuperSet / Tableau / Looker / Power Bi или аналоги) Опыт решения DevOps задач - Docker, Kubernetes (или Nomad). НАШ СТЕК: Базы данных: Postgres, Clickhouse, Mongo DB Для ETL: Airflow, Airbyte, DBT, Jitsu, Pipeline платформа Hevo Внешние источники данных: Facebook и Google - рекламные кабинеты Branch - трекер атрибуций Apphud - выручка Amplitude - продуктовая аналитика. BI - Superset. МЫ ПРЕДЛАГАЕМ: Стать частью амбициозной IT-команды с крутыми процессами и насыщенной корпоративной культурой Официальное оформление, белую заработную плату График работы 5/2 с гибким началом рабочего дня с 8:00 до 11:00 и возможностью работать как в офисе, так и удаленно Работу в уютном, двухэтажном офисе с зоной отдыха, 2 кухнями и мини-библиотекой, и все это в 8 минутах ходьбы от ст.м. Выборгская Образовательные мероприятия внутри команды (мы их назвали “ppsync”), где можно не только обмениваться опытом, но и прокачать скиллы ораторского мастерства и выступлений на публике Регулярные командные мероприятия.","Postgres,Clickhouse,Mongo DB,Airflow,Airbyte,DBT,Branch,Apphud,Amplitude,Superset,Python,SQL,A/B тесты,Английский — B1 — Средний",Peter Partner,"Санкт-Петербург, Выборгская, Лесная, Петроградская, Гельсингфорсская улица"
11995,77899629,Senior NLP Engineer / Data Scientist,до 370 000 руб. на руки,3–6 лет,"Полная занятость,полный день","КБЕР-РОМ — это неформальная обстановка, крутые Т-проекты в области медиаиндустрии и продукты, конкурирующие с лидерами рынка! У нас есть команда, которая создает ML решения, аналогов которых нет на рынке! Спроси себя, хочешь ли ты: обрабатывать миллионы видео со стримминговых сервисов предоставлять пользователям релевантный контент искать структуры в неструктурированных данных бороться за каждую миллисекунду скорости делать продукт, который сделает лучше пользовательский опыт. Наша команда растет и мы ищем Senior NLP Engineer / Data Scientist. Наш стек: Lang: Python/Go/C++ ML: Torch, CatBoost и многое другое =)  DB: PostgreSQL, GreenPlum, Mongo, ClickHouse, Redis, OpenSearch Queue: Rabbit, Kafka Orchestration: K8s DevOps: Docker, ArgoCD, Helm Services: AirFlow, SuperSet, ML-Flow, Git-Lab Log: ELK (под OpenSearch стек) Monitoring: Grafana, Prometheus. С чем можно будет поработать: Работа с большими данными и высокой нагрузкой С Machine Learning сервисами, которые приносят людям пользу =)  Общение с экспертами в области разработки и ML из разных областей. Чем предстоит заниматься: Разрабатывать модели NLP и IR сследовать текстовые данные UGC Строить и внедрять Pipeline-ы обработки текстовых данных нтегрировать модели в сервисы. Что ожидаем от Вас: Знание и применение базовых и ML алгоритмов Опыт построение NLP сервисов от постановки бизнес задачи до внедрения сервиса в Production Опыт разработки и внедрения моделей NLP в Production сервисы от 3х лет Знание и применение Python в Production от 3х лет Опыт работы с большими данными Применение в Production DL моделей Умение определить, где нужен DL, а где достаточно регулярки =)  Навыки работы с SQL и NoSQL базами данных. Будет плюсом: Опыт работы с Docker и K8s Умение работы с ML-Ops подходами Успешные внедрения в высоко-нагруженных проектах Публикации в NLP. Бенефиты: Мы - аккредитованная в Минцифрах IT-компания Оформление по ТК РФ, конкурентная заработная плата График работы 5\2, гибкое начало дня до 11 утра (возможен гибридный график работы или удаленка) ДМС со стоматологией и госпитализацией в классных клиниках Профессиональное обучение и конференции Стильный просторный лофт на территории Трехгорной мануфактуры. Тебе предстоит легкая 10 минутная пешая прогулка через парки от метро 1905 года и Краснопресненская Сhill Lounge с пятой плойкой и капсулой для сна с массажем Современное топовое оборудование, мощные ноутбуки Комфортная кухня с вкусным кофе, чаем, какао, орешками, фруктами, снэками и прочими ништяками Холодильник с колой и энергетиками По пятницам в офисе пицца, роллы или грузинская кухня Годовая подписка на топовый онлайн кинотеатр. Минусы: Очень много интересных и сложных задач Будут спрашивать результаты работы Нет возможности работы из-за границы.","Python,Go,C++,Torch,CatBoost,PostgreSQL,GreenPlum,MongoDB,ClickHouse,Redis,OpenSearch,RabbitMQ,Kafka,K8s,Docker,ArgoCD,Helm,AirFlow,SuperSet,ML-Flow,Git-Lab,ELK,Grafana,Prometheus",КБЕР-РОМ,"Москва, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с27"
11996,78124365,Data engineer,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Flowwow — маркетплейс, где продают свои товары тысячи локальных магазинов в 950 городах по всему миру, наше удобное приложение позволяет заказать, оплатить и отследить доставку цветов, тортов, украшений, картин и других товаров для себя и близких — где бы вы ни находились! Наша команда создает качественный удобный сервис, который делает счастливыми тысячи людей по всему миру.   Что нужно делать: Разрабатывать и оптимизировать процессы выгрузки данных из различных источников Разрабатывать процессы обработки данных Оркестрация ETL/ELT на Airflow Развитие Data Quality фреймворка Развитие Airflow DAG генератора Глубокая работа с Data Catalog и DA Рефакторинг кода DE проекта Участие в формировании Data Flow Что мы ждем от вас: Опыт работы от 2 лет Опыт работы с любым cloud провайдером Python: ООП, asyncio, multiprocessing, pandas Опыт работы с api (интеграции) Понимание разницы между ETL/ELT OLAP/OLTP Хорошие навыки работы с консолью Уверенные знания SQL: агрегации, джойны, оконки, вложенные запросы, индексы, оптимизация запросов Airflow (операторы, хуки, сенсоры, restapi plugin) Будет плюсом: Опыт в разработке сервисов (Fastapi) Опыт в web-парсинге (Selenium) Devops опыт (Docker, k8s, grafana, настройка окружения на серверах и тд.) Условия: С первого дня — работа в технологической компании над сервисом, приносящим пользу сотням тысяч людей официальное трудоустройство культура открытости и взаимопомощи: у нас работают люди, вовлеченные в процесс и не безразличные к тому, что они делают возможность быстро реализовать свои идеи и чувствовать вклад в общий успех удалённая работа или современный комфортный офис в центре Москвы на ваш выбор После прохождения испытательного срока — полис ДМС со стоматологией возможность проходить профильные курсы/обучение за счет компании подписка на консультации с психологом (по необходимости) компенсация расходов на занятия спортом.","Python,SQL,Airflow",ФЛАУВАУ,"Москва, Сухаревская, проспект Мира, 3с3"
11997,78183519,Sr. Azure Data Architect \ Sr. Azure Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Компания #AWARA IT — это компания, которая сочетает в себе любовь к самым перспективным и интересным технологиям мира и уверенность, что эти технологии должны нести лучшие из лучших : )  Наша команда – страстные фанаты и профессионалы своего дела. Непрерывное обучение и развитие являются частью нашего корпоративного ДНК. Мы сосредоточены на качестве поддержки наших клиентов и на реализации новых проектов, в результате - множество интересных и нестандартных задач и широкое поле возможностей для проявления себя!  Команда #AWARA IT работает на широком технологическом стеке, мы находимся в постоянном поиске лучших решений и новейших технологий для нас и наших клиентов. Наши ожидания: Высшее техническое образование Понимание Cloud based инфраструктуры, IaaS \ PaaS \ SaaS Понимание рынка программного обеспечения в направлении Data, Big Data, BI, Advanced Analytic. Понимание и глубокие технологические знания технологического стэка Azure Data Services. Отличные коммуникативные навыки Умение работать в условиях многозадачности Английский язык - разговорный уровень является обязательным, для свободного общения и участия в проектах. Обязанности: Участие в проектах по реализации и внедрению программных продуктов классa DWH \ BI на базе облачной платформы и сервисов Azure Анализ и оценка требований клиента, с последующим формированием плана работ Проектирование и разработка витрин данных для анализа и моделирования Проектирование и реализация корпоративного хранилища данных (DWH – Azure Synapse, Azure DB`s, Azure Services) Анализ производительности баз данных, хранилищ данных и их Performance tuning Проектирование реализация и настройка, настройка и внедрение процессов ETL \ ELT (Azure Data Factory, Azure Functions, Spark) Проектирование и реализация DataLake \ Delta Lake Мониторинг и оптимизация процессов сборки витрин Загрузка и обработка данных из различных источников Поддержка и развития базы знаний  Требования: Знания Azure Data Services – Azure Data Factory, Azure Data Lake, Azure SQL DB, Azure PostgreeSQL, Azure CosmosDB, Azure Synapse, Azure Spark, Azure Functions. Желателен опыт администрирования и работы с SQL Server \ Azure SQL DB, Azure Synapse. Опыт разработки и реализации Data Governance подходов и практик. Опыт работы с потоками данных и их загрузкой (ETL\ELT, батчи, потоковая обработка) Опыт поддержки инфраструктуры данных (devops, аналитические базы данных, ETL-инструменты, BI-инструменты) Опыт проектирования и реализации хранилищ данных (DWH) Хорошее знание и опыт работы со стэком Azure Data Services Желателен опыт разработки на Python/Scala/Java Знание и опыт работы и реализации MDM – Master Data Management будет очень весомым преимуществом. Условия: Официальное трудоустройство в соответствии с ТК РK с первого дня Полностью ""белая"" заработная плата, премии по итогам успешных проектов ДМС после прохождения испытательного срока Гибкое начало рабочего дня (по договоренности с руководителем отдела), удаленная работа. Возможен гибридный график работы по желанию. Сертификация и обучение за счет компании Печеньки, шахматные турниры, корпоративные мозгобойни и многое другое","SQL,PostgreSQL,Azure Synapse,Azure Data Factory,Azure Spark,Azure DataBricks,Azure DB`s,Azure Function,Python,Hadoop,ETL,ELT,DataLake,DeltaLake,DWH,Cистемы управления базами данных,Базы данных,Spark,Работа с базами данных,Моделирование,Умение работать с клиентами",Авара Ай Ти Казахстан,
12004,79155981,Data Engineer (remote),от 200 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Кто мы: BestDoctor — экосистема медицинских и страховых сервисов, созданная экспертами для удобного управления здоровьем. Мы меняем рынок медицинского страхования и отношение людей к своему здоровью с помощью качественного сервиса и принципиально нового клиентского опыта. Благодаря глубокой экспертизе в создании медицинских решений и любви к своему делу, нам удалось создать ту самую экосистему полезных, эффективных и, главное, простых медицинских сервисов для управления здоровьем компаний и людей. Чего мы достигли:  За семь лет мы вышли на второе место по числу клиентов среди insurtech компаний в Европе. Сегодня с нами уже 100 000+ застрахованных пользователей (40 000 из них мы подключили в 2021 году), а в списке клиентов — Мегафон, Aviasales, МТС Банк, Нетология, InDriver, Эвотор, Ivi.ru, Ostrovok.ru, VC.ru и еще 140 компаний.  Создали экосистему медицинских сервисов, которая включает: сервис онлайн-поддержки 24/7, сервис онлайн записи в оффлайн клинику, своя виртуальная клиника, сервис второго мнения специалиста, чекапы, сервис поддержки психологов и др. Наша следующая цель — сделать все продукты, входящие в экосистему BestDoctor, мультисервисными, разработать подбор индивидуальных программ, создать возможность управлять бюджетом, улучшить HR-кабинет и умную маршрутизацию каждого сотрудника для B2B сегмента.  для этого ищем лучших экспертов, чтобы вместе захватить рынок. Подробнее о сервисе BestDoctor: https://bestdoctor.ru/ и https://hh.ru/article/29681 О проекте: За время существования компании мы накопили много данных и разных инструментов аналитики. На этих данных мы строим предложения для новых клиентов и продлеваем старых, проводим переговоры с клиниками и непосредственно помогаем нашим пациентам. Главная задача - весь этот информационный поток перенести в чётко организованную систему сбора, обработки и анализа данных любого объёма. Сейчас мы планируем вести сборку data lake house на базе GreenPlum, куда будут сливаться данные всех источников, таких как, PostgreSQL, Yandex,Google drive, сторонние API и др.). Мы мигрируем туда с Postgres+Astroniomer. Также у нас будет большой проект с фичастором и MLFLOW. В твоих задачах будет много архитектуры и хорошего продакшн кода, перенос, рефакторинг старого и написание очень динамического и автоматизированого нового, а также опыт с очень крутым датасайнсом, аналитикой и продуктом. В целом, тебе предстоит: Мигрировать даги с Airflow c Астрономера на Кубер Развивать и оптимизировать GreenPlum(PXF) даги Пилить Data Managment нового поколения нтегрировать сторонние API. Что для нас важно: Опыт программирования на Python 3 Опыт работы с Airflow Отличные знания и опыт работы с SQL. Опыт работы с GreenPlum и PostgreSQL Дополнительным плюсом будет: Опыт работы с Apache Kafka Навыки в DevOps / опыт работы с Docker Опыт работы с Apache Spark Опыт работы с хранилищами (DataVault Anchor LakeHouse FeatureStore) Как мы нанимаем: Мы готовы оперативно выходить с оффером, если понимаем, что подходим друг другу. 1 этап - телефонное интервью с HR (15-20 минут) 2 этап - техническое интервью с лидом аналитики 3 этап - финальное интервью с CDO и HR. Почему с нами круто: Мы меняем рынок медицинского страхования, и у нас это отлично получается В нас поверили и проинвестировали топовые венчурные фонды в России: российский Winter Capital, шведский VNV Global и австрийская страховая компания Uniqa Удаленный формат работы (будем рады тебя видеть у нас в офисе (м.Савёловская) У нас гибкий график работы, который подойдет как жаворонку, так и сове Тебя будет окружать команда талантливых и мотивированных людей Мы предоставим тебе ноутбук и всю необходимую технику, которая позволит эффективно и комфортно работать Медицинское обслуживание через систему BestDoctor.  Ты будешь частью большого социально значимого дела. Мы реализуем амбициозную задачу — меняем рынок здравоохранения, действительно помогаем людям, и у нас это отлично получается.  у тебя получится!","PostgreSQL,Python,SQL,AirFlow,GreenPlum",BestDoctor,
12005,79155951,Data Engineer (remote),от 200 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Кто мы: BestDoctor — экосистема медицинских и страховых сервисов, созданная экспертами для удобного управления здоровьем. Мы меняем рынок медицинского страхования и отношение людей к своему здоровью с помощью качественного сервиса и принципиально нового клиентского опыта. Благодаря глубокой экспертизе в создании медицинских решений и любви к своему делу, нам удалось создать ту самую экосистему полезных, эффективных и, главное, простых медицинских сервисов для управления здоровьем компаний и людей. Чего мы достигли:  За семь лет мы вышли на второе место по числу клиентов среди insurtech компаний в Европе. Сегодня с нами уже 100 000+ застрахованных пользователей (40 000 из них мы подключили в 2021 году), а в списке клиентов — Мегафон, Aviasales, МТС Банк, Нетология, InDriver, Эвотор, Ivi.ru, Ostrovok.ru, VC.ru и еще 140 компаний.  Создали экосистему медицинских сервисов, которая включает: сервис онлайн-поддержки 24/7, сервис онлайн записи в оффлайн клинику, своя виртуальная клиника, сервис второго мнения специалиста, чекапы, сервис поддержки психологов и др. Наша следующая цель — сделать все продукты, входящие в экосистему BestDoctor, мультисервисными, разработать подбор индивидуальных программ, создать возможность управлять бюджетом, улучшить HR-кабинет и умную маршрутизацию каждого сотрудника для B2B сегмента.  для этого ищем лучших экспертов, чтобы вместе захватить рынок. Подробнее о сервисе BestDoctor: https://bestdoctor.ru/ и https://hh.ru/article/29681 О проекте: За время существования компании мы накопили много данных и разных инструментов аналитики. На этих данных мы строим предложения для новых клиентов и продлеваем старых, проводим переговоры с клиниками и непосредственно помогаем нашим пациентам. Главная задача - весь этот информационный поток перенести в чётко организованную систему сбора, обработки и анализа данных любого объёма. Сейчас мы планируем вести сборку data lake house на базе GreenPlum, куда будут сливаться данные всех источников, таких как, PostgreSQL, Yandex,Google drive, сторонние API и др.). Мы мигрируем туда с Postgres+Astroniomer. Также у нас будет большой проект с фичастором и MLFLOW. В твоих задачах будет много архитектуры и хорошего продакшн кода, перенос, рефакторинг старого и написание очень динамического и автоматизированого нового, а также опыт с очень крутым датасайнсом, аналитикой и продуктом. В целом, тебе предстоит: Мигрировать даги с Airflow c Астрономера на Кубер Развивать и оптимизировать GreenPlum(PXF) даги Пилить Data Managment нового поколения нтегрировать сторонние API. Что для нас важно: Опыт программирования на Python 3 Опыт работы с Airflow Отличные знания и опыт работы с SQL. Опыт работы с GreenPlum и PostgreSQL Дополнительным плюсом будет: Опыт работы с Apache Kafka Навыки в DevOps / опыт работы с Docker Опыт работы с Apache Spark Опыт работы с хранилищами (DataVault Anchor LakeHouse FeatureStore) Как мы нанимаем: Мы готовы оперативно выходить с оффером, если понимаем, что подходим друг другу. 1 этап - телефонное интервью с HR (15-20 минут) 2 этап - техническое интервью с лидом аналитики 3 этап - финальное интервью с CDO и HR. Почему с нами круто: Мы меняем рынок медицинского страхования, и у нас это отлично получается В нас поверили и проинвестировали топовые венчурные фонды в России: российский Winter Capital, шведский VNV Global и австрийская страховая компания Uniqa Удаленный формат работы (будем рады тебя видеть у нас в офисе (м.Савёловская) У нас гибкий график работы, который подойдет как жаворонку, так и сове Тебя будет окружать команда талантливых и мотивированных людей Мы предоставим тебе ноутбук и всю необходимую технику, которая позволит эффективно и комфортно работать Медицинское обслуживание через систему BestDoctor.  Ты будешь частью большого социально значимого дела. Мы реализуем амбициозную задачу — меняем рынок здравоохранения, действительно помогаем людям, и у нас это отлично получается.  у тебя получится!","PostgreSQL,Python,SQL,AirFlow,GreenPlum",BestDoctor,
12052,75663573,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","IT-компания Selecty в активном поиске Data Engineer в крупную страховую компанию. Проект: внедрение единой для компании платформы MLOps Текущая команда проекта ML OPS: 15 DS, 4 MLOps, Data engineer, выделенные специалисты от отделов нформационной безопасности, Devops, нфраструктуры (K8s). Сейчас в проекте 25+ человек. Планируется дальнейшее расширение проекта В рамках проекта предстоит: Сбор информации из различных источников, построение витрин данных. 4 среды - dev, test, preprod, prod Oracle (legacy), мигрируем в postgreSQL, redis, ArangoDB, Spark/Hadoop Расширение имеющегося технологического стека Что для нас важно: Опыт работы cо Spark/Hadoop, Kafka, HiveQL Опыт работы с PostgreSQL, графовые DB (ArangoDB, Spark GraphX) разработка витрин NoSQL (MongoDB, HBase) S3 работа с чувствительными данными оптимизация запросов BigData версионирование git. Комфортные условия и полезные бонусы: Оформление в штат по бессрочному трудовому договору, полностью белую заработную плату: оклад + стабильная ежеквартальная премия + годовой бонус После 3 месяцев работы базовый пакет ДМС (поликлиника) спустя 9 месяцев работы – расширенный ДМС (стоматология, имуннотерапия, диспансеризация, лечение сложных заболеваний, телемедицина, плановая и экстренная помощь) + ДМС для родственников Удаленный формат работы (однако если хотите работать в офисе, то в Москве и Санкт-Петербурге это можно организовать) Гибкое начало рабочего дня на ваше усмотрение: с 8:00 до 17:00, с 9:00 до 18:00, с 10:00 до 19:00 Бесплатный корпоративный доступ к электронной библиотеке «Альпина» Льготный отдых в ГК «меретинский» в г.Сочи Скидки на обучение в языковых школах Speak English и Skyeng – от 15 – 25% Корпоративные предложения от сетей фитнес-клубов: WORLD CLASS, Зебра, X-fit Скидки от партнеров на приобретение недвижимости, авто и др. Подарки на Новый Год детям Льготные страховые продукты (Страхование-Тур, Страхование-Авто, Страхование-мущество) У вас будет наставник на период испытательного срока (3 мес), который поможет адаптироваться в компании + будет команда, которая ответит на ваши вопросы в процессе работы Возможность внести свой вклад в развитие нового проекта и самой команды Мы не ограничиваем и даем возможность дальше прокачивать hard skills на других проектах. Ждем тебя в команде!","Hadoop,Работа с большим объемом информации,NoSQL,Big Data,Разработка нового продукта,Spark",Selecty,
12057,76712124,Data Engineer (СПб),з/п не указана,3–6 лет,"Полная занятость,полный день","В связи с активным развитием корпоративной дата-платформы нам требуется нженер данных, который улучшит процессы разработки дата-пайплайнов. Наш стек: Airflow, nifi, dbt, Object storage, greenplum, dataproc, datalens, Analysis Services. Мы ожидаем: уверенные знания SQL (PostgreSQL) владение Python опыт работы с Airflow, DBT либо аналогичными инструментами будет плюсом понимание принципов работы Apache Kafka, опыт участия в разработке кубов или BI-отчетов, использование DevOPS методик. Ваши задачи: разработка и поддержка пайплайнов данных поддержка ETL-процессов формирование и доработка витрин данных сопровождение процессов тестирования качества данных. Мы предлагаем: официальное трудоустройство с первого дня работы график работы — 5/2 и гибкое начало дня и гибридный режим современный офис рядом с метро Звёздная: кухни, вкусный кофе, места для отдыха ДМС с момента трудоустройства программа адаптации и welcome-тренинг бонусы для сотрудников: реферальные программы, корпоративные мероприятия, мерч, подарки для детей корпоративные скидки: английский, спорт, кафе и рестораны в ТРЦ разделяем принципы устойчивого развития: раздельный сбор отходов, контейнеры для батареек и своп-вечеринки в офисе. Компания входит в список аккредитованных Т компаний, на сотрудников распространяются все социальные льготы для профильных специалистов, в том числе льготная ипотека и освобождение от призыва на военную службу.","ETL,Анализ данных,качественные исследования,Java,Python,SQL,data engineer",Монополия,"Санкт-Петербург, Звёздная, Звездная улица, 1"
12058,79251949,Senior Data Engineer [CJ Monitoring & Discovery],з/п не указана,3–6 лет,"Полная занятость,гибкий график","МТС Digital – сердце цифровой экосистемы МТС. Облачные сервисы, суперкомпьютер, системы видеоаналитики, IoT, собственная лаборатория AI и 20+ петабайт данных, финтех, стриминг, гейминг, мобильные приложения. Каждый день мы работаем над тем, чтобы вывести мобильную и веб-разработку на новый уровень, благодаря сплоченным продуктовым командам и agile методологиям. Мы ищем Data инженера в новый продукт CJ Monitoring & Discovery - это сервис для анализа клиентского опыта, задача которого помочь продуктам и экосистеме в целом узнать больше о своих пользователях, их опыте, эмоциях и отношении к изменениям. Чем предстоит заниматься: собирать и обрабатывать данные из различных источников автоматизировать ETL-процессы строить процессы сбора и репликации витрин для построения дашбордов настраивать и автоматизировать проверки качества данных писать автотесты для своего кода документировать код и скрипты DDL настраивать CI/CD для разрабатываемых пайплайнов участвовать в построении правильной архитектуры данных data-платформы участвовать в определении технологического стека. Что мы хотим видеть в вас: понимание моделей данных и принципов устройства хранилищ данных знание SQL и Python знание стека Spark и опыт работы с большими объемами данных опыт работы с ClickHouse/PostgreSQL умение работать в Unix консоли, базовое понимание (как минимум умение читать) shell scripts знание технического английского, навыки поиска информации. Будет плюсом: базовые навыки MLOps опыт участия в проектах по созданию цифровых продуктов по методологии Agile. Что мы предлагаем: собственную платформу MTS Ocean для получения Т-ресурсов, а это значит, что деплой, мониторинг, observability - не будут для вас проблемой, вы сможете сосредоточиться на фичах профессиональные гильдии инженеров по направлениям, чтобы поддерживать друг друга и обмениваться опытом внутреннюю площадку TechTalks для обмена опытом, дискуссий, развития навыков самопрезентации участие во внешних IT конференциях. Мы выступаем на HighLoad++, DataFest, Mobius, Test Driven Conf, Joker, DevOps, Матемаркетинг и даже проводим собственную конференцию по архитектуре Hello, conference! полезные курсы и вебинары в корпоративном университете и электронные библиотеки. А еще: медицинскую страховку с 1 месяца со 100% покрытием расходов, включая стоматологию, страхование жизни и здоровья в поездках за рубеж. А еще можно застраховать родственников с корпоративной скидкой доступ к сервису «Понимаю»: онлайн-консультации с психологом, юристом, экспертом по финансам или ЗОЖ корпоративный и командный психолог в офисе и массажный кабинет единую подписку МТС Premium — KION light в онлайн-кинотеатре KION, сервис МТС Music, 30 дней бесплатного пользования подпиской OZON Premium скидки и предложения от партнеров на фитнес, занятия английским и прочее.",Big Data,МТС,"Москва, Технопарк, проспект Андропова, 18к9"
12059,78564408,Data engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Мы интернациональная команда, занимающаяся адаптацией,  локализацией и созданием новых сервисов экосистемы для дочерних банков экосистемы Сбер. Чем предстоит заниматься: полным циклом разработки всех слоев хранилища данных и отображения отчетности участвовать в составлении плана проекта, оценка проектных сроков и рисков участвовать в проектировании системы, решать сложные исследовательские задачи по реализации никем ранее не реализованного функционала развивать корпоративное хранилище и витрины данных (АС Облако данных) для развития международного бизнеса Сбербанка. Участвовать в сложных интеграционных проектах по развитию корпоративного DWH (преимущественно Hadoop, возможно, интеграции с БД Oracle и Teradata) в роли разработчика. разрабатывать и проектировать потоки данных, алгоритмы загрузки и обработки данных в Hadoop с использованием Apache Spark разрабатывать и оптимизировать ETL, обеспечивать производительность и стабильность, при необходимости участвовать в анализе инцидентов организовывать оптимальный процесс разработки участвовать в приемке системы Мы ожидаем: опыт работы в области Data engineer от одного года Работа с данными: знание SQL - простые запросы, Join`ы, агрегаты, группировки, вложенные запросы знание python: стандартные структуры данных (dict, list, set, модуль collections), pandas, numpy, h5py опыт работы с Hadoop (Hive, Spark, HBase) является плюсом Моделирование: Feature Engineering: - методы оценки значимости и отбора признаков, методы уменьшения размерности, приемы работы с текстом Model - умение различать основные классы задач (регрессия, классификация, кластеризация) и формулировать бизнес-задачу в их терминах. Знать основные методы и знать api по их использованию Python - sklearn, numpy, scipy, xgboost (в порядке убывания приоритета) Evaluation: умение различать методы оценки качества модели под основные классы задач и понимать плюсы и минусы их применения. (f1, precision, recall, roc auc, mse, rmse, silhouette) опыт работы с инструментами для организации и автоматизации работы: GridSearch, pipelines, ide, git, Jira, Confluence понимание методологии Agile и DevOps владение английским языком на уровне чтения технической документации Мы предлагаем: работа в команде профессионалов, возможность разрабатывать уникальные и крупные проекты масштаба нашей страны можно работать в офисе или в смешанном графике конференции и обучение на корпоративных или вендорских курсах за наш счёт отличная ДМС, включая несчастные случаи и тяжелые заболевания льготные условия по ипотеке и кредитам материальная помощь и социальная поддержка корпоративная пенсионная программа офис в бизнес-центре Поклонка (м. Кутузовская)","Python,Hadoop,Spark,DWH",Сбер. IT,"Москва, Поклонная улица, 3"
12066,79190614,Data Engineering Intern,от 85 000 руб. до вычета налогов,не требуется,"Стажировка,полный день","IT community at P&G is looking for interns to join our small but mighty Data Engineering team in Moscow! We offer you an exciting experience – a 6-month paid internship at P&G, where you will be responsible for building solutions leveraging various Azure components and tools. This is your chance to work on interesting, global projects with some highly skilled and fun people. Your manager and team members will support and coach you, while you will be the leader of your project. We will provide you with all the necessary training and knowledge to perform well during your internship. Our stack Azure Cloud: Azure Data Factory, SQL Database, etc. Databricks (Python/PySpark/SQL) Data visualization with Power BI Azure DevOps What can you expect? You can expect meaningful work from Day 1. In this role, you will use cutting-edge technology, an industry-leading data solution architecture, and a governance model to solve real P&G business problems. During your internship, you will have the opportunity to: Learn from the global P&G IT community to advance your skills and reapply the best practices Develop business analytics products as part of a SCRUM team. You will need to bring technical solutions to obtain, process, store data, and provide business insights. You will learn to work with technologies like MS Azure, Python/PySpark, Power BI, etc Become a professional in your specific project area and be able to understand a business need and transform it into an end-to-end solution Create automated dataflows and be accountable for the whole ETL cycle Get access to the comprehensive training portfolio, including MS Certifications, Coursera, and other courses. Compensation & benefits Monthly salary 85 000 RUB gross Monthly lunch & flexibility allowance 5 000 RUB gross Hybrid WFH/WFO schedule Access to P&G’s global comprehensive training portfolio Relocation support in case you move to Moscow from another region Job Qualifications Mandatory 3+ year students and recent graduates with any higher education degree (up to 2 years after graduation) Good command of English (Upper-Intermediate or higher level) Python basic knowledge Availability for at least a 6-month internship Readiness to work 40 hours per week Eagerness to learn, experiment, fail, and try again Nice to have Cloud understanding Experience with using database technology (SQL) Experience with data visualization tools Just so you know All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, age, sexual orientation, gender identity and expression, marital status, citizenship, HIV/AIDS status, or any other legally protected factor No immigration sponsorship is available for this position. P&G is a leading global consumer goods company whose winning brands are built around the model of innovation. Whatever your passion is, we want to ignite your potential to become your very best self. We hold true to our purpose, values, and principles as we seek to make a difference in the world around us. You will engage in meaningful work that will touch the lives of others and have a real impact. Everything at P&G starts with understanding – understanding our consumers and our employees as we innovate to improve lives now and for generations to come.","SQL,Английский — B2 — Средне-продвинутый","«Procter & Gamble», Студент","Москва, Войковская, Ленинградское шоссе, 16ас2"
12072,76671592,Разработчик Hadoop Big Data (стрим Витрины ПК),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Вместе с нами ты будешь: Проектирование и разработка SQL-процедур, обработчиков данных на Spark (Scala) и ETL-процессов (в т.ч. AirFlow) Оптимизация производительности кода Разработка и ведение схемы данных Участие в проведении тестирований Взаимодействие с аналитиками, командами развития платформ, DevOps инженерами Развитие wiki в Confluence Какие знания и навыки для нас важны: Опыт работы с инструментарием Hadoop (HDFS, Yarn, Spark, Hive) Опыт работы с промышленными DWH на основе MPP СУБД (Teradata, Exadata, Greenplum), от 2-х лет Знание теории построения DWH ETL - практический опыт проектирования и разработки регламентных потоков данных при помощи Airflow SQL - уверенные знания (DML,DDL), опыт разработки хранимых процедур Опыт работы с библиотекой Pandas Опыт работы с Impala Понимание принципов и инструментария CI/CD (Git/Bitbucket, Teamcity)","SQL,Hadoop,Spark,Hive,SCALA","ннотех, Группа компаний",
12076,76402191,Разработчик Hadoop Big Data (стрим Витрины ПК),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Вместе с нами ты будешь: Проектирование и разработка SQL-процедур, обработчиков данных на Spark (Scala) и ETL-процессов (в т.ч. AirFlow) Оптимизация производительности кода Разработка и ведение схемы данных Участие в проведении тестирований Взаимодействие с аналитиками, командами развития платформ, DevOps инженерами Развитие wiki в Confluence Какие знания и навыки для нас важны: Опыт работы с инструментарием Hadoop (HDFS, Yarn, Spark, Hive) Опыт работы с промышленными DWH на основе MPP СУБД (Teradata, Exadata, Greenplum), от 2-х лет Знание теории построения DWH ETL - практический опыт проектирования и разработки регламентных потоков данных при помощи Airflow SQL - уверенные знания (DML,DDL), опыт разработки хранимых процедур Опыт работы с библиотекой Pandas Опыт работы с Impala Понимание принципов и инструментария CI/CD (Git/Bitbucket, Teamcity)","SQL,Hadoop,Spark,Hive,SCALA","ннотех, Группа компаний",
12103,79244489,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
12121,79244493,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
12122,79244491,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
12136,79089912,Lead Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Зона ответственности команды DWH - качественные и своевременные данные, решающие потребности бизнеса. За платформу данных и подключение источников к озеру данных отвечает отдельная платформенная команда. Объемы данных в компании исчисляются петабайтами. Основной процессинг данных на текущий момент осуществляется на облачной платформе AliBaba MaxCompute. На этот год перед командой стоит задача перенести процессинг данных на свою платформу данных, которая основывается на Hadoop-стеке (Hive, Spark, Airflow). В рамках этой активности мы планируем не просто переосмыслить процесс загрузки данных, но и внедрить новые подходы и практики. В частности, планируем в ближайшее время опробовать Dbt поверх Spark. Поэтому у вас будет возможность практически с нуля выстроить процесс обработки данных. Обязанности: Быть драйвером процесса переноса текущего DWH на платформу Hadoop. Определять архитектуру, внедрять и развивать инженерные подходы и практики Проектирование и моделирование слоев обработки данных Менторинг разработчиков (код ревью, развитие технических навыков) Оптимизация производительности сложных процессов загрузки данных Обеспечивать контроль за качеством данных и соблюдение SLA Требования: Глубокое знание стека Hadoop (Hive, Spark, Kafka) Опыт работы с Python или Java от 3-х лет Практический опыт проектирования хранилищ данных (Kimball, DataVault) Опыт написания дата пайплайнов, опыт работы с Airflow Понимание подходов к организации разработки (CI/CD, DevOps) Будет плюсом: Опыт работы c Dbt Понимание предметной области электронной коммерции Опыт разработки потоковой обработки данных (Spark Streaming / Flink) Опыт работы с форматами delta/hudi/iceberg. Условия: Сильная команда, с которой можно расти Сложные, нетривиальные задачи для маркетплейса с миллионами пользователей ДМС со стоматологией Гибкий график работы Достойная зарплата Комфортный офис в Cити. Возможность работать удаленно.","hadoop,DWH,Airflow",AliExpress Россия,"Москва, Пресненская набережная, 10блокС"
12161,79117910,Data engineer,з/п не указана,1–3 года,"Полная занятость,удаленная работа","В связи с формированием проекта MLOps в компании нгосстрах приглашаем в команду Дата инженера Проект: внедрение единой для компании платформы MLOps Текущая команда проекта ML OPS: 15 DS, 4 MLOps, Data engineer, выделенные специалисты от отделов нформационной безопасности, Devops, нфраструктуры (K8s). Сейчас в проекте 25+ человек. Планируется дальнейшее расширение проекта Предстоящие задачи: Разработка ETL потоков Разработка витрин данных Миграция с Oracle (legacy) в PostgreSQL, Redis, Ceph(S3) Для нас важно: Опыт работы cо Spark/Hadoop, Kafka, HiveQL Опыт работы с PostgreSQL, Oracle опыт разработки на Scala/Python NoSQL (MongoDB, HBase) Ceph(S3) Желательно (необязательно) o Flink, опыт работы со стриминговыми пайплайнами o опыт работы c ArangoDB, Spark GraphX o опыт работы c Redis Предлагаем: Оформление в штат по бессрочному трудовому договору, полностью белую заработную плату: оклад + стабильная ежеквартальная премия + годовой бонус После 3 месяцев работы базовый пакет ДМС (поликлиника) спустя 9 месяцев работы – расширенный ДМС (стоматология, иммунотерапия, диспансеризация, лечение сложных заболеваний, телемедицина, плановая и экстренная помощь) + ДМС для родственников Удаленный формат работы (однако если хотите работать в офисе, то в Москве и Санкт-Петербурге это можно организовать) Гибкое начало рабочего дня на ваше усмотрение: с 8:00 до 17:00, с 9:00 до 18:00, с 10:00 до 19:00 Бесплатный корпоративный доступ к электронной библиотеке «Альпина» Льготный отдых в ГК «меретинский» в г. Сочи Скидки на обучение в языковых школах Speak English и Skyeng – от 15 – 25% Корпоративные предложения от сетей фитнес-клубов: WORLD CLASS, Зебра, X-fit Скидки от партнеров на приобретение недвижимости, авто и др. Подарки на Новый Год детям Льготные страховые продукты (Страхование-Тур, Страхование-Авто, Страхование-мущество) У вас будет наставник на период испытательного срока (3 мес), который поможет адаптироваться в компании + будет команда, которая ответит на ваши вопросы в процессе работы Возможность внести свой вклад в развитие нового проекта и самой команды Мы не ограничиваем и даем возможность дальше прокачивать hard skills на других проектах.","Python,SQL,Git,Spark,Scrum",нгосстрах,
12167,79111005,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Наш целевой стек технологий это MS SQL, OLAP Cubes, ClickHouse, dbt, Airflow. Основные языки разработки Python, SQL и bash. Все это подкрепляется устойчивыми и прогрессивными DevOps практиками CI/CD. Что предстоит делать: Совместно с командой усовершенствовать текущие решения по загрузке и обработке данных нтеграция с новыми источниками данных (DB, API, файлы) Разработка и поддержка существующих библиотек кода и проведение code review Усиление экспертизы Python внутри команды Что мы ожидаем: Сильная экспертиза в Python и его экосистемы (9+, black, pylint, pytest, pandas, polars, pip) Опыт написания unit и acceptance тестов Обширный опыт работы с инструментами Airflow, Jupyter. Опыт работы с такими СУБД как MS SQL, ClickHouse Опыт написания сложных SQL запросов - ANSI SQL 2003+ Опыт использования практик и инструментов CI/CD, docker. Уверенные знания принципов построения системной архитектуры, архитектуры данных, работы с базами данных Большим плюсом будет опыт работы с dbt Сильные коммуникативные навыки, командная работа и желание расти, изучать новые технологии и развиваться вместе с командой. Условия: карьерный рост и интересные кейсы возможность реализовывать свой потенциал «белую» заработную плату гибридный график работы, гибкое время начала и окончания рабочего дня работу в комфортном офисе в шаговой доступности от м. Ботанический сад оформление согласно ТК РФ с первого рабочего дня возможность обучения и развития.",,ГК АСНА,"Москва, Ботанический сад, улица Докукина, 16с1"
12313,76402167,Разработчик Hadoop Big Data (стрим Витрины ПК),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Вместе с нами ты будешь: Проектирование и разработка SQL-процедур, обработчиков данных на Spark (Scala) и ETL-процессов (в т.ч. AirFlow) Оптимизация производительности кода Разработка и ведение схемы данных Участие в проведении тестирований Взаимодействие с аналитиками, командами развития платформ, DevOps инженерами Развитие wiki в Confluence Какие знания и навыки для нас важны: Опыт работы с инструментарием Hadoop (HDFS, Yarn, Spark, Hive) Опыт работы с промышленными DWH на основе MPP СУБД (Teradata, Exadata, Greenplum), от 2-х лет Знание теории построения DWH ETL - практический опыт проектирования и разработки регламентных потоков данных при помощи Airflow SQL - уверенные знания (DML,DDL), опыт разработки хранимых процедур Опыт работы с библиотекой Pandas Опыт работы с Impala Понимание принципов и инструментария CI/CD (Git/Bitbucket, Teamcity)","SQL,Hadoop,Spark,Hive,SCALA","ннотех, Группа компаний",
12342,78333637,Senior Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Наш клиент - крупная международная FMCG-компания, ведущий игрок на рынке, находится в поисках Senior Data Engineer, который присоединится к команде Больших данных в Москве.  ЧЕМ НУЖНО БУДЕТ ЗАНМАТЬСЯ: отвечать за создание систем и решений с использованием различных облачных компонентов и инструментов заниматься разработкой и внедрением сложных технических решений для получения, обработки и хранения данных. автоматизировать и оптимизировать внутренние процессы ETL в MS Azure. и т.д. НАШ СТЕК: Azure Cloud (ADF, SQL DB, etc.) Databricks (Python/PySpark/SQL) Data visualization with Power BI Azure DevOps (SCRUM, CI/CD) ЧЕГО МЫ ЖДЁМ: Высшее образование (DipHE) Продвинутые навыки программирования на Python и SQL, навыки программирования на PySpark Практический опыт написания чистого и эффективного кода Знание и/или опыт использования или создания инструментов CI/CD Знание методологий SCRUM и DevOps Хорошее знание английского языка (уровень Upper-Intermediate или выше). ЧТО МЫ ПРЕДЛАГАЕМ: конкурентная заработная плата + годовой бонус Медицинское страхование, страхование путешествий и жизни Компенсация питания Гибридный график работы Поддержка при перезде в Москву из другого региона.  Будем рады Вашему отклику!","Python,Spark,Английский — B2 — Средне-продвинутый",ГЕТ ЭКСПЕРТС РЕКРУТМЕНТ,
12366,78074144,"нженер по СУБД (PostgreSQL Database Engineer), DBA",з/п не указана,1–3 года,"Полная занятость,полный день",,,Ростелеком нформационные Технологии,"Тверь, Краснофлотская набережная, 1к1"
12367,78062870,GCP Data Architect/Team Lead,от 5 000 до 6 000 USD на руки,более 6 лет,"Полная занятость,полный день",,,E-book Applications,
12380,78581500,GCP Data Architect/Team Lead,до 6 000 USD на руки,более 6 лет,"Полная занятость,полный день","Мы — консалтинговая компания по разработке программного обеспечения. Работаем с новаторами в области технологий, помогая им воплощать свои идеи в жизнь. В течение 5 лет мы были увлечены разработкой технологий машинного обучения и искусственного интеллекта для управления данными и курирования контента для приложений EdTech, IoT и розничной торговли. Мы ищем архитектора данных GCP/руководителя группы для одного из самых интересных проектов в области биоинформатики, поддерживающего научное сообщество или генетиков, находящихся на передовой генетических исследований одноклеточных. Это роль, где Вы будете использовать свои навыки инженера данных и Google Cloud Platform для разработки и внедрения современной, масштабируемой платформы данных для нашего научного сообщества и проекта Human Cell Atlas.  Мы гарантируем будущему коллеге: Стабильный конкурентоспособный доход Официальное оформление в международную компанию - Consulting Agteement Полностью белую заработную плату, выплачивается без задержек ндексацию заработка График работы 5/2 с плавающим началом рабочего дня Полностью удаленный формат работы из любой точки мира Среду полностью свободную от бюрократии и микроменеджмента нтересные инженерные задачи, которые позволят раскрыть ваш креатив и потенциал Возможность повлиять на продукт на его первых стадиях и стать частью яркой команды настоящих профи своего дела.  Чем предстоит заниматься: Выступать в качестве эксперта в области инженерии данных и технологий данных GCP. Работать с командами клиентов и учеными над проектированием и внедрением моделей данных для транзакционных и больших данных в качестве исходных данных для обработки Machine Learning. Работать с методами Agile и DevOps и подходами к реализации в процессе доставки. Оценивать поддержку новых технологий и специфических для науки случаев использования.  Мы ожидаем от кандидата: Опыт работы в IT проектах от 6 лет. Опыт проектирования и построения конвейеров данных с использованием сервисов GCP, таких как BigQuery, Dataflow, Dataproc, Pub/Sub, Cloud Functions и т.д. Опыт использования Python или Java для обработки данных и написания сценариев Опыт управления командой и руководства членами команды. Практические навыки в области анализа кода, проектирования архитектуры, кодирования и т.д. Английский язык на уровне C1/B2.  Если в этом описании Вы увидели себя, смелее направляйте ваше резюме! (Ссылка на Телеграмм ниже)","Architecture,Administrating Skills,Английский — C1 — Продвинутый,SQL,Python,Java,Machine Learning,Data Science,Data Analysis,Deep Learning,Big Data,Team management,NoSQL,ML,Fluent English,Английский — C1 — Продвинутый",Wanted,
12431,78960127,Data-инженер (стрим еСпортс),з/п не указана,3–6 лет,"Полная занятость,полный день","MTS Digital — это инновационное подразделение МТС, которое работает над созданием экосистемы цифровых сервисов, мобильными приложениями, продуктами в финтехе, стриминге, гейминге, «облаках», AI и других направлениях.  Мы расширяем команду, которая занимается разработкой универсальной UGC платформы для развития инструментов стриминга и новых видео-форматов для блогеров, и ищем Data инженера.  Что предстоит делать: работать с представлениями данных, OLAP и различными BI-Аналитическими системами формировать отчеты, аналитические справки и презентации для продуктовой аналитики составлять дашборды, отчеты, выборки в рамках продуктовых задач формировать требования к источникам данных в рамках продуктовых задач. Наши ожидания: опыт работы с базами данных, умение писать сложные запросы, опыт создания дашбордов опыт обработки и структурирования данных опыт работы с DWH, MDM и комплексными хранилищами данных умение работать с Grafana, Clickhouse, Redash, PostgreSQL умение получать прямой доступ к данным умение описывать структуры данных, документирование данных умение работать со сложными аналитическими запросами в БД, знать язык SQL, читать и понимать процедуры написанные на pl\sql, pl\pgsql умение формировать выгрузки из БД, на основании тех. задания, сформированного дата-аналитиком, умение автоматизировать регулярные процессы в соответстии с требованями бизнеса Что мы предлагаем: собственную платформу MTS Ocean для получения Т-ресурсов, а это значит, что деплой, мониторинг, observability - не будут для вас проблемой, вы сможете сосредоточиться на фичах профессиональные гильдии инженеров по направлениям, чтобы поддерживать друг друга и обмениваться опытом внутреннюю площадку TechTalks для обмена опытом, дискуссий, развития навыков самопрезентации участие во внешних IT конференциях. Мы выступаем на HighLoad++, DataFest, Mobius, Test Driven Conf, Joker, DevOps, Матемаркетинг и даже проводим собственную конференцию по архитектуре Hello, conference! полезные курсы и вебинары в корпоративном университете и электронные библиотеки. А еще: медицинскую страховку с 1 месяца со 100% покрытием расходов, включая стоматологию, страхование жизни и здоровья в поездках за рубеж. Можно застраховать родственников с корпоративной скидкой доступ к сервису «Понимаю»: онлайн-консультации с психологом, юристом, экспертом по финансам или ЗОЖ корпоративный и командный психолог в офисе и массажный кабинет единую подписку МТС Premium — KION light в онлайн-кинотеатре KION, сервис МТС Music, 30 дней бесплатного пользования подпиской OZON Premium скидки и предложения от партнеров на фитнес, занятия английским и прочее.","Работа с базами данных,PostgreSQL,ClickHouse,Olap (online analytical processing),База данных: Olap,DWH,BI,OLAP",МТС,
12439,78960860,Data engineer (junior),з/п не указана,1–3 года,"Полная занятость,полный день","Задачи: Создание и поддержка витрин данных в периметре Фабрики Данных (АС Облако Данных) Установка дистрибутивов Участие в настройке инструментов процесса DevOps Мониторинг работы процессов расчета витрин и Web приложения Требования: Опыт программирования Java 8/Scala Понимание принципов функционального программирования Опыт работы с базами данных, знание SQL Пользователь Linux (работа в терминале, bash скрипты) Знание английского языка на уровне свободного чтения технической литературы Будет плюсом: Python, Spark, Hadoop Условия: Место работы: м. Кутузовская, Кутузовский проспект 32 к1 Доступны режимы работы: офис, смешанный, дистанционный Оформление согласно ТК РФ Социальный пакет: ДМС, спортзал (фитнес, йога), спортивные и культурно-массовые мероприятия, возможность обучения за счет компании, льготные условия кредитования Отличная профессиональная команда Офис класса А++",,Сбер. IT,
12458,78901125,Tribe Data Lead [OPS Platform],з/п не указана,3–6 лет,"Полная занятость,гибкий график","МТС Digital – сердце цифровой экосистемы МТС. Облачные сервисы, суперкомпьютер, системы видеоаналитики, IoT, собственная лаборатория AI и 20+ петабайт данных, финтех, стриминг, гейминг, мобильные приложения. Каждый день мы работаем над тем, чтобы вывести мобильную и веб-разработку на новый уровень, благодаря сплоченным продуктовым командам и agile методологиям. щем лида на направление Data в самый большой трайб Т-кластера ""Технологические платформы"". У нас 150+ сотрудников, 9 продуктов в портфеле, еще 3 новых заезжают в этом году и технологическая трансформация в самом разгаре. Что мы делаем: Т для Т: 6 продуктов (ITSM, inventory & asset management, monitoring & observability etc) - для всей экосистемы МТС Финансовый учет: 2 продукта - внутри Диджитала Управление инвестициями: 1 продукт - для головного ПАО. Чем предстоит заниматься: совместно с Tech Governance МТС и лидом практики кластера драйвить технологическую трансформацию в продуктах трайба подтягивать практики продуктовых команд трайба по своему направлению, не гнушаясь работы ""руками"" развивать свое направление в трайбе, заносить улучшения в продукты и в подходе bottom-up в кластер и Tech Gov отвечать за портфель продуктов трайба по своему направлению. Что мы ждем от кандидата: знание принципов построения корпоративной архитектуры данных опыт участия в сложных миграционных или инновационных проектах понимание принципов построения DWH, Data Lake, Data Mesh, опыт в построении и миграции хранилищ знание принципов Data Governance, жизненного цикла данных, lineage, опыт работы с Business Glossary и Data Catalog навыки анализа и обработки больших массивов данных опыт разработки ETL/ELT-процессов, знание соответствующих инструментов (AirFlow) практический опыт использования Data Quality управленческий опыт в Data-командах знание SQL и оптимизации SQL запросов опыт работы с хранилищами разных архитектур: mpp, columnar, relation, hadoop, in-memory. Что мы предлагаем: собственную платформу MTS Ocean для получения Т-ресурсов, а это значит, что деплой, мониторинг, observability - не будут для вас проблемой, вы сможете сосредоточиться на фичах профессиональные гильдии инженеров по направлениям, чтобы поддерживать друг друга и обмениваться опытом внутреннюю площадку TechTalks для обмена опытом, дискуссий, развития навыков самопрезентации участие во внешних IT конференциях. Мы выступаем на HighLoad++, DataFest, Mobius, Test Driven Conf, Joker, DevOps, Матемаркетинг и даже проводим собственную конференцию по архитектуре Hello, conference! полезные курсы и вебинары в корпоративном университете и электронные библиотеки. А еще: медицинскую страховку с 1 месяца со 100% покрытием расходов, включая стоматологию, страхование жизни и здоровья в поездках за рубеж. А еще можно застраховать родственников с корпоративной скидкой доступ к сервису «Понимаю»: онлайн-консультации с психологом, юристом, экспертом по финансам или ЗОЖ корпоративный и командный психолог в офисе и массажный кабинет единую подписку МТС Premium — KION light в онлайн-кинотеатре KION, сервис МТС Music, 30 дней бесплатного пользования подпиской OZON Premium скидки и предложения от партнеров на фитнес, занятия английским и прочее.",,МТС,"Москва, Технопарк, проспект Андропова, 18к9"
12475,78959836,Data-аналитик (стрим еСпортс),з/п не указана,3–6 лет,"Полная занятость,полный день","MTS Digital — это инновационное подразделение МТС, которое работает над созданием экосистемы цифровых сервисов, мобильными приложениями, продуктами в финтехе, стриминге, гейминге, «облаках», AI и других направлениях.  Мы расширяем команду, которая занимается разработкой универсальной UGC платформы для развития инструментов стриминга и новых видео-форматов для блогеров, и ищем Data аналитика.  Что предстоит делать: формировать отчеты, аналитические справки и презентации для продуктовой аналитики составлять дашборды, отчеты, выборки в рамках продуктовых задач формировать требования к источникам данных в рамках продуктовых задач. Наши ожидания: опыт работы с базами данных, умение писать сложные запросы, опыт создания дашбордов опыт обработки и структурирования данных умение работать с Grafana, Сlickhouse, Redash умение получать прямой доступ к данным умение описывать структуры данных, документирование данных. Что мы предлагаем: собственную платформу MTS Ocean для получения Т-ресурсов, а это значит, что деплой, мониторинг, observability - не будут для вас проблемой, вы сможете сосредоточиться на фичах профессиональные гильдии инженеров по направлениям, чтобы поддерживать друг друга и обмениваться опытом внутреннюю площадку TechTalks для обмена опытом, дискуссий, развития навыков самопрезентации участие во внешних IT конференциях. Мы выступаем на HighLoad++, DataFest, Mobius, Test Driven Conf, Joker, DevOps, Матемаркетинг и даже проводим собственную конференцию по архитектуре Hello, conference! полезные курсы и вебинары в корпоративном университете и электронные библиотеки. А еще: медицинскую страховку с 1 месяца со 100% покрытием расходов, включая стоматологию, страхование жизни и здоровья в поездках за рубеж. Можно застраховать родственников с корпоративной скидкой доступ к сервису «Понимаю»: онлайн-консультации с психологом, юристом, экспертом по финансам или ЗОЖ корпоративный и командный психолог в офисе и массажный кабинет единую подписку МТС Premium — KION light в онлайн-кинотеатре KION, сервис МТС Music, 30 дней бесплатного пользования подпиской OZON Premium скидки и предложения от партнеров на фитнес, занятия английским и прочее.","ClickHouse,Базы данных,PostgreSQL,Grafana,Redash,Анализ данных,SQL",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
12484,72312345,Data Engineer,до 400 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Мы в Rubbles создаем решения на базе анализа данных и искусственного интеллекта для оптимизации технологических и бизнес-процессов такие как: системы предсказания спроса на товары в ритейле, рекомендательные системы в банках, цифровые двойники, cистемы поддержки принятия решений на производстве и многое другое. Алгоритмы Rubbles ежедневно улучшают работу крупнейших банков, ритейл-сетей, нефтегазовых компаний и других предприятий. Мы ищем data engineer'ов разного уровня для усиления нашего направления, которое занимается разработкой систем прогнозирования спроса на товары, ценообразования, автоматического подбора оптимальных промо-акций и др. Задачи: Разработка и развитие платформы прогнозирования – архитектура и реализация инструментов для построения ML-пайплайнов (подготовка данных, сбор фичей, обучение моделей, применение моделей, ведение ML-экспериментов и т.п.) Помощь коллегам DS в оптимизации их работающих пайплайнов. Проактивность с предложениями оптимизации Взаимодействие с коллегами Devops по настройке окружений, деплоя кода, работы с инфраструктурой компании Общение с коллегами DQ, выяснение деталей наполенения данных, участие в составлении БТ к данным Решение неожиданных проблем с данными, задержками их доставки. Минимальные требования: Уверенные знания Python 3.7 + Spark 2.4 / Spark 3.0 (структуры данных, алгоритмы, концепции языка) Уверенные знания SQL: агрегации, джойны, вложенные запросы, индексы, оптимизации запросов Глубокие теоретические знания стека технологий и практический опыт (Spark, Hadoop, Hive Kubernetes (K8S)) Linux Опыт проектирование БД, понимание концепций OLAP и OLTP Опыт оптимизаций sql-запросов и понимание оптимизаций на уровне spark catalyst. На что ещё смотрим: Опыт работы с Airflow и другими подобными инструментами для запуска регулярных задач Опыт Devops (Docker, Gitlab-CI, настройка окружения на серверах и др.) Опыт разработки сервисов (Flask, Django, Asyncio и др.) Опыт проектирования высоконагруженных приложений и/или приложений работы с большими данными Опыт использования машинного обучения Опыт разворачивания, настройки мониторинга и передача на поддержку разработанных решений Pytest/Unitest Опыт работы с такими базами данных как PostgresQL, Greenplum, Clickhouse, SQLAlchemy. У нас: Работа в одной из самых сильных ML команд в России Гибкий график работы, гибкое предоставление отгулов и отпусков Поддержка в профессиональном и карьерном росте, оплата профильного обучения, конференций и книг, корпоративные скидки на курсы английского Совместная работа с опытными разработчиками, аналитиками данных, менеджерами, продуктологами ДМС со стоматологией после испытательного срока (3 месяца) по всей России При желании работать из офиса – уютный офис в центре Москвы (2 минуты от м. Сухаревская) со всем необходимым для комфортной работы. Особенно актуальное: Мы аккредитованная Т-компания со всеми вытекающими льготами.","Python,Spark,Hadoop,SQL,Big Data,Hive,Kubernetes,Linux",Rubbles,
12492,78887882,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","СберЗдоровье - аккредитованная IT-компания, крупнейшая в России Digital Health платформа, объединяющая различные сервисы цифровой медицины. Сервис начал свою работу в 2012 году под брендом DocDoc. Мы помогли миллионам людей получить помощь и продолжаем повышать качество медицинских услуг. Об IT в цифрах: 3 бизнес-направления 15+ команд (каждая наша команда кросс-функциональная, 7-12 человек, включает в себя QA, DevOps, аналитиков, архитекторов, Web/Mobile разработчиков и конечно же своего PM) 250+ IT специалистов (devops, manual/auto QA, web/mobile devs, backend devs, аналитики и архитекторы) из 40+ городов Чтобы система была безопасней, а наши пользователи — счастливей, мы открыли вакансию DevSecOps. Почему у нас интересно? Потому, что у нас современный и востребованный продукт. Цели и задачи (на любой вкус): Выбрать целевую БД и построить хранилище данных Vertica / Greenplum / Citus / что-то другое Разобраться с CDC — думаем про Debezium DV2.0 / Anchor / Гибрид DataOps / MLOps — затащить лучшие инструменты и практики Airflow + DBT + Great Expectations + DVC + MLFlow + label studio или любой другой стек в рамках здравого смысла Каталог данных / Data Discovery / Data Lineage Datahub / Amundsen / Marquez / другое отличное решение Архитектура и имплементация своего click+event stream решения Snowplow / Rudderstack / Jitsu / другое отличное решение Что надо уметь: Опыт 2+ года в роли DE с похожими задачами Отличные знания Python и SQL Уверенные знания и опыт по нескольким пунктам из списка: Модели хранилищ данных: плюсы, минусы, подводные камни Airflow / Prefect / Dagster DBT / что-то схожее Great Expectations / другие DQ либы MLFlow / Kubeflow и DVC Kafka и Spark / Flink Vertica / Greenplum / Citus / Clickhouse Что тебе может дать СберЗдоровье: Возможность развития в команде ведущей MedTech-компании России. Свободный выбор рабочего формата: удалённый внутри страны или гибридный в Москве. Офис на набережной рядом с метро «Автозаводская». Корпоративное медицинское решение в любом городе страны со стоматологией и психологами. Поддерживаем активный образ жизни: выбирай виды спорта по душе (корпоративные команды, компенсация абонемента). Оплата профильного обучения и конференций. Скидки и бенефиты от наших партнёров. Оплачиваемые курсы английского языка. Льготная ипотека. Приятное дополнение: Всегда поддержим, если ты захочешь посетить профильные конференции, и, тем более, выступить на них. Мы общаемся на “ты”, не любим бюрократию и всегда помогаем друг другу.","Работа с базами данных,DataOps,MLOps,Airflow,Python,MS SQL,Prefect,Dagster,Great Expectations,MLFlow,Kubeflow,DVC,Kafka,Spark,Flink,Vertica,Greenplum,Citus,ClickHouse",СберЗдоровье,
12540,76703124,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","ЧЕМ ВЫ БУДЕТЕ ЗАНМАТЬСЯ: Сбор, обработка и парсинг ""сырых"" данных Поддержка и развитие корпоративного хранилища данных Определение потребностей и требований бизнес-пользователей Управление потоками данных Организация работы с большими данными Создание витрин данных Управление данными и распределение на слои (горячие, холодные) Написание SQL-запросов для получения данных Написание ТЗ для DevOps, DevSecOps, DataOps Развитие стандарта по управления данными. ЭТА РАБОТА ДЛЯ ВАС, ЕСЛ МЕЕТЕ: Опыт проектирования и разработки архитектуры БД Опыт работы c MPP системами (Greenplum) Опыт разработки Python и Java/Scala Опыт разработки сложных SQL запросов Опыт работы с ETL инструментами Опыт построения отчетности Опыт работы с нереляционными БД Понимание специфики работы с персональными данными. ПРЕМУЩЕСТВОМ БУДЕТ: Опыт в качестве DE или аналитика данных Знание принципов гибкого подхода MLOps Опыт работы с docker, k8s, kafka. ЖДЁМ ВАШЕ РЕЗЮМЕ!","Архитектура БД,MPP,Python,Java/Scala,SQL,MLOps",АЛРОСА нформационные технологии,"Москва, Новокузнецкая, Павелецкая, Третьяковская, Озерковская набережная, 30"
12545,76693962,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","ЧЕМ ВЫ БУДЕТЕ ЗАНМАТЬСЯ: Сбор, обработка и парсинг ""сырых"" данных Поддержка и развитие корпоративного хранилища данных Определение потребностей и требований бизнес-пользователей Управление потоками данных Организация работы с большими данными Создание витрин данных Управление данными и распределение на слои (горячие, холодные) Написание SQL-запросов для получения данных Написание ТЗ для DevOps, DevSecOps, DataOps Развитие стандарта по управления данными. ЭТА РАБОТА ДЛЯ ВАС, ЕСЛ МЕЕТЕ: Опыт проектирования и разработки архитектуры БД Опыт работы c MPP системами (Greenplum) Опыт разработки Python и Java/Scala Опыт разработки сложных SQL запросов Опыт работы с ETL инструментами Опыт построения отчетности Опыт работы с нереляционными БД Понимание специфики работы с персональными данными. ПРЕМУЩЕСТВОМ БУДЕТ: Опыт в качестве DE или аналитика данных Знание принципов гибкого подхода MLOps Опыт работы с docker, k8s, kafka. ЖДЁМ ВАШЕ РЕЗЮМЕ!","Архитектура БД,MPP,Python,Java/Scala,SQL,MLOps",АЛРОСА нформационные технологии,"Москва, Новокузнецкая, Павелецкая, Третьяковская, Озерковская набережная, 30"
12550,78823057,Data engineer (Рекламная платформа),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы - новая быстрорастущая команда, создающая сервис, который будет управлять цифровыми рекламными поверхностями и платформой по размещению рекламы на поверхностях Банка и Экосистемы. спользуя данные СБЕРа и технологические решения его экосистемы, мы сможем реализовать уникальный сервис на рынке digital marketing. Он позволит нам показывать пользователям рекламу, которая будет нравиться и которая будет делать рекламные продукты эффективными и измеримыми для рекламодателей. Если вы талантливый и амбициозный специалист в сфере Т, если вы хотите быть причастными к созданию лучших продуктов для лучших клиентов и уверенно отвечать за результаты, то мы рады принять вас в команду. Чем предстоит заниматься: Разрабатывать и поддерживать микросервисы для работы с данными в экосистеме Hadoop (Cloudera, Hortonworks, Apache BigTop и др.) Разрабатывать и оптимизировать пайплайны обработки данных на python / scala - от логов nginx до записи в ClickHouse Решать сложные технические задачи в ETL слое - развивать и сопровождать DWH на базе Hadoop/ Greenplum/ ClickHouse Быть одним из драйверов развития архитектуры и инфраструктуры проекта. Мы ожидаем: Поиск, обработка и построение витрин данных на инфраструктуре Hadoop Опыт промышленной разработки на стеке Java/Scala/Python Опыт реализации REST, SOAP. Понимание принципов работы SSO, Kerberos Опыт разработки приложений с использованием инструментов Spark Streaming, Hbase, Spark, Kafka, Hive, Impala, Hue и т.д. Хорошие знания SQL, опыт работы с одной из реляционной БД - Oracle/PostgreSQL/mySQL/MS SQL Server Понимание принципов модели распределенных вычислений, принципов организации Data Lake/DWH Понимание подходов к организации разработки (CI/CD, DevOps), практический опыт работы с инструментами Jenkins, SonarQube, TeamCity, Anisble, Git (BitBucket/GitLab). Мы предлагаем: нтересные задачи по продуктам, влияющим одновременно на всю Экосистему: мы пишем продукты с 0, а значит никакого legacy и свобода творчества Команда специалистов из топовых Т компаний Регулярное обучение и профильные конференции, современное оборудование для работы Уровень дохода, который готовы обсуждать и отталкиваться от ваших пожеланий, плюс премии Комфортный офис и гибкий график Множество плюшек от Сбера.","Git,SCALA,PostgreSQL,Python,Hadoop",Сбер. IT,"Москва, Оружейный переулок, 41"
12558,78823057,Data engineer (Рекламная платформа),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы - новая быстрорастущая команда, создающая сервис, который будет управлять цифровыми рекламными поверхностями и платформой по размещению рекламы на поверхностях Банка и Экосистемы. спользуя данные СБЕРа и технологические решения его экосистемы, мы сможем реализовать уникальный сервис на рынке digital marketing. Он позволит нам показывать пользователям рекламу, которая будет нравиться и которая будет делать рекламные продукты эффективными и измеримыми для рекламодателей. Если вы талантливый и амбициозный специалист в сфере Т, если вы хотите быть причастными к созданию лучших продуктов для лучших клиентов и уверенно отвечать за результаты, то мы рады принять вас в команду. Чем предстоит заниматься: Разрабатывать и поддерживать микросервисы для работы с данными в экосистеме Hadoop (Cloudera, Hortonworks, Apache BigTop и др.) Разрабатывать и оптимизировать пайплайны обработки данных на python / scala - от логов nginx до записи в ClickHouse Решать сложные технические задачи в ETL слое - развивать и сопровождать DWH на базе Hadoop/ Greenplum/ ClickHouse Быть одним из драйверов развития архитектуры и инфраструктуры проекта. Мы ожидаем: Поиск, обработка и построение витрин данных на инфраструктуре Hadoop Опыт промышленной разработки на стеке Java/Scala/Python Опыт реализации REST, SOAP. Понимание принципов работы SSO, Kerberos Опыт разработки приложений с использованием инструментов Spark Streaming, Hbase, Spark, Kafka, Hive, Impala, Hue и т.д. Хорошие знания SQL, опыт работы с одной из реляционной БД - Oracle/PostgreSQL/mySQL/MS SQL Server Понимание принципов модели распределенных вычислений, принципов организации Data Lake/DWH Понимание подходов к организации разработки (CI/CD, DevOps), практический опыт работы с инструментами Jenkins, SonarQube, TeamCity, Anisble, Git (BitBucket/GitLab). Мы предлагаем: нтересные задачи по продуктам, влияющим одновременно на всю Экосистему: мы пишем продукты с 0, а значит никакого legacy и свобода творчества Команда специалистов из топовых Т компаний Регулярное обучение и профильные конференции, современное оборудование для работы Уровень дохода, который готовы обсуждать и отталкиваться от ваших пожеланий, плюс премии Комфортный офис и гибкий график Множество плюшек от Сбера.","Git,SCALA,PostgreSQL,Python,Hadoop",Сбер. IT,"Москва, Оружейный переулок, 41"
12560,75525561,Data Engineer (Аудиторные технологии),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы - новая быстрорастущая команда, создающая сервис, который будет управлять цифровыми рекламными поверхностями и платформой по размещению рекламы на поверхностях Банка и Экосистемы. спользуя данные СБЕРа и технологические решения его экосистемы, мы сможем реализовать уникальный сервис на рынке digital marketing. Он позволит нам показывать пользователям рекламу, которая будет нравиться и которая будет делать рекламные продукты эффективными и измеримыми для рекламодателей. Если вы талантливый и амбициозный специалист в сфере Т, если вы хотите быть причастными к созданию лучших продуктов для лучших клиентов и уверенно отвечать за результаты, то мы рады принять вас в команду. В рамках данной позиции предстоит: разрабатывать и поддерживать микросервисы для работы с данными в экосистеме Hadoop развивать и сопровождать DWH на базе Hadoop быть лидером поставки сервиса, отвечать за техническую целостность продукта и его работу в промышленном контуре Наши ожидания от вас: не менее 2 лет опыта работы на лидирующей позиции в проекте, связанном с обработкой данных готовность принимать решения и брать на себя ответственность практический опыт разработки и хорошее знание Python опыт промышленной разработки на стеке Java/Scala/Python практический опыт разработки приложений с использованием инструментов Spark Streaming, Hbase, Spark, Kafka, Hive, Impala, Hue и т.д. хорошие знания SQL, опыт работы с одной из реляционной БД - Oracle/PostgreSQL/mySQL/MS SQL Server понимание подходов к организации разработки (CI/CD, DevOps), практический опыт работы с инструментами Jenkins, SonarQube, TeamCity, Anisble, Git (BitBucket/GitLab). Мы предлагаем: интересные задачи по продуктам, влияющим одновременно на всю Экосистему: мы пишем продукты с 0, а значит никакого legacy и свобода творчества команда специалистов из топовых Т компаний регулярное обучение и профильные конференции, современное оборудование для работы официальное трудоустройство согласно ТК РФ белая заработная плата ДМС оздоровительные программы для детей сотрудников возможность обучения за счет компании выплаты материальной помощи в особых/чрезвычайных случаях дисконт-программы от компаний партнеров льготное кредитование комфортный офис и гибкий график.","Git,PostgreSQL,SQL,Java,Python",Сбер. IT,"Москва, Оружейный переулок, 41"
12589,72161518,Старший дата-инженер / Senior Data Engineer,от 270 000 руб. до вычета налогов,3–6 лет,"Полная занятость,полный день","Are you ready to take your career to the next level? P&G's IT community is looking for a Senior Data Engineer to join our Data team in Moscow! In this role, you will be responsible for building systems and solutions leveraging various Cloud components & tools. This is your chance to work on interesting, global projects with some highly skilled and fun people. We will provide you with all the necessary training and knowledge to perform well during your journey at P&G. Our stack Azure Cloud (ADF, SQL DB, etc.) Databricks (Python/PySpark/SQL) Data visualization with Power BI Azure DevOps (SCRUM, CI/CD) What can you expect? In this role, you will use cutting-edge technology, an industry-leading data solution architecture, and a governance model to solve real P&G business problems. You will have the opportunity to: Design and implement complex technical solutions to obtain, process, and store data. Automate and optimize internal ETL processes in MS Azure. Share the best industry practices with the local Data Engineering community, deliver training sessions and other learning opportunities. Get access to the comprehensive training portfolio, including MS Certifications, Coursera, and other professional courses. Learn from the global P&G IT community to advance your skills. Compensation & Benefits Monthly salary starting from 270M RUB gross Annual bonus Monthly lunch & flexibility allowance 5 000 RUB gross Medical, travel, and life insurance Flexible work hours and the possibility to work from home Access to P&G’s global comprehensive training portfolio Relocation support in case you move to Moscow from another region Qualifications: Mandatory A university degree (DipHE) is required Advanced Python and SQL programming skills PySpark programming skills Hands-on experience in writing clean & effective code Knowledge and/or experience in leveraging or building CI/CD tools Knowledge of SCRUM and DevOps methodologies Good command of English (Upper-Intermediate or higher level) Qualifications: Nice to have Experience in implementing projects & solutions using Microsoft Azure or any other cloud stack Just So You Know All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, age, sexual orientation, gender identity and expression, marital status, citizenship, HIV/AIDS status, or any other legally protected factor. No immigration sponsorship is available for this position. P&G is a leading global consumer goods company whose winning brands are built around the model of innovation. Whatever your passion is, we want to ignite your potential to become your very best self. We hold true to our purpose, values, and principles as we seek to make a difference in the world around us. You will engage in meaningful work that will touch the lives of others and have a real impact. Everything at P&G starts with understanding – understanding our consumers and our employees as we innovate to improve lives now and for generations to come.","Python,SQL,Английский — B2 — Средне-продвинутый","«Procter & Gamble», Опытный специалист","Москва, Войковская, Ленинградское шоссе, 16ас2"
12601,77599910,Senior DevOps engineer на продукт МТС Аналитика (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data в МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior DevOps engineer на продукт МТС Аналитика Описание продукта: МТС Аналитика – это единая аналитическая платформа для анализа поведения пользователей в web и app приложениях экосистемы МТС. Наша цель – эффективная рекламная атрибуция, обогащенные Big Data полезные данные о когортах, кросс-продуктовый пользовательский путь и LTV пользователя и продукта, сдобренные собственным UI для визуализации метрик и командной работы. Мы ищем DevOps инженера, которые поможет нам развивать платформу. Обязательно: опыт работы с python или go опыт работы с реляционными и нереляционными базами данных: работа под нагрузкой, репликация, резервирование, профилирование опыт работы с веб-серверами и балансировщиками нагрузки опыт работы с системами управления конфигурацией, инструментами CI/CD и Git понимание работы сети (IP/TCP/HTTP), умение диагностировать и решать проблемы понимание работы docker опыт работы с kubernetes опыт администрирования java приложений опыт работ по настройке и внедрению средств мониторинга микросервисной архитектуры и средств защиты информации в инфраструктуре непрерывной разработки в соответствии с концепциями SDLC и DevOps опыт внедрения, развития и поддержки инструментов информационной безопасности в архитектуре и процессах непрерывной разработки/доставки микросервисов (CI/CD), средств контроля качества кода умение выявлять архитектурные недочеты и риски в планируемой и реализованной инфраструктуре Что предстоит делать? обеспечивать оснащение необходимыми мониторингами, графиками и CI/CD для новых и/или существующих компонентов платформы развертывать кластера хранилищ данных и очередей сообщений масштабировать всю систему в связи с постоянно растущей нагрузкой автоматизировать ручную работу чтобы не тратить время на рутину внедрять новые и развивать существующих практик DevOps внутри команд разработки формировать требования безопасности и внедрять корпоративные инструменты безопасной разработки осваивать и внедрять новые методики и инструменты DevOps Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой.","CI/CD,Python,Go,Git",МТС,
12636,78754704,Senior Архитектор в Golden Record (Big Data),з/п не указана,3–6 лет,"Полная занятость,гибкий график","Big Data в МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior Архитектор в Golden Record Описание продукта: Golden record - это платформа, которая собирает клиентские данные из разных источников (более 10) в группе компаний, очищает и стандартизирует их. Затем объединяет эти данные в «экосистемных» клиентов, получая эталонные данные. Далее эти данные предоставляются для использования на всем ландшафте группы компаний. Одной из задач является уменьшение времени подключения к платформе как в качестве поставщика данных, так и в качестве потребителя, с учетом требований информационной безопасности, регуляторов. Также в качестве источников данных могут добавляться сторонние (3-d party) сервисы. Обязательно: опыт работы с реляционными (Oracle, PostgreSQL, MS SQL), NoSQL, Key-Value базами данных от 5-и лет опыт участия в проектах по созданию и развитию и моделированию данных DWH/Data Lake/MDM/RDM от 3-х лет опыт проектирования API от 1 года опыт работы с очередями (Kafka, RabbitMQ) от 1 года понимание шаблонов проектирования интеграционных решений (batch, streaming) понимание принципов работы высоко-доступных, гео-распределенных систем знание SQL на уровне Middle+, знание одного из языков Java, Python, Scala, C# (потребуется code review + помощь в создании POC (proof of concept) Будет плюсом: GraphQL Cassandra / Scylla Aerospike CE знание систем класса MDM, систем класса CDC Что предстоит делать? проектировать архитектуру платформы GR HUB для выполнения функциональных и нефункциональных требований, с учетом ограничений информационной безопасности, законодательства и внутренних политик проектировать и стандартизировать варианты интеграции поставщиков и потребителей данных из ландшафта МТС с платформой GR HUB (ETL, Streaming, API) проектировать варианты интеграций со сторонними поставщиками данных (3-d party API) для расширения модели данных, дополнительной валидации атрибутов (API) проанализировать применимость систем класса CDC (change data capture) либо паттерна transactional outbox или других паттернов для интеграции с legacy-системами ландшафта МТС, выбирать и совместно с командами систем-источников реализовать решение совместно с разработчиками и DevOPS инженерами команды проектировать и внедрять процессы CI/CD, мониторинга для обеспечения заявленных показателей доступности и надежности, скорости выпуска релизов поддерживать в актуальном состоянии архитектурную документацию, участвовать в защитах решения на комитетах, готовить архитектурную часть документации для перевода платформы в опытно-промышленную и промышленную эксплуатации (ОПЭ) Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой.","API,CI/CD,SQL,Kafka,Java,Python,SCALA,C#",МТС,
12676,78669166,Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Мы интернациональная команда, занимающаяся адаптацией,  локализацией и созданием новых сервисов экосистемы для дочерних банков экосистемы Сбер. Чем предстоит заниматься: полным циклом разработки всех слоев хранилища данных и отображения отчетности участвовать в составлении плана проекта, оценка проектных сроков и рисков участвовать в проектировании системы, решать сложные исследовательские задачи по реализации никем ранее не реализованного функционала развивать корпоративное хранилище и витрины данных (АС Облако данных) для развития международного бизнеса Сбербанка. Участвовать в сложных интеграционных проектах по развитию корпоративного DWH (преимущественно Hadoop, возможно, интеграции с БД Oracle и Teradata) в роли разработчика. разрабатывать и проектировать потоки данных, алгоритмы загрузки и обработки данных в Hadoop с использованием Apache Spark разрабатывать и оптимизировать ETL, обеспечивать производительность и стабильность, при необходимости участвовать в анализе инцидентов организовывать оптимальный процесс разработки участвовать в приемке системы. Мы ожидаем: опыт работы в области Data engineer от одного года. Работа с данными: знание SQL - простые запросы, Join`ы, агрегаты, группировки, вложенные запросы знание python: стандартные структуры данных (dict, list, set, модуль collections), pandas, numpy, h5py опыт работы с Hadoop (Hive, Spark, HBase) является плюсом. Моделирование: Feature Engineering: - методы оценки значимости и отбора признаков, методы уменьшения размерности, приемы работы с текстом Model - умение различать основные классы задач (регрессия, классификация, кластеризация) и формулировать бизнес-задачу в их терминах. Знать основные методы и знать api по их использованию Python - sklearn, numpy, scipy, xgboost (в порядке убывания приоритета). Evaluation: умение различать методы оценки качества модели под основные классы задач и понимать плюсы и минусы их применения. (f1, precision, recall, roc auc, mse, rmse, silhouette) опыт работы с инструментами для организации и автоматизации работы: GridSearch, pipelines, ide, git, Jira, Confluence понимание методологии Agile и DevOps владение английским языком на уровне чтения технической документации. Мы предлагаем: работа в команде профессионалов, возможность разрабатывать уникальные и крупные проекты масштаба нашей страны можно работать в офисе или в смешанном графике конференции и обучение на корпоративных или вендорских курсах за наш счёт отличная ДМС, включая несчастные случаи и тяжелые заболевания льготные условия по ипотеке и кредитам материальная помощь и социальная поддержка корпоративная пенсионная программа офис в бизнес-центре Поклонка (м. Кутузовская).","Python,Hadoop,Spark,DWH",Сбер. IT,
12677,78668027,"Big Data Engineer (Spark, Hadoop)",з/п не указана,3–6 лет,"Полная занятость,полный день","Нашему будущему коллеге предстоит работать над проектом: OMNI-дашборды - системой визуализации отчетности для покрытия потребности в аналитических инструментах для высшего и среднего менеджмента Компании. Работать над развитием Корпоративного Хранилища Данных (Hadoop), которое является основным источником данных для этого проекта. Также, в работе у команды проект по переезду с google analytics на Snowplow. Через несколько месяцев мы планируем проект по развитию Больших данных клиентской аналитики. Цель проекта – реализовать уникальную систему по работе с клиентскими данными ПАО ""Детский мир"" на основе используемых компонентов и стэка технологий и программного обеспечения компании. По итогам проекта в компании появится единый источник непротиворечивой и консистентной информации для принятия управленческих решений. Мы ищем эксперта с высокой ролью ответственности на проекте, умеющего самостоятельно и в команде принимать решение по архитектуре и реализации. Наш стек: последние версии Apache Spark и Apache Airflow Hadoop 3 Docker, Kubernetes GitLab для CI/CD Что нужно делать? создавать Spark ETL pipeline для загрузки данных в HDFS и преобразования данных на HDFS обсуждать с аналитиками алгоритмы преобразования данных, переводить SQL от аналитиков в Spark API участвовать в code review проектировать и создавать архитектуру проекта и адаптировать ее под новые требования выстраивать процессы CI/CD, мониторинга, взаимодействовать с командой DevOps заниматься созданием и развертыванием REST-сервисов на базе Spring Kotlin заниматься развертыванием вспомогательной инфраструктуры (Airflow, Zeppelin, Spark History/Thrift Server) в Kubernetes Заниматься созданием Streaming job Наши ожидания: знания SQL опыт работы с Docker обязателен понимание жизненного цикла разработки ПО, культуры CI/CD опыт создания и оптимизации Spark batch jobs, Scala API (PySpark не используется) Опыт разработки на Java (kotlin) Spring Service опыт работы с Airflow, умение создавать DAG'и, состоящие из Task и Sensor Будет плюсом: опыт работы с Kubernetes, Helm опыт работы с Kafka, Nifi, Spark Streaming любые открытые инструменты для Streaming опыт работы с GitLab CI/CD проектирование сбора/визуализации метрик с использованием Prometheus/Grafana Мы предлагаем: Официальное оформление в соответствии с ТК РФ стандартный трудовой договор (П,ГПХ не делаем), официальная аккредитация IT компании (выписки по форме от генерального сотрудникам делаем, помогаем сотрудникам с отсрочкой). Разноплановые и нестандартные задачи, уникальный опыт, отсутствие легаси Продуктовая команда, отсутствие бюрократии и длительных согласований, заинтересованный в результате бизнес Высокий уровень оклада + годовая премия График работы 5/2, гибкое начало рабочего времени, возможна частично-удаленная/или полностью удаленная работа на выбор, офис Москва м/мцк/мцд Окружная. Можно работать из другой страны до 180 дней. Расширенный полис ДМС Скидка на продукцию компании Выдаем современные макбуки","Spark,Hadoop,Kafka,Kubernetes,Java",Детский Мир,
12682,78685018,Data Engineer (Разработчик ETL),з/п не указана,3–6 лет,"Полная занятость,полный день","В 2022 году Московской бирже исполнилось 30 лет. Мы появились вместе с современной Россией и за эти годы с нуля создали рынок инвестиций. Сегодня миллионы людей и тысячи компаний доверяют нам и пользуются нашей инфраструктурой. Ежедневно на наших торговых платформах совершаются миллионы транзакций в минуту – без задержек, без перебоев. Мы храним в депозитарии цифровые записи о каждом активе, который торгуется на бирже. Мы следим за тем, чтобы все операции соответствовали правилам торгов и требованиям регуляторов. А еще мы активно развиваемся и давно вышли за рамки классического биржевого бизнеса. Мы разрабатываем и поддерживаем платформы, которые соединяют финансовые компании и клиентов, Мы идем на внебиржевой рынок и создаем на нем удобные сервисы, Мы открываем новые возможности для инвесторов, корпораций, банков. Мы развиваем финансовую культуру страны. В #moexteam уже больше 2200 человек: Т-специалисты и эксперты по развитию рынков, продуктовые и проектные менеджеры, финансисты и юристы, маклеры и многие другие. Мы разные, но всех нас объединяет общая цель – помочь людям и компаниям управлять деньгами, используя передовые технологии и знания. В Департамент по работе с данными открыта вакансия Разработчик ETL (Data Engineer) Чем предстоит заниматься Разработка интеграционных ETL процессов обмена данными между автоматизированными системами Группы Московская Биржа для задач монетизации Группы Разработка процедур контроля интеграционных процессов обмена данными между автоматизированными системами Группы Московская Биржа Разработка объектов СУБД Oracle (stored procedures, view) пре- и пост- обработки данных для загрузки данных в Витрины и Единое Хранилище Данных для задач монетизации Группы. Руководство группой разработчиков: технические консультации разработчикам, архитектурный контроль выполняемых работ ( команда аутстафферов) Мы ожидаем от вас Опыт работы разработчиком ПО или ETL от 5 лет, предпочтительно в финансовом/банковском секторе Уверенное знание SQL Опыт работы с Oracle DB Желателен опыт работы с GreenPlum Уверенное знание bash-скрипт Уверенное знание Python, XML, JSON, Rest API, Kafka Желательно знание Java и желание развиваться в направлении Java Опыт работы с технологиями DataOps/DevOps/CI/CD - Непрерывная интеграция и непрерывная поставка, включая: GIT, Jenkins Английский язык технический Грамотная устная и письменная речь.","ETL,SQL,Oracle DB,GreenPlum,Python,XML,JSON API,Rest API,Kafka,Java,Git,Jenkins,CI/CD",Московская Биржа,
12698,78641714,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Команда по работе с проблемными активами Сбера ищет Разработчика ETL-процессов / Data Engineer (Hadoop). Команда «Управленческая отчетность и Бизнес-планирование» отвечает за несколько основных направлений: - Управленческая отчетность по Корп. взысканию (формирование «чистых» витрин данных, расчет всех финансовых показателей) - Бизнес-планирование (все основные фин. показатели + P&L, поскольку ДРПА – профит-центр) - Подготовка материалов на Правление и КО в рамках защит бизнес-планов - Визуализация аналитических материалов в BI-системе (разработка mashup-ов/dashboard-ов) Обязанности • разработка прототипов витрин данных в Hadoop (Hive, Spark, Scala), PostgreSQL • перенос и оптимизация реализованных алгоритмов с SAS на Scala Требования • знание экосистемы Hadoop: Hive, Spark • опыт разработки на Spark, Scala, PostgreSQL • хорошее знание SQL • проектирование и разработка потоков данных, алгоритмов загрузки и обработки данных в Hadoop • выстраивание и оптимизация производительности ETL-потоков • наличие развитых аналитических способностей и системное мышление • общий стаж работы не менее 3 лет • непреодолимая тяга к обучению и саморазвитию • высшее техническое образование. Преимуществом будет: • если вы участвовали в построении DEVOPS-трубы (настройка BitBucket, Nexus, Jenkins) • опыт разработки на Scala и если вы участвовали в релизном процессе вывода витрин в ПРОМ Что мы предлагаем: В связи с общебанковской миграцией L2P и уходом вендоров стоит амбициозная задача – текущее аналитическое решение мигрировать (etl – в сторону КАП, свои витрины (свою логическую обработку) – замена стека с SAS на PG SE). Задача очень сложная, но по масштабам интересная, как и люди в нашей команде. • современный IT-офис вблизи Москва-Сити в пяти минутах от метро ""Кутузовская"", с фитнес залом • стабильную белую заработную плату и годовую премию • заряженную команду профессионалов и адекватное руководство • важные и амбициозные задачи • бесплатное обучение в лучшем корпоративном университете • льготные условия по ипотеке • скидки и бонусы от партнеров Сбера • ДМС с первого рабочего дня с возможностью прикрепления родственников к программе • сплоченный коллектив, работающий над общими задачами и умеющий хорошо отдыхать.",,Сбер для экспертов,
12739,78570837,Data Engineer at Orca Security,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Он Зэ Спот Девелопмент,
13044,79057856,Data Analyst (mobile games),з/п не указана,1–3 года,"Полная занятость,полный день","Мы расширяем команду и ищем талантливого Аналитика данных. Новый аналитик будет работать с продуктовыми и маркетинговыми метриками мобильных игр, развивать систему мониторинга этих метрик, проводить АБ-тесты и улучшать персональные офферы. Если мат.стат, Python и уверенные знания об игровой индустрии в наличии, как и желание вникать в суть вещей, то делайте тестовое и откликайтесь на вакансию! Основные направления работы сследовать аномалии в продуктах и искать их причины. Вести АБ-тесты, от формирования гипотезы до проверки результатов. Участвовать в разработке внутренних продуктов в роли продакт-оунера. Придумывать и прорабатывать LiveOps-акции и новые способы монетизации, не забывая оценить их результат. Ключевые требования Законченное высшее образование От 1 опыта работы аналитиком данных Опыт работы с играми или мобильными приложениями Уверенные знания математической статистики и теории вероятностей Владение Python для ежедневной работы Знание SQL, опыт с Clickhouse будет плюсом Знание методологии А/В-тестирования Понимание продуктовых метрик, опыт применения к играм будет плюсом Желание развиваться в аналитике игр Готовность много учиться и применять свои навыки на практике Широкий кругозор в мобильных играх: умение выделить плюсы\минусы решений в различных жанрах и аргументировать их. Мы предлагаем Профессиональное развитие в игровой аналитике данных Работа с проектами на разных стадиях разработки Результаты, которыми можно гордиться (и рассказать на конференциях) Достойная белая заработная плата Удаленный, офисный или гибридный формат работы Бюджет на профессиональное обучение и посещение конференций Частичная компенсация фитнеса и ДМС со стоматологией Онлайн-корпоративы и оффлайн-встречи отдела за настолками, стильный мерч и киберспортивные турниры. Процесс отбора на вакансию. Отклик с выполненным тестовым заданием (появится после нажатия кнопки ""откликнуться""). Общение с HR. Техническое собеседование с руководителем отдела. Принятие решения со стороны компании и кандидата. В случае отказа на любом этапе HR свяжется с вами по указанным контактам и сообщит о решении.","Python,SQL,Pandas,A/B тесты",Crazy Panda,
13171,79275855,Marketing analyst / Data analyst in marketing / Web analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Lucy in the Sky - бренд молодежной женской одежды, наш головной офис, студия дизайна и производство находится в городе Лос Анджелес, США. Lucy in the Sky Tech - это наша команда аналитиков, дизайнеров, web/mobile разработчиков и тестировщиков. Мы занимаемся автоматизацией e-commerce. Нашей Tech командой мы работаем над следующими проектами компании: - внутренняя система компании, которая позволяет автоматизировать весь бизнес и производственный процесс, работу склада, клиентский сервис и другие - интернет-магазин - мобильное приложение. В данный момент мы в поисках кандидата на позицию Marketing analyst, основной задачей которого будет аналитика и повышение эффективности платных рекламных каналов. Анализ эффективности маркетинговых каналов, инструментов Анализ отклонений, поиск точек роста и инсайтов в данных Помощь команде маркетинга с гипотезами, метриками и экспериментами. Ожидания от кандидатов: Аналогичный опыт работы аналитиком данных в маркетинге от 3 лет Успешные кейсы по оптимизации и увеличению конверсии Владение инструментами обработки данных (SQL, Python) Опыт работы с системами визуализации данных (AWS QuickSight, Data Studio, Power BI, Tableau, Splunk либо аналоги) Умение анализировать цифры, работать с маркетинговой аналитикой и оценивать эффективность маркетинговых инвестиций Системный подход в работе, аналитическое мышление Знание английского B1 Intermediate и выше (поиск информации и свободный разговорный английский) Будет плюсом опыт работы с каналами Facebook, Google, Tik Tok, Snapchat. Мы предлагаем: Отсутствие бюрократии, решения принимаем быстро Полностью удаленная работа из любой точки мира Зарплата в долларах Перевод зарплаты в криптовалюте (USDT) или любой иностранный банк Контрактная работа с американской компанией Работаем по американскому календарю  Регулярный Performance Review и Salary Review Оплачиваемый отпуск Оплачиваемый больничный Оплата онлайн курсов Udemy.","Анализ данных,Data Analysis,SQL,Python,MS Excel,Системное мышление,Аналитическое мышление,Аналитика,Маркетинг,Английский — B1 — Средний",Lucy in the Sky Inc,
13223,79120973,Data Engineer,от 2 500 до 4 000 USD на руки,3–6 лет,"Полная занятость,полный день","LATOKEN is the supermarket of assets where it is easy to discover, exchange, earn and spend crypto. Mission: Well-structured and secure data and monitoring.  Story: Product, Finance, OKRs, and Dash Teams need well-structured and secure data and monitoring to analyze and track the improvement of the services and product performance. Key PROBLEM's: The monitoring system alerts for any downtime, latency, or success rate issues of the services. All company data and events are merged and consolidated into the Data Base (DWH, PostgreSQL, Segment, Indicative, Google Analytics) to support the Monitoring system, Token Discovery, OKRs and Analytical Dashes. Acquisition channels, conversions, and users are correctly mapped and easy to access. Token DB is representative of the market and token data is correct and complete with on-chain and smm data. (30k tokens by end of April) How: Create new data pipelines for business need. Maintain scripts and pipelines in case of problems or new requirements. Define necessary events, set up recording and make available for reports and dashboards. Maintain and update token DB. Constraints: All OKRs of the company are consolidated into Platform Ops. All scripts are consolidated into Gitlab. Main performance number: Ops OKR Health Second performance number: Free Space DWH Third performance number: Query response time, sec avg  Functions: • OKRs Health : Calculate OKRs correctly, daily and in time • DWH objects audit • Queries : Advice on optimization and writing queries to databases. • Data quality : Keep data in order and provide reliable reporting • Automation : Automation of OKRs and slack bots for automated ops processes • Audit : Audit of DWH state and automated scripts  Requirement skills and experience: 2+ years of PostgresSQL DB administration experience 2+ years of experience writing Python scripts and applications for loading data Experience in configuring a database in a high-availability architecture Experience in database optimization for different load profiles Experience in automating data loading from different sources (CRM, ERP, Web resorses) Eager to work with people with high-performance standards Will be a plus: Experience with financial data Experience as a data/product analyst","Python,DWH,PostgresSQL,CRM,ERP",LATOKEN,
13232,71354549,Chief Data Scientist / DS Team Lead,з/п не указана,3–6 лет,"Полная занятость,полный день","Responsibilities: Collaborate, coach, and learn with a growing team of experienced Data Scientists and Data Trainees Collaborate with business partners to develop novel ways to meet objectives utilizing cutting edge techniques and tools Share passion for Data Science with broader enterprise community identify and develop long-term processes, frameworks, tools, methods and standards Effectively communicate the analytics approach and how it will meet and address objectives to business partners Advocate and educate on the value of data driven decision making focusing on the “how and why” of solving problems Lead analytic approaches, integrating work into applications and tools with data engineers, business leads, analysts and developers Create repeatable, interpretable, dynamic and scalable models that are seamlessly incorporated into analytic data products Engineer features by using their business acumen to find new ways to combine disparate internal and external data sources Domain Expertise: Bachelor’s degree required, in quantitative discipline and demonstrated Data Science skill set 4+ years work experience, 1+ year work experience as a team lead Python or R proficiency working with DataFrames and proficiency writing complex SQL queries Proficiency with Machine Learning to solve clustering, classification, regression, anomaly detection, simulation and optimization problems on large scale data sets Proven ability to merge and transform disparate internal & external data sets together to create new features Experience with Big Data technologies preferred — Hadoop, Spark, H20.ai, Cloud AI platforms, containerization Experience with supporting deployment, monitoring, maintenance and enhancement of models preferred Experience with data visualization tools preferred — Tableau, R Shiny, Plotly, etc. We Offer: Competitive salary Advanced benefits package (annual bonus, health insurance, mobile compensation, partial fitness compensation, 3-year saving plan) Professional development and career growth Ability to take part in digital transformation in a large company","Python,Machine Learning,SQL,Big Data,Spark,Data Analysis,Teambuilding,ML",Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
13236,75918379,Data Science Engineer (Computer Vision),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Merk это: Mobile, web, desktop и embedded разработка Работа с крупными зарубежными стартапами Более 450 специалистов высочайшей квалификации Более 40 млн пользователей наших приложений по всему миру Неоднократные попадания в Top AppStore и Google Play, упоминания в TechCrunch, Engadget, Gizmodo, Verge Офисы продаж расположены в Нью-Йорке, Майами, Атланте Центр разработки в России, Сербии, Армении и Казахстане Обязательные требования: Разговорный английский не ниже B2 Экспертный опыт работы с Python и создания пакетов (Numpy, Pandas, Matplotlib, Sklearn) Опыт работы с C++ Знание классических алгоритмов ML Опыт создания и обучения нейронных сетей с использованием Tensorflow/PyTorch Опыт работы с алгоритмами Computer Vision (Object Detection, 3D Mesh) Будет плюсом: Знание и понимание ООП Опыт в области робототехники Знание SQL на уровне выполнения сложных запросов выборки данных Наши условия: Заработная плата, адекватная знаниям и опыту Официальное оформление Возможность работать удаленно или из заграничных офисов Полный комплект оборудования для работы Гибкий график, главный принцип – работать с душой и пользой 40 часов в неделю) Дружелюбные, опытные коллеги и заботливое начальство Субсидирование профильных курсов и английского языка Рассматриваем кандидатов, готовых к релокации (Сербия, Армения, Грузия и иные направления) Приходи и создавай будущее вместе с нами!","Python,Numpy,Matplotlib,Sklearn,SQL,ML,Keras,Tensorflow,PyTorch,Computer Vision,Английский — B2 — Средне-продвинутый",Merk Team,
13257,79120974,Data Engineer,от 1 500 до 4 000 USD на руки,3–6 лет,"Полная занятость,полный день","LATOKEN is the supermarket of assets where it is easy to discover, exchange, earn and spend crypto. Mission: Well-structured and secure data and monitoring.  Story: Product, Finance, OKRs, and Dash Teams need well-structured and secure data and monitoring to analyze and track the improvement of the services and product performance. Key PROBLEM's: The monitoring system alerts for any downtime, latency, or success rate issues of the services. All company data and events are merged and consolidated into the Data Base (DWH, PostgreSQL, Segment, Indicative, Google Analytics) to support the Monitoring system, Token Discovery, OKRs and Analytical Dashes. Acquisition channels, conversions, and users are correctly mapped and easy to access. Token DB is representative of the market and token data is correct and complete with on-chain and smm data. (30k tokens by end of April) How: Create new data pipelines for business need. Maintain scripts and pipelines in case of problems or new requirements. Define necessary events, set up recording and make available for reports and dashboards. Maintain and update token DB. Constraints: All OKRs of the company are consolidated into Platform Ops. All scripts are consolidated into Gitlab. Main performance number: Ops OKR Health Second performance number: Free Space DWH Third performance number: Query response time, sec avg  Functions: • OKRs Health : Calculate OKRs correctly, daily and in time • DWH objects audit • Queries : Advice on optimization and writing queries to databases. • Data quality : Keep data in order and provide reliable reporting • Automation : Automation of OKRs and slack bots for automated ops processes • Audit : Audit of DWH state and automated scripts  Requirement skills and experience: 2+ years of PostgresSQL DB administration experience 2+ years of experience writing Python scripts and applications for loading data Experience in configuring a database in a high-availability architecture Experience in database optimization for different load profiles Experience in automating data loading from different sources (CRM, ERP, Web resorses) Eager to work with people with high-performance standards Will be a plus: Experience with financial data Experience as a data/product analyst","Python,DWH,PostgresSQL,CRM,ERP",LATOKEN,
13258,79244492,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
13266,75918380,Data Science Engineer (Computer Vision),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Merk это: Mobile, web, desktop и embedded разработка Работа с крупными зарубежными стартапами Более 450 специалистов высочайшей квалификации Более 40 млн пользователей наших приложений по всему миру Неоднократные попадания в Top AppStore и Google Play, упоминания в TechCrunch, Engadget, Gizmodo, Verge Офисы продаж расположены в Нью-Йорке, Майами, Атланте Центр разработки в России, Сербии, Армении и Казахстане Обязательные требования: Разговорный английский не ниже B2 Экспертный опыт работы с Python и создания пакетов (Numpy, Pandas, Matplotlib, Sklearn) Опыт работы с C++ Знание классических алгоритмов ML Опыт создания и обучения нейронных сетей с использованием Tensorflow/PyTorch Опыт работы с алгоритмами Computer Vision (Object Detection, 3D Mesh) Будет плюсом: Знание и понимание ООП Опыт в области робототехники Знание SQL на уровне выполнения сложных запросов выборки данных Наши условия: Заработная плата, адекватная знаниям и опыту Официальное оформление Возможность работать удаленно или из заграничных офисов Полный комплект оборудования для работы Гибкий график, главный принцип – работать с душой и пользой 40 часов в неделю) Дружелюбные, опытные коллеги и заботливое начальство Субсидирование профильных курсов и английского языка Рассматриваем кандидатов, готовых к релокации (Сербия, Армения, Грузия и иные направления) Приходи и создавай будущее вместе с нами!","Python,Numpy,Matplotlib,Sklearn,SQL,ML,Tensorflow,PyTorch,Computer Vision,Английский — B2 — Средне-продвинутый",Merk Team,
13269,71322369,Data Scientist Middle/Senior,з/п не указана,3–6 лет,"Полная занятость,полный день","Responsibilities: Collaborate with business partners to develop novel ways to meet objectives utilizing cutting edge techniques and tools Effectively communicate the analytics approach and how it will meet and address objectives to business partners Advocate and educate on the value of data driven decision making focusing on the “how and why” of solving problems Lead analytic approaches, integrating work into applications and tools with data engineers, business leads, analysts and developers Create repeatable, interpretable, dynamic and scalable models that are seamlessly incorporated into analytic data products Engineer features by using their business acumen to find new ways to combine disparate internal and external data sources Share their passion for Data Science with broader enterprise community identify and develop long-term processes, frameworks, tools, methods and standards Collaborate, coach, and learn with a growing team of experienced Data Scientists Stay connected with external sources of ideas through conferences and community engagements Domain Expertise: Bachelor’s degree required Graduate degree in quantitative discipline and demonstrated Data Science skill set, plus 3+ years work experience Must have Python or R proficiency working with DataFrames Must have proficiency writing complex SQL queries Must have proficiency with Machine Learning to solve clustering, classification, regression, anomaly detection, simulation and optimization problems on large scale data sets Must have proven ability to merge and transform disparate internal & external data sets together to create new features Advanced time series forecasting understanding – from classical linear approaches to ML ones Understanding the key business metrics and its application to ML models Experience with sophisticated data cleansing approaches & robust models Proficiency validating the current approaches and understanding the improvement area Experience with Big Data technologies preferred — Hadoop, Spark, H20.ai, Cloud AI platforms, containerization Experience with supporting deployment, monitoring, maintenance and enhancement of models desired Experience with data visualization tools preferred — Power BI, Tableau, R Shiny, Plotly, etc. Experience with AB testing preferred We offer: Competitive salary Advanced benefits package (annual bonus, health insurance, mobile compensation, partial fitness compensation, 3-year saving plan) Professional development and career growth Ability to take part in digital transformation in a large company","Python,Machine Learning,SQL,Big Data,Data science",Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
13272,79244487,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
13277,79244488,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
13281,78052551,Data Engineer (аналитик больших данных),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Обязанности: Разработка и поддержка инфраструктуры для хранения и обработки данных Создание ETL-процессов, используя внутренние и внешние источники данных Обеспечение полноты и доступности данных для решения задач в области статистического анализа и машинного обучения Наш технологический стек: CDH, Hadoop, Spark, Kafka, Hive, Impala, Kudu, Hue, Zeppelin, Jupyter, StreamSets. Требования: Опыт работы с распределенными системами хранения и обработки данных: Cloudera, Hadoop, Spark, Hive, Impala, Kudu Опыт работы с распределенными системами построения потоков данных: Kafka, Oozie, Airflow, StreamSets Опыт проектирования схем хранения данных Владение языком программирования Python Уверенные знания SQL Опыт администрирования OC Linux Желателен опыт администрирования Tableau Желателен опыт сбора информации о действиях пользователей с UI (web, mobile app). Условия: У нас нет бессмысленного формализма и дресс-кода, мы не занимаемся микро-менеджментом и осмотрительно относимся к KPI Удаленный режим работы Амбициозные и интересные задачи Конкурентная заработная плата в полном соответствии с ТК РФ Соцпакет с первого дня работы (ДМС, скидки на корпоративные продукты Сбера) Стабильная Компания","Python,SQL,Linux",Деловая среда,
13445,78998578,Data Insight Analytics Expert,з/п не указана,3–6 лет,"Полная занятость,полный день","Your responsibilities: Lead Segmented Execution deployment & value delivery of the use case core features Partner with Commercial managers, Regional Marketing managers, Regional General Sales managers to identify and ensure adaptation of regional specifics Deliver outlets segmentation based on external data sources and drive changes in execution strategy & resources allocation Lead internal advancements of market situation modelling and deriving insights from data analysis Design and implement novel Data Mining/Machine Learning approaches to structure and identify the key business problems that data and analytics can solve Develop and own Power BI reporting & Dashboarding Communicate solutions to non-technical teams Support data inventory and data management processes Requirements: University degree (business, math, economics, finance, statistic, science) English B2+ 3+ years experience of hands-on experience in big data analytics over big data (Data Engineering and Optimization experience) Power BI experienced user or significant experience in other data visualization platform Experience with geospatial data and relevant applications (QGIS etc.) MS Office – deep knowledge incl excel power functions: pivot/query, power point Experience in change management related to Big Data implementation is desirable Exceptional programming skills with Python and/or R Solid knowledge of the Azure Data bricks platform and the overall Azure Cloud environment Solid knowledge of Hadoop, Spark, Hive, Power BI and/or other visualization tools. SQL Server experience – ability to write complex queries We offer: Competitive salary Good opportunities for professional and career growth within great company Flexible working hours: 9.00 - 17.30 (8-16.30, 10-18:30 as the options) Internal educational courses and trainings Social package: Medical insurance, mobile compensation, corporate discounts","Python,Git,Big Data,Английский язык,Hive,Английский — C1 — Продвинутый",Мултон Партнерс,
13506,78537830,Data Engineer,от 1 500 до 4 000 USD на руки,3–6 лет,"Полная занятость,полный день","LATOKEN is the supermarket of assets where it is easy to discover, exchange, earn and spend crypto. Mission: Well-structured and secure data and monitoring.  Story: Product, Finance, OKRs, and Dash Teams need well-structured and secure data and monitoring to analyze and track the improvement of the services and product performance. Key PROBLEM's: The monitoring system alerts for any downtime, latency, or success rate issues of the services. All company data and events are merged and consolidated into the Data Base (DWH, PostgreSQL, Segment, Indicative, Google Analytics) to support the Monitoring system, Token Discovery, OKRs and Analytical Dashes. Acquisition channels, conversions, and users are correctly mapped and easy to access. Token DB is representative of the market and token data is correct and complete with on-chain and smm data. (30k tokens by end of April) How: Create new data pipelines for business need. Maintain scripts and pipelines in case of problems or new requirements. Define necessary events, set up recording and make available for reports and dashboards. Maintain and update token DB. Constraints: All OKRs of the company are consolidated into Platform Ops. All scripts are consolidated into Gitlab. Main performance number: Ops OKR Health Second performance number: Free Space DWH Third performance number: Query response time, sec avg  Functions: • OKRs Health : Calculate OKRs correctly, daily and in time • DWH objects audit • Queries : Advice on optimization and writing queries to databases. • Data quality : Keep data in order and provide reliable reporting • Automation : Automation of OKRs and slack bots for automated ops processes • Audit : Audit of DWH state and automated scripts  Requirement skills and experience: 2+ years of PostgresSQL DB administration experience 2+ years of experience writing Python scripts and applications for loading data Experience in configuring a database in a high-availability architecture Experience in database optimization for different load profiles Experience in automating data loading from different sources (CRM, ERP, Web resorses) Eager to work with people with high-performance standards Will be a plus: Experience with financial data Experience as a data/product analyst","Python,DWH,PostgresSQL,CRM,ERP",LATOKEN,
13520,77913328,Senior DataBase Administrator,з/п не указана,более 6 лет,"Полная занятость,полный день","Since 2003, Murano has been developing software that simplifies and optimizes the customer's daily work and contributes to the digitalization of key US industries as well. Besides the client projects, the company maintains and develops its product based on the .NET platform: the world’s leading insurance submission, application, and policy management system, which is used by more than half of independent insurance agencies in the United States. Murano's head office locates in Los Angeles, and its team works from different cities and countries worldwide. This vacancy is opened on our outsourcing project. As a Senior Database Administrator, your job duties will include managing all database systems, automating processes such as back-ups and upgrades, assessing and improving performance, ensuring security compliance, and designing and implementing tests of the system to address issues with accessing data. The Senior Database Administrator will help manage and maintain large scale data in multiple environments. PROJECT OVERVIEW The project is a push-to-talk (PTT) solution that provides instant and reliable access to people and information for deskless teams so they can collaborate and communicate for efficient teamwork. Providing crystal-clear reception workers can securely collaborate across teams, departments, offices, and countries on any smart device and any network. Over 130 million people worldwide use this app to build stronger communication, collaboration, and cohesion no matter where you are. Our technology enables direct communication - the power that conveys a sense of urgency and builds trust. There is no greater form of instant, efficient and effective communication in today’s digital age. This solution enables the human voice. The technology stack of the platform: C++, Golang, AWS, Linux, MySQL, MongoDB, Elasticsearch, and Redis. The project team: Software Development: Backend Team, Front-end Team, Mobile Team Project Manager, Tech Lead. REQUIREMENTS 5+ years of database management experience, including relational and non-relational technologies, preferably in Linux environments Solid SQL knowledge Familiarity with one or more programming languages Strong organizational and analytical problem-solving skills Positive attitude and collaborative style. RESPONSIBILITIES Install and maintain database servers, including MySQL, MongoDB, Elastic, etc. Review and improve database performance Troubleshoot database issues Respond to technical support requests Conduct regular maintenance Audit and improve our data security Improve disaster recovery database management solutions Review and design database cloud migration strategy.","Английский язык,MS SQL,Linux,SQL,Английский — C1 — Продвинутый",Murano Software,
13679,77148399,Data Science/Data Analyst,з/п не указана,3–6 лет,"Полная занятость,удаленная работа",,,MY.GAMES,
13682,78961342,ML Research Engineer/Data Science Engineer,з/п не указана,1–3 года,"Полная занятость,удаленная работа","MY.GAMES is a leading European publisher and developer headquartered in Amsterdam, with over one billion registered users worldwide. War Robots, Hustle Castle, Rush Royale, Left to Survive, Tacticool, and many other games were developed and produced by MY.GAMES. The company creates and publishes games for PC, consoles, and mobile devices. We have more than a dozen game development studios united under MY.GAMES, as well as MGVC, a global game investment company. The global MY.GAMES and MGVC partner network comprises over 40 studios. Our studios are professional teams with their own unique atmosphere. We’re united by a common passion: transforming our enthusiasm and talent into fabulous games. We create engaging products which captivate millions of people all over the world. What you’ll do: Prepare and analyze in-game and advertising data Build ML models for predicting ""monetary"" events, striking a compromise between performance (both learning and prediction) and accuracy Develop strategies/distributed systems for optimal budget spending Analyze and build ML models and heuristic approaches to cut off fraudulent traffic Analyze user history from ad auctions using the unsupervised approach Conduct A/B tests for model versions What you need to succeed: Basic algorithmic training: knowledge of basic algorithms and data structures, as well as their implementation in standard libraries Strong knowledge of Python, ability to write testable codes for production processes, ability to solve analytical and data preparation tasks English for reading technical documentation and analyzing professional articles Knowledge of probability theory, statistics, algebra, numerical and Bayesian methods Experience supporting the full life cycle of models, including analyzing raw data, generating hypotheses, creating models, conducting experiments, and introducing the results in production Experience applying ML algorithms practically: linear algorithms (linear and logistic regression, etc.), compositional algorithms (random forest, gradient boosting, etc.) Nice to have: Knowledge of Factorization machines, SVD decomposition, and unsupervised approaches Knowledge of Python libraries and basic data science SQL knowledge What we offer: Work remotely from all around the world Collaborative working atmosphere in an internal game dev community that unites more than 40 in-house and partner studios A strong team of specialists across different areas — access unique expertise and professional knowledge Possibility to experiment and work on interesting tasks with ambitious goals — we have all resources to implement new ideas Create great games and win the hearts of players Push the boundaries of the game industry and lead the way forward","Data Science,Python",MY.GAMES,
13731,78529466,Руководитель отдела (Master data management),з/п не указана,3–6 лет,"Полная занятость,полный день","Mediascope – исследовательская компания, которая работает на стыке медиа и IТ. Почти 30 лет мы анализируем аудиторию телевидения, интернета, радио и прессы, создаем уникальные аналитические продукты, которыми пользуются более 1000 российских медиа, рекламных агентств и компаний-рекламодателей. Наша задача – создавать и поддерживать индустриальные стандарты работы с данными на рынке медиа и рекламы, а также развивать медиаисследования в России.  Мы являемся аккредитованной IТ-компанией и входим в ТОП-15 работодателей России в категории «средние компании» по версии рейтинга hh.ru. Нам важно сохранять высокий темп развития компании, и мы стремимся, чтобы качество наших продуктов и нашей работы продолжало расти. щем в команду профессионала, который выстроит процесс управления НС (RDM) на платформе Ataccama для управления НС в Mediascope Data Platform, а также наберет сотрудников в свой отдел. Роль будет совмещать в себе проектирование архитектуры, управление проектами и аналитику. Чем предстоит заниматься Анализ, унификация, нормализация НС Компании в мастер системах компании Разработка подходов и методов работы по нормализации и структуризации больших массивов данных Ведение и преобразование существующей архитектуры классификации данных Ведение дорожной карты \ стратегии развития классификации данных Разработка шаблонов наименований для унификации, нормализации данных Участие в архитектурном комитете, взаимодействие с аналитиками, разработчиками и коллегами из бизнес-подразделений Разработка документации, регламентирующей работу с данными Построение работы отдела, набор сотрудников в команду Что для этого потребуется Обладать опытом проектирования DWH Опыт применения Spark SQL и Pyspark в целях формирования наборов данных и их обработки Опыт анализа больших массивов данных Будет плюсом опыт работы с платформой Attacama Навык анализа технической документации Мы предлагаем Возможность выбирать комфортный формат работы – офис, удалёнка или гибрид, гибкое начало рабочего дня Конкурентную белую зарплату Официальное оформление, гарантию соблюдения трудового кодекса РФ, стабильную выплату заработной платы Расширенную медицинскую страховку (включая стоматологию). Работа в Mediascope – это Сложные и нестандартные задачи. Погружайтесь в работу с данными в индустриях, где происходит все самое интересное: Медиа, Реклама, Web, Mobile. Современные технологии и эффективные подходы к работе. Применяйте актуальные инструменты для успешной работы. Непрерывное развитие. Получайте новые знания на профильных конференциях, обменивайтесь опытом с коллегами-экспертами и участвуйте в еженедельных образовательных митапах компании. Профессиональные и открытые коллеги. Работайте в команде сильных специалистов, основа которой - открытость, человечность, доверие, экологичность общения. Откликайтесь, и давайте обсудим все детали вакансии!","Python,SQL,Аналитические исследования,Аналитическое мышление,Архитектура,Анализ данных,Системный анализ",Mediascope,"Москва, Марьина Роща, Савёловская, улица Двинцев, 12к1Б"
13749,78889781,Data Engineer (relocation to Germany),з/п не указана,более 6 лет,"Полная занятость,полный день","Our partner, a well-known German online platform, is looking for a Data Engineer Advanced Analytics (m/f/d) to resolve technical data issues, and optimize their data architecture. This is a full-time position in Dusseldorf metropolitan area, Germany (partial work from home is possible). Relocation from abroad is possible. We will take care of your visa application and relocation to Germany. Your family members (spouse, children under 18 years old) will get a visa as well. About the company: In the team, everything revolves around one topic: creating data-based added value for the company and its customers around the world In international projects, they develop customized data & analytics solutions for their business and IT teams They support the entire organization in making important decisions based on reliable data and state-of-the-art analyses Your responsibilities: Design, develop, optimize and maintain squad-specific data architecture and pipelines that adhere to defined ETL and data lake principles Prepare, coordinate and organize the handover of data architecture and pipeline artifacts to the platform team Resolve technical data issues Participate in building data products for Analytics and Data Scientists / Machine Learning Engineers to improve their productivity Mentor data and analytics professionals on data standards and practices Propose and contribute to training and improvement plans regarding analytical data engineering skills, evaluation of new tools for analytical data engineering or data science Educating in machine learning, data science, computer vision, artificial intelligence, statistics, or applied mathematics Required qualifications: At least a Bachelor’s degree in Information Technologies or a related field Experience in data engineering and solutions for cloud computing services in the area of data and analytics Knowledge of SQL and data analytics and experience with at least one programming language (e.g., Python, Scala) Experience in database development and data modeling, ideally with Databricks/Spark and SQL Server DB Knowledge of relational, NoSQL, and cloud database technologies Would be a plus: experience with MS Azure tools such as Data Factory, Event Hub, Databricks, ML, Synapse, Purview. Knowledge of data and analytics, e.g. dimensional modeling, ETL, reporting tools, data governance, data warehousing, and structured and unstructured data Excellent English (at least C1 level) Benefits: Mobile working within Germany incl. equipment and flexible working hours State-of-the-art technologies Attractive remuneration Vacation and Christmas bonus Future-oriented training & development Modular onboarding and an onboarding buddy Health perks Relocation package If you are interested in joining the team as Data Engineer, do not hesitate to apply for the job and send us your CV","SAP MM,Ariba,Procurement,Logistics,SAP MDG,SAP S/4HANA,English,Английский — C1 — Продвинутый",Transparent Hiring,
13761,78887882,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","СберЗдоровье - аккредитованная IT-компания, крупнейшая в России Digital Health платформа, объединяющая различные сервисы цифровой медицины. Сервис начал свою работу в 2012 году под брендом DocDoc. Мы помогли миллионам людей получить помощь и продолжаем повышать качество медицинских услуг. Об IT в цифрах: 3 бизнес-направления 15+ команд (каждая наша команда кросс-функциональная, 7-12 человек, включает в себя QA, DevOps, аналитиков, архитекторов, Web/Mobile разработчиков и конечно же своего PM) 250+ IT специалистов (devops, manual/auto QA, web/mobile devs, backend devs, аналитики и архитекторы) из 40+ городов Чтобы система была безопасней, а наши пользователи — счастливей, мы открыли вакансию DevSecOps. Почему у нас интересно? Потому, что у нас современный и востребованный продукт. Цели и задачи (на любой вкус): Выбрать целевую БД и построить хранилище данных Vertica / Greenplum / Citus / что-то другое Разобраться с CDC — думаем про Debezium DV2.0 / Anchor / Гибрид DataOps / MLOps — затащить лучшие инструменты и практики Airflow + DBT + Great Expectations + DVC + MLFlow + label studio или любой другой стек в рамках здравого смысла Каталог данных / Data Discovery / Data Lineage Datahub / Amundsen / Marquez / другое отличное решение Архитектура и имплементация своего click+event stream решения Snowplow / Rudderstack / Jitsu / другое отличное решение Что надо уметь: Опыт 2+ года в роли DE с похожими задачами Отличные знания Python и SQL Уверенные знания и опыт по нескольким пунктам из списка: Модели хранилищ данных: плюсы, минусы, подводные камни Airflow / Prefect / Dagster DBT / что-то схожее Great Expectations / другие DQ либы MLFlow / Kubeflow и DVC Kafka и Spark / Flink Vertica / Greenplum / Citus / Clickhouse Что тебе может дать СберЗдоровье: Возможность развития в команде ведущей MedTech-компании России. Свободный выбор рабочего формата: удалённый внутри страны или гибридный в Москве. Офис на набережной рядом с метро «Автозаводская». Корпоративное медицинское решение в любом городе страны со стоматологией и психологами. Поддерживаем активный образ жизни: выбирай виды спорта по душе (корпоративные команды, компенсация абонемента). Оплата профильного обучения и конференций. Скидки и бенефиты от наших партнёров. Оплачиваемые курсы английского языка. Льготная ипотека. Приятное дополнение: Всегда поддержим, если ты захочешь посетить профильные конференции, и, тем более, выступить на них. Мы общаемся на “ты”, не любим бюрократию и всегда помогаем друг другу.","Работа с базами данных,DataOps,MLOps,Airflow,Python,MS SQL,Prefect,Dagster,Great Expectations,MLFlow,Kubeflow,DVC,Kafka,Spark,Flink,Vertica,Greenplum,Citus,ClickHouse",СберЗдоровье,
13841,75729898,Senior Database Developer MS SQL,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Привет! Мы – компания, создающая комплексные решения для управления крупными инвестиционно-строительными проектами. За последние годы мы запустили десятки решений в лидерах нефтегазовой, энергетической и горнодобывающей отраслей и продолжаем движение вперёд. Наша IT команда развивает собственные продукты enterprise-уровня, обеспечивающие потребности наших заказчиков. Команда создаёт web-, desktop-, mobile-приложения c единым back-end и БД, и передаёт их в b2b-проекты. Cегодня нам нужен Senior Database Developer MS SQL, готовый совершенствовать наш софт. нтеграции с большими внешними системами и корпоративными шинами, унификация продуктов как «под капотом», так и с точки зрения пользовательского опыта – это про нас. Задачи: Разработка интеграционных решений Разработка серверной части корпоративной информационной системы (Хранимые процедуры, функции, таблицы, представления и т.д.) Разработка отчетов Разработка и настройка конфигураций КС разработанной компанией. У тебя есть: Хорошие знания MS SQL или Oracle DB Хорошее знания J2EE, JSP, С#, CristalReport или другой системой корпоративной отчетности, знание технологий BI Опыт разработки отчетов и/или приложений более 3-х лет Желание работать в команде и развивать свои профессиональные навыки. Мы предлагаем: Работу в Аккредитованной IT-компании Возможность участвовать в крупных интересных проектах Дистанционный режим работы Достойный уровень заработной платы, обсуждается индивидуально по итогам интервью Оформление по ТК РФ.","Delphi,SQL,MS SQL,MS SQL Server,Borland Delphi,Reporting,Fast Report",Промэкспертиза,
13878,75918378,Data Science Engineer (Computer Vision),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Merk это: Mobile, web, desktop и embedded разработка Работа с крупными зарубежными стартапами Более 450 специалистов высочайшей квалификации Более 40 млн пользователей наших приложений по всему миру Неоднократные попадания в Top AppStore и Google Play, упоминания в TechCrunch, Engadget, Gizmodo, Verge Офисы продаж расположены в Нью-Йорке, Майами, Атланте Центр разработки в России, Сербии, Армении и Казахстане Обязательные требования: Разговорный английский не ниже B2 Экспертный опыт работы с Python и создания пакетов (Numpy, Pandas, Matplotlib, Sklearn) Опыт работы с C++ Знание классических алгоритмов ML Опыт создания и обучения нейронных сетей с использованием Tensorflow/PyTorch Опыт работы с алгоритмами Computer Vision (Object Detection, 3D Mesh) Будет плюсом: Знание и понимание ООП Опыт в области робототехники Знание SQL на уровне выполнения сложных запросов выборки данных Наши условия: Заработная плата, адекватная знаниям и опыту Официальное оформление Возможность работать удаленно или из заграничных офисов Полный комплект оборудования для работы Гибкий график, главный принцип – работать с душой и пользой 40 часов в неделю) Дружелюбные, опытные коллеги и заботливое начальство Субсидирование профильных курсов и английского языка Рассматриваем кандидатов, готовых к релокации (Сербия, Армения, Грузия и иные направления) Приходи и создавай будущее вместе с нами!","Python,Numpy,Matplotlib,Sklearn,SQL,ML,PyTorch,Computer Vision,Tensorflow,Английский — B2 — Средне-продвинутый",Merk Team,
13881,76139031,Senior Data Engineer (Scala),з/п не указана,3–6 лет,"Полная занятость,полный день","MY.GAMES is a leading European publisher and developer headquartered in Amsterdam, with over one billion registered users worldwide. War Robots, Hustle Castle, Rush Royale, Left to Survive, Tacticool, and many other games were developed and produced by MY.GAMES. The company creates and publishes games for PC, consoles, and mobile devices.  We have more than a dozen game development studios united under MY.GAMES, as well as MGVC, a global game investment company. The global MY.GAMES and MGVC partner network comprises over 40 studios.  Our studios are professional teams with their own unique atmosphere. We’re united by a common passion: transforming our enthusiasm and talent into fabulous games. We create engaging products which captivate millions of people all over the world. What you will do: Together with a team of ML engineers, participate in the development of machine learning services for games Improve the reliability and fault tolerance of the recommendations calculation serviceSupport existing ETL processes Participate in the support and improvement of ML services infrastructure Participate in the development of production code in terms of loading and processing data What you need to succeed: Experience with Scala or Java Experience processing large amounts of data in realtime or near realtime Docker knowledge Profound knowledge of SQL Experience with message brokers, such as Kafka, RabbitMQ Ability to optimize data processing and loading Knowledge of Linux, Bash Nice to have: Experience in Python development using OOP concepts Understanding of the Hadoop principles, knowledge of Hive and Spark Experience with Airflow, Kubernetes Experience with Tarantool Knowledge of Lua Understanding of machine learning principles What we offer: Work remotely from all around the world Collaborative working atmosphere in an internal game dev community that unites more than 40 in-house and partner studios A strong team of specialists across different areas — access unique expertise and professional knowledge Possibility to experiment and work on interesting tasks with ambitious goals — we have all resources to implement new ideas Create great games and win the hearts of players Push the boundaries of the game industry and lead the way forward","Java,SCALA,Big Data,hadoop,Spark streaming",MY.GAMES,
13918,77963503,Senior QA engineer на продукт МТС Аналитика (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data в МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior QA engineer на продукт МТС Аналитика МТС Аналитика – это единая аналитическая платформа для анализа поведения пользователей в web и app приложениях экосистемы МТС Наша цель – эффективная рекламная атрибуция, обогащенные Big Data полезные данные о когортах, кросс-продуктовый пользовательский путь и LTV пользователя и продукта, сдобренные собственным UI для визуализации метрик и командной работы Мы ищем Senior QA engineer, который поможет нам с «нуля» создать и развивать платформу. У нас вы сможете принять участие в разработки event-based архитектуры платформы, поработать с streaming технологиями, технологиями Big Data, in-memory базами данных и аналитическими хранилищами Для автоматизации тестирования используем: Python, PyTest, Allure Report/Allure TestOps, Selenium, Appium. Для нагрузочного тестирования - Locust Наши преимущества: Опытные и отзывчивые коллеги, которые готовы ответить на любые вопросы Платформа создается с «нуля», никакого легаси Сложный и большой проект, в котором можно многому научиться Возможность получить опыт в тестировании и автоматизации тестов различных видов систем (UI, Back, Mobile, BigData) Обязательно: Опыт от 3х лет в QA Опыт разработки или автоматизации тестов на Python, либо желание перейти на Python Опыт тестирования и автоматизации тестов Web и Mobile (native или гибридных) продуктов Опыт работы с Appium, Appium Inpector, Android SDK Опыт работы с системами непрерывной интеграции Опыт работы с Docker, docker-compose Владение SQL на базовом уровне (select с подзапросами, join, группировками) Знание систем контроля версий Git Знание основ Linux и навыки работы с командной строкой Что предстоит делать? Развивать фреймворк автоматизации тестов Web UI и Mobile компонентов платформы на интеграционном и e2e уровне Участвовать в релизном процессе и ручное прохождение тестов business-critical функционала, если по каким-то причинам их не удалось автоматизировать Проводить интеграционное тестирование с продуктами смежных команд Документировать найденные ошибки в системе баг-трекинга, контроль их исправления Контролировать тестовое покрытие и актуализация тестовой документации в TMS (Allure TestOps) Проводить нефункциональные виды тестирования (нагрузочное, отказоустойчивости) Что вы найдете в команде Big Data? Стек: для автоматизации тестирования используем: Python, PyTest, Allure, Selenium (там, где есть UI), Aquas (внутренний фреймворк для автоматизации тестов ETL), для нагрузочного тестирования - Locust, Jmeter Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16” MacBook Pro или Dell на выбор. Есть ли обучение? Конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: Первичный созвон с HR HR + тех. интервью с лидом направления Собеседование с PO и командой, вы бор кандидатом проекта","Тестирование,Python,Pytest,SQL,Mobile,Web,Selenium,Docker,Allure,Appium,Android SDK",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
13925,77493400,Assortment & Data Manager,з/п не указана,3–6 лет,"Полная занятость,полный день","Responsibilities: Must SKU list database (company’s SKU listing guidelines) analyses and preparation Dedicated Target Listing for channels and for TOP-30 customers Analyzing of novelties' performing Analyzing of a potential in listings Channel\Categories development trends tracking Placement booklet compilation Cross-team collaboration with Sles, Marketing, CatMan and Supply Management and Development of the team Requirements: Higher education in Economics/ Physic / mathematic Ability to analyze and evaluate big data and reports Great energy Intermediate English level Salary&Benefits: A unique opportunity to drive forward local market and an extensive work experience in constantly changing environment Compensation depends on experience and will be discussed individually (salary+yearly bonus) Mobile phone compensation Lunches Well-being program Medical & life insurance after 3 months Sick leave is compensated by the company Hybrid work model Opportunity to join a vibrant culture of trust and belonging Extended paid vacation (31 calendar days per year)","assortment management,Английский — B1 — Средний",Henkel Russia (LAB Industries),"Москва, Колокольников переулок, 11"
14199,78423651,Data Analyst,до 150 000 руб. на руки,1–3 года,"Полная занятость,полный день","The position is open with our client, of a large Chinese company. Responsibility: Data analysis specialist, responsible for Internet operation data analysis and report development. Analyze operation data and monitor operation indicators together with operation manager. Plan data requirements with operation manager, and develop data reports. Previous experience and Abilities Requested: Good skill of Microsoft office software, especially excel, macro skill will be a plus. Have experience in data analysis of Internet operation platforms. Be sensitive to data and have strong data analysis capabilities. Be proficient in SQL language. Proficient in using FineBI data processing tools would be a plus. Fluent in English and native local language. Chinese language would be a plus. Excellent communication skill in internal and external. Ability to handle multiple tasks concurrently, prioritizing and accurately completing them in a potentially stressful environment. Conditions: Working time: 5/2 since 9.30 a.m. to 18.00 p.m. Opportunity for professional growth and career development Mobile phone allowance.","MS Excel,SQL,Fine BI,Power BI,Английский язык,Английский — B2 — Средне-продвинутый",Manpower,
14210,78392417,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","PixelPlex is a leading product development and outsourcing company. Since 2013 we have been focusing on blockchain development and consulting services, yet our expertise also spans AI, AR/VR, IoT, and mobile. Our offices are located in London, New York, Pfffikon, Dubai, Tokyo and Minsk. Our professional experts from Web, Mobile, Blockchain, QA, BA, PM, and UI/UX departments work with both world-renowned brands and promising startups and always strive to deliver top results. We are seeking a skilled Database Developer to design, implement, and maintain complex database systems. As a Database Architect, you will be responsible for analyzing user requirements, creating data models, designing database architecture, and ensuring the performance, security, and scalability of our database systems. You will also collaborate with cross-functional teams to develop effective data management solutions. Responsibilities: Analyze user requirements and translate them into database design Defining database development standards and work with application development teams to plan implementation Proactively reviewing databases and identifying areas of improvement in current systems (optimization of views, indexes, fragmentation etc) Monitoring and Auditing database regularly to maintain quality Engaging with development teams on database design and reviewing database changes to make sure they align with architecture standards Recommend efficient tooling for development, monitoring and troubleshooting Creating roadmap for database upgrades and utilize new technology/features available with upcoming database versions Creating standards and recommend database features that can be leveraged for performance and scalability Review database settings and work with System DBA to make sure the settings are optimal Working with application development teams to optimize slow performing queries Troubleshoot and resolve database issues. Requirements: Bachelor's or Master's degree in Computer Science or related field Proven experience as a Database Architect or similar role Experience in Database technologies like PostgreSQL, MongoDB, AWS database offerings Hands on experience in query optimization In-depth knowledge of database design principles, data modeling, and data management Familiarity with cloud-based database solutions Excellent problem-solving and analytical skills Experience in tuning database configurations for optimal performance Experience with Big Data technologies such as Hadoop, Spark, Hive, Pig, Kafka, etc. Experience with database replication techniques such as master-slave replication, multi-master replication, etc. Knowledge of sharding and partitioning strategies to improve database performance and scalability Familiarity with database clustering and load balancing techniques Familiarity with data modeling techniques for real-time analytics such as event sourcing, CQRS, etc. We offer: Decent salary Flexible working hours Two fully paid sick days during the first two calendar years three sick days from the third years onwards Interesting projects and the opportunity to introduce/implement your own ideas Compensation for sports activities Medical insurance English language courses as well as a speaking club in the office Loyalty program Compensation for education activities and technical literature A bright corporate life (birthday greetings from the company, hockey tournaments, etc.) Possibility to work both in the office in Minsk and remotely x-box, VR helmets, and other cool benefits.","Big Data,Databases,PostgreSQL,MongoDB",ПикселПлекс Лабс,
14261,78301838,Digital Data Analyst,от 150 000 до 249 000 руб. на руки,более 6 лет,"Полная занятость,полный день","Responsibilities: Generate and test hypotheses for conversion growth together with our agencies Predict the cost and likelihood of conversion: CPO, CPL, etc. Building an unified Brand database from various sources (Data of e-commerce, registrations on the site, Smart TV Users, mobile app, data from media campaigns, etc.), development of a long-term communication strategy with different segments of the Brand database Develop data-driven proposals for business process optimization and work them through with internal stakeholders. Communicate and Collaborate with internal business stakeholders, data science peers from Agencies and the Colleagues responsible for data storage. Regular A/B testing, hypotheses, test setup, analysis of results, debriefing, performance reporting Making forecasts of site performance indicators (traffic, revenue, conversion, average check, bounce rate and deliverability). Audit existing data processes to ensure they are functioning correctly. Work with performance team to help architect solutions when problems exist Track the implementation of KPIs, conduct a deep factor analysis of deviations, prepare proposals based on the results of the analysis and contribute to their implementation Determination and prediction of the unsubscription rate, fraud search, analysis of appeals to the Brand through various channels (website, social networks, instant messengers, customer service, etc.) Development of a strategy for managing communication channels with Subscribers, setting up personalized communication processes (e-mail, messengers, push notifications, calls, etc.) Evaluate demand and calculate unit economics, calculate payback and break-even point Requirements: 5+ years experience in data science or analytics, data marketing with data management responsibilities The ability to find data insights and a willingness to understand the essence of the processes that this data shows MS Excel, SQL – advanced user, able to quickly work with big data sets. Strong analysis skills, experience with searching insights in data and developing recommendations based on analytics. Intermediate+ English. Excellent communication skills, willing and readiness to communicate with internal customers. Ability to balance multiple, competing directions and manage multiple projects successfully Possess knowledge of methods and metrics of statistical analysis and machine learning, understanding of their applicability, and ability to explain them to the Colleagues Experience in implementing projects in the field of data analysis Experienced in the use of statistical analysis/modeling - correspondence analysis, time series analysis and other regression, clustering, factor analysis etcюб Proficient in use statistical software (Python, SQL) Knowledge of the principles of Google Marketing Platform tools and ability to work with Google Tag Manager Understanding attribution models for each digital channel Conditions: Registration according to the Labor Code of the Russian Federation Working hours at office 9:00 – 18:00 Trial period of 3 months Medical insurance (VMI), Life insurance after the trial period Lunch allowance Incentive pay according to corporate policy. Place of work: Business office building near M. Belorusskaya Salary is negotiable","Data Science,SQL,MS PowerPoint,Big Data,Анализ данных,Marketing Strategy Development,Analytical skills,MySQL,Статистический анализ,Английский — C1 — Продвинутый",HS Ad,"Москва, 4-й Лесной переулок, 4"
14364,78148594,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","We are a 750-employee IT company headquartered in the US (Dallas area), having an offices in Poland, Lithuania, Latvia, Belarus, Ukraine, Finland, UAE. We have been in the IT business for 33 years and continue growing. We have an interesting project and we are looking for a Data Engineer in Minsk. In this role, you will act and manage technical support of data and reporting applications to ensure effective data services delivery and support enterprise strategies, will perform database analysis, design and administration functions to deliver on strategic projects specific to organizational goals. You would have an opportunity to work with some of the latest technologies such as AWS, Redshift as well as some extremely talented individuals. Telecom domain. Responsibilities: -The main task is to help the core development team, develop optimal queries, improve the structure and performance of the database, participate in the migration of applications from on-premises to AWS Cloud (OLTP and OLAP applications) -Support of custom data applications such as data pipelines/ETLs/data processing. Requirements: -Create, perform аnalytical solution for mobile operator -Experience in developing data solutions based on AWS -Strong Knowledge (writing effective queries) in MS SQL, MySQL, Redshift -Knowledge of Tableau, PostGre -English level: Intermediate (B1+) -Strong analytical skills, good communication skills, both oral and written. We propose challenging and interesting projects with a modern stack in a nice team.","Tableau,AWS,Databases,Analytical skills,Data Analysis,English,PostgreSQL,MySQL",Научсофт,"Минск, улица Леонида Беды, 2"
14385,77536865,Data Scientist Junior/Junior+,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
14413,78347781,Data Analyst,до 4 000 USD на руки,1–3 года,"Полная занятость,полный день","At Neiro.ai we are developing entertainment products using generative AI Why us? We have a strong engineering team (ex-Samsung AI, Yandex, JetBrains, VK, PicsArt, VisionLabs) We have raised money from investors of Looksery and AI Factory (both acquired by Snap for $150M and $166M) We develop state-of-the-art generative AI (Lip-Sync, Text-to-speech, Voice Conversion, Dialogue Engine) and build unique entertainment products More than 500 000 000 video views on TikTok with content generated by our apps Your Responsibility Selection and development of a system for collecting, analyzing, and visualizing product metrics Create a plan for the integration of analytical systems with products Verify the correctness of analytical pipelines with developers Analyzing data from mobile analytics systems based on the user's behavior Own dashboards and maintain analytical pipelines Proactively propose product/marketing changes based on insights from data & setting up experiments Looking for anomalies/patterns/bugs in data and data collection pipelines Product metrics comparison with market benchmarks & competitors Key Qualifications: 1+ years of experience in Data Analyst / Product Analyst / Data Scientist roles Experience setting up mobile analytical systems SQL + Python Experience in A/B testing Excellent knowledge of statistics relevant to product analytics Intermediate analytical, verbal, and written English communication skills Fast learner. You should pick up and run with new workflows quickly Understanding of product metrics, unit economics, and principles of their optimization Proactivity and Autonomy It would be great to have Track record of collaborating with engineers on solving problems What do we offer The ability to understand how entertaining mobile products are built Direct work with C-level. Fast communication between UA/Mobile/Marketing teams. Our products are based on our own Generative AI (Computer Vision, Speech, NLP). Working with us is an excellent opportunity to understand how modern Machine Learning works. Opportunity to become Head of Analytics Salary & stock options to be discussed Remote work or Relocation package to Tbilisi Necessary equipment/software/education Our Process Test assignment HR interview  CEO Interview","Amplitude,Firebase,Google Analytics,Retention,Play Console,SQL,Python,Data Analysis,Английский — C1 — Продвинутый",Botan Investments,
14414,78347782,Data Analyst,до 4 000 USD на руки,1–3 года,"Полная занятость,полный день","At Neiro.ai we are developing entertainment products using generative AI Why us? We have a strong engineering team (ex-Samsung AI, Yandex, JetBrains, VK, PicsArt, VisionLabs) We have raised money from investors of Looksery and AI Factory (both acquired by Snap for $150M and $166M) We develop state-of-the-art generative AI (Lip-Sync, Text-to-speech, Voice Conversion, Dialogue Engine) and build unique entertainment products More than 500 000 000 video views on TikTok with content generated by our apps Your Responsibility Selection and development of a system for collecting, analyzing, and visualizing product metrics Create a plan for the integration of analytical systems with products Verify the correctness of analytical pipelines with developers Analyzing data from mobile analytics systems based on the user's behavior Own dashboards and maintain analytical pipelines Proactively propose product/marketing changes based on insights from data & setting up experiments Looking for anomalies/patterns/bugs in data and data collection pipelines Product metrics comparison with market benchmarks & competitors Key Qualifications: 1+ years of experience in Data Analyst / Product Analyst / Data Scientist roles Experience setting up mobile analytical systems SQL + Python Experience in A/B testing Excellent knowledge of statistics relevant to product analytics Intermediate analytical, verbal, and written English communication skills Fast learner. You should pick up and run with new workflows quickly Understanding of product metrics, unit economics, and principles of their optimization Proactivity and Autonomy It would be great to have Track record of collaborating with engineers on solving problems What do we offer The ability to understand how entertaining mobile products are built Direct work with C-level. Fast communication between UA/Mobile/Marketing teams. Our products are based on our own Generative AI (Computer Vision, Speech, NLP). Working with us is an excellent opportunity to understand how modern Machine Learning works. Opportunity to become Head of Analytics Salary & stock options to be discussed Remote work or Relocation package to Tbilisi Necessary equipment/software/education Our Process Test assignment HR interview  CEO Interview","Amplitude,Firebase,Google Analytics,Retention,Play Console,SQL,Python,Data Analysis,Английский — C1 — Продвинутый",Botan Investments,
14478,79244494,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
14479,79244493,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
14480,79244489,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
14481,79244491,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
14482,79244490,Database Developer,з/п не указана,3–6 лет,"Полная занятость,полный день","Database Developer Designer About us: Velvetech is an international company, based in the US, with 20+ years of experience in software and hardware development for clients all around the world, especially for US clients. As an official Microsoft Gold Partner, our company is listed in the top 5 software development companies in Illinois, USA. US clients as leading trading and financial organizations, insurance companies, large healthcare associations, pharmaceutical and energy companies, equipment manufacturers, hi-tech startups, etc. Areas of expertise are consulting, development, implementation and support of software solutions with modern microservices backends (.NET Core, Node.js, Java, SQL Server, PostgreSQL, MongoDB, Redis, RabbitMQ), web front-ends (React, Angular), and mobile development (Swift, Kotlin, Java). Most of the systems are prepared for cloud infrastructures (AWS, Azure, GCP), and heavily rely on Docker, Kubernetes while modern CI/CD is made using GitLab CI or TeamCity. Principles are based on Agile Methodology, Scrum and Kanban. Various projects coded in GitLab or GitHub are built with multiple coordinated teams, collaborating via Jira, Confluence, MS Teams, and Slack. Velvetech constantly follows the Tech trends and actively cooperates with startups in such breakthrough areas as Machine Learning, the Internet of Things, Blockchain, FPGA, and AI. Responsibilities: If you are interested in analyzing and understanding a large amount of raw data to find patterns that will support developing and maintaining computer software applications, then we will save this seat for you. Working fully remotely from the coziness of your home and many benefits, you will be able to grow and improve your skills with our cooperative and friendly team. You need to be experienced as a strong middle plus or senior expert. Analyze database structures and models to identify data integrity and performance Design, implement, and tune tables, queries, stored procedures, and indexes in OLTP and OLAP environments Develop and maintain enterprise-wide (domain) data models Serves as a data resource for the organization Gathers and analyzes data supporting business cases, projects and systems requirements Design and develop logical and physical database models Design models for Self-Services Analytics and Reporting Collaborates with both internal and external teams to identify and validate data structures and fields along with defining build requests for new reports, dashboards and ML models Prepare report datasets for programs, management, and various requirements on time Supports the preparation and evaluation of special data projects Utilize ETL data methods (Extraction, Transform, and Loading) to bring disparate data sources together into the correct format required by applications Review data for quality assurance discrepancies and communicate issues to supervisor and affected staff as needed Provide support for reporting issues or failures at any time Assemble large, complex data sets that meet functional and technical requirements Work with stakeholders, including the business analytics teams and application architecture teams, to assist with data-related technical issues and support their data infrastructure needs Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value Requirements: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as experience with complex Stored Procedures for data processing Advanced data modeling skills of both OLAP and OLTP databases Experience building and optimizing data pipelines, architectures and datasets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience performing SQL performance tuning and optimization Experience supporting and working with cross-functional teams in a dynamic environment 5+ years' experience building large-scale operational data stores in Oracle, MS SQL Server or equivalent relational database Candidates should also have 3+ years of experience using the following software/tools: Experience with Spark, Databricks, Snowflake are plus Experience with relational SQL and NoSQL databases, including Oracle, MongoDB and Azure SQL Experience with AWS/Azure cloud services Experience with stream-processing systems: Event, Hubs, Kafka, Spark-Streaming are plus Experience with Python is plus Experience with Big Data Warehouses (MPP) are plus 7+ years of hands-on experience in data modeling, model driven engineering and design patterns 5+ years of hands-on experience in Data Lakes and Data warehousing, messaging, distributed Data architectures, and establishing Data platforms to support complex Analytical usage, including Operational ML use cases. Benefits: Velvetech is in the TOP 5 development companies in Illinois, USA You have FLEXIBLE working conditions and a COOPERATIVE environment A COMPETITIVE and performance-based salary, fair compensation and benefits Many CHALLENGING and exciting projects with new opportunities and learning GROWTH opportunities, skills and competencies improvement, and professional certification In-company TRAINING (English, Software / DevOps / Project management / Design / Business) Our team: We are a friendly team of 150+ professionals where everyone is able to achieve high results and grows professionally not only due to their own knowledge and skills but also with the support of colleagues. Values that we highly appreciate are high performance, responsibility, respect, and loyalty. In order to have a highly motivated team, Velvetech invests in their people, additional education, certification, and others. You choose your career path and we are here to support you! People work together in harmony, encouraging each other to continuously learn, progress, and pursue perfection. Our employees enjoy working as we turn challenges into advantages to share success with each other. You have a chance to become a part of a friendly and professional team that creates robust software solutions to deliver maximum value to our international clients.","Spark,Kafka,NoSQL,SQL,Snowflake,MongoDB,Azure SQL,OLAP and OLTP,ETL,Английский — B2 — Средне-продвинутый","Velvetech, LLC",
14503,78537829,Data Engineer,от 1 500 до 4 000 USD на руки,3–6 лет,"Полная занятость,полный день","LATOKEN is the supermarket of assets where it is easy to discover, exchange, earn and spend crypto. Mission: Well-structured and secure data and monitoring.  Story: Product, Finance, OKRs, and Dash Teams need well-structured and secure data and monitoring to analyze and track the improvement of the services and product performance. Key PROBLEM's: The monitoring system alerts for any downtime, latency, or success rate issues of the services. All company data and events are merged and consolidated into the Data Base (DWH, PostgreSQL, Segment, Indicative, Google Analytics) to support the Monitoring system, Token Discovery, OKRs and Analytical Dashes. Acquisition channels, conversions, and users are correctly mapped and easy to access. Token DB is representative of the market and token data is correct and complete with on-chain and smm data. (30k tokens by end of April) How: Create new data pipelines for business need. Maintain scripts and pipelines in case of problems or new requirements. Define necessary events, set up recording and make available for reports and dashboards. Maintain and update token DB. Constraints: All OKRs of the company are consolidated into Platform Ops. All scripts are consolidated into Gitlab. Main performance number: Ops OKR Health Second performance number: Free Space DWH Third performance number: Query response time, sec avg  Functions: • OKRs Health : Calculate OKRs correctly, daily and in time • DWH objects audit • Queries : Advice on optimization and writing queries to databases. • Data quality : Keep data in order and provide reliable reporting • Automation : Automation of OKRs and slack bots for automated ops processes • Audit : Audit of DWH state and automated scripts  Requirement skills and experience: 2+ years of PostgresSQL DB administration experience 2+ years of experience writing Python scripts and applications for loading data Experience in configuring a database in a high-availability architecture Experience in database optimization for different load profiles Experience in automating data loading from different sources (CRM, ERP, Web resorses) Eager to work with people with high-performance standards Will be a plus: Experience with financial data Experience as a data/product analyst","Python,DWH,PostgresSQL,CRM,ERP",LATOKEN,
15747,79089818,Senior Data Scientist в направление рекламной платформы RnD (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior Data Scientist в направление рекламной платформы RnD Описание продукта: Рекламная платформа МТС включает в себя: 1. Программатик. DSP платформа, которая подключена ко всем популярным SSP и рекламным сетям. 2. Медиапланировщик. нструмент планирования маркетингового бюджета, определение наилучшего сплита как по основным каналам, так и внутри каналов. 3. Система аналитики. Аналитика трафика и событий. Построение MTA (Multi touch atributuon), сквозная аналитика. Обязательно: глубокое понимание статистических подходов и методов (регрессия, свойства распределений, оценка максимального правдоподобия, проверка гипотез и их правильное использование) и опыт их применения свободное владение основными библиотеками на Python (pandas, numpy, matplotlib, seaborn, etc.) коммерческий опыт применения классических алгоритмов машинного обучения (LR, RF, XGBoost/LGBM/CatBoost), понимание их преимуществ, недостатков и ограничений высокий уровень владения SQL опыт в распределённых/параллельных вычислениях с помощью следующих технологий: Hadoop, Spark, Dask и другие умение общаться с бизнес-заказчиком, объяснять простым языком полученные результаты и процесс работы алгоритма Желательно: опыт работы в медиа, понимание сферы digital рекламы стремление вникнуть в бизнес соответствующей отрасли диплом в области компьютерных наук, статистики, прикладной математики или другой релевантной анализу данных области английский язык (устный и письменный) на уровне Upper Intermediate опыт применения deep learning алгоритмов в NLP, CV направлениях (для подключения к R&D задачам) Что предстоит делать? собирать и обрабатывать данные из хранилищ компании подготавливать витрины данных, необходимые для разработки моделей машинного обучения. Задача частично закрывается data engineering специалистами разрабатывать модели машинного обучения как для MVP проектов, так и решений, выводящихся в production разрабатывать методологии применения различных ML алгоритмов для решения задач команды. подготавливать рекомендации по внедрению методологий и использованию продуктов для внутренних заказчиков компании проводить консультации и обмениваться идеями с младшими специалистами и коллегами по команде Стек технологий: Python, Pandas, Numpy, Matplotlib, Seaborn, LR, RF, XGBoost/LGBM/CatBoost, Hadoop, Spark, Dask. Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные и международные конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Python,SQL,Математическая статистика,Big Data,Machine Learning,NLP,Hadoop,Spark,Pandas,Numpy,Matplotlib,Seaborn",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
15915,76491071,Middle+ Data Scientist на продукт Маркетолог (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Data Scientist на продукт Маркетолог Описание продукта: Маркетолог является 2-ым самым крупным В2В продуктом по выручке в МТС. Мы занимаемся не только классическим вариантом телеком-рекламы (sms, mms, обзвон), но также имеем собственную DSP и активно размещаемся в digital каналах. Модели помогают эффективнее таргетироваться на абонентов в различных каналах (dsp, sms, обзвон), тем самым повышая эффективность рекламных кампаний. Обязательно: знание python на продвинутом уровне (ds, ml библиотеки – sklearn/catboost, lgbtm) опыт работы с Docker и AirFlow опыт работы с Hadoop, Apache Spark, SQL сильные теоретические знания ML умение переложить бизнес задачу на язык анализа данных, умение простым языком объяснять сложные вещи, интерпретировать результат (придется работать, как с внешними, так и с внутренними заказчиками) опыт работы в телекоме, маркетинге, рекламе Что предстоит делать? строить модели предсказания поведения пользователя работать с базами данных (проводить проверку и приемку витрин для дальнейшей работы по части ML) документировать процессы и процедуры, связанные с разработкой моделей проводить А/В тесты, дизайн экспериментов, введение культуры проведения A/B тестов в продукте писать ТЗ для инженеров Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Docker,AirFlow,Hadoop,SQL,Machine Learning,Маркетинг,Spark,sklearn,Catboost,ML,Big Data,Python",МТС,
16105,78373823,Data scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Банки.ру — самый большой финансовый маркетплейс в России, высокотехнологичная компания, которая успешно конкурирует на рынке труда как работодатель в сфере IT и цифрового маркетинга. Более 70% нашего штата — это IT-специалисты и digital-маркетологи. Мы помогаем клиентам в выборе самых выгодных финансовых продуктов, предоставляем оперативную и достоверную информацию о финансовом рынке, являемся площадкой для обсуждения вопросов, связанных с работой банков и страховых, микрофинансовых и инвестиционных компаний. Мы создаём сервисы, которыми ежемесячно пользуемся сами, пользуются наши близкие и друзья. Ежемесячный трафик Банки.ру составляет около 20 млн посещений ( по данным SimilarWeb).  Чем предстоит заниматься: Сбор данных, выбор модели, тестирование, внедрение Построение алгоритмов Next Best Action, Uplift сследование данных (ad-hoc аналитика, сегментация/кластеризация) Разработка и тестирование новых признаков, интерпретируемых и не интерпретируемых (эмбеддингов) Создание метрик оценки качества data-продуктов Построение продакшен пайплайнов ML-моделей, ведение с АБ-тестирования. Наши ожидания: Уверенное владение Python и SQL Знание ML (алгоритмы, метрики) и опыт работы с ML-библиотеками Знание классических алгоритмов и структур данных Хорошая математическая подготовка Знание границ применимости алгоритмов и метрик, умение выбрать подходящие под задачу Опыт работы с TensorFlow/ PyTorch.  Будет плюсом: Опыт работы с RL моделями Понимание базовых принципов работы с CUDA Опыт построения рекомендательных систем. Опыт разработки продакшн решений Опыт построение CI/CD для ML-моделей. Мы предлагаем: Достойная оплата труда (обсуждается индивидуально на встрече) + полугодовые премии. Официальное оформление по ТК РФ с первого рабочего дня. Участие в конференциях, митапах, обучающих курсах. Возможность карьерного роста внутри команды. ДМС+ стоматология, иностранный язык, фитнес, профессиональное обучение, такси, отсутствие дресс-кода, гибкое начало рабочего дня. Формат работы: офис, частичная или полная удаленка. Офис в шаговой доступности от м. Нахимовский пр-т.","Python,SQL,CUDA,Data Analysis,TensorFlow",Банки.ру,"Москва, Нахимовский проспект, Одесская улица, 2кА"
16591,78685969,Data Analyst (Customer Experience Analytics Team),от 3 000 USD на руки,1–3 года,"Полная занятость,удаленная работа","Tabby creates financial freedom in the way people shop, earn and save by reshaping their relationship with money. Over 3,000,000 active users choose Tabby to stay in control of their spending and make the most out of their money. Over 10,000 global brands and small businesses, including H&M, Adidas, IKEA, SHEIN, noon, and Bloomingdale's use Tabby's technology to accelerate growth and gain loyal customers by offering flexible payments online and in stores. Tabby is active in Saudi Arabia, UAE, Egypt and Kuwait and backed by leading investors including Sequoia Capital India, STV, PayPal Ventures, Mubadala Investment Capital, Arbor Ventures and others.  About the role We are looking for the Data Analyst to the Customer Experience Analytics Team to own the data universe of CX function. CX aims to create a frictionless customer journey, analyzing root causes for the customer contacts, trying to measure friction along the journey, and identify internal opportunities for improvement across all functions. That requires a CX Data analyst to get familiar with how the company works, what are the KPIs and measures existing across customer-relevant functions, starting from the Customer Service through Partner Service, Risk and so on. You will be successful in the role, if you combine natural curiosity, passion for self-development and business literacy. Your reporting line is to the Head of CX analytics, and you will have colleagues in your team as well as bigger analytical function to collaborate with and to learn from. You'll be working in a dynamic, rapidly evolving environment with the following responsibilities: Be a key player of CX team in the field of data analytics Connect data from internal and external sources and organize it for business analysis Perform a deep statistical analysis to connect internal execution, Voice of the Customer data layer and company profitability Perform data visualization Identify business issues and opportunities.  You should apply if you have experience in CX Analytics Retention analysis Data visualization SQL Clustering Connecting data from rigorous sources Creating custom API connectors Regression analysis Statistics (great understanding).  Nice to have experience in Business analysis Setting up AI or using 3rd party AI tools.  Relocation We offer remote work from anywhere in the world and are happy to work out an individual relocation plan for you. Our employees have the opportunity to choose a country for registration: at the moment those are Armenia/Georgia. We will help you open a legal entity and a bank account. In Armenia and Georgia the taxes are compensated by Tabby. For our employees we cover the following: Flight to Armenia/Georgia Accommodation during the paperwork completion period Opening a bank account and getting a residence permit in one of the mentioned countries Family relocation (dependants). New employees can also choose an alternative method of relocation to another country of their choice. In this case, Tabby will reimburse up to $5,000 of verified costs upon opening a legal entity and a bank account.  What you can expect A competitive salary dependent on your experience Excellent health benefits Flexible working hours and freedom to manage your own time to do your job well, while also remaining in touch with your team A working environment that gives you autonomy and responsibility from day one. We are open to insights and new ideas, and we are ready to experiment An equitable, high-performing workplace that gives people from all backgrounds the support they need to thrive, grow and meet their goals (whatever they may be).","SQL,Business Analysis,Data Analysis,Английский — B2 — Средне-продвинутый",Tabby,
16631,79165756,Data Scientist,от 300 000 до 400 000 руб. на руки,более 6 лет,"Полная занятость,полный день","Чем предстоит заниматься: Технический enabling: осуществлять техническую поддержку продуктового HW/SW стека проекта внутри экосистемы банка ( + внешние пользователи при необходимости ) Проводить регулярное бенчмаркирование и эксперименты с приложениями и моделями пользователей, проводить анализ результатов, давать обратную связь продуктовым командам Совместно с продуктовыми командами реализовать интеграцию продукта в рабочие системы пользователей : обеспечить работу пользовательских сеток на sample без ошибок, сборку моделей с ПО и работу продуктовых задач в боевом режиме Pre-sale, post sale support: регулярно и своевременно отвечать на вопросы пользователей, bug tracking, При необходимости проводить технические тренинги для заказчиков. Требования: Хорошие коммуникационные навыки, customer focus Linux – на уровне пользователя Python – знание языка, Numpy, Pandas, Matplotlib/Plotly Знание одного из фреймворков: Pytorch, TensorFlow Знания Git и Docker на пользовательском уровне Понимание математического аппарата обучения нейронных сетей Опыт написания пользовательских слоев для фреймворков Практический опыт обучения нейронных сетей для решения задач в одной из областей: CV,NLP,Audio, Rec systems Знание основных базовых архитектур нейросетей и метрик качества в одной или нескольких областях: CV,NLP,Audio, Rec systems Владение английским языком на уровне достаточном для чтения технической литературы",,Сбер. IT,
16632,79110745,Data Engineer,от 4 000 до 6 000 EUR до вычета налогов,3–6 лет,"Полная занятость,удаленная работа","щу Data Engineer в SportTech компанию Sportradar. Sportradar - крупнейший провайдер спортивных данных в мире, работают с FIFA, UEFA, NBA, NHL, ITF и многими другими. Торгуются на Nasdaq. Нанятый человек присоединится к annotation/labeling команде в computer vision продуктах, состоящей из 3 (будет 4) SW Engineers, 1 MLOps и 1 Product Manager’а. Annotation является частью более крупной команды Automated content, состоящей из 70 человек (аналитика, дополненная реальность). Задачи Взаимодействие с data scientist’ами и аналитиками, работа над поиском новых способов генерации и улучшения качества данных. Data modeling, создание и поддержка датасетов и инструментов для их генерации. Развитие ETL и data ingestion пайплайнов. Стек: Python, Pandas, Postgres, SQLAlchemy, Airflow, AWS (RDS, S3, Step Functions, EC2). Требования Разговорный английский Опыт работы Data Engineer от 2х лет, предпочтительно с подготовкой датасетов для ML Представление о статистическом анализе данных, методах ML Python, SQL, AWS (RDS, S3, Step Functions, EC2) Плюсом будет: Airflow, Spark, Pandas, AWS SQS, SNS, EventBridge, Lambda. Этапы интервью 30 минут звонок с рекрутером, я проверю англ, отвечу на вопросы, уточню пожелания. После 2 инженера проведут техническое интервью (1-2 собеседования). Условия Первые 6 месяцев работа удаленная, не из РФ/РБ, по b2b контракту. ЗП до 6k EUR gross + после 6 мес, RSU и годовой бонус (об этом ниже). После - релокация с официальным трудоустройством на Кипр или в Словению, возможно в Сербию. Если вы уже легализовались в Европе, то добавляются спания, Австрия, Германия, Польша, Словакия. Условия в этих странах варьируются, например где-то есть фитнес в офисе, где-то нет. Где-то будет сложнее устроить человека с РФ паспортом, где-то проще. К ЗП добавится страховка, годовой бонус до 10% (обычно он в районе 6-8%), RSU в размере ~30% от годового дохода, а вот пересмотра фиксированной части ЗП в сторону увеличения, скорее всего, не будет. Часы работы гибкие, нужно пересекаться в часы, о которых договоритесь с командой. Посещение офиса от 3х дней в неделю. Если поселитесь очень далеко, то можно попробовать договориться на меньше.","Python,SQL,AWS,Английский — B2 — Средне-продвинутый",4CV Recruitment Services,
16633,79105752,Data Scientist (удаленно),з/п не указана,1–3 года,"Полная занятость,полный день","Мы, Dataacquisition , команда энтузиастов в области Big Data и машинного обучения, ищем технически подкованного специалиста по Data Science и машинному обучению. Обязанности: · Реализация проектов из сфер CV, OCR, NLP, семантическая сегментация, построение предиктивных моделей и других задач из сферы · Работа с подготовкой и аннотацией данных (датасетов) · Подбор, доработка и обучение моделей, подходящих для решения той или иной задачи · Проверка полноты, точности, уверенности и других характеристик моделей, необходимых для реализации той или иной задачи · Работа в связке с проджект менеджером и другими разработчиками Требования: · Linux и администрирование распределенных систем · Пунктуальность, систематичность, ответственное отношение к дедлайнам . Уверенное владения Python для ML (преимущественно nlp и cv) . Опыт реализации и применения моделей машинного обучения . Знание основных алгоритмов и структур данных . опыт работы с ML-библиотеками и библиотеками для работы с данными: pandas, numpy, sklearn, catboost, xgboost, lightgbm, pytorch, tf и др.) . Приветствуется опыт работы с различными источниками данных: SQL, Hive, Presto, Kafka, etc. Условия: · Удаленная занятость · з/п по договоренности · Работа в перспективной и динамично развивающейся сфере Big Data, возможность получить опыт участия в проектах с крупнейшими заказчиками из самых разных сфер (маркетинг, производство, финансы, агросектор и других) · Возможности финансового и карьерного роста · Корпоративные занятия по английскому языку","Python,SQL,Linux,Numpy,Pandas,Machine Learning,Машинное обучение,Data Analysis,Mathematical Statistics,Big Data,Data Science,sklearn,PyTorch",Горбунов лья Николаевич,
16634,79212095,Data Scientist (Junior+Middle),з/п не указана,1–3 года,"Полная занятость,полный день","В команду машинного обучения ищем специалиста с опытом решения прикладных задач. С тебя желание развиваться и расти в молодой, но амбициозной компании. В помощь широкий стек технологий, а тажке сильный коллектив единомышленников, желающий создать лучшую страховую компанию на рынке. Обязанности Анализ клиентской базы: сегментация, склонность к покупке/оттоку, оценка потенциала развития клиентов Построение предиктивных моделей, подготовка и внедрение моделей в prod Мониторинг эффективности, дообучение, корректировка моделей Создание витрин данных для моделирования, featurestore Требования Опыт работы от 1 года Владение SQL, Python и библиотеками анализа данных: Pandas, NumPy, scikit-learn, xgboost Знания в направлениях CV, OCR, Image Recognition, Auto-encoders, Recommender Systems. Отличная математическая подготовка Уверенное знание математики, алгоритмов машинного обучения, статистики, алгоритмов и структур данных Опыт работы с различными источниками данных Плюсом будет опыт работы с docker, airflow, git, bash. Условия Гибридный формат работы (офис + удаленная работа) Офис м. Проспект Мира выгодные ипотечные льготные условия кредитования бесплатная подписка СберПрайм+ скидки на продукты компаний-партнеров: Okko, Сбер Маркет, Delivery Club, Самокат, Ситимобил, Сбер Еаптека и другие ДМС с первого дня и льготное страхование для близких корпоративная пенсионная программа детский отдых и подарки за счет Компании обучение за счет Компании: онлайн курсы в Виртуальной школе Сбера и неограниченный доступ к библиотеке, обучение в Корпоративном университете, тренинги, митапы и возможность получить новую квалификацию реферальная программа для сотрудников: можно пригласить в команду знакомых профессионалов и получить вознаграждение до 100 тыс. рублей скидки на отдых в лучшем в мире курортном комплексе «Mriya Resort & SPA» в Ялте.",,Страховая компания Сбербанк страхование,
16635,79255312,Intern Data Scientist,з/п не указана,1–3 года,"Стажировка,полный день","В команду Управления внутреннего аудита по Среднерусскому банку ПАО Сбербанк требуется специалист (стажер), который обеспечит реализацию алгоритмических и технологических задач, связанных с развитием и внедрением наших решений. Обязанности Обязанности обязанности - реализация digital-задач - подготовка и обработка данных для реализации digital-задач - участие в проектах в качестве DA/DE/DS - сопровождение действующих инструментов -аналитика данных Требования Требования Высшее образование (не оконченное): Техническое / Физико-математическое Опыт проведения / участия в Т-проектах Хорошее знание языков программирования Python, SQL Умение работать с большими объемами данных, навык их систематизации Компетенции в области Data Science Понимание базовых ML-алгоритмов Приветствуется опыт работы с Hadoop, знание Spark и Java Приветствуется знание инструментов BI аналитики Знание английского языка в объеме, необходимом для работы с технической документацией Развитые коммуникативные навыки Умение работать в режиме многозадачности Условия Офис м.Римская/Площадь льича (10 минут от метро) Работа только в офисе Официальное трудоустройство по ТК РФ с первого дня работы – срочный трудовой договор Корпоративный спортзал Постоянное развитие профессиональных навыков за счет использования современных технологий и внутренних тренингов.",,Сбер для экспертов,
16636,79112858,Data Scientist R&D,от 150 000 до 300 000 руб. до вычета налогов,1–3 года,"Полная занятость,гибкий график","Мы в Rubbles занимаемся разработкой и внедрением DS-продуктов в крупные бизнесы. Например, системами предсказания спроса на товары в ритейле и fmcg, рекомендательными системами, системами предсказания поломок оборудования, поисковыми системами для онлайн-магазинов, системами оптимизации производства в промышленности, цифровые двойники и многим другим. Алгоритмы Rubbles ежедневно улучшают работу крупнейших банков, ритейл-сетей, нефтегазовых компаний и других предприятий. Мы ищем data scientist уровня middle для решения задач в промышленности: предсказание поломок оборудования, рекомендательные системы для минимизации остановок оборудования и самое разное детектирование неоптимальностей (например, простои грузовиков вне положенных мест, аномальное количество отходов производства на каком-то из тех. переделов). Существенной частью работы будет исследование проблем производства и формализация задач совместно с бизнес-аналитиками и коллегами-дсами Обязанности: Проверка и валидация бизнес-гипотез с существенным погружением в предметную область Решение ML-задач, к которым свелась бизнес-проблема, выбор лучшего решения (например, детектирование аномалий vs semi-supervised learning? Найти таргет для обучения с учителем vs найти глазами кластер с остановами?) Построение воспроизводимых пайплайнов ML-моделей: Получение - развернуть дамп базы, сходить на ftp-сервер Обработка - пайплайн выживает даже при битых данных Обучение - не бояться применять эвристики при необходимости Валидация - корректно выстраивать процесс в зависимости от решаемой задачи - мониторить не только технические но и бизнес-метрики не заглядывая в будущее, имитировать работу реальной системы Деплой - под присмотром ДЕ или же самостоятельно. Участие в пресейлах - решение реальной задачи в формате хакатона. Минимальные требования: Опыт работы с классическими ML-алгоритмами (Бустинг, логрег, леса. Знаете границы применимости, умеете генерировать подходящие под задачу фичи, а потом подобрать лучший алгоритм) Опыт решения задач с существенной исследовательской составляющей Опыт разработки на python (pandas, numpy, sklearn) от 1 года, знаете как писать эффективный код (векторизация, распараллеливание). Будет плюсом: Опыт работы на позиции, связанной с промышленной разработкой Опыт работы с глубоким обучением (pytorch) Опыт работы над задачами промышленности в одной из областей: нефтехимия, приборостроение, логистика Soft-skills и прошлый опыт работы в проектной команде Опыт проведения и/или анализа результатов АБ-тестов. У нас: Работа в одной из самых сильных ML команд в России Гибкий график работы, гибкое предоставление отгулов и отпусков Гибкий формат работы: полная удаленка/гибрид/офис в Мск. Поддержка в профессиональном и карьерном росте, оплата профильного обучения, конференций и книг, корпоративные скидки на курсы английского Совместная работа с опытными разработчиками, аналитиками данных, менеджерами, продуктологами ДМС со стоматологией после испытательного срока (3 месяца) по всей России При желании работать из офиса – уютный офис в центре Москвы (2 минуты от м. Сухаревская) со всем необходимым для комфортной работы. Особенно актуальное: Мы аккредитованная Т-компания со всеми вытекающими льготами.","Python,Pandas,Machine Learning,Numpy,Аналитические исследования,Задачи оптимизации,sklearn",Rubbles,"Москва, проспект Мира, 3с3"
16638,78771412,Data Scientist / Python разработчик,з/п не указана,не требуется,"Полная занятость,полный день","Наша компания занимается предоставлением полного спектра услуг по разработке ПО для заказчиков со всего мира. У компании несколько офисов – девелоперские центры в Ростове-на-Дону (головной офис) и в поселке Красная Поляна (Краснодарский край), а так же офисы продаж в Мельбурне (Австралия) и Тель-Авиве (зраиль). Мы предоставляем услуги web-разработки, мобильной разработки, десктопной разработки, разработки в области data science, проектирования, тестирования и создания UX/UI-дизайна. Мы приглашаем на работу разработчиков в отдел Data Science в головной офис в Ростове-на-Дону. Если Вам интересно заниматься инновационными разработками, если Вы хотите работать над сложными задачами, решение которых еще не было найдено, если Вы любите науку и хотите развиваться, эта работа для Вас! Рассматриваем соискателей только на работу в офисе. Удаленного формата работы нет. Требования: знания и опыт разработки Python опыт работы с различными научными и специализированными пакетами (numpy, scipy, matplotlib, pandas, TensorFlow и т.д.) работа на различных версиях среды разработки не должна представлять для вас проблем знание базовых алгоритмов и структур данных, понимание принципов оценки эффективности алгоритмов приветствуются базовые знания в одной или нескольких из следующих областей: - компьютерное зрение, обработка изображений - обработка текстов на естественных языках - работа со звуком - машинное обучение - обработка сигналов - математическое моделирование. желание развиваться в области прикладной математики, машинного обучения и программирования умение быстро искать информацию в интернете умение разбираться в чужом коде английский на уровне чтения профессиональной литературы (по математике и программированию), а также написания технической документации желательно наличие примеров написанных программ ответственность обучаемость умение работать в команде. Условия: оформление согласно Трудовому Кодексу РФ восьмичасовой рабочий день. Обеденный перерыв 1 час + два кофе-брейка по 15 минут гибкое начало рабочего дня достойная заработная плата оплачиваемые переработки (9-й и 10-й час в день по тарифу 150%‚ 11-й и далее по тарифу 200%) система премирования только крупные и сложные проекты работа с инновационными технологиями, о которых другие компании боятся даже подумать профессионально выстроенная система обучения сотрудников по всем направлениям работы компании большой и дружный коллектив, где всегда присутствует атмосфера взаимопомощи при возникновении любых вопросов работа только ради результата, а не ради процесса уважительное отношение к сотрудникам регулярная обратная связь корпоративное такси для жителей отдаленных районов комплексные обеды (собственная столовая с поваром) современный‚ технологичный и уютный офис (1100 кв.м) с огромным количеством зелени неограниченная парковка для сотрудников компании кофе, чай, снэки (перекусы) доступный досуг (настольный футбол, настольный теннис, PlayStation VR‚ Sega Mega Drive 2, сцена с профессиональным музыкальным оборудованием, массажное кресло Yamaguchi YA-6000) много зон отдыха внутри офиса своя большая территория с лавочками, деревьями и зелеными газонами Crossfit-площадка все вышеперечисленное - правда.","Python,MATLAB,Математический анализ,Математическое моделирование,Математическое программирование,Математическая статистика,Pandas,Machine Learning,Numpy,Data Analysis,Matplotlib,SciPy,Deep Learning,Data Science,Машинное обучение,Scikit-learn,Maple,Mathematical Analysis,PyTorch,Mathematical Modeling,sklearn,Tensorflow,Keras,Computer Vision",ЗАЗЕКС,"Ростов-на-Дону, Обсерваторная улица"
16639,75789450,Data Scientist,от 220 000 до 270 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Мы, ООО ""КСОР"" - команда неравнодушных людей. Мы повышаем уровень безопасности на дорогах, а также обеспечиваем высокий уровень обслуживания и гарантий для наших клиентов. Мы первые, кто создал бесконтактную систему мониторинга состояния водителя ""Антисон"". Это нейросеть, фиксирующая в реальном времени поведение и состояние человека за рулем. Наша миссия – свести к нулю число дорожно-транспортных происшествий, обеспечить безопасность и защитить жизни людей. Сейчас ""Антисном"" оборудован весь пассажирский транспорт Москвы (а это уже более 8000 пассажирских автобусов и 1500 локомотивов метро). За 2020 год мы снизили аварийность на дорогах города на 26%.  мы продолжаем дорабатывать и улучшать нашу систему. ""Антисон"" - полностью наша разработка: как hardware, так и software. Сейчас мы ищем в команду Middle/Senior Data Scientist (направление Computer Vision). Ключевая цель: Разработка алгоритмов компьютерного зрения, подбор и обучение моделей, подбор оптимальных настроек алгоритмов, определение текущего качества алгоритмов и их улучшение. Обязанности: Придумывать и реализовывать подходы к решению задач компьютерного зрения и машинного обучения, формировать требования совместно с командой по бизнесу и инфраструктуре. Планировать эксперименты, обучать модели, проводить оценку их качества и встраивать в пайплайны. Регистрировать результаты обучающих прогонов моделей и отслеживать динамику их показателей. Писать алгоритмы пред- и постобработки изображений и видео. Добавлять новые фичи в уже работающие проекты. Формировать РД, такие, как полезные модели, изобретения. Требования: Опыт работы по специальности от 2 лет. Опыт решения задач классификации, детекции, сегментации, трекинга для изображений Понимание классических алгоритмов ML. Опыт работы на Python и базовыми инструментариями DS. Знание классических алгоритмов компьютерного зрения Понимание работы основных архитектур для задач CV (YOLO, U-Net, ResNet и тд). Уверенное пользование одним из фреймворков для обучение сетей: PyTorch, Tensorflow/Keras. Уверенное пользование OpenCV. Опыт работы с ОС Linux, Git, Docker. Математический бэкграунд — алгебра, теория вероятностей, математический анализ Написание читаемого и поддерживаемого кода. Умение понимать и имплементировать подходы из научных публикаций по CV/DL. Умение реализовать полный цикл разработки модели от постановки эксперимента до выкатывания в продакшн. Будет плюсом: Знание C++, а также умение портировать код и модели под плюсы. Умение конвертации моделей между фреймворками. Опыт внедрения алгоритмов машинного зрения в Edge системы с ограниченными ресурсами, работающие под Linux-подобные ОС: Jetson, Raspberry PI... Опыт работы с фреймворками для оптимизации сетей: TensoeRT, OpenVino, Tengine. Опыт оптимизации решений: квантизация, мердж слоёв, Knowledge Distillation. Опыт в соревнованиях по анализу данных и машинному обучению, пет-проекты. Хорошая алгоритмическая подготовка. Опыт работы с gstreamer/ffmpeg. Мы предлагаем: Оформление по ТК РФ с первого рабочего дня Полный ДМС со стоматологией после 6 месяцев работы График 5/2, гибридный формат работы (офис/удаленка), гибкое начало дня до 11:00 Годовая премия Корпоративная электронная библиотека Корпоративные мероприятия, дружный и сильный коллектив Возможность пройти оплачиваемое обучение (повышение квалификации).","Математическая статистика,PyTorch,Python,Docker,Linux,C++,Mathematical Statistics,нейросети,Git,Machine Learning,Computer Vision,Keras,Tensorflow,Алгоритмы,ML,OpenCV",КСОР,
16640,79173134,Аналитик Data Scientist,от 50 000 до 100 000 руб. на руки,1–3 года,"Полная занятость,полный день","Мы - амбициозная молодая команда Фаворит Фэшн Груп, которая за пару лет уверенно вышла в лидеры продаж на маркетплейсах! Одно из главных наших направлений – собственное производство и продажа одежды на всех известных маркетплейсах. Мы гордимся тем, что предоставляем нашим клиентам широкий выбор стильной и качественной одежды. В связи с быстрым ростом компании, мы предлагаем вам стать частью нашей команды и вместе двигаться к успеху! В связи с активным развитием нам нужен в нашу команду: Аналитик Data Scientist (jun+) Условия: Работа в растущей компании, занимающей лидирующие позиции в отрасли Заработная плата от 50 000 до 100 000 руб., обсуждается с финальным кандидатом в зависимости от компетенций и стеков Полный рабочий день в офисе Loft Ville (Павелецкая наб., 2) Полный рабочий день, 5/2, 9.00 - 18.00 нтересные практические задачи, над которыми предстоит работать Возможность получить глубокую техническую экспертизу Возможность профессионального развития и карьерного роста до Руководителя отдела аналитики Коллектив единомышленников - профессионалов своего дела Возможность обучения в элитной закрытой бизнес-школе управления. Требования: Профильное высшее образование (техническое, математическое) Опыт работы в роли Аналитика - от 1 года Знание Excel, Google Таблицы – на уровне эксперта / продвинутого пользователя Знание на практике основных бизнес-метрик, бизнес-процессов, KPI Умение ориентироваться в маркетинговых и финансовых показателях Личные качества: аналитический склад ума, внимательность, ответственность, умение доносить информацию в простом и понятном виде, критическое мышление. Обязанности: Сбор информации из разных источников, ее анализ и представление в наиболее удобном для восприятия виде Финансовый анализ спроса сбыта и ценообразования, разработка и осуществление мер по обеспечению финансовой устойчивости Формирование сводных отчетов из больших объемов и разрозненных данных, в т.ч. «с нуля» Анализ бизнес-процессов в компании и подготовка рекомендаций по их улучшению.","Аналитическое мышление,Анализ данных,Анализ бизнес показателей,MS SQL,Математическая статистика,Аналитические исследования,Анализ финансовых показателей,Математический анализ,Сбор и анализ информации,Системное мышление,Data Analysis,Data Scientist,Английский — B2 — Средне-продвинутый",ФАВОРТ ФЭШН ГРУП,"Москва, Павелецкая, Павелецкая набережная, 2с1"
16641,78876532,Эконометрист/Data scientist (Junior/Middle) в консалтинг,от 40 000 руб. на руки,1–3 года,"Полная занятость,полный день","Консалтинговая компания с 20-летним опытом работы на рынке РФ, цифровое направление - BST Digital. Вакансия на проекты с крупнейшими банками и ритейлерами, а также для развития новых ML-продуктов. деальный кандидат - тот, кто знает эконометрику/мат.статистику, любит усидчиво моделировать и изучать данные, генерировать гипотезы и придумывать фичи, программирует на Python, умеет просто объяснять сложные модели и мат.методы, также хорошо знает машинное обучение или недавно начал его изучать и уже имеет учебный или рабочий опыт. Рассматриваются кандидаты как с опытом работы (банки/ритейл/консалтинг/стартапы), так и сразу после вуза. Обязанности: Построение моделей эластичности спроса на банковские продукты и моделей прогнозирования в ритейле в т.ч. с учётом гео-аналитических данных Построение прогнозных моделей финансовой сферы оценки кредитных рисков: EaR, PD и др. Написание тестов для мониторинга качества моделей Подбор статистических методов и влияющих факторов Анализ метрик качества модели, чувствительности к факторам, устойчивости результатов Активное обсуждение результатов с клиентом и внутри команды Участие в сборе и обработке данных Требования Экономическое или техническое образование (предпочтительно: ВШЭ, РЭШ, МГУ, МФТ и др. технические вузы, но главное - желание) Знания эконометрики, математической статистики, математических методов в экономике Знание макроэкономики, банковского дела, основ денежно-кредитной политики Опыт построения эконометрических моделей, сценарного моделирования Умение быстро работать с большими объемами информации Умение программировать на Python Большим плюсом будет знание методов машинного обучения, стат.пакетов Будет здорово, если вы: Можете быстро погрузиться в суть проекта и овладеть инструментами моделирования Умеете легко находить общий язык с коллегами и клиентами Системно и критически мыслите Внимательно относитесь к деталям Условия: Возможность удаленной работы Конкурентный уровень заработной платы Супер-интересные задачи и топовые клиенты для резюме Возможности для быстрого профессионального развития Возможность получения уникального опыта Работа в молодой и дружной команде с опытными наставниками График работы 5/2 Комфортный офис в самом центре Москвы (Маяковская) Соблюдение ТК РФ",,БСТ Менеджмент-Консалтинг,"Москва, Замоскворецкая линия, метро Маяковская"
16642,79145846,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Обязательные: Опыт формализации и решения задач оптимизационных математических моделей Понимание методов и алгоритмов оптимизации(как минимум, симплекс-метод при решении) Опыт работы с софтом для решения оптимизационных моделей (желательно Gurobi, либо CPlex), оптимизационных задач. Желаемые: Опыт выполнения реальных проектов с применением языка программирования Java либо C# Знание SQL (на уровне написания запросов), опыт работы с любой промышленной СУБД Навыки работы с применением системы сборки (например, Maven, Gradle) Навыки работы с системой контроля версий (например, Git, SVN, TFS). Требования: Разработка экономико-математических моделей: логистики (желательно связанной железной дорогой) Разработка, начиная с проработки и согласования с Заказчиком методики, используемой в модели, и заканчивая реализацией модели в соответствии с согласованной методикой в конструкторе моделей. Условия: Официальное трудоустройство по ТК РК Дружный коллектив.",,сткомтранс,"Алматы, проспект Аль-Фараби, 77/7"
16643,79169643,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Участие в оценке эффективности маркетинговых мероприятий, поиск фрода, построение моделей оттока клиентов, uplift моделирование, рекомендательных систем Выбор оптимального метода моделирования Дизайн и проведение А-Б тестов, проверка статистических гипотез, представление результатов бизнес-заказчику Визуализация данных по итогам проведения аналитики code review Требования: Опыт работы на позиции data scientist от 1-3 лет SQL, Python, Excel Опыт работы с (pandas, numpy, sklearn, optuna) Знание классических алгоритмов ml и что находится у них под капотом (catboost, xgboos, lgbm, als, lightfm и т.д) Методичность работы с информацией, выявление взаимосвязей Опыт использования на практике знаний в области прикладной математической статистики, теории вероятностей Способность быстро оценивать ситуацию и принимать решения Способность точно, аккуратно и педантично выполнять работу в установленные сроки, ответственность за результат Высшее образование (техническое, экономическое). Участие в хакатонах, Kaggle, как плюс Условия: Отпуск 28+3 дня ДМС, бонусы при выходе в отпуск, насыщенная социальная программа Уровень заработной платы обсуждается по итогам собеседования Работа в офисе (Большая Ордынка, 3) Оформление в ООО ""ЛКАРД"".",,ЛУКОЙЛ,"Москва, улица Большая Ордынка, 3"
16644,78706463,Data Scientist,до 300 000 руб. на руки,3–6 лет,"Полная занятость,полный день","щем специалиста по Data Science в Точку. Мы — финтех-компания, создаём онлайн-банк и другие сервисы для предпринимателей и предприятий. Тебе предстоит строить и улучшать модели машинного обучения, а также придумывать новые кейсы применения  в наших банковских и небанковских сервисах для бизнеса. Как мы работаем У нас микросервисная архитектура. Команды работают с последними технологиями, областями вроде машинного обучения и big data, а также свободны в принятии технических и продуктовых решений. Заботимся о качестве кода: проводим ревью, всё покрываем тестами и даём обратную связь. спользуем Agile, SCRUM и OKR. Что делать Участвовать в новом проекте с применением  в сервисах Точки. Разрабатывать модели машинного обучения: GAN-модели, рекомендательные системы. Придумывать и проверять гипотезы, которые позволят улучшить и оптимизировать внутренние процессы в Точке. Будешь доставать данные из баз и других источников, приводить их к нужному виду, анализировать и строить модели. Тебе предстоит планировать и ставить эксперименты, анализировать результаты и их статистическую значимость. Ты подойдёшь, если Знаешь Python, умеешь обрабатывать данные с помощью pandas, NumPy и Plotly. Есть опыт работы с SQL. Есть опыт работы с методами машинного обучения и основными инструментами data science: Scikit-learn, XGBoost, CatBoost. Разбираешься в математической статистике, теории вероятности и знаешь, как проводить A/B тестирования. Есть опыт работы с нейросетями, понимаешь их принципы работы в сфере изображений и текста. Что ждёт тебя в Точке Официальная зарплата до 300 000 . Точная сумма зависит от твоих навыков и ожиданий — обсудим их на собеседовании. Пятидневная рабочая неделя с гибким началом и окончанием дня. Удалёнка или любой офис Точки в городах присутствия. Наши офисы — это продуманные опенспейсы, где есть индивидуальные места для работы, зоны отдыха и кухни с кофе и перекусами. Ты можешь самостоятельно выбрать, где работать — ходить в офис необязательно. Понятная система развития и роста по грейдам. Бесплатное обучение: ты сможешь ездить на IT-конференции, митапы и хакатоны и проходить курсы за счёт компании. А ещё пользоваться нашей библиотекой и платформой с онлайн-курсами. Бесплатная страховка здоровья со стоматологией и корпоративный психолог. Активная корпоративная жизнь: мы проводим спортивные марафоны, гастрономические вечера, музыкальные лайвы и многое другое. Мы ценим твоё время, поэтому не затягиваем процесс собеседования и сделаем пре-оффер в течение 24 часов.","Нейросети,Python,Машинное обучение,NLP,ML,GAN,SQL",Точка,
16645,77954455,Data Scientist (Middle+),от 170 000 до 240 000 руб. на руки,1–3 года,"Полная занятость,удаленная работа","AnyQuery — SaaS сервис AI поиска для eCommerce, обрабатывает миллиарды поисковых запросов на 250 интернет-магазинах (Ситилинк, ЦУМ, Эльдорадо, Спортмастер, Петрович, Азбука Вкуса и тд)  У нас огромная экспертиза в машинном обучении, high load системах.  В текущей команде около 80 человек, компания продолжает расти и ищет Data Scientist. Что надо делать: Разрабатывать модели схожести запросов и товаров Разрабатывать модели ранжирования Разрабатывать модели исправления опечаток Дорабатывать сервис метрик и производить анализ метрик Анализировать поиск, выдвигать гипотезы по повышению качества поиска Что нужно уметь : Уметь писать готовый к production код (Python) меть математический бекграунд (профильное техническое/математическое образование, хорошее понимание мат.статистики, линейной алгебры) Опыт работы с текстовыми данными или задачами поиска будет серьезным плюсом Java/Scala/Elasticsearch/C++ будет плюсом Почему нужно идти к нам? Удаленную фултайм работу Работу с настоящей командой из 70+ профессионалов, готовых прийти на помощь. Полностью белую заработную плату, оформление по тк. У нас крутая продуктовая культура. Мы смогли за 2 года обогнать лучших мировых игроков по функционалу, за счет плотной работы с клиентами, быстрых MVP и точных решений #B2B #AI #SaaS Enterprise - мы занимаемся очень перспективным бизнесом. За ним и настоящее и будущее. AI — этого становится все больше, растущий рынок, вам это пригодится. А SaaS любят потому, что хороший ретеншн и рациональное принятие решения об использовании. У нас очень крутая школа и репутация - выпускники нашей команды работают в самом топе - Ebay Europe, Constructor IO, Microsoft Europe, Semrush, Lamoda, Yandex, AliExpress, RichRelevance. Корпоративные программы английского ""Skyeng"" Diginetica аккредитована для участия в программе IT ипотеки. Мы также заботимся о твоем ментальном здоровье, предлагаем скидки на услуги сервиса ""Ясно""","SCALA,Java,SQL,Анализ данных,Python,Elasticsearch,Big Data,С++,Tensorflow,Pytorch,SciPy,Numpy,Pandas,Word2vec,Xgboost",DIGINETICA,
16646,79219377,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Компания lifetech ищет в свою команду Data Scientist. Какие задачи Вас ждут у нас? Анализ ключевых метрик продуктов, поведения пользователей Участие в формировании KPI для бизнеса звлечение больших объемов данных из различных внутренних и внешних источников с последующим анализом Сбор и анализ данных, построение сегментаций, визуализация результатов в доступном читабельном виде Формирование и проверка гипотез, подготовка предложений для бизнеса на основании исследований Оценка эффективности рассылок, предложения по оптимизации Постоянное улучшение существующих предиктивных моделей и построение новых (отток, скоринг, фрод, CLV и т.п.) Участие в разработке проектов в областях CV(OCR, Object Detection) Ответственность за все стадии ML-проектов: от формализации задачи до внедрения в продакшен Взаимодействие со смежными командами аналитиков и разработчиков, активное участие в развитии сервисов. Наши ожидания: Высшее образование в области математики, статистики, информатики, инженерии или других связанных областях Опыт работы с данными от 2 лет Знание языков программирования Python, R, SQL, а также инструментов машинного обучения и анализа данных, такими как Pandas, Scikit-learn, TensorFlow, pyTorch , OpenCV и другими Практический опыт работы в сфере обработки изображений, в решениях задач детекции, распознавании машинописного текста Знание наиболее распространенных алгоритмов машинного обучения, понимание их теоретических основ Системное мышление, способность самостоятельно разбираться в особенностях продуктов и поведении пользователей Аналитический склад ума, умение анализировать данные, извлекать ценные инсайты и делать выводы Умение объяснять сложные технические концепции простым языком и работать в команде, включая нетехнических специалистов Умение работать с большими объёмами данных и уметь обрабатывать их с помощью соответствующих инструментов Навык визуализации и наглядного представления данных скренняя увлеченность данными, желание копать до получения ответа на свой вопрос. Что мы предлагаем Вам: Офис в БЦ Виктория Олимп, г. Минск, Победителей, 103 Подробнее о нашей социальной политике и бенефитах можно узнать в профиле компании","SQL,Python",Лайфтех,
16648,78853190,Младший научный сотрудник (Junior Data Scientist),з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем исследователей в области Deep Learning для участия в проекте по разработке технологий голосовой биометрии. Эти технологии применяются в множестве наших продуктов, которые используются различными крупными отечественными и зарубежными компаниями. Направление голосовой биометрии комплексное и включает в себя решение задач начиная от детектирования речевой активности и заканчивая оптимизацией задачи идентификации на больших объемах данных. На текущем этапе команда сосредоточена на задачах VAD и диаризации. В данном проекте вас ждет работа в интересной команде. Многие из нас имеют многолетний опыт работы с технологиями обработки звука и речи. Регулярно публикуемся в индексируемых журналах и участвуем в конференциях. Стараемся не пропускать релевантные конкурсы и занимаем лидирующие позиции в них. Обязанности: зучение существующих SOTA методов по направлениям VAD, диаризации, верификации и идентификации дикторов Проектирование и реализация моделей, которые позволяют создавать SOTA решения Работа с данными, предобработка, создание тренировочных и тестовых наборов Проведение экспериментов для апробации подготовленных решений Тестирование и оптимизация разработанных решений для дальнейшей передачи их на встраиваниев прод Публикация статей, участие в конкурсах. Что важно для нас: Опыт от 1 года в профильной области Математическая база, понимание статистики, теории вероятностей Понимание и практический опыт в области машинного обучения Знакомство с направлением глубокий нейронных сетей Уверенное владение Python Опыт работы с PyTorch.","Python,PyTorch",ЦРТ | Группа компаний,"Санкт-Петербург, Выборгская, Лесная, Петроградская, Выборгская набережная, 45Е"
16649,79226615,Data Scientist (TTS),з/п не указана,3–6 лет,"Полная занятость,полный день","Just AI одна из лидирующих продуктовых компаний в сфере Conversational AI. Нашими продуктами пользуется около ста крупных российских и ряд международных IT-компаний, телеком-компаний, банков (Yandex, Mail.ru Group, Сбер, МТС, Мегафон, Альфа-банк, HH.ru, Qiwi, BNP Paribas). Наши SAAS платформы и инженерные фреймворки используют более 50 000 разработчиков и малых-средних компаний по всему миру. Наш фокус – технологии понимания естественного языка, инструменты для создания голосовыхассистентов, машинного обучения, speech synthesis and voice cloning и системы управления диалогом, NLU/NLP/DM/ODQA/CDQA. Мы ищем нового коллегу в нашу R&D команду синтеза речи, который займётся развитием базовой технологий, исследованием и имплементацией последних достижений в этой области, а также разработкой пайплайнов для надежного полностью автоматизированного создания моделей голосов на основе данных пользователей. В R&D команде, которая занимается вопросами синтеза речи, сейчас работает 4 человека. Ваши будущие задачи: Развитие и поддержка существующих продуктов, связанных с синтезом голосов наразличных языках. сследование проблем, связанных с управлением интонацией, ритмикой, темпом и прочими характеристиками синтезированной речи. Выполнение исследовательских задач в составе группы по проблемам разработки мультиязычных мультиспикерных систем синтеза речи. Взаимодействие с командами разработки. Наши ожидания: Опыт решения задач Text-to-Speech или смежных (Voice cloning / Voice transfer) в рамках рабочих проектов и глубокое понимание теоретических основ для решения описанных выше задач. Опыт работы с диффузионными моделями будет плюсом. Сильные навыки имплементации, обучения и дебага нейросетевых моделей на PyTorch. Сильные навыки программирования на Python, умение писать тесты на ds-компоненты и приложения, понимание дизайна и структуры ds-проектов. Умение работать с информацией: черпать идеи для улучшения продуктов из различных источников (статьи, реализации, собственный опыт / идеи), проработать, имплементировать и объяснить коллегам. Мы предлагаем: нтересные проекты, возможность быстрой имплементации результатов исследований в продукты. Возможности для профессионального роста и обмена опытом как внутри коллектива, так и в рамках внешнего сотрудничества с нашими партнерами, университетами и сообществами. Работа в нашем офисе в Петербурге или удаленная работа: вы можете работать удаленно. Также мы можем предложить официальное трудоустройство в Казахстане или Армении. Отличный современный офис с велопарковками, удобными рабочими местами, общими рабочими зонами, фруктами и снеками. Just AI входит в группы IT-компаний i-Free, объединяющей 16 компаний со штатом около 1000 человек – обилие ивентов по обмену опытом, митапов, возможности для горизонтального развития в компаниях группы. Помощь в релокации, в подборе подходящего жилья, релокационный бонус (при переезде в Петербург). Неповторимая корпоративная культура Just AI DNA, вечеринки, совместные кинопросмотры и многое другое…",,Just AI,"Санкт-Петербург, Петроградская, Чкаловская, Большая Зеленина улица, 24"
16650,78997546,Data scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Сбор, очистка данных Формирование гипотез по монетизации данных Построение математических моделей Мониторинг, валидация моделей. Требования: Понимание банковских процессов Знание математических моделей Знание SQL Знание python (основные библиотеки для работы с данными). Условия: Пятидневная рабочая неделя (с 08.30 до 17.30) Стабильный доход: оклад + премии Социальный пакет (мед страховка, выплаты к значимым событиям, годовая премия, материальная помощь к отпуску). Корпоративное обучение, включающее в себя тренинги как на повышение профессионального уровня, так и для расширения кругозора Курсы английского языка Корпоративная библиотека Условия для применения личных и профессиональных способностей.",,Банк ВТБ (Беларусь). Back-office,
16651,78448054,"Специалист/нженер (AI, Data Scientist, Big Data, Machine learning, Нейронные сети, ChatGPT)",з/п не указана,3–6 лет,"Полная занятость,гибкий график","ПК ЛДЕРГРУПП – это успешная и динамичная команда профессионалов, реализующая проекты в области проектирования линейных объектов по всей территории России в качестве Генерального проектировщика. Условия: Персональный график работы (офис, удаленно, гибридный). Любая форма трудоустройства (Официально, ГПХ, Самозанятость). Уровень оплаты обсуждается индивидуально. Территориально: ст.м. Киевская офис класса А (в пешей доступности). Возможность участвовать в реализации новых уникальных проектов на базе . Профессиональный творческий коллектив. Задачи: Аналитика рынка AI-сервисов под бизнес-задачи кампании. Проведение тестирований на основе технологий искусственного интеллекта (-Сервисов). Подготовка протоколов и результатов исследований. Разработка и внедрение актуальных технологий AI для оптимизации бизнес-процессов Компании. Подбор и координация работы подрядчиков-разработчиков систем -Сервисов. Требования: Профильное высшее образование и навыки работы с разными языками программирования. Знание техник и алгоритмов AI (Data Scientist, Big Data, Machine learning, Нейронные сети, ChatGPT). Практический опыт разработки и внедрения программных продуктов. Опыт управления внутренними и внешними командами разработчиков.",,ПК ЛидерГрупп,
16652,79255620,Data scientist в команду развития скоринговых моделей,з/п не указана,1–3 года,"Полная занятость,полный день","Тебе предстоит: Строить и внедрять скоринговые модели Заниматься исследованием источников данных Реализовывать переменные и скоры для использования в моделях Развивать инструменты аналитики и построения скоринговых моделей для многих команд Тинькофф Менторить сотрудников, развивать их хард скиллы Что мы ждем: Опыт разработки ML-моделей Хорошее знание классического ML Знание Python, SQL Хорошее владение математической статистикой и теорией вероятности Умение работать с большими объемами информации и данных Будет плюсом: Высшее техническое образование Знание основ DL Опыт построения скоринговых моделей, А/Б тестирование Мы предлагаем: Работу в офисе у метро «Водный стадион». График работы — гибридный Платформу обучения и развития Тинькофф Апгрейд. Курсы, тренинги, вебинары и базы знаний. Поддержка менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Бесплатный фитнес-зал Tinkoff Sport. Тренируйтесь, посещайте групповые программы, грейтесь в сауне и участвуйте в спортивных турнирах Бесплатные обеды в Tinkoff Cafe. А если захотите перекусить, на каждом этаже есть кухня с чаем, кофе и фруктами Достойную зарплату — обсудим ее на собеседовании","ML,Mathematical Statistics,Python,Математическое моделирование",Тинькофф,"Москва, Водный стадион, Головинское шоссе, 5А"
16653,78121640,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Точка-Точка (аккредитованная Т компания) — российский разработчик и производитель инновационных решений для транспортной логистики (логистическая платформа перевозки грузов) Точка-Точка занимается разработкой уникального продукта в области грузоперевозок на базе систем искусственного интеллекта, а также реализует R&D проекты в области AI/ML. На текущий момент реализована система принятия решений по цене перевозки, ранжированию заявок и подбору перевозчиков. Приглашаем Data Scientist в команду AI для ML-разработки полного цикла: от хранения и обработки данных до деплоя и автоматического масштабирования готовой модели. Задачи: ведение и архитектурный контроль за развитием сервисов анализ данных, построение моделей для решения бизнес-задач формирование требований к разрабатываемой системе выбор фреймворков, эксперименты взаимодействие с различными командами: DevOps, QA, BigData исследование рынка и применение новых технологических решений участие в проведении обновлений системы Пожелания к опыту: опыт сопровождения ds-моделей в промышленной эксплуатации от 3-х лет глубокое знание принципов Data Science и MLOps опыт конфигурирования поддержки системы CI/CD понимание скриптовых языков: bash, python знакомство с библиотеками для анализа данных: numpy, pandas, matplotlib или seaborn опыт работы с контейнерной виртуализацией Личные качества: аналитический склад ума и деловая хватка нацеленность на результат умение выстраивать эффективное взаимодействие отличные презентационные навыки Мы предлагаем Вам: работу в перспективной амбициозной компании все инструменты для работы полностью белую, конкурентную заработную плату профессиональный коллектив удаленный формат работы","скусственный интеллект,R&D проекты в области AI/ML,Архитектора решений в команду AI для ML-разработки полного цикла,Data Science,MLOps,CI/CD,Bash,Python,Контейнерная виртуализация,numpy,pandas,matplotlib,seaborn,скусственный нтеллект,Машинное обучение,Machine Learning,Нейронная сеть",Центр 2М,"Москва, улица Космонавта Волкова"
16654,79115973,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Команда занимается разработкой моделей с применением искусственного интеллекта для создания персонализированного рекламного контента (текста и изображений) под каждого клиента. Для этого мы применяем самые современные модели, такие как, текстовые генеративные модели (gpt-like) и диффузионные модели (Stable diffusion, Kandinsky). Возможность участвовать в создании и развитии уникального для российского рынка продукта, развиваться в области исследований клиентского поведения и NLP алгоритмов. Работа в молодой сплоченной команде, интересные задачи, общение в сообществе DS Сбера и возможность выступления на мероприятиях этого сообщества. щем DATA SCIENTIST c опытом разработки и обучения NLP/ NLU моделей и генеративных моделей (gpt-like). ОБЯЗАННОСТ: Разработка алгоритмов: Генерации и перефразирования текстов (смс, push, email, баннеры) по заданным условиям (данные о контексте, сегменте и пр.) Проверки текстового контента на юридические риски Подбора контента (текст/ изображения) для повышения конверсии (откликов). ТРЕБОВАНЯ: Опыт в части моделирования и обработки данных - не менее 1 года Понимание не только того, как обучить модель на готовом датасете, но и как самому собрать датасет, сделать расчёт на новых данных и отправить результаты в продакшен Понимание и опыт практического применения алгоритмов машинного обучения: композиционные алгоритмы (случайный лес, градиентный бустинг и т.д.), линейные алгоритмы (линейная и логистическая регрессии и т.д.), нейронные сети Знание базовых алгоритмов NLP, как строится мешок слов, tf-idf, word2vec, doc2vec, и т.д Уверенное знание Python и библиотеки PyTorch Знание архитектур CNN, LSTM, transformer Понимание различий между BERT/GPT/T5 и задач, которые они решают. ПРЕМУЩЕСТВОМ БУДЕТ: Опыт работы с базами данных. Знание SQL на уровне создания таблиц, написания сложных запросов для выгрузки данных, создания процедур Опыт работы с фреймворками Hadoop (HDFS, Hive), Spark. УСЛОВЯ: Работу в стабильной компании, белую заработную плату Оформление в соответствии с ТК РФ с первого дня работы Расширенный социальный пакет: ДМС (включая стоматологию), корпоративные скидки на посещение фитнес-клубов, футбольная и волейбольная секции Профессиональное обучение и развитие Есть возможность полностью удаленной работы.",,Ц АЙ-ТЕКО,
16655,79089106,Data scientist (нестандартные ML-модели),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы ищем талантливого DS в направление R&D. Как часть нашей команды, ты будешь иметь возможность работать над уникальными проектами, связанными с нейронными сетями, моделями выживаемости, causal inference / uplift моделями и многим другим. В твои задачи будет входить исследование и построение ML-алгоритмов, их реализация на Python, последующая автоматизация обучения и применения ML-моделей с помощью MLOps инструментов и многое другое. ЧТО НУЖНО БУДЕТ ДЕЛАТЬ: R&D нестандартных финтех ML-моделей на табличных данных (например, causal inference, анализ выживаемости, разновидности регрессии, обучение с подкреплением) R&D deep learning моделей на поведенческих данных Реализация под ключ DS-проектов (модели кредитного скоринга, ценообразования, отклика клиентов на предложения по запросу бизнес-подразделений банка, LTV) Программная реализация новых методов и алгоритмов во внутренних библиотеках и фреймворках банка ЧТО ВАМ ДЛЯ ЭТОГО НЕОБХОДМО: Законченное высшее образование либо обучение на старших курсах по направлению прикладная математика и информатика, кибернетика, физика Глубокое понимание методов прикладной математической статистики и классического машинного обучения, профессиональный или академический опыт применения от 2 лет Понимание основ глубокого обучения, профессиональный или академический опыт применения от 1 года Общая культура разработки при проведении R&D (написание понятного программного кода, использование git, знание основ linux) Умение писать аналитические запросы на SQL для обработки больших объемов данных Будет плюсом : опыт обработки больших данных с помощью Apache Spark опыт исследовательской работы (гранты, написание научных статей, исследование в индустрии) в области ML и DL МЫ ПРЕДЛАГАЕМ: Фиксированный оклад + система премирования Социальный пакет Команда, открытая самым смелым идеям Внутренние программы обучения и развития Высокий уровень ответственности и возможность самостоятельно принимать решения Атмосфера, где легко оставаться собой: минимум формализма, открытые коммуникации и отсутствие дресс-кода","Python,SQL,ML,Машинное обучение,uplift modeling,модели ценообразования,causal inference,Git,Linux,Deep Learning,Apache Spark",Банк Хоум Кредит,
16656,78769816,Ведущий специалист отдела математического моделирования / Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы тебе: работу над актуальными финтех-продуктами продуктивную и вдохновляющую атмосферу понятные задачи: полный цикл анализа данных и моделирования для повышения доходности портфеля просроченных займов (предсказание доходности клиента при различных методах взыскания, сегментация клиента для оптимизации работы моделей, выбор оптимального действия при взыскании в т.ч. с помощью машинного обучения и углубленной аналитики, участие в выработке и оптимизации стратегии взыскания на основании моделей) анализ эффективности и участие во внедрении новых источников данных (анкеты клиента внутренняя и внешняя кредитная история, мобильное приложение и др.) создание мониторинговой отчетности по математическим моделям стабильную, официальную зарплату комьюнити крутых профессионалов и наставников, где ценят усилия и результаты каждого сотрудника, честны, открыты и уважительны друг к другу удаленный или гибридный формат работы (офис или коворкинг) прокачку знаний и программы развития (внутреннее/внешнее обучение) профессиональный и карьерный рост дружелюбную атмосферу и развитую корпоративную культуру, где инициируем изменения и всегда готовы к любым вызовам ежегодные конференции, тимбилдинги, митапы и другие мероприятия Ты нам: опыт работы в data science от 2х лет высшее математическое/техническое образование знание и навыки работы с SQL высокий уровень владения python опыт работы с основными ML пакетами опыт разработки и мониторинга качества скоринговых и других математических моделей проактивность и включенность в работу понимание основных бизнес-процессов финансовой организации нестандартные решения и желание экспериментировать, развиваться Ты нам – отклик и желание работать, Мы тебе – приглашение присоединиться к нашей крутой команде!",,Eqvanta,
16657,78386771,Middle+ Data Scientist,от 160 000 до 200 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","AgentApp — платформа для бизнеса, которая позволяет запустить продажи страховок со своего сайта или моб. приложения для клиентов со всей страны. Над продуктом работает единая команда разработчиков, аналитиков, маркетологов, а также экспертов в страховом бизнесе. 200 000 000р.+ — ежемесячный объем продаж через платформу. AgentApp — активно развивающийся стартап, позволяющий сотрудникам быстро развиваться профессионально и прокачивать скиллы. Наш продукт интегрирован в моб.приложения Сбербанк, OZON, ВТБ, МТС, Райффайзен, Газпром и имеет аудиторию свыше 70 млн пользователей. Мы находимся в поиске крутого специалиста, который поможет развивать наш Big Data проект! Что нужно будет делать: Разработка моделей скоринга Построение упрощенной модели по характеристикам авто и данным об убытках за пару лет Разработка моделей сегментации клиентов на основании их профилей и анализа их поведения. Мониторинг текущих показателей, обеспечением чистоты входящих данных, улучшением текущих моделей. Разработка инструментов мониторинга сследование тенденций и технологий в сфере Data Science, AI и Machine Learning с целью их последующего применения. Ждем от кандидата: Опыт подготовки неструктурированных данных для обучения модели (feature engineering) Прикладной опыт выведения моделей в продакшн Навык работы с базами данных: владение SQL / Hive / Hadoop / SQL Alchemy Опыт реализации классических ML-моделей: регрессия, классификация, кластеризация, понижение размерности данных Навыки Python-разработчика: работа с файлами - прочитать/записать, работа с АП http-сервисов через xml / json (SOAP/REST). Опыт работы с python-библиотеками (logging, yaml, xml, json, requests, threading) + ORM (sqlalchemy, ponyORM, tortoise) + навыки в ООП (работа через классы). Этапы интервью: 1. HR интервью (30 мин). Знакомство с вакансией. 2. Техническое интервью с CTO и тимлидом. (1-2 часа) 3. Знакомство с СЕО (30 мин) 4. Оффер. С нас: Работа над инновационном продуктом, который востребован на рынке Стабильная зарплата с потенциальными бонусами и регулярной индексацией Удаленная работа (при необходимости использование офиса в пешей доступности от ст.м. Василеостровская и ст.м. Спортивная (СПб)) Прокачка скиллов по запросу или по необходимости (курсы, книжки, семинары) Официальное трудоустройство.","SQL,Python,Базы данных,Big Data,ML",Remokate,
16659,79002008,Аналитик/Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Взаимодействие с пользователями и контрагентами Агентства, разработчиками систем в части сбора бизнес требований. Анализ и оптимизация процессов взаимодействия Оказание консультационных услуг в области бухгалтерского, управленческого учета и отчетности Разработка конечных решений, формирование технических спецификаций на модернизацию существующей, разработку дополнительной функциональности Разработка технических заданий и постановка задач разработчикам Разработка и ведение пользовательской и проектной документации Взаимодействие с пользователями и контрагентами Агентства, разработчиками систем в части сбора бизнес требований. Разработка конечных решений, формирование технических спецификаций на модернизацию существующей, разработку дополнительной функциональности Требования: Понимание терминологии, понятийного аппарата и бизнес-процессов, связанных c бухгалтерским учетом, кредитным конвейером, управлением кредитными рисками и кредитным портфелем, а также процессов обслуживания физических лиц, связанных формированием продуктов и услуг для физических лиц (кредитование, пластиковые карты, депозиты) Знания нормативных документов ЦБ, регламентирующих деятельность Банков в части корпоративного и розничного бизнеса Знание типов межсистемных коммуникаций, понимание принципов построения баз данных Знание теории языков программирования/навыки программирования Профильное техническое образование в сфере Т (или подтвержденный опыт работы в Т) Опыт составления технической документации Знанием ER нотаций Уверенные знания SQL Условия: оформление в соответствии с ТК РФ, наличие ДМС, возможность участия в корпоративных образовательных программах по различным направлениям деятельности график работы: 5/2 с 9.00 до 18.00 офис в центре Москвы (м.Белорусская) заработная плата по результатам собеседования",,Государственная корпорация Агентство по страхованию вкладов,"Москва, Белорусская, 5-я улица Ямского Поля, 5с1"
16660,79120228,Data Scientist (NLP),з/п не указана,1–3 года,"Полная занятость,полный день","Мы работаем в корпоративно-инвестиционном блоке, который отвечает за работу с бизнесом. Наша команда занимается обработкой естественного языка и извлечением знаний из неструктурированных источников. Мы делаем решения для бизнеса и помогаем коллегам, работающим с клиентами. Среди наших решений есть как внутренние, так и те, которые мы выводим на внешний рынок. Команда распределена между Москвой и Санкт-Петербургом и сейчас мы ищем Middle/Senior Data Scientist в Санкт-Петербург. В поиске Middle/Senior Data Scientist команды, который обладает опытом в NLP, будет курировать младших сотрудников и проводить code-review, владеет advanced технологиями, а также готов предлагать новые идеи, проверять гипотезы и внедрять новые подходы в работу. У нашей команды наработан большой практический опыт, так что на каждом этапе пути у вас будут опытные коллеги, которые могут оказать поддержку. В свою очередь, мы ожидаем, что вы внесёте свой вклад в развитие команды и направления. Обязанности Основные задачи: · Текстовая классификация · Тематическое моделирование · Задачи NER, ABSA · Наставничество Требования Что мы ожидаем от кандидатов: · Знание алгоритмов и библиотек ML (стек: pandas, sklearn, numpy, scipy) · Опыт работы с нейросетями (tensorflow / pytorch ) · Знание алгоритмов и опыт работы с NLP · Опыт работы с Git · Знание SQL · Открытость и инициативность, желание развиваться Наш тех стек: · python, pandas, sklearn, numpy, scipy · pytorch, natasha, pymorphy, gensim, bigartm, transformers, BERT, fasttext, Word2Vec · SQL, Spark, Hadoop stack · linux, docker, git Преимуществами будут: · Опыт внедрения ML решений в бизнес процессы (Nexus, Jenkins, CTL) · Опыт работы с Hadoop stack (pyspark) Условия - Фиксированный оклад + годовой бонус - ДМС, страхование от несчастных случаев, социальные гарантии - Митапы DS Community банка и корпоративные мероприятия - Участие в различных конференциях для DS/DE - Корпоративное обучение - Комфортный офис в 5 минутах ходьбы от м.Нарвская - В офисе бесплатный фитнес-зал с душевыми кабинами, настольный теннис, кикер.",,Сбер для экспертов,
16661,79061359,Аналитик данных / Data Analytics,з/п не указана,1–3 года,"Полная занятость,полный день","Компания «ЮрСпектр» является надежным партнером для сотен тысяч пользователей наших корпоративных клиентов, предоставляя уникальную правовую информацию и сервисы по электронному документообороту. Наши продукты: - онлайн-сервис готовых правовых решений ""ilex"" - справочно-правовая система ""КонсультантПлюс"" - сервисы для обмена электронными документами podpis.by и ilex. Накладные. ООО «ЮрСпектр» уже более 23 лет является надежным, ответственным и заботливым работодателем для более 900 сотрудников в разных регионах Беларуси! С нами у Вас будет возможность: - развиваться как профессионал своего дела, с возможностью постоянно наращивать свои знания и получать экспертный опыт - работать в инновационной компании с современными методологиями, инструментами и технологиями - иметь гарантии и уверенность в завтрашнем дне - найти новых коллег-единомышленников!  Присоединяйся к нашей команде в качестве аналитика данных Ваш будущий функционал это: обработка информации, которая поступает от пользователей сервиса ilex (как пользователь осуществляет поиск, какими функциями чаще пользуется, частота открытия документов и т.д.) выдвижение гипотез, проверка и анализ полученных данных, касающиеся поведения пользователей сервиса ilex подготовка аналитических отчетов взаимодействие с различными подразделениями компании в соответствии с их персональными запросами. Что для нас важно: хорошее знание SQL (postgresql) навыки планирования и алгоритмизации опыт работы c BI инструментами (Apache Superset / Google Data Studio / Power BI /Tableau ) хорошее владение Python (pandas, numpy) уверенное знание Excel (в т.ч. сводные таблицы). преимуществом будут: наличие высшего образования в области вычислительной математики, статистики, анализа данных и т.п. опыт работы с финансовыми показателями релевантный опыт работы (Финансовый аналитик, Бизнес аналитик, Data Scientist, Data Engineer, Системный аналитик, Product Analyst, Bi Analyst, маркетолог-аналитик). Мы с радостью готовы предложить Вам: смешанный формат работы: преимущественно удалённая работа +офис по необходимости менторство в период адаптации, мы обучим вас всем необходимым инструментам для работы толерантный подход к ошибкам, если они связаны с проверкой гипотез, поиском новых точек роста и стремлением улучшить работу возможность развиваться как профессионал своего дела, постоянно наращивая свои знания и получать экспертный опыт различные интеграционные мероприятия с ведущими спикерами России и Беларуси офис в центре города, недалеко от ст.м. Молодежная гибкий график (начало рабочего дня с 8 до 10, окончание с 17 до 19, сокращенный на 1 час рабочий день по пятницам) корпоративную социальную политику в соответствии с законодательством (плюс 3 социальных дня в году за счёт компании). Если Вас заинтересовала данная вакансия, присылайте своё резюме, будем рады видеть Вас в нашей команде!","Работа с большим объемом информации,Деловая переписка,Аналитическое мышление,Python,SQL,Tableau,MS Excel",ЮрСпектр,"Минск, Молодежная, Пинская улица, 28А"
16662,78867877,Data scientist / Python разработчик,з/п не указана,1–3 года,"Полная занятость,полный день","Пауэр Тех – IT компания, которая занимается созданием высоконагруженных сервисов в области интернет-рекламы. В настоящее время нашей команде требуется Python разработчик. Тебе предстоит: Работать с базами данных Программировать на Python Работать с API Наши требования: Ключевые навыки: Python, SQL Опыт работы с БД (MongoDB, PosgreSQL, Clickhouse) Знание английского языка, умение выразить и написать свою мысль. Условия: Работа в аккредитованной ит-компании Официальное трудоустройство, оплачиваемый отпуск и больничный Хорошая зарплата, соответствующая твоему профессиональному уровню Комфортный офис в центре города Обеды за счет компании Чай, кофе, печеньки для эффективной работы)","Big Data,Data Analysis,Mathematical Analysis,Python,SQL,Английский язык,PostgreSQL,MongoDB",Пауэр Тех,"Рязань, улица Павлова, 5"
16663,77480809,Data Scientist/ML,з/п не указана,1–3 года,"Полная занятость,полный день","Работа в Agile команде по методологии SAFE занимающейся системой принятия решения по конкретному виду страхования. Команда занимается разработкой и внедрением ML моделей, сложной аналитикой и внедрением на её основе бизнес правил, а так же тарификацией. КЛЮЧЕВЫЕ ЗАДАЧ: Полный цикл построение ML моделей: Сбор и подготовка данных Первичный анализ Обсуждение потенциальных фичей с экспертами предметной области Анализ фичей и фича-инжиниринг Построение различных типов моделей их сравнение Подбор гиппер параметров Презентация результатов заказчику Подготовка к внедрению. Типовые задачи: Построение моделей прогнозирования убытка (Частота/Тяжесть) Построение моделей противодействия мошенничеству Модели динамического ценообразования. Основные используемые типы моделей: GLM Градиентный бустинг (XGBoost, CatBoost) Любые другие типы моделей которые покажут свою эффективность на ретро данных. ДЛЯ НАС ВАЖНО: Стек: MS SQL, Oracle Python (jupyter notebook: Pandas, Statsmodels, Scikit Learn, SciPy) GitLab Apache Airflow Grafana ML Flow. У НАС ЕСТЬ: Работа в крупной и стабильной компании Официальное трудоустройство по ТК РФ Скидки на страховые продукты Гибридный график работы 2/3 (офис + удаленный формат) Офис расположен: г. Москва, ул. Островная д.4 (рядом с офисом собственная, большая, бесплатная парковка) Корпоративный транспорт от ст. м. «Октябрьское поле» и «Кунцевская».","Data Science,Machine Learning,ML","ВСК, САО","Москва, Островная улица, 4"
16664,78778781,Senior Data scientist,от 4 000 USD на руки,3–6 лет,"Полная занятость,полный день","Приглашаем в нашу команду профессионального и амбициозного Senior Data scientist / Аналитика данных. Вам предстоит решать сложные, но очень интересные задачи. Мы - международная финтех компания AMarkets. С 2007 года предоставляем передовые решения для торговли на финансовых рынках для трейдеров и инвесторов во всем мире. Задачи, которые предстоит решать: Сбор, валидация и анализ данных из корпоративных информационных систем Анализ исторических данных Построение алгоритмических математических моделей Разработка и обучение нейронных сетей Анализ и прогноз временных рядов Кластеризация и сегментация клиентской базы Разработка моделей скоринга клиентов Разработка моделей прогнозирования и моделирования сальдо торговых счетов клиентов Разработка моделей прогнозирования и моделирования LT клиентов Разработка моделей прогнозирования и моделирования оттока клиентов Разработка моделей прогнозирования и моделирования LTV Прогнозирование кол-ва обращений в поддержку Прогнозирование и моделирование показателей эффективности клиентской поддержки Выдвижение и проверка гипотез для улучшения ключевых показателей эффективности бизнеса Разработка новых показателей (метрики, KPI). Наши ожидания: Опыт работы в финтех индустрии, брокерских, букмекерских компаниях или игорной индустрии от 3 - х лет Высшее образование (желательно наличие ученой степени) в таких предметных областях, как: математика, финансы или экономика, информатика, физика, инженерия или аналогичные сследовательский склад ума: быть глубоким мыслителем, творческим человеком, настойчивым, умным, инициативным, внимательным к деталям Критическое мышление и способность придумывать нестандартные подходы Сильная рабочая этика Уверенное пользование инструментами BI аналитики Tools: MySQL, Google BigQuery, Python, Hadoop, Git Английский язык: upper -intermediate (B2). Будет плюсом: Сильный послужной список академических достижений (докторская степень, научные публикации, презентации на конференциях, гранты или награды) Знание финансовых рынков. Мы предлагаем: Релокация в Черногорию , г. Подгорица В случае релокации - работа в комфортабельном офисе, переезд и легализация за счет компании Конкурентную заработную плату в зависимости от ваших компетенций и опыта ДМС, программа лояльности для сотрудников Сплоченная команда профессиональных единомышленников Амбициозные и интересные задачи.",,AMarkets,
16665,79114600,Data scientist (коллекшн),з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Осуществляет разработку, внедрение, мониторинг и обновление скоринговых моделей, которые используются во взыскании Осуществляет обеспечение ежедневного расчета всех моделей для их применения в процессе Осуществляет выделение однородных сегментов на основе моделей, с использованием подхода «риск-баланс» и с помощью других факторов для дальнейшей обработки различными инструментами Проводит оценку экономического эффекта от внедрения скоринговых моделей, уровней отсечения сследует возможности повышения эффективности прогнозных моделей Проводит А/Б тестирование новых моделей на части портфеля Проводит анализ эффективности взыскания на всех стадиях/процессах Осуществляет планирование/прогнозирование эффективности взыскания Осуществляет Ad-hock аналитику по направлению взыскания Разрабатывает бизнес-требования/технические задания в IT подразделения Банка (ДРТ, АБЦТ, ДТ и т.д.) и внешним вендорам на изменение стратегии работы по сформированным сегментам. Требования: Уверенное владение SQL, MS Office Навыки работы в одном или нескольких инструментах по анализу данных: R (RStudio), Python, SAS Guide/Miner Опыт разработки и/или мониторинга, валидации моделей по взысканию (Soft, Hard, Self Cure) опыт разработки и/или валидации скоринговых моделей в подразделениях розничных кредитных рисков/взыскание. Условия: Стабильная заработная плата Работа в уютном офисе ул. Люсиновская, д. 27 Корпоративная социальная программа ДМС (включая стоматологические услуги) по факту прохождения испытательного срока Льготные условия кредитования Реферальная программа с возможностью получить вознаграждение до 100 000 руб. за кандидата, трудоустроенного по Вашей рекомендации Внутреннее и внешнее обучение у лучших специалистов Электронная библиотека, включающую более 2000 книг бизнес-литературы Скидки на фитнес и участие в корпоративных спортивных активностях Скидки на посещение игр хоккейного клуба «Ак Барс», бесплатное посещение игр баскетбольного клуба «Уникс».",,Ак Барс Банк,
16666,76939162,Data Scientist (RecSys),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Чем предстоит заниматься: Команда занимается разработкой рекомендательных систем для всех сервисов компании. Сейчас основными задачами являются обновление основных моделей умного поиска недвижимости, персональных подборок и рекомендаций статей. меется пул задач, связанных с персонализацией контента. От вас мы ожидаем: опыт полного цикла решения ML задачи (от 2 лет) хорошее знание Python и SQL владение стандартным DS-стеком и одним из DL-фреймворком (keras/pytorch) понимание основ рекомендательных систем и методов их оценки опыт проведения A/B тестов и понимание теоретических основ базовая математическая (линейная алгебра, теорвер, матстаты, методы оптимизации) и алгоритмическая (алгоритмы, структуры данных) подготовка. Будут плюсом: высшее образование в топ вузе успешный опыт участия в соревнованиях практический опыт запуска рекомендательных систем знания и реализованные NLP/CV проекты опыт работы с docker, airflow, clickhouse опыт написания unit-тестов, разработки архитектуры и code review. Мы предлагаем: работу в аккредитованной IT компании конкурентную заработную плату полис ДМС с первого месяца работы корпоративный университет, онлайн-курсы для повышения квалификации, конференции, митапы фитнес-зал в здании офиса льготную программу ипотеки для сотрудников MacBook (или другой ноутбук на выбор) + дополнительные мониторы и т.д. комфортный офис класса А в 5 минутах от станции метро и МЦК Кутузовская гибкое начало рабочего дня и возможность работать в гибридном или удаленном формате.","Python,SQL,PyTorch,Математическая статистика,Keras",Домклик,"Москва, Кутузовская, Кутузовский проспект, 32к1"
16667,79191791,Middle Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Сейчас мы активно развиваем команду, поэтому открываем набор на вакансию Data Scientist для участия в сложных долгосрочных проектах для западных (США, Германия, Великобритания, Дания) и крупных российских компаний. Основные задачи: Решать задачи классификации, прогнозирования и сегментации. Проводить исследования, искать лучшие способы подготовки данных и более подходящие модели. Автомтизировать полученные решения. Требования: Умение анализировать существующий код и находить в нем места для улучшения. Сильные математические навыки. Уверенное знание Python, SQL и ML-библиотек (pandas, numpy, sklearn, scipy и тд) Умение оценивать сроки разработки модели. Плюсом будет: Опыт работы с облачными хранилищами S3, Snowflake, Redshift или другими. Опыт работы с SageMaker или Dataiku. Опыт работы в фармацевтической области. Знание R. Опыт работы с GitHub, Jira, Confluence. Что мы ожидаем от кандидата: Опыт работы в аналогичной должности от 3 лет Опыт работы на западных проектах - как преимущество Опыт организации работы сотрудников в удаленном режиме Хороший разговорный и письменный английский (Upper Intermediate и выше), так как у нас много иностранных проектов Готовность к большому потоку задач, инициативность Что мы предлагаем: Работу в крупной компании, включенной Минцифры РФ в реестр аккредитованных IT-компаний (отсрочка от армии, Т-ипотека) нтересные Российские и международные проекты Высокую белую и ежегодно индексируемую заработную плату Оформление по ТК, 100% оплату больничного и отпуска Добровольное медицинское страхование (ДМС) со стоматологией и международная страховка зучение английского языка и English Speaking Club Демократичный подход к дресс-коду и процессам, гибкое начало рабочего дня Техника для комфортной работы из дома Еженедельные семинары, участие в конференциях и митапах, оплачиваемые сертификационные экзамены гры, зажигательные тимбилдинги, масштабные корпоративные мероприятия, выезды на природу","Python,SQL,Английский язык,MS SQL",WaveAccess,
16668,78056289,Data Scientist CV,з/п не указана,3–6 лет,"Полная занятость,полный день","Sber AI - это RnD-подразделение, в котором мы создаем продукты на базе искусственного интеллекта и внедряем их в бизнес. У нас очень много изобретений и работы, мы рады расширению команды. Что делать: улучшать/исправлять модели в продакшене (в основном это CV, но бывает и NLP) создавать новые модели собирать данные и настраивать разметку новых датасетов, файнтюнить наши большие модельки заниматься MLOps Необходимые знания: sklern, numpy, keras, tensorflow, pytorch python (C/C++ будет плюсом) docker, kuber, kafka, sql/nosql db Условия: Возможности саморазвития: оплата поездок на конференции, прохождение курсов, спортзал. Выгодная ипотека для каждого сотрудника и льготные условия кредитования Бесплатная подписка СберПрайм+ Скидки на продукты компаний-партнеров: Okko, Сбер Маркет, Delivery Club, Самокат, Сбер Еаптека и другие ДМС с первого дня и льготное страхование для близких корпоративная пенсионная программа Курсы для будущих родителей, материальная поддержка и тематическое сообщество для молодых мам Детский отдых и подарки за счет Компании Обучение за счет Компании: онлайн курсы в Виртуальной школе Сбера и неограниченный доступ к библиотеке, обучение в Корпоративном университете, тренинги, митапы и возможность получить новую квалификацию Реферальная программа для сотрудников: можно пригласить в команду знакомых профессионалов и получить вознаграждение до 100 тыс. рублей Скидки на отдых в лучшем в мире курортном комплексе «Mriya Resort & SPA» в Ялте.",,Сбер. IT,
16669,78762450,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","МТС Финтех – одно из ключевых направлений развития Группы МТС. Мы развиваем цифровые финансовые продукты и сервисы на стыке банкинга и телекома. Основа МТС Финтех – МТС Банк – стабильный цифровой банк с фокусом на мобильное приложение и финансовые сервисы нового поколения. Наша команда занимается управлением модельным риском и мы ищем специалиста Data Scienсe. Чем предстоит заниматься: Работой с большими данными для поиска выявления закономерностей, особенностей и отклонений Участвовать в разработке и построении математической модели посредством используемых языков программирования (например, Python) Участвовать в выполнении разовых аналитических задач, направленных на выявление возможности оптимизации и изменение логики анализируемых процессов Постановкой через ПО Jira задач для Отдела риск-технологий Управления развития инфраструктуры розничных рисков Департамента развития инфраструктуры розничных рисков и поддержки бизнес процессов Блока розничных рисков (далее по тексту – «Отдел риск-технологий») Созданием документации по логике работы процесса разработки математических моделей, паспорта модели, а также необходимых правил и условий для мониторинга Участием в тестировании изменений, вносимых в процесс принятия решения по кредитным заявкам при внедрении новой математической модели, а также при выводе модели из эксплуатации с Отделом риск-технологий Что мы ждем от кандидата: Практическую работу с профессиональными базами и/или хранилищами данных, SQL-программирование Владение любым языком программирования (Python, Go, Scala) Опыт решения задач классификации и детектирования/сегментации, понимание метрик эффективности машинного обучения Опыт построения моделей прогнозирования потерь Знания в области прикладной статистики, математики, эконометрики Опыт подготовки презентаций для руководства уровня начальника управления Опыт постановки, контроля выполнения и тестирования задач в ПО Jira, ПО Gitlab, Airflow Что мы предлагаем: В МТС Финтех тебя ждет культура творчества и экспериментов: мы всегда ищем новые решения, задаем тренды и не боимся быть не похожими. А еще: Работа в современной надежной цифровой компании Достойная заработная плата Аgile-культура: продуктовые команды, Scrum и Kanban, демо-дни, внутренние митапы и таунхоллы Доступ к корпоративной библиотеке Alpinа, корпоративный университет МТС и программы развития Отсутствие дресс-кода, гибкий формат работы Комфортный и стильный офис в двух минутах от м. Технопарк Корпоративное кафе «Мечта» и отличный кофе на первом этаже БЦ Специальный тариф на мобильную связь для тебя и близких и предложения от партнеров банка и МТС ДМС со стоматологией с первого дня На всякий случай в офисе работает врач, а для желающих мы периодически организуем вакцинацию – это удобно Мы за спорт: вместе тренируемся в MTS Fintech Run Club, в офисе есть бесплатный тренажерный зал. Ты можешь присоединиться к корпоративным спортивным командам и занятиям йогой Поддержка сотрудников: программа материальной помощи в различных жизненных ситуациях","Python,SQL,Математическая статистика,Atlassian Jira,DS,Data Scientist,Математическое моделирование,система принятия решения,Go,SCALA,машинное обучение,модель прогнозирования потерь",МТС Банк,"Москва, проспект Андропова, 18к1"
16670,77982614,Data scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Самостоятельная разработка моделей МЛ для максимизации прибыли по продуктам П/МСБ (одобрения, отклик от предоодбрения, чувствительность к ставке) Разработка онлайн процессов для предодобреных продуктов П/МСБ) Парсинг внешних источников, графы связей Выстраивание новых гипотез, обогащение данных с внешних источников Мониторинг качества внедренных алгоритмов, скоринговых моделей. Требования: Высшее математическое / техническое образование Опыт разработки/внедрения/ мониторинга моделей машинного обучения Обязательное знание алгоритмов машинного обучения Знание кредитного конвейера, ценообразования продуктов Технологический стек: SQL, Python, Lightbm, docker, kubernetes, airflow. Условия: Ежеквартальные премии Корпоративные предложения по фитнесу Корпоративные скидки на онлайн обучение в Skyeng для вас и ваших близких Бесплатная подписка на онлайн библитеку «Альпина Паблишер» Приятная рабочая атмосфера в современном офисе в деловой части города Возможность строить карьеру в одном из крупнейших банков Казахстана.",,Jusan Bank,
16671,79098508,Data Scientist (Research Scientist),з/п не указана,1–3 года,"Полная занятость,полный день","We are a highly performing research team at Sber. Our goal is to implement cutting edge technologies into risk management processes. We work with such data as graphs, click-streams, transactions, geo-data, etc. We are looking for a researcher to develop the most advanced AI technologies for risk management. Key responsibilities: Conduct, direct, and coordinate all phases of research projects, demonstrating skill in all stages of the research process: • Define key research questions, work with multiple information sources • Review research papers, algorithms, models, and code, and evaluate their applicability to the problem at hand • Formulate research plan, experiment methodology and design • Create proof-of-concept implementations of new models and techniques, carry out experiments • Interpret and communicate results, including to non-technical stakeholders • Contribute to internal research community by producing publications. Our expectations: • Research-based BSc/MSc in Computer Science, Statistics, Mathematics or related quantitative field • 1+ years of academic or industrial research experience, including reviewing research papers • Excellent programming skills in Python, PyTorch, including implementation of research algorithms • Excellent knowledge of Probability and Statistics, Linear Algebra • Ability to convey rigorous mathematical concepts and considerations to non-technical stakeholders • Good knowledge of modern neural networks: Transformer, GPT, etc • Publications at NeurIPS, ICML, ICLR or similar are preferred. We offer: • Excellent IT architecture • Comfortable office • NVIDIA HGX • Continuous learning and development • DS community.","Data Mining,Python,Анализ данных,Английский — C1 — Продвинутый",Сбер. Data Science,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
16672,78331454,Data Scientist (middle),з/п не указана,3–6 лет,"Полная занятость,полный день","НОЦ ""Технологии искусственного интеллекта"" МГТУ им. Баумана приглашает на работу Data Scientist (middle). Ваши задачи: Решение бизнес-задач с помощью анализа данных и машинного обучения. Разработка моделей поиска связей, поиска аномалий и прочих операций. Построение моделей прогнозирования, классификации, регрессии, кластеризации. Полная поддержка моделей: от написания запроса для выгрузки обучающей выборки из хранилищ данных до анализа результатов A/B-экспериментов и переключения всех пользователей на новый функционал. Проведение разведочного анализа данных. Создание контекстно-рекомендательных систем. Построение предиктивных Data Driven сервисов. Работа с временными рядами, NLP, видеоинформацией, анализом естественного языка и неструктурированным текстом. Распознавание и извлечение сущностей из документов для автоматизации рутинных операций и классификации документов. Построение AutoML решений для максимального быстрого прототипирования. Мы ожидаем от Вас: Высшее техническое образование в области Т, повышение квалификации в области Data Science. Опыт работы от 3 лет. Понимание архитектуры и принципов разработки приложений. Опыт проектирования решений. Уверенные знания в области построения алгоритмов ML и AI, понимание типов данных. Навыки быстрого и качественного написания прототипов моделей  Навыки преобразования датасетов. Аналитические способности и логическое мышление Технологический стек: Владение Python и основными ML-библиотеками (numpy, pandas, sklearn и т.п.) RAD Studio, Visual Studio, Qt, PyCharm, Jupyter. 4Postgresql, hase - хранение данных Sklearn, tensorflow, sparkML (DL) - для ML, DL, RL Приветствуется: Знание MLOps, опыт работы с NLP задачами. Опыт работы с kafka, hadoop, spark, Flask, Docker. Знание языков Python, С, С++ и/или С#. SQL Понимание принципов работы на отечественном и зарубежном «железе». Мы предлагаем Вам: Работа в стабильной аккредитованной российской IT-компании. Амбициозные и интересные задачи с достойным вознаграждением. Возможность профессионального и карьерного роста. Возможность публиковаться в международных журналах за счет МГТУ. Оформление по ТК РФ. График работы: 5/2 (офис). Удобный офис в пешей доступности от станции метро Бауманская. Заработная плата обсуждается по результатам собеседования. Мы лояльны и не обременены бюрократией, так что твоя инициатива всегда в тему.","Python,NLP,ML,Numpy,Pandas,Machine Learning,Data Science,Tensorflow,Sklearn,DL,RL,SQL,CV",Композиты России,"Москва, Бауманская, Арбатско-Покровская линия"
16673,68148229,Data Scientist (SberDevices),з/п не указана,1–3 года,"Полная занятость,полный день","SberDevices - инновационное направление компании, которое создает умные устройства, виртуальные ассистенты и другие продукты в области Speech Recognition, NLP, Computer Vision. Команда речевых технологий ищет ML/DL Engineer. У нас сильная и очень драйвовая команда (ex-:yandex:, выпускники МФТ, МГУ, ВШЭ, ШАД), и мы создаем технологическую платформу: занимаемся созданием и развитием голосовых технологий (ASR, TTS, Keyword Spotting, Emotion Recognition). В последние годы эта область развивается быстрыми темпами, и мы активно следим и внедряем лучшие решения в наши продукты. Что предстоит делать: Keyword Spotting Задачи: исследование и разработка моделей распознавания ключевых слов детекция рекламы, многоступенчатые модели kws фильтрация и обработка речевых данных для обучения внедрение моделей в production ASR Задачи: разработка и внедрение в продакшн моделей машинного обучения для распознавания речи работа с данными, построение языковых моделей смежные задачи: endpoint detection, speaker separation, on-device ASR и т.д. Обязанности: исследование и разработка моделей распознавания ключевых слов фильтрация и обработка речевых данных для обучения внедрение моделей в production Требования: глубокое понимание нейросетевых архитектур (CNN, RNN, Transformer, MobileNet) умение быстро разобрать статью с arxiv опыт работы с deep learning фреймворками (Tensorflow, PyTorch) уверенное владение Python, Git, Linux опыт использования библиотек для анализа данных (numpy, matplotlib) хорошее знание классических алгоритмов и структур данных Будет плюсом: знание C++, CUDA (для ASR) опыт внедрения моделей на мобильные устройства опыт работы с моделями распознавания речи базовое понимание цифровой обработки сигналов Условия: Самые инновационные, амбициозные проекты и задачи Профессиональное обучение, семинары, тренинги, конференции, корпоративная библиотека ДМС, страхование жизни Свободный дресс-код Гибкий график для оптимального баланса работы и личной жизни Льготные кредиты и корпоративные скидки Конкурентная компенсация (оклад и премии по результатам деятельности).","PyTorch,Tensorflow,Python,Deep Learning,NLP",Сбер. IT,"Москва, Кутузовская, Кутузовский проспект, 32"
16674,78618131,Специалист по машинному обучению и анализу данных / Data Scientist (Middle),з/п не указана,1–3 года,"Полная занятость,полный день","Марс в поиске Специалиста по машинному обучению и анализу данных / Data Scientist в центральную команду монетизации данных бизнес-сегмента Pet Nutrition. Задачи команды – проверка дата гипотез и разработка дата продуктов для большого количества бизнес функций внутри компании. деальный кандидат умеет работать с большими данными так, чтобы находить возможности для оптимизации продуктов и процессов, а также использовать модели для проверки эффективности различных вариантов действий. Вы будете: Взаимодействовать с заинтересованными сторонами в рамках всей организации, чтобы определить возможности использования данных компании для разработки бизнес-решений и монетизации данных звлекать и анализировать данные из баз данных компаний для оптимизации и улучшения инструментов, процессов и поиска точек роста компании Разрабатывать пользовательские модели данных и алгоритмов для применения к наборам данных Разрабатывать процессы и инструменты для мониторинга и анализа производительности модели и точности данных Представлять результаты моделирования для бизнес-аудитории, включая руководителей организации Реализовывать стратегию управления бизнес-данными и рекомендовать улучшения Проектировать, разрабатывать / рефакторить, разворачивать дата продукты Продвигать в организации использование разработанных внутри дата продуктов с помощью презентаций, документации и совместной работы бизнес функций Разрабатывать инструменты и автоматизировать рабочие процессы Превращать неструктурированные недостатки и болевые точки в конкретные бизнес и технические требования для проверки гипотез или разработки дата продуктов. Мы ожидаем: Ученая степень и соответствующий опыт в области статистики, математики, информатики или смежных областях Уверенное знание SQL, Python, алгоритмов машинного обучения и статистики Подтвержденный опыт создания пайплайнов машинного обучения, работающих в продуктивной среде разработки (обучение, оценка, использование в системах реального времени) Опыт использования облачных платформ (Azure ML, Google Cloud Platform ML, AWS SageMaker, Yandex Cloud Platform) и развертывания аналитики в продуктивной среде Опыт работы со стеком Azure (Data Lake, Database, Data Factory, Data Brick и т. д.) и/или Yandex Cloud (Data Proc, Data Sphere и т. д.) – будет плюсом Опыт визуализации данных с использованием Power BI/ggplot/plotly/ – будет плюсом Высокие навыки коммуникации, решения проблем, стремление к обучению Самостоятельного специалиста, с высокой ответственностью, а также готового преуспевать в развивающейся организации и привносить структуру в неструктурированные ситуации Средний или выше среднего уровень знания английского языка (разговорный и письменный). Мы предлагаем: Конкурентная зарплата, система бонусов, ДМС и страхование жизни с первого рабочего дня Корпоративная пенсионная программа Компенсация питания Оплата мобильной связи Гибкий рабочий график Дополнительный оплачиваемый отпуск при стаже работы от 5 лет Насыщенная образовательная программа, которую формируете вы",Английский — B2 — Средне-продвинутый,Марс,"Москва, Сокол, Ленинградский проспект, 72к1"
16675,79015089,"Data-scientist, ML (удалённо)",от 150 000 руб. на руки,1–3 года,"Частичная занятость,гибкий график","Data-scientist, ML (удалённо, full-/part-time) Привет меня зовут Ранис, я CEO молодого стартапа Vicnis, я бы хотел пригласить к себе в команду на место ML-разработчика, да вообще настощего добряка. Vicnis - это HR-помощник на базе AI (). Он полностью берет на себя процесс устного и письменного собеседования и в конечном итоге предоставляет отчет и все необходимые данные о соискателе, даже составляет полное резюме для соискателя. В команде 8 человек, люди из разных уголков мира: Республика Беларусь, зраиль, Грузия. В сопроводительном письме попрошу скинуть telegramm, мне там проще общаться) Задачи, которые стоят перед нами: Создание продукта с нуля (который перевернет рынок HR) реализовать его до MVP Разработка технической стратегии и планов на реализацию проекта Контроль качества продукта От тебя мы ждем вот что: Опыт работы в разработке NLP-приложений и знание инструментов по обработке естественного языка на Python, таких как SpaCy, NLTK, Gensim и т.д. Понимание основных приемов обработки естественного языка, включая способы извлечения ключевых слов, именованных сущностей, анализ синтаксиса, грамматические модели и обработку структурных данных. Опыт работы с такими инструментами, как Tensorflow, PyTorch, NumPy, Pandas, Jupyter Notebook, понимание системы контроля версий (Git). Базовые знания математической статистики и теории вероятности. Глубокое понимание методов для работы с данными и алгоритмов машинного обучения, таких как классификация, кластеризация, регрессия, обработка последовательностей и т.д. Понимание принципов построения диалоговых систем, в том числе умения разрабатывать и применять техники генерации ответов и распознавания речи. Опыт работы с облачной инфраструктурой. Понимание архитектуры и дизайна диалоговых систем с использованием фреймворка на основе правил и/или машинного обучения. Ответственность, коммуникативные навыки для работы в команде Опыт работы с SQL + Желание развиваться и изучать новые инструменты и технологии для оптимизации работы и улучшения результатов. + Знание мемов:) Условия: Важно, чтобы тебе было комфортно: непринципиально, где ты находишься и во сколько начинаете рабочий день и даже если все делается на дедлайне:), главное – выполненные задачи. Полностью удаленный формат работы, что означает можно пойти на свою любимую кухню и попить чай с любимыми конфетками нтересные задачи и команда, мотивированная на результат Ещё раз попрошу скинуть свой telegramm в сопроводительном письме! ТЫ закладываешь ""семечко"" в формировании инновационных идей в стране, новые интересные кейсы, постоянное обучение чему-то новому, стабильное получение знаний. Буду рад пообщаться с тобой! (c) CEO Ранис Гализянов.","Удаленная работа,Agile,Проектирование с нуля,Грамотно поставленная речь,Спокойствие,Общение,Работа в команде,Умение работать в условиях многозадачности,Проектирование пользовательских интерфейсов,Python,Pandas,ООП,Git,Machine Learning,NLP,Английский — B2 — Средне-продвинутый",Брами Бразерс,"Казань, Козья слобода, Кремлевская, Площадь Тукая, ул. Пушкина, 80"
16676,78961029,Data Scientist,от 160 000 до 180 000 руб. на руки,1–3 года,"Полная занятость,полный день","О компании: Компания Сайберфизикс занимается разработкой системы предиктивной аналитики оборудования и оптимизации технологических процессов на основе комбинации машинного обучения и численного моделирования. Основным продуктом компании является платформа создания моделей, обеспечивающая для пользователя полный цикл no-code разработки - от загрузки данных до production. Кого мы ищем? Талантливого DS вычислительного ядра основного продукта. Вы будет заниматься исследованиями и разработками передовых моделей и алгоритмов в области промышленной диагностики и оптимизации. Что предстоит делать: спользовать методы machine learning для улучшения существующих подходов системы предиктивной аналитики оборудования и оптимизации технологических процессов Анализировать эффективность существующих вычислительных алгоритмов, оценивать внедрения новых Разрабатывать программно-вычислительные модули в составе основного продукта Требования: Хорошая математическая подготовка: теория вероятностей, статистика, методы и алгоритмы machine learning Опыт разработки библиотек на Python Продвинутый уровень владения tensorflow, pandas, numpy, scikit-learn Уметь генерировать гипотезы и проверять их Будет преимуществом: Опыт разработки вычислительных модулей и их взаимодействия между собой Продвинутый уровень знаний ООП Знание принципов многопоточности и многопроцессорности Python Условия: Возможность работать по СЗ и ГПХ Гибкий график, отсутствие обязательного расписания Возможность работать удаленно (либо офис в БЦ Савеловский Сити м. Дмитровская) Предоставление ДМС после испытательного срока Бесплатный чай/кофе/шоколадки/печенье в офисе","Machine Learning,Python,Tensorflow,Pandas,ООП,Numpy",CyberPhysics,"Москва, Дмитровская, Дмитровская, Савёловская, Новодмитровская улица, 2к2"
16677,79093240,"Data scientist (junior/middle), команда разработки портфельных моделей",з/п не указана,1–3 года,"Полная занятость,полный день","В команду, которая занимается разработкой портфельных моделей, ищем коллегу уровня junior+ или middle, с опытом работы в банке. Периметр клиентов для разработки моделей: малый и средний бизнес, КБ, Банки, Суверены, Субъекты, Проектное финансирование, Девелопмент ОБЯЗАННОСТ: участие в разработке симуляционных моделей, построение и сценарный анализ матриц миграции корпоративных клиентов, оценка стрессовых параметров кредитного риска (PD, LGD, EAD) участие в разработке и внедрении моделей прямого и обратного стресс-теста кредитного риска, оценка сценариев, выполнение стресс-тестов и анализ результатов построение моделей оценки экономического капитала под различные виды рисков участие в разработке требований к Т реализации портфельных моделей. Требования: высшее образование (математическое / физико-математическое) фундаментальные знания в области финансовой математики и стохастического анализа, теории вероятностей, математической статистики, алгоритмов машинного обучения и их реализации в среде Python или R желателен опыт от двух лет в стресс-тестировании / стохастическом моделировании / в эконометрическом моделировании владение одним из языков/инструментов анализа данных (предпочтителен Python) и структурированных запросов для работы с данными (T-SQL, Impala, Hive, Spark SQL) опыт работы в области разработки моделей в Банке или консалтинговой компании будет плюсом сертификаты CFA, FRM, PRM будут плюсом. Условия: трудоустройство согласно Законодательству конкурентная заработная плата профессиональное обучение и развитие добровольное медицинское страхование, льготные условия кредитования корпоративная пенсионная программа, материальная помощь спортивная жизнь и корпоративные мероприятия возможность построить карьеру в ведущем банке России.","Python,SQL,Английский язык,Финансовая математика,Стохастический анализ","ПАО ВТБ, Технологический блок","Москва, Выставочная, Филевская линия"
16678,79021402,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","By joining KAZ Minerals as a Data scientists, you will: Solve the most complex and practical tasks of the Metals and Mining industry, the key economy sector of Kazakhstan, with immediate impact on operations. The industry has been accumulating enormous operational data, but lagging behind using these data for an educated decision making based on the power of advanced analytics and artificial intelligence Take part in building a Digital and Analytics arm of the most advanced M&M company in Kazakhstan, creating impact-oriented culture without bureaucracy. KAZ Minerals is aiming to become the most innovative and digitally driven mining companies in Kazakhstan, and have started the development of artificial intelligence solution to optimize its production. The company plans to build the team of best data scientists, who would like to lead this direction Implement advanced analytics solution might require some business trips to the Operations sites in Eastern and Northern parts of Kazakhstan, where you will be working with the experienced international and local miners and metallurgists Job duties: Develop complex models and algorithms that drive innovation throughout the organization. This may include improving on-time performance, network planning, etc. Conduct advanced statistical and other analysis to provide actionable insights, identify trends, and measure performance Provide coaching and insight on analytic approaches and can objectively weigh trade-offs of different analytic methods Guide data engineering efforts to ensure alignment with future data science needs Provide guidance to business leaders and data engineering function highlighting data integrity risks Collaborate with analytics engineers to implement and deploy scalable solutions Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders Skills and qualification requirements: BS/MS in computer science, statistics, economics, mathematics, ops research or related technical discipline 2+ year of experience as a data analyst and/or data scientist Knowledge of machine learning, statistics, optimization, or related field Experience with Python is required Experience with SQL, Pandas, Numpy, SciPy, Scikit-learn, xgboost Experience with BI and visualization tools is a plus Experience in the Metals and Mining industry is a plus Professional attitude and service orientation superb team player Good written and verbal communication skills along with strong desire to work in cross-functional teams","Python,Data Mining,SQL,Machine Learning,Data Science,Numpy",KAZ Minerals Management,
16679,79267342,Data Scientist (команда поиска и рекомендаций по RuStore),з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем специалиста по data science в команду поиска и рекомендаций по RuStore. Благодаря нашему поиску и системе рекомендаций миллионы посетителей находят в магазине приложений то, что им нужно, за пару кликов. Наша команда занимается улучшением качества поиска и рекомендаций. Мы исследуем, как можно применить современные подходы машинного обучения для ранжирования и построения ленты рекомендаций пользователей. Модели и алгоритмы, показавшие наилучшее качество, внедряются в продакшен — здесь нужно и знание С++ для получения наибольшей производительности, и понимание принципов построения высоконагруженных систем. сходные данные и аналитика обрабатывается на кластере с помощью Hadoop (Map-Reduce). спользуемый стек технологий: python, C++, java, pytorch, catboost, hadoop, clickhouse. Задачи: улучшать качество поисковой системы: разрабатывать модели и алгоритмы ранжирования делать рекомендации приложений на основе машинного обучения, в том числе персонализированные контентные рекомендации и текстовая релевантность работа с семантическими нейронными сетями. Требования: владение С++ или python знание классических алгоритмов и структур данных знание базовых алгоритмов машинного обучения опыт работы со стандартным ML-стеком (numpy, sklearn, pandas) и deep learning фреймворками (pytorch/tensorflow) знание и опыт в области современного NLP, в т.ч. знакомство с современными моделями (BERT, GPT) знание видов и подходов к разработке рекомендательных систем. Будет плюсом: опыт работы в интернет-проектах понимание пользовательских метрик качества.","Python,C++,Hadoop,PyTorch,Clickhouse,Machine learning",VK,"Москва, Аэропорт, Ленинградский проспект, 39с79"
16680,76827021,Data Scientist / ML нженер,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Stellar Labs,"Москва, Белорусская, Белорусская, Лесная улица, 43"
16681,78359038,Data Scientist (логистика),от 130 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Обязанности: Работа с большими массивами логистических данных Поиск инсайтов в данных по заданной логике и без неё Разработка системы построения оптимальных маршрутов Расчет статистик по вагонам и контрагентам железнодорожной сети Создание моделей и алгоритмов обработки данных для использования в процессах подразделений Работа с базами данных - обработка, проверка, загрузка, контроль качества (ETL процессы). Требования: Высшее образование в области компьютерных наук, математики, физики Опыт работы в должности data scientist от 2-х лет Готовые кейсы по созданию алгоритмов обработки данных для решения практических задач Знание Python в части дата анализа на уровне Middle (основные библиотеки - pandas,numpy, matplotlib, scipy) Опыт работы с базами данных PostgreSQL, ClickHouse. Условия: Оформление: по ТК РФ, оплачиваемый больничный и отпуск 28 дней в году Заработная плата: оклад 130 000 на руки + KPI График работы: 5/2 с пн. по пт. 09:00 до 18:00 Место работы: современный офис в 10 минутах от метро Парнас Оплата обучения: для улучшения ваших профессиональных навыков за счет компании.",,Северный Путь,
16682,78937901,Junior Data scientist (Аналитик),от 60 000 руб. на руки,не требуется,"Полная занятость,полный день","Zaymigo – это современная FinTech компания на рынке онлайн кредитования. Работаем с 2013 года. У нас более 2 000 000 клиентов. В команде больше 130 человек. Мы создаем сервис, дающий людям простой доступ к деньгам в любой стране. Наша компания имеет гибкий подход к решению задач, реализуем лучшие предложения наших сотрудников, поощряем нестандартный подход к делу. Сейчас находимся в поиске аналитика данных (data scientist). Над какими задачами будем работать: Построение рисковых скоринговых моделей Мониторинг работы моделей и их валидация Анализ рисковой отчетности работы компании и подготовка рекомендаций Участие в проектах внутри команды риск-аналитиков. Мы ждем от Вас: Серьезную математическую подготовку Опыт применения методов статистического анализа и моделирования Опыт работы с алгоритмами машинного обучения Уверенное знание языка Python для анализа больших данных Будут плюсом: навыки владения любым программным обеспечением для статистического анализа данных: SPSS, Statistica, Stata, R и т.п. Опыт работы от полугода в fintech компаниях, банках. Что мы предлагаем: Возможность делать крутые проекты, участвовать во всех этапах деятельности аналитического отдела 8-часовой график работы Проработанный план профессионального развития Посещение отраслевых конференций за счет компании Официальное трудоустройство по ТК РФ Комплектация рабочего места по Вашим запросам Рост ЗП согласно уровню выполняемых задач Молодой, сплоченный коллектив, дружественный микроклимат в отделе Офисный формат работы","Python,Статистический анализ,Прогнозирование,Математическая статистика",Займиго МФК,"Нижний Новгород, Горьковская, Ковровская улица, 21А"
16683,79273001,Data scientist (Middle),з/п не указана,1–3 года,"Полная занятость,полный день","Привет, ищем в нашу команду Middle Data scientist, формат работы: удаленный, гибридный/офисный по Москве О проекте: Персонализация офферов для клиентской базы в рамках CVM (Customer Value Management) Предсказание потребления, конверсии, выручки, построение look-alike по целевым сегментам Участие в дизайне, подготовке и анализе АБ тестов для прилотирования моделей Какие задачи необходимо решать: Разработка моделей машинного обучения на больших данных Feature-engineering, аналитика данных для поиска инсайтов по профилю клиента Настройка Data Quality и Model Quality для ML моделей нтерпретация и презентация результатов работы разработанных моделей Для решения этих задач требуется: Высшее образование Знания в области математики, теории вероятности, мат. статистики (высшее образование, наличие ученой степени будет дополнительным плюсом) Знание алгоритмов машинного обучения, принципов их работы, ключевых особенностей и ограничений Знание инструментов анализа данных, библиотек машинного обучения Python, PySpark. Опыт работы с Airflow, MLflow будет плюсом Опыт работы в области Data Science от 2х лет",,"МегаФон, IT","Москва, Маяковская, Новослободская, Чеховская, Оружейный переулок, 41"
16684,79054184,Data Scientist (NLP),з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Анализ тональности отзывов клиентов Классификация обращений как внешних клиентов, так и сотрудников Анализ текстов и документов (например, сравнение договоров). Требования: Высшее образование в области компьютерных наук, физики, математики или статистики Опыт работы в должности Data Scientist от 2-х лет Хорошие знания в области нейронных сетей, основных нейроархитектур для работы с текстом Практический опыт разработки моделей обработки текстов Отличное знание Python Опыт работы с основными DS-библиотеками для работы с данными: pandas, NumPy, Matplotlib, Seaborn Опыт работы с NLP-библиотеками: pymorphy2, spaCy, NLTK, fastText Опыт работы с DL-фреймворками: TensorFlow, Keras, PyTorch Хорошее знание T-SQL. Условия: Бесценный опыт работы над интересными проектами в сильной команде экспертов. Достойный уровень заработной платы, официальное оформление в аккредитованной Т-компании, социальные гарантии. Комфортные условия: гибкий график работы (удаленно/гибрид/офис), свободный дресс-код. Наши современные офисы расположены в центрах города СПб, Москве, Владимире, Омске, в которых есть зоны отдыха с кикером, настольными играми и игровыми приставками. ДМС + Программа «Кафетерий льгот»: сотрудники за счет компании могут компенсировать расходы на страхование, обучение, спорт, спортивный инвентарь Развитие и обучение: оплата внешних тренингов, семинаров и конференций, корпоративная библиотека.","NLP,Machine Learning,Python,PyTorch,Tensorflow,Keras",БиАйЭй-Технолоджиз,"Санкт-Петербург, Фрунзенская, Московский проспект, 94"
16685,79100996,Chief Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы делаем Т для ритейла реального времени. Наши Т-продукты автоматизируют разное: закупки, логистику, работу дарксторов, сборку и доставку заказа до двери, управление промокампаниями и остальные этапы большого процесса. спользуем интеллектуальные системы прогнозирования, а разные этапы выполнения заказа автоматизируем роботическими системами. Наши ключевые направления: Быстрая доставка, Маркетплейс, Логистика. Наша цель — сделать все необходимые Т-инструменты и инфраструктуру, чтобы все нужные товары могли попадать домой к людям мгновенно (насколько это возможно в физическом мире). Для эффективной работы сервисов мы активно используем модели машинного обучения, число которых измеряется десятками (ценообразование, прогноз спроса, рекомендации). Каждая из моделей вносит существенный вклад в развитие бизнеса, разрабатывает их команда, каждый участник которой влияет на продукт напрямую. Сейчас мы ищем Chief Data Scientist в команду Samokat.tech, который сплотит и возглавит несколько data science-команд и в партнерстве с продуктовой вертикалью будет работать над развитием и поддержкой сервисов. Чем предстоит заниматься Найм и контроль объема компетенций в DS командах, работающих с продуктовой вертикалью. Вопросы обучения, развития, использования инструментария DS. Контроль качества и эффективности работы DS команд. Разработка стратегии развития блока DS команд, работающих с продуктовой вертикалью. Взаимодействие с другими продуктовыми вертикалями в разрезе DS (в т.ч. с целью переиспользования алгоритмов). Помощь во взаимодействии с корпоративной и DS-инфраструктурой Работа с DS-метриками: составление дерева DS-метрик, сопоставление с бизнес метриками. Учет общей стратегии развития бизнеса и продуктов при приоритезации backlog'ов команд Главные требования опыт руководства командами в области ML и DS от 10 человек опыт внедрения корпоративных моделей данных, развития инструментов и систем для работы с данными развитые навыки коммуникации, способность быстро погружаться в специфику бизнеса структурное мышление и умение излагать свои мысли опыт работы в электронной коммерции будет плюсом. Что мы используем в проектах разработка: Python, GitLab, Docker, Kubernetes, AirFlow данные: Hadoop, PostgreSQL, Kafka отчеты и мониторинги: Prometheus, Grafana задачи: Jira, Confluence Мы предлагаем Все классические условия с запасом Samokat.tech – аккредитованная IT-компания, поэтому: белая зарплата и ДМС, возможность работать удалённо или ходить в офис в Москве, Санкт-Петербурге или Твери. Т-сообщество Развиваем комьюнити по функциональным направлениям, проводим внутренние митапы. Участвуем во внешних конференциях – ходим послушать, рассказать о своём опыте и пообщаться. Делаем собственное внешнее мероприятие Samokat Tech Meetup. Помогаем нашим ребятам делиться опытом друг с другом и с внешним сообществом: готовим доклады, пишем статьи, публикуем опенсорс, дружим с экспертами и соседями по индустрии.  Атмосфера Дни рождения команд, неформальные встречи, English-клуб и много другого — чтобы развиваться, отдыхать и жить чуть-чуть интереснее.",Английский — A1 — Начальный,Самокат (ООО Умное пространство),
16686,79281445,Middle Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Корпоративно-инвестиционный блок отвечает за работу с юридическими лицами и индивидуальными предпринимателями от микробизнеса до крупнейшего. Ключевым направлением является развитие продуктов экосистемы и банковские услуги (кредиты, РКО, депозиты и т.д.), а также аналитические услуги и юридическое сопровождение бизнеса. Наше подразделение занимается разработкой рекомендательных моделей по продуктам Торгового финансирования по разным сегментам клиентов, а также работой с колл-центрами, разбросанными по нескольким городам (транскрибации), и CV-задачами (распознавание документов, автоматическая сверка, поиск ошибок/неточностей). Основная задача - рост продаж продуктов торгового финансирования во всех сегментах корпоративных клиентов Сбербанка, а также физических лиц. Обязанности Построение, поддержка и развитие рекомендательных систем по продуктам торгового финансирования (аккредитивы, эскроу) Глубокая продуктовая/клиентская аналитика и использование ее в моделях (кластеризации, сегментации, поиск новых фичей и пр.) Максимальное погружение в контекст задачи\систему продаж. 90% успеха состоит в понимании процесса, контекста и задачи, а не в подборе гиперпараметров модели Оптимизация бизнес процессов с использованием инструментов Process mining Требования Отличное понимание классического ML, опыт и знание основных необходимых библиотек (catboost, lightgbm, pandas, etc.) Уверенное знание SQL, умение строить сложные запросы Отличная математическая подготовка. Способность прочитать статью и имплементировать, например, кастомную лосс-функцию в модель Jupyter, pycharm, git, jira, conflience Плюсом будет Опыт работы со Spark/Hadoop (Pyspark) Практический опыт DL Понимание банковской специфики и финансов. Например, что такое финансовая отчетность компаний Условия Офис на метро Кутузовкая, прекрасная панорама Москвы с 23 этажа башни, спортзал Адекватные боссы, много адекватных людей вокруг Существенный годовой бонус ДМС с первого дня работы Безлимитный кофе/чай, печеньки Гибкое начало дня (с 8 до 11)","ML,Python,SQL",Сбер. Data Science,
16687,76934468,Data scientist / Аналитик данных,з/п не указана,1–3 года,"Полная занятость,полный день","Мы – Цифровая платформа КАМАЗ, продуктовая IT компания. Наш профиль – это грузовые и пассажирские перевозки. Обеспечиваем телеметрию и развиваем умную логистику. Мы ищем: Data scientist на проект Микротранзит – общественный транспорт с умной моделью построения маршрута, персонализированные перевозки по требованию в крупных городах России.  У нас вам предстоит работать над нашим собственным сервисом «Челнок» по улучшению городской инфраструктуры. Это абсолютно новый способ в России передвижения по городу, гибрид общественного транспорта и такси. У нас динамические маршруты: развозим пассажиров, которым «по пути» уже в трёх городах (Москва, Набережные Челны, Красногорск) и нновационном центре «Сколково». Наш сервис обрабатывает запросы от мобильных приложений пассажира и водителя, строит маршруты, связывает пассажиров и автобусы, а также позволяет диспетчерам мониторить состояние автопарка. Нашей команде приходится справляться с высокой нагрузкой, а также решать по-настоящему нестандартные задачи. Ссылка на мобильное приложение «Челнок»: https://app.mt.dpkapp.ru/go Вам предстоит: 80 % времени работать с данными из разных источников Отрабатывать гипотезы Обучать ML модели Решать оптимизационные задачи в транспорте и не только Реализовывать продакшн решения на базе ваших обученных моделей Наш стек: ClickHouse, PostgreSQL, HDFS MlFlow, AirFlow GitLab, Kubernetes, Docker Python Необходимые скиллы: SQL на уровне среднего запроса сложности (выгрузки, агрегации) Знать принципы работы алгоритмов машинного обучения (линейные модели, деревянные модели и ансамбли основанные на деревянных, нейронные сети и др.) Любить теорию вероятности и математическую статистику Писать понятный и воспроизводимый код Представлять данные в виде понятных сводных таблиц/графиков (гистограммы, тепловые карты, зависимости) Формулировать и проверять на данных статистические гипотезы Быть внимательным к физике данных, чтобы делать правильные Sanity Check результаты и выводить корректные выводы У нас: Официальное трудоустройство Работа в центре Санкт-Петербурга, Малая Конюшенная улица дом 1-3 Гибридный формат работы, гибкое начало и конец рабочего дня Выдаем ноутбуки: MacBook, Lenovo ThinkPad Компенсации спорта и курсов иностранного языка, обучение за счет компании Атмосфера той самой идеальной команды!","ClickHouse,SQL,Python,Статистика",KAMAZ DIGITAL,"Санкт-Петербург, Малая Конюшенная улица, 1-3"
16688,78149683,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","В отдел по работе с данными ритейла требуется Data Scientist. Мы ищем не просто коллегу, который будет заниматься реализацией проектов, но и единомышленника! Вакансия открыта в г. Нижний Новгород, полностью удаленного формата работы нет.  Что нужно будет делать? Планировать и проводить исследования данных Распределять задачи в группе Визуализировать и презентовать результаты исследований Строить пайплайны обработки данных Оценивать корректность ML моделей Составлять и реализовывать алгоритмы. Что для этого нужно? Высшее высшее математическое/техническое образование Уверенное знание Python Знание библиотек NumPy, pandas, matplotlib, sklearn Хорошее знание алгоритмов и структур данных Понимание принципов обучения ML-моделей Знание SQL, GIT Умение реализовывать переиспользуемые решения. Что предлагаем? Возможность развить свои навыки анализа и обработки данных на реальных проектах в команде опытных аналитиков и датасаентистов Возможность освоить методы data science Гибридный формат работы (офис Нижнего Новгорода).","Python,SQL,MS PowerPoint,Статистический анализ,ML,Data Science",Моризо Диджитал,"Нижний Новгород, Горьковская, Алексеевская улица, 6/16"
16690,79281445,Middle Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Корпоративно-инвестиционный блок отвечает за работу с юридическими лицами и индивидуальными предпринимателями от микробизнеса до крупнейшего. Ключевым направлением является развитие продуктов экосистемы и банковские услуги (кредиты, РКО, депозиты и т.д.), а также аналитические услуги и юридическое сопровождение бизнеса. Наше подразделение занимается разработкой рекомендательных моделей по продуктам Торгового финансирования по разным сегментам клиентов, а также работой с колл-центрами, разбросанными по нескольким городам (транскрибации), и CV-задачами (распознавание документов, автоматическая сверка, поиск ошибок/неточностей). Основная задача - рост продаж продуктов торгового финансирования во всех сегментах корпоративных клиентов Сбербанка, а также физических лиц. Обязанности Построение, поддержка и развитие рекомендательных систем по продуктам торгового финансирования (аккредитивы, эскроу) Глубокая продуктовая/клиентская аналитика и использование ее в моделях (кластеризации, сегментации, поиск новых фичей и пр.) Максимальное погружение в контекст задачи\систему продаж. 90% успеха состоит в понимании процесса, контекста и задачи, а не в подборе гиперпараметров модели Оптимизация бизнес процессов с использованием инструментов Process mining Требования Отличное понимание классического ML, опыт и знание основных необходимых библиотек (catboost, lightgbm, pandas, etc.) Уверенное знание SQL, умение строить сложные запросы Отличная математическая подготовка. Способность прочитать статью и имплементировать, например, кастомную лосс-функцию в модель Jupyter, pycharm, git, jira, conflience Плюсом будет Опыт работы со Spark/Hadoop (Pyspark) Практический опыт DL Понимание банковской специфики и финансов. Например, что такое финансовая отчетность компаний Условия Офис на метро Кутузовкая, прекрасная панорама Москвы с 23 этажа башни, спортзал Адекватные боссы, много адекватных людей вокруг Существенный годовой бонус ДМС с первого дня работы Безлимитный кофе/чай, печеньки Гибкое начало дня (с 8 до 11)","ML,Python,SQL",Сбер. Data Science,
16691,79028437,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Прямо сейчас мы ищем Data Scientist`a. Аналитический центр - это сердце корпорации, ведь именно с его помощью мы принимаем решения по развитию бизнеса. Вот чем нужно будет заниматься: Подготовка витрин для моделей машинного обучения Разработка моделей машинного обучения на табличных данных Разработка и улучшение моделей STT, работа с текстом (NLP модели) (как преимущество) Расчёт бизнес-value разработанных моделей. Опыт и навыки, которые необходимы для выполнения задач: Знание Python, умение писать поддерживаемый код Знание основных ML-библиотек (catboost, lightgbm, xgboost, prophet, лин регрессия, k-means, DBSCAN) SQL на экспертном уровне (умение оптимизировать запросы) Хорошее знание мат. статистики и теории вероятности. Будет очень здорово, если имеешь опыт работы с: GIT, BASH, Airflow, Docker. Что мы готовы предложить: Работа над уникальными проектами с лидерами сегмента Возможности профессионального роста и развития в динамично развивающейся компании Возможность бесплатного посещения бизнес-мероприятий Корпорации Корпоративные скидки на любые образовательные программы Синергии до 100% Собственная столовая с вкусной и здоровой пищей, корпоративное кафе Офис в шаговой доступности от м. Сокол График работы: 5/2 с 9.00 до 18.00, или с 10.00. до 19.00.","Python,SQL,NLP,Data Analysis,Bash,Теория вероятностей,Математическая статистика,XGBoost",СНЕРГЯ,
16692,79273001,Data scientist (Middle),з/п не указана,1–3 года,"Полная занятость,полный день","Привет, ищем в нашу команду Middle Data scientist, формат работы: удаленный, гибридный/офисный по Москве О проекте: Персонализация офферов для клиентской базы в рамках CVM (Customer Value Management) Предсказание потребления, конверсии, выручки, построение look-alike по целевым сегментам Участие в дизайне, подготовке и анализе АБ тестов для прилотирования моделей Какие задачи необходимо решать: Разработка моделей машинного обучения на больших данных Feature-engineering, аналитика данных для поиска инсайтов по профилю клиента Настройка Data Quality и Model Quality для ML моделей нтерпретация и презентация результатов работы разработанных моделей Для решения этих задач требуется: Высшее образование Знания в области математики, теории вероятности, мат. статистики (высшее образование, наличие ученой степени будет дополнительным плюсом) Знание алгоритмов машинного обучения, принципов их работы, ключевых особенностей и ограничений Знание инструментов анализа данных, библиотек машинного обучения Python, PySpark. Опыт работы с Airflow, MLflow будет плюсом Опыт работы в области Data Science от 2х лет",,"МегаФон, IT","Москва, Маяковская, Новослободская, Чеховская, Оружейный переулок, 41"
16693,79177142,"Data Scientist (Gurobi, Cplex, SCIP, CBC)",з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Разработка моделей планирования цепочек поставок, производства и тд. Разработка моделей системы поддержки принятия стратегических решений. Требования: Опыт разработки моделей оптимизации с помощью MIP, MINLP (Gurobi, Cplex, SCIP, CBC), мета-эвристик Реализация собственных эвристик и написание callback-ов для солверов Опыт оптимизации расчетного движка под конкретную задачу Высшее математическое образование. Условия: Бесценный опыт работы над интересными проектами в сильной команде экспертов Достойный уровень заработной платы, официальное оформление в аккредитованной Т-компании, социальные гарантии Офисный формат работы ДМС + Программа «Кафетерий льгот»: сотрудники за счет компании могут компенсировать расходы на страхование, обучение, спорт, спортивный инвентарь Развитие и обучение: оплата внешних тренингов, семинаров и конференций, корпоративная библиотека.","Python,Gurob,Cplex,CBC,SCIP",БиАйЭй-Технолоджиз,
16694,79057338,Chief Data Scientist,з/п не указана,более 6 лет,"Полная занятость,полный день","Сегодня Сбер ищет chief data scientist в блок «Транзакционный бизнес B2C». Основными задачами CDS станут поиск потенциала применения искусственного интеллекта в бизнесе, формирование и развитие команды DS, разработка и запуск  решений в продуктах банка, которыми ежедневно пользуются десятки миллионов человек, совершающих сотни миллионов операций. Основные задачи: Анализ актуальных задач и процессов в бизнес-командах, помощь в поиске потенциальных точек приложения искусственного интеллекта Запуск и ведение проектов по внедрению  решений Повышение операционной эффективность бизнеса за счет ML Формирование и развитие DS/MLops экспертизы в подразделении Проведение мероприятий для бизнес-команд и руководителей по новым возможностям  Представление проектов на внутренних и внешних мероприятиях в качестве спикера Наши ожидания от кандидата: Широкий кругозор в области классического и глубокого машинного обучения Знакомство с сиcтемами обработки больших данных (Spark, Greenplum) Опыт работы в руководящие роли в области больших данных Опыт управления в проектах внедрения платформ и корпоративных моделей данных, внедрения инструментов/систем для работы с данными Опыт формирования команд и управления техническими специалистами Опыт совместной работы в рамках кросс-функциональных команд, с участием топ-менеджеров Плюсом – опыт организации взаимодействия с научным сообществом и/или ведение собственной исследовательской деятельности Плюсом – навыки публичных выступлений и/или проведения обучающих программ. Условия: Уникальные масштабные проекты, работа в приоритетном направлении Достойная заработная плата (оклад + годовая премии) Современные рабочие места и программное обеспечение потека выгоднее для каждого сотрудника и льготные условия кредитования Бесплатная подписка СберПрайм+ Скидки на продукты компаний-партнеров: Okko, Сбер Маркет, Delivery Club, Самокат, Сбер Еаптека и другие ДМС с первого дня и льготное страхование для близких Корпоративная пенсионная программа Обучение за счет Компании: онлайн курсы в Виртуальной школе Сбера и неограниченный доступ к библиотеке, обучение в Корпоративном университете, тренинги, митапы и возможность получить новую квалификацию Реферальная программа для сотрудников: можно пригласить в команду знакомых профессионалов и получить вознаграждение до 100 тыс. рублей Скидки на отдых в лучшем в мире курортном комплексе Mriya Resort & SPA Возможность принять участие в других крупных и уникальных проектах банка. Доступ к уникальным технологическим ресурсам банка, в том числе, суперкомпьютеру Christofari.",,Сбер. Data Science,
16695,78331454,Data Scientist (middle),з/п не указана,3–6 лет,"Полная занятость,полный день","НОЦ ""Технологии искусственного интеллекта"" МГТУ им. Баумана приглашает на работу Data Scientist (middle). Ваши задачи: Решение бизнес-задач с помощью анализа данных и машинного обучения. Разработка моделей поиска связей, поиска аномалий и прочих операций. Построение моделей прогнозирования, классификации, регрессии, кластеризации. Полная поддержка моделей: от написания запроса для выгрузки обучающей выборки из хранилищ данных до анализа результатов A/B-экспериментов и переключения всех пользователей на новый функционал. Проведение разведочного анализа данных. Создание контекстно-рекомендательных систем. Построение предиктивных Data Driven сервисов. Работа с временными рядами, NLP, видеоинформацией, анализом естественного языка и неструктурированным текстом. Распознавание и извлечение сущностей из документов для автоматизации рутинных операций и классификации документов. Построение AutoML решений для максимального быстрого прототипирования. Мы ожидаем от Вас: Высшее техническое образование в области Т, повышение квалификации в области Data Science. Опыт работы от 3 лет. Понимание архитектуры и принципов разработки приложений. Опыт проектирования решений. Уверенные знания в области построения алгоритмов ML и AI, понимание типов данных. Навыки быстрого и качественного написания прототипов моделей  Навыки преобразования датасетов. Аналитические способности и логическое мышление Технологический стек: Владение Python и основными ML-библиотеками (numpy, pandas, sklearn и т.п.) RAD Studio, Visual Studio, Qt, PyCharm, Jupyter. 4Postgresql, hase - хранение данных Sklearn, tensorflow, sparkML (DL) - для ML, DL, RL Приветствуется: Знание MLOps, опыт работы с NLP задачами. Опыт работы с kafka, hadoop, spark, Flask, Docker. Знание языков Python, С, С++ и/или С#. SQL Понимание принципов работы на отечественном и зарубежном «железе». Мы предлагаем Вам: Работа в стабильной аккредитованной российской IT-компании. Амбициозные и интересные задачи с достойным вознаграждением. Возможность профессионального и карьерного роста. Возможность публиковаться в международных журналах за счет МГТУ. Оформление по ТК РФ. График работы: 5/2 (офис). Удобный офис в пешей доступности от станции метро Бауманская. Заработная плата обсуждается по результатам собеседования. Мы лояльны и не обременены бюрократией, так что твоя инициатива всегда в тему.","Python,NLP,ML,Numpy,Pandas,Machine Learning,Data Science,Tensorflow,Sklearn,DL,RL,SQL,CV",Композиты России,"Москва, Бауманская, Арбатско-Покровская линия"
16696,78596130,Data scientist Middle,з/п не указана,3–6 лет,"Полная занятость,полный день","так, тебе предстоит: Находить и реализовывать решения ряда задач в области компьютерного зрения в медицине Помогать врачам в подготовке датасетов Обучать модели и проводить оценку их качества Заниматься усовершенствованием пайплайнов, оптимизацией моделей и внедрением в продуктив. Мы будем рады рассмотреть твою кандидатуру, если у тебя есть: Успешный профессиональный опыт решения задач по компьютерному зрению не менее 1 года Математический бэкграунд, знание основ машинного обучения и компьютерного зрения Опыт построения моделей с помощью фреймворка pytorch Опыт использования OpenCV Любовь к Python, ООП и структурам данных Хорошие отношения с ОС Linux, Git, Docker. Плюсом будет: Знание классических алгоритмов компьютерного зрения Знание классических архитектур object detection, semantic segmentation Опыт использования MLFlow.",,"билайн: Т, Data, Digital",
16697,76934468,Data scientist / Аналитик данных,з/п не указана,1–3 года,"Полная занятость,полный день","Мы – Цифровая платформа КАМАЗ, продуктовая IT компания. Наш профиль – это грузовые и пассажирские перевозки. Обеспечиваем телеметрию и развиваем умную логистику. Мы ищем: Data scientist на проект Микротранзит – общественный транспорт с умной моделью построения маршрута, персонализированные перевозки по требованию в крупных городах России.  У нас вам предстоит работать над нашим собственным сервисом «Челнок» по улучшению городской инфраструктуры. Это абсолютно новый способ в России передвижения по городу, гибрид общественного транспорта и такси. У нас динамические маршруты: развозим пассажиров, которым «по пути» уже в трёх городах (Москва, Набережные Челны, Красногорск) и нновационном центре «Сколково». Наш сервис обрабатывает запросы от мобильных приложений пассажира и водителя, строит маршруты, связывает пассажиров и автобусы, а также позволяет диспетчерам мониторить состояние автопарка. Нашей команде приходится справляться с высокой нагрузкой, а также решать по-настоящему нестандартные задачи. Ссылка на мобильное приложение «Челнок»: https://app.mt.dpkapp.ru/go Вам предстоит: 80 % времени работать с данными из разных источников Отрабатывать гипотезы Обучать ML модели Решать оптимизационные задачи в транспорте и не только Реализовывать продакшн решения на базе ваших обученных моделей Наш стек: ClickHouse, PostgreSQL, HDFS MlFlow, AirFlow GitLab, Kubernetes, Docker Python Необходимые скиллы: SQL на уровне среднего запроса сложности (выгрузки, агрегации) Знать принципы работы алгоритмов машинного обучения (линейные модели, деревянные модели и ансамбли основанные на деревянных, нейронные сети и др.) Любить теорию вероятности и математическую статистику Писать понятный и воспроизводимый код Представлять данные в виде понятных сводных таблиц/графиков (гистограммы, тепловые карты, зависимости) Формулировать и проверять на данных статистические гипотезы Быть внимательным к физике данных, чтобы делать правильные Sanity Check результаты и выводить корректные выводы У нас: Официальное трудоустройство Работа в центре Санкт-Петербурга, Малая Конюшенная улица дом 1-3 Гибридный формат работы, гибкое начало и конец рабочего дня Выдаем ноутбуки: MacBook, Lenovo ThinkPad Компенсации спорта и курсов иностранного языка, обучение за счет компании Атмосфера той самой идеальной команды!","ClickHouse,SQL,Python,Статистика",KAMAZ DIGITAL,"Санкт-Петербург, Малая Конюшенная улица, 1-3"
16698,76827021,Data Scientist / ML нженер,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Stellar Labs,"Москва, Белорусская, Белорусская, Лесная улица, 43"
16699,79093240,"Data scientist (junior/middle), команда разработки портфельных моделей",з/п не указана,1–3 года,"Полная занятость,полный день","В команду, которая занимается разработкой портфельных моделей, ищем коллегу уровня junior+ или middle, с опытом работы в банке. Периметр клиентов для разработки моделей: малый и средний бизнес, КБ, Банки, Суверены, Субъекты, Проектное финансирование, Девелопмент ОБЯЗАННОСТ: участие в разработке симуляционных моделей, построение и сценарный анализ матриц миграции корпоративных клиентов, оценка стрессовых параметров кредитного риска (PD, LGD, EAD) участие в разработке и внедрении моделей прямого и обратного стресс-теста кредитного риска, оценка сценариев, выполнение стресс-тестов и анализ результатов построение моделей оценки экономического капитала под различные виды рисков участие в разработке требований к Т реализации портфельных моделей. Требования: высшее образование (математическое / физико-математическое) фундаментальные знания в области финансовой математики и стохастического анализа, теории вероятностей, математической статистики, алгоритмов машинного обучения и их реализации в среде Python или R желателен опыт от двух лет в стресс-тестировании / стохастическом моделировании / в эконометрическом моделировании владение одним из языков/инструментов анализа данных (предпочтителен Python) и структурированных запросов для работы с данными (T-SQL, Impala, Hive, Spark SQL) опыт работы в области разработки моделей в Банке или консалтинговой компании будет плюсом сертификаты CFA, FRM, PRM будут плюсом. Условия: трудоустройство согласно Законодательству конкурентная заработная плата профессиональное обучение и развитие добровольное медицинское страхование, льготные условия кредитования корпоративная пенсионная программа, материальная помощь спортивная жизнь и корпоративные мероприятия возможность построить карьеру в ведущем банке России.","Python,SQL,Английский язык,Финансовая математика,Стохастический анализ","ПАО ВТБ, Технологический блок","Москва, Выставочная, Филевская линия"
16700,75981474,Data scientist (RecSys),з/п не указана,1–3 года,"Полная занятость,удаленная работа","В связи с расширением команды Data science проекта ""Персонализация"", ищем middle/senior специалиста на позицию Data Scientist в продукт ""Рекомендательная система"". Вам предстоит принимать участие в полном цикле разработки алгоритмов: от проверки гипотез и создания прототипов до написания кода, который будет использоваться в production. Какие задачи мы решаем? Разрабатываем data-driven алгоритмы для обеспечения персонализированного взаимодействия с пользователями в наших цифровых продуктах Как правило, алгоритмы представляют собой микс из rule-based эвристик на статистических метриках и ML моделей Примеры наших задач: Составление персональных рекомендаций Формирование персональных сортировок товарной выдачи и баннерных слайдеров Выделение сегментов из клиентской базы Стек технологий: Для разработки используем: Python, Spark, SQL Oracle, Hive/Impala Для организации работы: Jira, Confluence, Git Мы ждём от наших будущих коллег: Высшее техническое образование Аналитический подход к решению задач, желание самостоятельно генерировать идеи Уверенное владение SQL: сложные запросы, аналитические функции Уверенное владение Python (библиотеки работы с данными) Опыт использования и внедрения алгоритмов машинного обучения будет преимуществом",,"Компания «СПОРТМАСТЕР», Sportmaster Lab",
16701,78618131,Специалист по машинному обучению и анализу данных / Data Scientist (Middle),з/п не указана,1–3 года,"Полная занятость,полный день","Марс в поиске Специалиста по машинному обучению и анализу данных / Data Scientist в центральную команду монетизации данных бизнес-сегмента Pet Nutrition. Задачи команды – проверка дата гипотез и разработка дата продуктов для большого количества бизнес функций внутри компании. деальный кандидат умеет работать с большими данными так, чтобы находить возможности для оптимизации продуктов и процессов, а также использовать модели для проверки эффективности различных вариантов действий. Вы будете: Взаимодействовать с заинтересованными сторонами в рамках всей организации, чтобы определить возможности использования данных компании для разработки бизнес-решений и монетизации данных звлекать и анализировать данные из баз данных компаний для оптимизации и улучшения инструментов, процессов и поиска точек роста компании Разрабатывать пользовательские модели данных и алгоритмов для применения к наборам данных Разрабатывать процессы и инструменты для мониторинга и анализа производительности модели и точности данных Представлять результаты моделирования для бизнес-аудитории, включая руководителей организации Реализовывать стратегию управления бизнес-данными и рекомендовать улучшения Проектировать, разрабатывать / рефакторить, разворачивать дата продукты Продвигать в организации использование разработанных внутри дата продуктов с помощью презентаций, документации и совместной работы бизнес функций Разрабатывать инструменты и автоматизировать рабочие процессы Превращать неструктурированные недостатки и болевые точки в конкретные бизнес и технические требования для проверки гипотез или разработки дата продуктов. Мы ожидаем: Ученая степень и соответствующий опыт в области статистики, математики, информатики или смежных областях Уверенное знание SQL, Python, алгоритмов машинного обучения и статистики Подтвержденный опыт создания пайплайнов машинного обучения, работающих в продуктивной среде разработки (обучение, оценка, использование в системах реального времени) Опыт использования облачных платформ (Azure ML, Google Cloud Platform ML, AWS SageMaker, Yandex Cloud Platform) и развертывания аналитики в продуктивной среде Опыт работы со стеком Azure (Data Lake, Database, Data Factory, Data Brick и т. д.) и/или Yandex Cloud (Data Proc, Data Sphere и т. д.) – будет плюсом Опыт визуализации данных с использованием Power BI/ggplot/plotly/ – будет плюсом Высокие навыки коммуникации, решения проблем, стремление к обучению Самостоятельного специалиста, с высокой ответственностью, а также готового преуспевать в развивающейся организации и привносить структуру в неструктурированные ситуации Средний или выше среднего уровень знания английского языка (разговорный и письменный). Мы предлагаем: Конкурентная зарплата, система бонусов, ДМС и страхование жизни с первого рабочего дня Корпоративная пенсионная программа Компенсация питания Оплата мобильной связи Гибкий рабочий график Дополнительный оплачиваемый отпуск при стаже работы от 5 лет Насыщенная образовательная программа, которую формируете вы",Английский — B2 — Средне-продвинутый,Марс,"Москва, Сокол, Ленинградский проспект, 72к1"
16702,54829296,Data scientist (Персонализация),з/п не указана,1–3 года,"Полная занятость,удаленная работа","В компанию требуется специалист на позицию Data Scientist в Департамент управления данными. Вам предстоит решение широкого спектра задач по автоматизации построения моделей машинного обучения: от получения и преобразования данных до мониторинга эффективности моделей и построения визуализаций. В данный момент активно внедряем машинное обучение для рекомендательных систем поиска по каталогу интернет-магазина Спортмастер, а также для оптимизации рекламных кампаний. Чем вам предстоит заниматься: спользовать алгоритмы машинного обучения для решения бизнес-задач сследовать данные с целью получения новых признаков клиентов Разрабатывать требования для сбора данных, дизайн A/B тестов Заниматься написанием эффективного кода для получения агрегатов данных клиентов Развивать инфраструктуру для автоматического построения и использования моделей машинного обучения Стек технологий: Для разработки используем: Python, Spark, Oracle, Airflow, Superset, Docker Для организации работы: Jira, Confluence, Git Мы ждём от наших будущих коллег: Опыт использования и внедрения алгоритмов машинного обучения Знание базовых алгоритмов и структур данных, понимание плюсов и минусов Уверенное знание математической статистики, умение применять для решения задач Уверенное знание SQL и готовность писать эффективные запросы Уверенное владение Python (библиотеки работы с данными) Технический английский на уровне чтения статей и участия в конференциях Наши преимущества: Возможность использовать выбранные инструменты для решения задач (у нас нет ограничений по стеку) Конкурентная заработная плата по результатам собеседования Возможность предлагать и реализовывать свои идеи Возможность работать с мощным железом: NVidia DGX-2, Oracle Exadata, кластеры Hadoop/Spark",,"Компания «СПОРТМАСТЕР», Sportmaster Lab",
16703,67054541,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы, Группа анализа данных, занимаемся разработкой моделей и алгоритмов машинного обучения в первую очередь для направлений Производства и Качества, а также внедряем ML в другие сферы компании. Сейчас в команде 7 специалистов (Data Scientist, ML Engineer, Business Analyst). Мы расширяем команду и ищем еще одного специалиста уровня middle+/senior. Подробнее о том, что мы делаем: Создаем цифровой двойник биореактора и рассказываем об этом на Highload++ Выявляем аномалии в time-series (отказ датчиков, нестандартные режимы работы и т.п.) Проводим explorative-анализ данных, делаем пилоты для решения задач заказчиков с помощью ML, статистики, CV Пишем понятный и поддерживаемый код, делаем качественные, воспроизводимые пайплайны обучения моделей Брейнштормим и генерируем идеи всей командой. Наш стэк: Python, Airflow, MLFlow, Git, MongoDB, PostgreSQL. О том как мы собираем данные для экспериментов: habr.com/ru/company/biocad/blog/586124/. О том, как мы подружили биореакторы и ML: highload.ru/spb/2022/abstracts/9112. Тебе предстоит: Погружаться в предметные области, работать с заказчиками Выполнять исследовательские задачи, искать причинно-следственные связи Проявлять инициативу, предлагать собственные гипотезы Создавать осмысленные модели Участвовать в разработке архитектуры ML сервисов Документировать и презентовать результаты работы. Требования: Знание классических методов ML Наличие практических достижений в области ML Знание статистики и умение ее применять Опыт вывода ML решений в prod Уверенный Python, Git Желание разбираться в предметной области, работать с заказчиками. Будет плюсом: Знакомство ETL (Airflow, NiFi) или готовность разбираться в нем MLFlow Умение работать с Docker контейнерами Terminal (Linux) Условия: Работа в динамично развивающейся инновационной биотехнологической компании полного цикла Достойный уровень оплаты труда, годовое премирование, официальное оформление по ТК РФ Комфортные условия: можно работать удаленно или в современном стильном офисе у м. Гостиный двор, сокращенный рабочий день в пятницу Экспертная команда, возможность самостоятельного построения процессов и глубокого погружения в бизнес, высокий темп работы и возможность применять современные технологии и инструменты Забота о сотрудниках: ДМС со стоматологией после испытательного срока, внутренняя программа поддержки здоровья и благополучия сотрудников B-WELL, программы помощи сотрудникам в трудных жизненных ситуациях программа корпоративных скидок Best Benefits (спорт, отдых, рестораны, обучение и не только) Широкий спектр для обучения и развития: у нас есть внутренний корпоративный университет, корпоративная онлайн-библиотека Alpina Digital, внешние обучения и конференции, возможность обучения английскому языку в формате софинансирования возможность участия в волонтерских программах.",,"БОКАД, биотехнологическая компания","Санкт-Петербург, тальянская улица, 17"
16705,79191723,Middle Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Сейчас мы активно развиваем команду, поэтому открываем набор на вакансию Data Scientist для участия в сложных долгосрочных проектах для западных (США, Германия, Великобритания, Дания) и крупных российских компаний. Основные задачи: Решать задачи классификации, прогнозирования и сегментации. Проводить исследования, искать лучшие способы подготовки данных и более подходящие модели. Автоматизировать полученные решения. Требования: Умение анализировать существующий код и находить в нем места для улучшения. Сильные математические навыки. Уверенное знание Python, SQL и ML-библиотек (pandas, numpy, sklearn, scipy и тд) Умение оценивать сроки разработки модели. Плюсом будет: Опыт работы с облачными хранилищами S3, Snowflake, Redshift или другими. Опыт работы с SageMaker или Dataiku. Опыт работы в фармацевтической области. Знание R. Опыт работы с GitHub, Jira, Confluence. Что мы ожидаем от кандидата: Опыт работы в аналогичной должности от 3 лет Опыт работы на западных проектах - как преимущество Опыт организации работы сотрудников в удаленном режиме Хороший разговорный и письменный английский (Upper Intermediate и выше), так как у нас много иностранных проектов Готовность к большому потоку задач, инициативность Что мы предлагаем: Работу в крупной компании, включенной Минцифры РФ в реестр аккредитованных IT-компаний (отсрочка от армии, Т-ипотека) нтересные Российские и международные проекты Высокую белую и ежегодно индексируемую заработную плату Оформление по ТК, 100% оплату больничного и отпуска Добровольное медицинское страхование (ДМС) со стоматологией и международная страховка зучение английского языка и English Speaking Club Демократичный подход к дресс-коду и процессам, гибкое начало рабочего дня Техника для комфортной работы из дома Еженедельные семинары, участие в конференциях и митапах, оплачиваемые сертификационные экзамены гры, зажигательные тимбилдинги, масштабные корпоративные мероприятия, выезды на природу","Python,SQL,Английский язык,MS SQL",WaveAccess,
16706,75857475,Data Scientist (Платформа рекомендаций),з/п не указана,1–3 года,"Полная занятость,полный день","Работа в команде платформы рекомендательных систем — создаём продукты для пользователей SberDevices.  Что нужно делать: участвовать в разработке/проверке гипотез вместе с руководителем проекта и бизнес-заказчиком, интерпретировать результаты и оценивать качество разработанных моделей разрабатывать модели машинного обучения промышленного уровня исследовать данные из множества источников с целью формулирования гипотез создавать клиентские сегменты с использованием ML вести техническую команду и ставить задачи DE, DA и DS  Мы ожидаем, что вы: знаете теоретическую базу и имеете опыт в построении RecSys имеете практические опыт вывода ML-моделей в продакшн (от 5 лет) умеете интерпретировать бизнес задачи в технические имеете опыт организации A/B экспериментов  Почему вам понравится работать с нами: задачи, находящиеся на острие инноваций команда отзывчивых профи и гуру, которые всегда помогут фидбек и возможность увидеть результаты своей работы в продукте своя digital-платформа для развития ключевых IT-компетенций, внутренние и внешние конференции и проф. сообщества Сбера много корпоративных плюшек: расширенная программа ДМС (возможность подключения родственников), страхование жизни, специальные условия по кредитам/ипотеке, скидки от компаний-партнёров знаменитый офис на Кутузовском проспекте с парковкой, спортзалом, массажными креслами и возможностью выбора формата работы (офис, гибрид или удалёнка) атмосфера стартапа и надёжность гиганта.","ML,Python,A/B тесты,RecSys",Сбер. IT,"Москва, Кутузовская, Кутузовский проспект, 32"
16707,77181469,Data scientist / Аналитик риск-моделей,от 120 000 до 300 000 руб. на руки,1–3 года,"Полная занятость,полный день","Webbankir - российская финтех компания, маркетплейс финансовых продуктов и услуг в сегментах B2B и B2C. Мы ищем кандидата на должность Data scientist / Аналитик риск-моделей. Обязанности: Построение вероятностных скоринговых моделей Анализ имеющихся и новых источников данных и эффективное использование их для процесса принятия решений Мониторинг и калибровка имеющихся моделей, их обновление и развитие Анализ эффективности моделей и оперативное управление их применением Построение моделей текущей и будущей доходности, моделей взаимодействия с клиентом Участие в разработке и управлении лимитной и тарифной политиками Компании Анализ рисков по кредитным продуктам Подготовка, проведение и анализ результатов тестов Развитие процессов принятия кредитного решения и не только. Требования: Высшее математическое или техническое образование (предпочтительно: МГУ, МФТ, МФТ, МГТУ им. Баумана) Опыт построения моделей от 2-х лет Аналитический склад ума и умение концентрироваться на одной задаче и доводить дело до конца Хорошее знания теории вероятностей и математической статистики Опыт работы с SQL, SAS, Python, Zeppelin, другими системами/языками создания моделей Опыт взаимодействия с бизнесом и построение моделей решающих бизнес задачи Условия: Современный, просторный офис в Бизнес-парке ""GreenWood"" (ст. м. ""Сходненская"") Удобная транспортная доступность (на территории бизнес-центра есть большой паркинг) График работы: 5/2, гибрид (удалёнка/офис) Оформление на работу по Трудовому законодательству РФ (оплачиваемые отпуск, больничный) Достойная белая заработная плата Возможность карьерного роста Дружный коллектив, лояльное руководство Традиционные корпоративные мероприятия, ежемесячные денежные конкурсы, дни рождения сотрудников в приятной компании.","Python,SQL,Sas,Анализ данных,Математическая статистика",МФК ВЭББАНКР,"Москва, Сходненская, МКАД, 69-й километр, внешняя сторона, к1"
16708,78976610,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Вакансия с релокацией на Кипр после испытательного срока! Наш клиент - международная компания, которая разрабатывает надежные и актуальные IT-решения для b2c и b2b сегмента находится в поисках Data-scientist: Чем предстоит заниматься: Применение алгоритмов машинного обучения для создания прогностических моделей, определение оптимальных параметров модели и оценка их производительности. сследование и выявление закономерностей, трендов и зависимостей в данных с использованием статистических методов и визуализаций. Проведение работы с различными источниками данных, обработка пропущенных значений, удаление выбросов и преобразование данных для последующего анализа. Подготовка и представление результатов анализа и моделирования для коллег и руководства, включая разработку документации, демонстраций и презентаций. Мониторинг и оптимизация моделей: Отслеживание и анализ производительности развернутых моделей машинного обучения и их оптимизация на основе полученных результатов. Участие в разработке стратегий и подходов к управлению данными, включая вопросы конфиденциальности, безопасности и качества данных. Требования: Опыт работы с библиотеками для анализа данных и машинного обучения: NumPy, pandas, sklearn, scipy, matplotlib, TensorFlow или PyTorch. Английский язык - не ниже В2 Понимание проведения A/B тестирования. Понимание классических методов и алгоритмов машинного обучения, опыт их применения на практике. Базовые знания SQL запросов. Опыт прикладной разработки на Python будет являться большим плюсом. Условия: Белую заработную плату на уровне Ваших профессиональных навыков и пожеланий Помощь с релокацией на Кипр г. Лимассол (авиабилеты, трансфер, визовое сопровождение за счет компании) Офисный формат работы, бесплатные обеды нтересные задачи, перспективные проекты, продвинутые технологии Работу в русскоязычной команде.",,Employcity,
16709,76145682,Middle Data Scientist (команда перспективных алгоритмов машинного обучения),з/п не указана,3–6 лет,"Полная занятость,полный день","ОБЯЗАННОСТ: разрабатывать модели машинного обучения построение моделей на основе временных рядов построение моделей на графах построение look-alike моделей задачи по работе с текстом, табличными данными, графами связанности ТРЕБОВАНЯ: высшее математическое или техническое образование знания основ теории алгоритмов, теории вероятностей, математического анализа, математической статистики опыт в области CV не менее 1 года. понимание архитектур сверточных и рекуррентных нейросетей опыт обучения (дообучения) нейросетей/трансформеров для решения узких задач, понимание требуемых мощностей и временных затрат, затрат на подготовку данных навыки работы с Python, PyTorch, Pandas, Numpy, OpenCV приветствуются опыт использования HuggingFace, MxNet навыки работы с Git и с Conda окружениями знания основ SQL приветствуются знакомство со Spark хорошие коммуникационные навыки для эффективного взаимодействия в команде. УСЛОВЯ: трудоустройство согласно Законодательству конкурентная заработная плата профессиональное обучение и развитие добровольное медицинское страхование, льготные условия кредитования корпоративная пенсионная программа, материальная помощь спортивная жизнь и корпоративные мероприятия возможность построить карьеру в ведущем банке России.","Python,Spark,Hadoop,Hive,ML,SQL,DL,Pytorch","ПАО ВТБ, Технологический блок",
16710,70903553,Data Scientist (сопровождение процесса разработки и использования моделей),з/п не указана,1–3 года,"Полная занятость,полный день","Наша команда контроля и управления моделями является владельцем и заказчиком всех моделей оценки розничного кредитного риска банка. Мы участвуем во всех этапах создания и применения модели: постановка задачи, сопровождение разработки с командой DE, приемка результатов, оценка калибровок и уровней отсечения, мониторинг корректной работы модели. Непосредственной разработкой моделей занимаются наши коллеги из департамента моделирования, внедрением – владельцы системы. За все остальные этапы жизненного цикла модели отвечаем мы. Сейчас мы находимся в поиске коллеги, имеющего опыт в розничном риск-менеджменте, в разработке или мониторинге скоринговых моделей. ОБЯЗАННОСТ: участие в процессе управления разработкой новых и модификацией существующих моделей количественной оценки кредитного риска, включая: постановку задачи, предварительный анализ сегмента и параметров, передачу и уточнение требований, приемку результатов, согласование и подготовку материалов для утверждения использования моделей участие в расчете значений фактических и прогнозных риск-показателей участие в расчете (оценке) экономического эффекта от внедрения скоринговых моделей, уровней отсечения контроль корректности работы скоринговых моделей, участие (в рамках полномочий) в процессе мониторинга и валидации моделей исследование возможностей повышения эффективности прогнозных моделей участие в разработке и согласовании функциональных требований и технических заданий по доработке информационных систем Банка в части применения моделей для принятия кредитных решений и управления кредитным риском розничного портфеля. ТРЕБОВАНЯ: высшее образование (экономическое, техническое, математическое) опыт разработки и/или валидации скоринговых моделей розничного (не корпоративного!) сегмента. Подходит опыт в разных направлениях (маркетинг, коллекшен), но именно опыт в оценке кредитного риска розничного сегмента (модели PD, LGD, EAD для целей принятий кредитных решений, ПВР или МСФО9) является существенным преимуществом уверенное владение SQL, MS Office навыки работы в одном или нескольких инструментах по анализу данных: R (RStudio), Python, SAS Guide/Miner знание основ математической статистики, навык применения знаний математической статистики и теории вероятностей на практике при разработке моделей умение делать экономические выводы на основании статистического анализа, интерпретировать результаты и давать рекомендации опыт разработки и/или мониторинга, валидации моделей оценки кредитного риска розничного сегмента является преимуществом опыт работы в коммерческом банке (предпочтительно в розничных рисках) приветствуется понимание специфики процесса розничного кредитования хорошее понимание интерпретируемых методов моделирования: линейные и логистические регрессии, деревья решений (преимущества, недостатки и ограничения этих методов). УСЛОВЯ: трудоустройство согласно Законодательству конкурентная заработная плата профессиональное обучение и развитие добровольное медицинское страхование, льготные условия кредитования корпоративная пенсионная программа, материальная помощь спортивная жизнь и корпоративные мероприятия возможность построить карьеру в ведущем банке России.","Оценка рисков,MS PowerPoint,Статистический анализ,Управление рисками,Математическое моделирование,PD, LGD, EAD,SQL,Портфельные риски,кредитные риски","ПАО ВТБ, Подразделения Поддержки и Контроля",
16711,69379894,нженер / Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","НПКЦ диагностики и телемедицины («Радиология Москвы»), – государственная компания с более чем 20-летним опытом работы в здравоохранении. Наш Центр - ведущая экспертная организация по развитию и повышению эффективности службы лучевой и инструментальной диагностики в России. Обязанности: Проведение тестирований сервисов на основе технологий искусственного интеллекта (-Сервисов). Подготовка протоколов тестирования. Создание программного кода в соответствии с техническим заданием (готовыми спецификациями). Оптимизация программного кода с использованием специализированных программных средств. Оценка и согласование сроков выполнения поставленных задач. Аналитика результатов работы -Сервисов. Подготовка отчетных и демонстрационных материалов по проведенным разработкам Требования: Опыт работы frontend разработчиком (средний или базовый уровень) Опыт создания пользовательских интерфейсов Высшее образование (предпочтительные направления - медицинская техника, медицинская кибернетика, биофизика, медицинская физика, инженерное дело), ученая степень будет преимуществом Базовые навыки программирования (Python) Работа с медицинскими данными (принципы получения данных радиологических исследований, формат DICOM) Ведение и составление технической и отчетной документации Мы ценим: Стремление достигать результата Желание постоянно развиваться Готовность к динамичным изменениям скренность и открытость Умение работать в команде Навыки самоорганизации. Мы предлагаем: Официальное трудоустройство График 5/2 с 9.00 до 17.30, сб и вс выходные Годовая премия, белая зарплата! Выплаты 2 раза в месяц Возможность прохождения дополнительного образования по направлению от центра! Участие в амбициозных проектах в масштабах отрасли и страны Сопричастность к решению «сверхзадач» в системе здравоохранения Наставничество и поддержка в развитии на международном уровне Возможность развиваться опережающими темпами, участвуя в программах обучения Стать частью яркой профессиональной команды Дружный коллектив молодых и талантливых специалистов Карьерный рост.","Медицинское оборудование,Написание научный статей,Научная деятельность,Научные исследования",ГБУЗ «Научно-практический клинический центр диагностики и телемедицинских технологий ДЗМ»,"Москва, улица Петровка, 24"
16712,79222399,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Wildberries - это крупнейший маркетплейс Европы, 30 млн пользователей и масштабные технологические задачи. IT-штат компании состоит из 2 0000 самых разных специалистов, чьи таланты позволяют закрывать все бизнес-потребности и тем самым обеспечивать клиентоориентированный e-commerce сервис. Команда Антифрод-решений занимается поиском/анализом пользовательской информации на предмет возможных мошеннических/аномальных действий на маркетплейсе. Основная цель - вычленить негативные сущности (пользователей, поставщиков, изображения) и одним из методов обезвредить их. Есть своя инфраструктура, где хранятся и обрабатываются данные, решения доставляются в тест и продакшен. Стек: Python, Clickhouse, Kafka, NATS, Redis, Docker, K8S, Prometheus/Grafana/Redash. Сердце всех проектов – большой кластер ClickHouse, который используется для сохранения всей инфраструктуры. В данный момент есть задачи в направлении CV - поиск на изображениях ""негативной"" информации. Для развития системы и её усиления команда в поисках опытного DS-специалиста. Необходимый опыт и навыки: навыки разработки на Python опыт enterprise разработки CV-решений знание SQL опыт работы с Kubernetes, ClickHouse Будет плюсом опыт работы в антифрод-проектах (возможно, банковская сфера). Задачи: улучшать текущую систему антифрода, а конкретно - определять по фото, что в карточке товара представлены запрещённые вещества и неприемлемый контент участвовать в развитии системы для разметки данных, быть 'заказчиком' в рамках антифрод системы по фото. Что мы предлагаем: гибкое начало рабочего дня и гибридный формат работы: от офиса в Москве до удаленки из любой точки мира вариативность оформления: трудовой договор, самозанятость, П или ГПХ ДМС после 3-х месяцев испытательного срока: телемедицина, очные приемы, ежегодный чек-ап для сотрудника, а также онлайн-консультации для родственников корпоративные скидки у партнеров, внешние программы по обучению и внутренние митапы ежегодная 40%-ая скидка на покупку ноутбука или мобильного телефона.",,WILDBERRIES,"Москва, Парк культуры, Парк культуры, Фрунзенская, улица Тимура Фрунзе, 11с1"
16713,76536709,Data Scientist (LTV),з/п не указана,3–6 лет,"Полная занятость,полный день","Продуктовая команда департамента клиентской аналитики в поисках опытного Data Scientist для решения задач моделирования LTV абонентов и внедрение данной концепции в бизнес-процессы компании. Основные задачи: Решение бизнес-задач с помощью анализа данных и машинного обучения Статистический анализ и обработка данных Построение и валидация моделей машинного обучения Дизайн и проведение А/B-экспериментов Написание отказоустойчивого production-кода. Мы будем рады рассмотреть твою кандидатуру, если у тебя есть: Уверенное владение Python (нужно будет писать код, который пойдет в продакшн) и основными ML-библиотеками (numpy, pandas, sklearn, lightgbm и т.п.) Понимание классических методов и алгоритмов машинного обучения, опыт их применения на практике Хорошее знание SQL и умение копаться в источниках, опыт работы с инструментами экосистемы Hadoop (hive, spark) или готовность их быстро освоить Умение переложить бизнес-задачу на язык анализа данных, подобрать соответствующий алгоритм с учетом требований и ограничений, интерпретировать результат Хорошее знание теории вероятностей и математической статистики Будет плюсом: Опыт выведения моделей в продакшн Опыт с инструментами нашего стека (чем больше, тем лучше) Участие в хакатонах и соревнованиях по машинному обучению (например, Kaggle). Наш стек: Python, Spark, Hadoop, Hive, Airflow, Docker, k8s, MLFlow Git, Jira, Confluence.","Python,Linux,SQL,Математическая статистика,Hadoop,Git,Atlassian Jira,Spark,Data sciense,Анализ данных,Analysis,Статистика,Big Data,Статистический анализ","билайн: Т, Data, Digital",
16714,76974214,Data scientist (Ценообразование),з/п не указана,1–3 года,"Полная занятость,удаленная работа","В компанию требуется middle/senior специалист на позицию Data Scientist в Департамент управления данными на направление ""Ценообразование"". Вам предстоит работать над созданием аналитических продуктов с целью оптимизации процессов управления ценами и скидками по товару (Markdown Optimization, рекомендации по ценообразованию, автоматизация планирования). Какие задачи мы решаем? спользовать алгоритмы машинного обучения для решения бизнес-задач сследовать данные с целью получения новых признаков Разрабатывать требования для сбора данных, дизайн A/B тестов Заниматься написанием эффективного кода для получения агрегатов данных Развивать инфраструктуру для автоматического построения и использования моделей машинного обучения Стек технологий: Для разработки используем: Python + ML packages, Spark, Oracle, Airflow, Superset, Docker Для организации работы: Jira, Confluence, Git Мы ждём от наших будущих коллег: Опыт использования и внедрения алгоритмов машинного обучения Знание базовых алгоритмов и структур данных, понимание плюсов и минусов Уверенное знание математической статистики, умение применять для решения задач Уверенное знание SQL и готовность писать эффективные запросы Уверенное владение Python (библиотеки работы с данными) Технический английский на уровне чтения статей и участия в конференциях",,"Компания «СПОРТМАСТЕР», Sportmaster Lab","Москва, Аэропорт, Кочновский пр., 4К3"
16715,77557350,Аналитик данных/Middle Data scientist (Computer Vision),з/п не указана,1–3 года,"Полная занятость,полный день","змерительная система — это программно-аппаратный комплекс, состоящий из различных датчиков, программного обеспечения, нейронных сетей и моделей. Данные с компонентов системы поступают в её головной компьютер, где оператор может получить информацию о состоянии объекта, результатах измерений. змерительные системы, разработанные «Северсталью», уже испытаны на собственных производствах компании. Эти эффективные решения компания готова адаптировать под задачи заказчика. В связи с расширением команды мы находимся в поиске Middle Data scientist (Computer Vision). Некоторые наши проекты: Системы видеоинспекции- поверхности металлопроката, которые обеспечивают определение и классификацию дефектов с помощью видеокамер, машинного зрения и нейросетей Системы измерения геометрических параметров и формы продукции с помощью лазерных триангуляционных датчиков позволяют измерять длину, ширину и толщину продукции, её планшетность и серповидность либо комплекс параметров Датчики промышленного интернета вещей, с помощью которых можно предотвратить травмирование продукции при погрузочно-разгрузочных работах.  В твои обязанности будет входить: Участие в анализе и проработке бизнес требований Контроль технической стороны процесса разметки изображений внешними и внутренними ресурсами Обучение CV модели (object detection, object tracking, object classification, segmentation) Доведение своей рисерч модели до состояния MVP и вносить доработки по результатам пилотирования Вывод решения в продакшн, поэтому помимо тренировок сеток специалист будет заниматься следующими задачами: · выбирать оптимальный дизайн решения для задачи · проводить trade-off между качеством и скоростью · оптимизировать работу алгоритмов в зависимости от условий работы (on edge, прунинг, квантизация) Тестирование в наших задачах SOTA решения и прикручивание их в прод, где это осмысленно В ситуациях, где данных для обучения классических моделей недостаточно, находить нестандартные решения. Основные требования: Хорошие знания Python и умение писать на нем качественный и понятный код Классический ML - кластеризация, классификация, регрессия и тд. Стек sklearn, numpy, pandas, xgboost/lightgbm Знания методов математической статистики и теории вероятностей. Знание базовых алгоритмов машинного обучения, хорошее понимание основ DL Теоретические знания методов DL и оптимизации (основные концепты + более углублённые знания в CV с упором на детекцию и сегментацию + основные метрики в задачах CV) Знание хотя бы одного из фреймворков по глубокому обучению TensorFlow\PyTorch Хорошее понимание основ классического компьютерного зрения (базовые морфологические операции, Discrete Fourier Transform, Hough transforms, Sobel derivatives) Опыт работы с задачами object detection, segmentation, classification Опыт работы с OpenCV Опыт автоматизированного сбора и разметки данных, опыт работы с CVAT Умение читать, понимать, имплементировать статьи по компьютерному зрению Умение решать задачи по CV без больших данных. Теоретическая подготовка в области RL и опыт использования алгоритмов RL Будет плюсом: Опыт работы с Linux Знание Docker, Docker Compose Опыт работы с разными видами сенсоров в области машинного зрения (камеры, радары, лидары и т.д.) Знакомство с GANами, attention-механизмами, архитектурами типа encoder-decoder, знакомство с semi- и unsupervised learning, знания в области NLP, а также опыт реализации кастомных архитектур Огромным плюсом будут навыки в оптимизации скорости инференса DL-моделей с кастомной архитектурой на CPU и GPU, а также опыт работы с TorchScript, TensorRT, ONNX, конвертацией моделей между фреймворками, etc. Опыт разработки и деплоймента DL-проектов Знание английского на уровне, достаточном для комфортного чтения статей и блогов Профиль на kaggle (необязательно). Мы предлагаем: Мощную команду профессионалов Дополнительную мотивацию в виде годового бонуса, социальный пакет и скидки от партнеров Развитие нон-стоп. Мы вкладываемся в людей как в самое дорогое. Создаем авторские учебные курсы. Привлекаем внешних экспертов и наставников. Гарантии стабильности. Трудоустраиваем по ТК РФ. Зарплата выплачивается 2 раза в месяц и регулярно индексируется. Есть ДМС со стоматологией с первого рабочего дня. Работаем по бессрочному договору. Возможность работы удаленно или в г. Череповце.","Python,SQL,MS SQL,Английский язык,PostgreSQL",Северсталь. IT & Digital,
16716,70163749,Data Scientist (middle/senior),до 400 000 руб. до вычета налогов,3–6 лет,"Полная занятость,полный день","Мы в Rubbles занимаемся созданием Data Science-продуктов и разработкой аналитических решений для различных индустрий: системы предсказания спроса на товары для оффлайн-ритейлов, рекомендательные системы в банках, поисковые системы по товарам для онлайн-ритейлеров и многое другое. Среди наших клиентов: Сбербанк, Пятёрочка, KFC, Перекрёсток, Альфа-Банк, МВидео и др. Мы ищем data scientist'ов уровня middle/senior для усиления нашего направления, которое занимается разработкой систем прогнозирования спроса на товары, ценообразования, автоматического подбора оптимальных промо-акций и др. Обязанности: Моделирование и обработка данных на Python для извлечения бизнес-ценности из данных Построение воспроизводимых и переиспользуемых решений для работы с данными и моделями Детальное обсуждение поставленных перед командой задач и методов их решения совместно с коллегами и бизнес-заказчиками. На что смотрим: Опыт использования ml библиотек на Python (бустинг, нейронные сети и др.) и понимание особенностей реализации различных аспектов алгоритмов в коде Опыт работы на позиции, связанной с промышленной разработкой Понимание методов машинного обучения с точки зрения математики и умение адаптировать их под конкретные задачи Опыт работы с Spark, Pyspark, Pandas, SQL, Hive и др. Опыт проработки задачи от бизнес-постановки до математической формулировки и реализации в коде Опыт автоматизации пайплайнов работы с данными (Airflow и др.) и навыки devops (Docker, Kubernetes и др.). У нас: Работа в одной из самых сильных ML команд в России Гибкий график работы, гибкое предоставление отгулов и отпусков Поддержка в профессиональном и карьерном росте, оплата профильного обучения, конференций и книг, корпоративные скидки на курсы английского Совместная работа с опытными разработчиками, аналитиками данных, менеджерами, продуктологами ДМС со стоматологией после испытательного срока (3 месяца) по всей России При желании работать из офиса – уютный офис в центре Москвы (2 минуты от м. Сухаревская) со всем необходимым для комфортной работы. Особенно актуальное: Мы аккредитованная Т-компания со всеми вытекающими льготами.","Python,Spark,SQL,Machine Learning,Pandas,Машинное обучение,Data Science,Big Data",Rubbles,
16717,78928573,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Pudov – производитель продуктов питания и товаров повседневного спроса, лидер российского рынка в категории «Всё для выпечки». Мы трансормируемся из классической в цифровую компанию, внедряем и используем в работе передовые инструменты и современный стек технологий. Приглашаем в команду активного, внимательного и ответственного сотрудника на должность "" Data Scientist"". Готовы рассмотреть кандидатов без опыта работы, но с большим желанием развиваться в сфере Big Data. Обязанности: Анализ имеющихся данных в разных направлениях деятельности компании Оценка качества данных, валидация данных, построении правильной архитектуры данных Организация сбора данных (проработка необходимых параметров отчета, ТЗ на составление кастомизированного отчета для выгрузки данных из системы учета) Построение, обучение, тестирование моделей и алгоритмов для исследования данных с целью получения новых признаков клиентов, зависимостей, гипотез, прогнозов и т.д. нтерпретации данных в отчетах (выводы, графики, зависимости) Участие в подборе и внедрении ML-решений сследование новых алгоритмов и подходов, развитие экспертизы в области data science и machine learning. Требования: Высшее образование Опыт работы с большими массивами данных Активность, инициативность, аналитический склад ума Знание библиотек: Pandas, NumPy, Scikit-learn, TensorFlow, Keras, SciPy, Plotly, Seaborn, PyTorch Знание (линейной алгебры теории вероятности и математической статистики математический анализ и методы оптимизации временные ряды). Мы предлагаем: Мы предлагаем работу в проектах с реальными данными (производство, логистика, продажи, закупки, электронная коммерция, розница), возможность стать частью нашей команды Data Science Обучение от Сбера (нашего партнёра и лидера в области обработки и исследования данных) нтересные задачи, качественный продукт и амбициозные цели Карьерный рост и профессиональное развитие (каждый второй руководитель вырос внутри компании) Всё по ТК РФ: трудоустройство в штат компании, полностью «белая» ЗП, выплаты строго в срок Корпоративные скидки на продукцию компании (для сотрудников), корпоративные праздники, тренинги и обучение Возможность гибридного графика работы (возможность совмещать с учёбой или военной кафедрой) Возможность пройти практику и трудоустроится в Компанию. Добро пожаловать в команду!","Data Scientist,Аналитик,Pandas,NumPy,Scikit-learn,TensorFlow,Keras,SciPy,Plotly,Seaborn,PyTorch",Pudov,"Таганрог, улица Менделеева, 117/6"
16718,77774476,Data analyst/ Data Scientist  (удаленно),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Приглашаем DATA ANALYST/ DATA SCIENTIST присоединиться к нашей команде.  Мы занимаемся разработкой Centralized Data Platform (CDP) для домена Риски, создаем и развиваем скоринговые модели по клиентам. В Росбанке возможен полностью дистанционный формат работы: откуда работать - решать только тебе! Приходи к нам, чтобы работать над амбициозными и интересными проектами и наслаждаться балансом между работой и личной жизнью! Росбанк – частный универсальный банк, работающий на российском рынке с 1993 года. Росбанк обслуживает порядка 1,5 млн активных розничных клиентов, около 83 тысяч активных клиентов малого бизнеса и около 10 тысяч активных клиентов корпоративного бизнеса более чем в 60 регионах России. Росбанк входит в ТОП 5 самых надежных российских банков по версии журнала Forbes и включен Банком России в число 13 системно-значимых кредитных организаций России. Наш банк имеет наивысшие кредитные рейтинги российских и международных рейтинговых агентств. ОБЯЗАННОСТ: Проверка гипотез Построение ML моделей Сбор и анализ данных по клиентам Подготовка AD-hoc аналитики для принятия бизнес-решений. ТРЕБОВАНЯ: Опыт анализа данных от 2 лет Уверенное владение SQL Опыт построения моделей кластеризации и классификации с помощью ML Опыт работы с Python (анализ данных) Опыт работы с Hadoop, Spark Знание математической статистики и теории вероятности Опыт работы в банковской сфере будет преимуществом. УСЛОВЯ: Полностью дистанционный формат работы – это возможность работать из любой точки Стабильный и прозрачный доход: зарплата и премии по результатам работы График 5/2 31 календарный день оплачиваемого отпуска Забота о здоровье сотрудников: программа ДМС, включая стоматологию и консультации психолога, страхование при выезде за рубеж, скидки на абонементы в фитнес-клубы, страхование жизни Дополнительная оплата за больничный лист: доплата сверх пособия по болезни до оклада (до 5 рабочих дней в год) Личностное развитие и рост: корпоративная электронная библиотека Альпина с книгами, курсами, тестами по бизнесу и саморазвитию, возможность прохождения бесплатного обучения и тренингов, участия в регулярных встречах корпоративных клубов и скидки на курсы он-лайн школ Скидки и привилегии по кредитам, ипотека на льготных условиях, льготные условия обслуживания и т.п. Программа корпоративных скидок и привилегий Primezone: развлечение, отдых, товары для взрослых и детей, услуги (авиакомпании, рестораны, магазины электроники и т.п.), обучение Программа волонтерства и благотворительности Сообщества по интересам сотрудников.","SQL,Python,Hadoop,Spark,Анализ данных,Data Analysis,Data Science,Machine Learning,ML,Numpy,Pandas",«РОСБАНК»,
16719,79079445,Data Scientist (Middle+/Senior),з/п не указана,1–3 года,"Полная занятость,полный день","Мы в поисках скилловых специалистов в команду классического ML :) Команда распределенная, основные ячейки находятся в Новосибирске, Томске, СПб и также по всей России. Сейчас нас 100+ человек. Активно расширяем команду, которая работает над проектами: оценка платежеспособности клиента поиск аномального и фродерского поведения идентификация пользователей постпроцессинг данных. Задачи, которыми тебе предстоит заниматься: выгрузка данных из БД, парсинг логов сервисов обработка и подготовка данных с использованием Python создание и проверка признаков оценка качества и анализ данных доработка пайплайна расчета признаков для транзакций/заявок обучение классических ML моделей доставка моделей до боя, мониторинг моделей на бою доработка внутренних библиотек общение с бизнес-заказчиком анализ экономического эффекта изменений логики принятия решений. Что для нас важно: опыт работы с задачами машинного обучения/ опыт работы с данными в проектах, желательно по статистической обработке от 2-3 лет опыт разработки на Python опыт работы с библиотеками pandas, numpy, sklearn, catboost уверенные навыки использования Linux, Jupyter notebook, git, SQL знание основных моделей машинного обучения: деревья решений на градиентном бустинге, логистическая регрессия с регуляризацией, метод ближайших соседей и др. методов снижения размерности и кластеризации навыки визуализации результатов опыт самостоятельного ведения темы: дизайн, постановка задачи, проведение и оценка результатов А/Б тестов, оценка результата работы по задаче для позиции уровня senior: ожидаем опыт ведения более обширной темы (от идеи до прода), опыт ревью кода мидлов/опыт лидства команды доп. навыки: базовые навыки в airflow, pyspark, dvc. Мы предлагаем: Понятную траекторию роста (performance review, карьерные консультации, индивидуальная карта развития и т.д.) Обучение и развитие за счёт ресурсов компании (Учебный центр, корпоративная библиотека, оплата внешнего обучения) Социальный пакет (ДМС с первого рабочего дня, скидки от партнёров, детская программа, поддержка спорта, корпоративный транспорт и т.д.) Насыщенная корпоративная жизнь (радио, подкасты, кибертурнир, собственные мероприятия и участие в крупных событиях отрасли) Возможность быть преподавателем, наставником, автором корпоративного блога, спикером – каждый выбирает то, что подходит именно ему Официальное трудоустройство с первого дня, полностью белая зарплата.",,Центр финансовых технологий,
16720,79079447,Data Scientist (Middle+/Senior),з/п не указана,1–3 года,"Полная занятость,полный день","Мы в поисках скилловых специалистов в команду классического ML :) Команда распределенная, основные ячейки находятся в Новосибирске, Томске, СПб и также по всей России. Сейчас нас 100+ человек. Активно расширяем команду, которая работает над проектами: оценка платежеспособности клиента поиск аномального и фродерского поведения идентификация пользователей постпроцессинг данных. Задачи, которыми тебе предстоит заниматься: выгрузка данных из БД, парсинг логов сервисов обработка и подготовка данных с использованием Python создание и проверка признаков оценка качества и анализ данных доработка пайплайна расчета признаков для транзакций/заявок обучение классических ML моделей доставка моделей до боя, мониторинг моделей на бою доработка внутренних библиотек общение с бизнес-заказчиком анализ экономического эффекта изменений логики принятия решений. Что для нас важно: опыт работы с задачами машинного обучения/ опыт работы с данными в проектах, желательно по статистической обработке от 2-3 лет опыт разработки на Python опыт работы с библиотеками pandas, numpy, sklearn, catboost уверенные навыки использования Linux, Jupyter notebook, git, SQL знание основных моделей машинного обучения: деревья решений на градиентном бустинге, логистическая регрессия с регуляризацией, метод ближайших соседей и др. методов снижения размерности и кластеризации навыки визуализации результатов опыт самостоятельного ведения темы: дизайн, постановка задачи, проведение и оценка результатов А/Б тестов, оценка результата работы по задаче для позиции уровня senior: ожидаем опыт ведения более обширной темы (от идеи до прода), опыт ревью кода мидлов/опыт лидства команды доп. навыки: базовые навыки в airflow, pyspark, dvc. Мы предлагаем: Понятную траекторию роста (performance review, карьерные консультации, индивидуальная карта развития и т.д.) Обучение и развитие за счёт ресурсов компании (Учебный центр, корпоративная библиотека, оплата внешнего обучения) Социальный пакет (ДМС с первого рабочего дня, скидки от партнёров, детская программа, поддержка спорта, корпоративный транспорт и т.д.) Насыщенная корпоративная жизнь (радио, подкасты, кибертурнир, собственные мероприятия и участие в крупных событиях отрасли) Возможность быть преподавателем, наставником, автором корпоративного блога, спикером – каждый выбирает то, что подходит именно ему Официальное трудоустройство с первого дня, полностью белая зарплата.",,Центр финансовых технологий,
16722,79079448,Data Scientist (Middle+/Senior),з/п не указана,1–3 года,"Полная занятость,полный день","Мы в поисках скилловых специалистов в команду классического ML :) Команда распределенная, основные ячейки находятся в Новосибирске, Томске, СПб и также по всей России. Сейчас нас 100+ человек. Активно расширяем команду, которая работает над проектами: оценка платежеспособности клиента поиск аномального и фродерского поведения идентификация пользователей постпроцессинг данных. Задачи, которыми тебе предстоит заниматься: выгрузка данных из БД, парсинг логов сервисов обработка и подготовка данных с использованием Python создание и проверка признаков оценка качества и анализ данных доработка пайплайна расчета признаков для транзакций/заявок обучение классических ML моделей доставка моделей до боя, мониторинг моделей на бою доработка внутренних библиотек общение с бизнес-заказчиком анализ экономического эффекта изменений логики принятия решений. Что для нас важно: опыт работы с задачами машинного обучения/ опыт работы с данными в проектах, желательно по статистической обработке от 2-3 лет опыт разработки на Python опыт работы с библиотеками pandas, numpy, sklearn, catboost уверенные навыки использования Linux, Jupyter notebook, git, SQL знание основных моделей машинного обучения: деревья решений на градиентном бустинге, логистическая регрессия с регуляризацией, метод ближайших соседей и др. методов снижения размерности и кластеризации навыки визуализации результатов опыт самостоятельного ведения темы: дизайн, постановка задачи, проведение и оценка результатов А/Б тестов, оценка результата работы по задаче для позиции уровня senior: ожидаем опыт ведения более обширной темы (от идеи до прода), опыт ревью кода мидлов/опыт лидства команды доп. навыки: базовые навыки в airflow, pyspark, dvc. Мы предлагаем: Понятную траекторию роста (performance review, карьерные консультации, индивидуальная карта развития и т.д.) Обучение и развитие за счёт ресурсов компании (Учебный центр, корпоративная библиотека, оплата внешнего обучения) Социальный пакет (ДМС с первого рабочего дня, скидки от партнёров, детская программа, поддержка спорта, корпоративный транспорт и т.д.) Насыщенная корпоративная жизнь (радио, подкасты, кибертурнир, собственные мероприятия и участие в крупных событиях отрасли) Возможность быть преподавателем, наставником, автором корпоративного блога, спикером – каждый выбирает то, что подходит именно ему Официальное трудоустройство с первого дня, полностью белая зарплата.",,Центр финансовых технологий,
16723,78107782,Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","MAIN RESPONSIBILITIES: Working in Data Science team Leads the roll out of new or enhanced statistical sample based services. Ensures following best practices in sample based measurements. Consults with internal and external clients and helps provide expert consultation to solve complex data quality related issues. Ability to turn numbers into stories our clients can understand and respond to. Compiling and delivering documentation material such as power point slides for methodology questions and/or frequently asked questions. Works cross team to provide a professional, clear response to all clients. REQUIREMENTS: Master (or equivalent) in Statistics, Math, Economics, Computer Science or a related field Excellent knowledge of statistics and mathematics English - from Intermediate level Exceptional aptitude for data analysis and creative problem-solving R, Python, SQL or similar skills as a plus Proficiency in Excel, PowerPoint and Word A high degree of accuracy and attention to detail A strong communicator who is able to explain technical issues in a non-technical way Broad industry knowledge and methodologies is a benefit Excited by challenges, pro-actively interacting with others WE OFFER: Competitive salary Life and health insurance Corporate laptop and sim-card Work in an international, multicultural environment Access to learning platforms, mentorship programms and educational support to keep developing your skills Peer-to-peer recognition program to enable feedback sharing and reward your achievements Employees are provided access to PrimeZone Corporate Benefits Program (fitness, travel, restaurants, entertainment, etc.) Social and corporate events Office is near Tretyakovskaya metro station (Hybrid working module). ABOUT NIELSENIQ We are the most trusted source for complete consumer intelligence as we have for nearly 100 years. Our ability to provide global retailers, manufacturers and partners with the most comprehensive data, analysis and insights will remain unmatched. We deliver the complete truth. That’s why we are unrelenting in our pursuit of the most comprehensive data sets, measuring all transactions equally to deliver the knowledge people need. Our best-in-class data scientists and analysts simplify the complexity of this information, illuminating powerful insights through clear, compelling stories. We capture the world as it truly is to enable leaders to look forward and empower businesses to make decisions with confidence. Check our current job openings now to begin your NielsenIQ journey.",,NielsenIQ,
16724,79267194,Data engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы - IT компания, специализирующаяся на разработке «умных» информационных систем для медицины и ищем в свою команду Data Engineer. Занимаемся реализацией проекта федерального масштаба в сфере здравоохранения. Обязанности: Взаимодействие с data scientist’ами и аналитиками, работа над поиском новых способов генерации и улучшения качества данных. Data modeling, создание и поддержка датасетов и инструментов для их генерации. Развитие ETL и data ingestion пайплайнов. Развитие и улучшение существующих сервисов. Участие в проработке и реализации интеграций с другими сервисами и командами. Стек: Python, Pandas, Postgres, Airflow, S3. Требования: Опыт работы Data Engineer от 2х лет, предпочтительно с подготовкой датасетов для ML Представление о статистическом анализе данных, методах ML Отличное знание SQL, Python Опыт построения аналитического хранилища данных. Условия: Вы погрузитесь в специализацию IT в медицине и станете экспертом в этой области. Будете участвовать в реализации глобальных изменений и вместе с нами будете менять мир. Будете работа в коллективе профессионально зрелых и интересных коллег. Работа в атмосфере результативности и системности в сочетании с гибкими подходами к решению задач. Работа в офисе, гибридный и дистанционный форматы. Комфортный дресс-код smart casual и джинсы, чай на уютной кухне. Офис в 2 минутах от метро Менделеевская.",,Ртк-Элемент,"Москва, Менделеевская, Новослободская улица, 23"
16725,79110323,Data scientist (Управление рисками корпоративных клиентов),з/п не указана,1–3 года,"Полная занятость,полный день","Мы — амбициозная и дружная команда, ежедневно исследующая данные корпоративных клиентов Сбербанка. Наши модели – двигатель не имеющих аналогов в России продуктов в сфере управления рисками корпоративных клиентов. Сводная статистика о нас: Мы решаем задачи по 8 основным направлениям (от монументального ПВР до всеобъемлющих графов и молодого и амбициозного ESG) 95% наших моделей разрабатываются с применением облачных технологий Мы придерживаемся единого стандарта работы, используем JIRA/Confluence/BitBucket, у нас есть единый бэклог 25% нашей команды имеют западное образование и опыт работы в странах Европы Мы сотрудничаем с передовыми ВУЗами в 3-ёх городах России Просрочка по кредитному продукту на основе наших моделей стремится к 0. В команде с заказчиками мы: Погружаемся в предметную область Прорабатываем постановку задачи щем и исследуем данные Выбираем оптимальные методы моделирования Разрабатываем и верифицируем модели Готовим отчеты о разработке и презентуем результаты Мониторим модели Наслаждаемся результатом. В рамках работы над задачей мы будем: Разрабатывать и улучшать инструменты для машинного обучения (внутренние наработки, библиотеки) спользовать прогнозное моделирование, чтобы оптимизировать бизнес риск метрики Работать в команде с портфельными менеджерами, чтобы понять нужды бизнеса и предложить возможные решения Разрабатывать модели машинного обучения Разрабатывать архитектуру пилотов для тестирования гипотез Прокачивать коллег и развиваться самим. Качественные факторы кандидатов с высоким Feature important: Диплом в области компьютерных наук, статистики, прикладной математики или другой релевантной области Опыт работы от 3х лет с одной или несколькими СУБД: Oracle, MS SQL, Teradata либо СУБД стэка Bigdata Опыт работы с хранилищами данных от 1го года Опыт работы в роли аналитика с функцией подготовки выгрузки данных для заказчика Сильные компетенции в области реляционных СУБД и хранилищ данных: Глубокое понимание статистических подходов и методов (регрессия, свойства распределений, оценка максимального правдоподобия, проверка гипотез и их правильное использование) и опыт их применения Знания и опыт применения алгоритмов машинного обучения (GLM/Regression, Trees, Random Forest, Boosting), а также знание их преимуществ, недостатков и ограничений Приветствуется знание принципов работы нейронных сетей и опыт использования библиотек для их обучения (Keras/PyTorch/TensorFlow) Знание Python и основных DS библиотек Отличные знания английского языка (устный и письменный) как преимущество Опыт в распределённых/параллельных вычислениях с помощью следующих технологий: Hadoop, Spark, Dask и другие как преимущество А ещё у нас есть: Развитая IT архитектура. Мощный GPU кластер, возможность расчётов на суперкомпьютере top30 в мире Работа над передовыми задачами в банковском секторе Постоянное развитие: обучающие курсы от лучших университетов и компаний (МФТ, ВШЭ, NVIDIA и другие), участие в международных конференциях Большую сильную команду Развитое DS community.",,Сбер. Data Science,"Санкт-Петербург, Старо-Петергофский пр., д.30"
16726,72740316,Quant / Data Scientist (Руководитель направления Управление рисками),з/п не указана,3–6 лет,"Полная занятость,полный день","Наши эксперты и руководители работают над глобальными проектами, создают условия для роста и успехов всех сотрудников, а также делятся совей экспертизой во внешней среде ЧЕМ ПРЕДСТОТ ЗАНМАТЬСЯ: Доработка существующих моделей оценки ипотечных ценных бумаг и связанных деривативов (python): - Развитие внутренней симуляционной OAS модели - Участие в калибровке моделей машинного обучения, описывающих поведение ипотечных пулов Участие в развитии лучших на рынке публичных инструментов оценки ЦБ: ицб.дом.рф, калькулятор.дом.рф НАШ ПОЖЕЛАНЯ К СОСКАТЕЛЮ: Образование высшее (финансово-экономическое или техническое (при наличии знаний в области экономики и финансов) Желательно наличие профессиональных сертификатов (CFA, CQF, FRM) Опыт работы на связанных с количественной аналитикой позициях в финансовой сфере Понимание принципов работы финансовых рынков, инструментов с фиксированной доходностью, деривативов на процентные ставки (желательно) Опыт разработки финансовых моделей, оценки финансовых инструментов Опыт работы с большими массивами данных, хорошее знание SQL, базовые навыки аналитического программирования (Python, R) Желательно знание Latex, Jupyter lab, а также Shell, Git, Kubernetes Хорошее знание офисного ПО (MS Excel, Word, PowerPoint), опыт в написании отчетов, навыки презентаций ЧТО МЫ ПРЕДЛАГАЕМ: Оформление в соответствии с ТК РФ, полностью белая зарплата Гибридный формат работы Конкурентный уровень заработной платы + премии по итогам работы в соответствии с утвержденными внутренними политиками Расширенная программа ДМС, включая стоматологию Компенсация абонемента в фитнес-клуб (до 70% от стоимости) Компенсация обучения английскому языку (до 50% от стоимости) Профессиональное обучение Специальные условия по кредитам и ипотеке от Банка ДОМ.РФ для сотрудников Корпоративные скидки у партнёров группы ДОМ.РФ Активная социальная жизнь (спортивные, интеллектуальные мероприятия).","SQL,Python",ДОМ.РФ,
16727,71322369,Data Scientist Middle/Senior,з/п не указана,3–6 лет,"Полная занятость,полный день","Responsibilities: Collaborate with business partners to develop novel ways to meet objectives utilizing cutting edge techniques and tools Effectively communicate the analytics approach and how it will meet and address objectives to business partners Advocate and educate on the value of data driven decision making focusing on the “how and why” of solving problems Lead analytic approaches, integrating work into applications and tools with data engineers, business leads, analysts and developers Create repeatable, interpretable, dynamic and scalable models that are seamlessly incorporated into analytic data products Engineer features by using their business acumen to find new ways to combine disparate internal and external data sources Share their passion for Data Science with broader enterprise community identify and develop long-term processes, frameworks, tools, methods and standards Collaborate, coach, and learn with a growing team of experienced Data Scientists Stay connected with external sources of ideas through conferences and community engagements Domain Expertise: Bachelor’s degree required Graduate degree in quantitative discipline and demonstrated Data Science skill set, plus 3+ years work experience Must have Python or R proficiency working with DataFrames Must have proficiency writing complex SQL queries Must have proficiency with Machine Learning to solve clustering, classification, regression, anomaly detection, simulation and optimization problems on large scale data sets Must have proven ability to merge and transform disparate internal & external data sets together to create new features Advanced time series forecasting understanding – from classical linear approaches to ML ones Understanding the key business metrics and its application to ML models Experience with sophisticated data cleansing approaches & robust models Proficiency validating the current approaches and understanding the improvement area Experience with Big Data technologies preferred — Hadoop, Spark, H20.ai, Cloud AI platforms, containerization Experience with supporting deployment, monitoring, maintenance and enhancement of models desired Experience with data visualization tools preferred — Power BI, Tableau, R Shiny, Plotly, etc. Experience with AB testing preferred We offer: Competitive salary Advanced benefits package (annual bonus, health insurance, mobile compensation, partial fitness compensation, 3-year saving plan) Professional development and career growth Ability to take part in digital transformation in a large company","Python,Machine Learning,SQL,Big Data,Data science",Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
16728,78329281,Senior data scientist (экономические показатели),з/п не указана,3–6 лет,"Полная занятость,полный день","Задачи: Разработка моделей для прогнозирования развития проектов, реализуемых на площадке, их интеграция в цифровые продукты и интерпретация результатов моделирования Организация деятельности по выявлению качественных и количественных взаимосвязей между свойствами объектов, анализируемых в проектах Расширение практики использования инструментов продвинутой аналитики (advanced analytics) Разработка и реализация концепции создания центра в области продвинутой аналитики и исследования данных Взаимодействие с дата-офисом в целях развития Т-инфраструктуры и создания центра продвинутой аналитики Оперативное руководство деятельностью команды аналитиков (3-4 ед.), развитие компетенций команды, наставничество Требования: Высшее образование (математика, матметоды в экономике, экономическая статистика) Опыт реализации прикладных исследовательских и консалтинговых проектов по заказу органов власти от 3-х лет Владение Python / R / SQL на уровне уверенного пользователя, самостоятельное написание кода Знание статистических пакетов анализа данных (STATA, EViews, SPSS, MATLAB) Понимание современных инструментов управления данными, BI, аналитикой, ML и DS Развитые презентационные и коммуникационные навыки Английский язык – upper intermediate и выше Наличие публикаций в ведущих научных журналах (социально-гуманитарный блок) Приветствуется менеджерский опыт, готовность брать ответственность за результат команды Проактивность и ориентация на практический результат Учёная степень в области социально-гуманитарных наук будет преимуществом Мы предлагаем: Стать частью динамичной и быстроразвивающейся организации (мы работаем в атмосфере стартапа) Возможность решать интересные и важные государственные задачи федерального масштаба и видеть результаты своей работы Доступ к данным для научных исследований, развитая партнерская сеть с ВУЗами и компаниями-лидерами цифровизации Рабочее взаимодействие с руководством федеральных органов власти и командами членов Правительства РФ Современный офис с коворкингом, митинг-румами и ситуационным центром Программа ДМС",,Аналитический центр при Правительстве Российской Федерации,"Москва, Киевская, Киевская, Кутузовский проспект, 2/1с6"
16729,77899629,Senior NLP Engineer / Data Scientist,до 370 000 руб. на руки,3–6 лет,"Полная занятость,полный день","КБЕР-РОМ — это неформальная обстановка, крутые Т-проекты в области медиаиндустрии и продукты, конкурирующие с лидерами рынка! У нас есть команда, которая создает ML решения, аналогов которых нет на рынке! Спроси себя, хочешь ли ты: обрабатывать миллионы видео со стримминговых сервисов предоставлять пользователям релевантный контент искать структуры в неструктурированных данных бороться за каждую миллисекунду скорости делать продукт, который сделает лучше пользовательский опыт. Наша команда растет и мы ищем Senior NLP Engineer / Data Scientist. Наш стек: Lang: Python/Go/C++ ML: Torch, CatBoost и многое другое =)  DB: PostgreSQL, GreenPlum, Mongo, ClickHouse, Redis, OpenSearch Queue: Rabbit, Kafka Orchestration: K8s DevOps: Docker, ArgoCD, Helm Services: AirFlow, SuperSet, ML-Flow, Git-Lab Log: ELK (под OpenSearch стек) Monitoring: Grafana, Prometheus. С чем можно будет поработать: Работа с большими данными и высокой нагрузкой С Machine Learning сервисами, которые приносят людям пользу =)  Общение с экспертами в области разработки и ML из разных областей. Чем предстоит заниматься: Разрабатывать модели NLP и IR сследовать текстовые данные UGC Строить и внедрять Pipeline-ы обработки текстовых данных нтегрировать модели в сервисы. Что ожидаем от Вас: Знание и применение базовых и ML алгоритмов Опыт построение NLP сервисов от постановки бизнес задачи до внедрения сервиса в Production Опыт разработки и внедрения моделей NLP в Production сервисы от 3х лет Знание и применение Python в Production от 3х лет Опыт работы с большими данными Применение в Production DL моделей Умение определить, где нужен DL, а где достаточно регулярки =)  Навыки работы с SQL и NoSQL базами данных. Будет плюсом: Опыт работы с Docker и K8s Умение работы с ML-Ops подходами Успешные внедрения в высоко-нагруженных проектах Публикации в NLP. Бенефиты: Мы - аккредитованная в Минцифрах IT-компания Оформление по ТК РФ, конкурентная заработная плата График работы 5\2, гибкое начало дня до 11 утра (возможен гибридный график работы или удаленка) ДМС со стоматологией и госпитализацией в классных клиниках Профессиональное обучение и конференции Стильный просторный лофт на территории Трехгорной мануфактуры. Тебе предстоит легкая 10 минутная пешая прогулка через парки от метро 1905 года и Краснопресненская Сhill Lounge с пятой плойкой и капсулой для сна с массажем Современное топовое оборудование, мощные ноутбуки Комфортная кухня с вкусным кофе, чаем, какао, орешками, фруктами, снэками и прочими ништяками Холодильник с колой и энергетиками По пятницам в офисе пицца, роллы или грузинская кухня Годовая подписка на топовый онлайн кинотеатр. Минусы: Очень много интересных и сложных задач Будут спрашивать результаты работы Нет возможности работы из-за границы.","Python,Go,C++,Torch,CatBoost,PostgreSQL,GreenPlum,MongoDB,ClickHouse,Redis,OpenSearch,RabbitMQ,Kafka,K8s,Docker,ArgoCD,Helm,AirFlow,SuperSet,ML-Flow,Git-Lab,ELK,Grafana,Prometheus",КБЕР-РОМ,"Москва, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с27"
16730,79095952,Middle Data Scientist (Клиентская аналитика),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Компания MagnitTech— это опытная команда IT, которая создает экосистему современных цифровых продуктов Магнит: доставка продуктов, лекарств, инструменты для обеспечения лояльности клиентов, специальные проекты и продукты для внутренних нужд. Чем предстоит заниматься: Разрабатывать модели, позволяющие определять потребности и миссии клиентов на основании их покупок Разрабатывать алгоритмы кластеризации покупателей (бюджет, сегмент, портрет, потребность, RFM, L&G и т.д.) Разрабатывать алгоритмы кластеризации магазинов (бюджет, местоположение, состав покупателей и т.д.) Дорабатывать и оптимизировать существующие алгоритмы кластеризации Разрабатывать универсальные алгоритмы кластеризации не привязанные к конкретным данным. Стек технологий: Python, SQL, Git, Spark, S3, Linux, Bash, работа с облаками Мы ожидаем: Опыт работы с распределенными системами (HADOOP, YC DataProc, ClickHouse) посредством Spark Опыт работы с данными посредством SQL (Teradata, MS SQL, Postgres, Oracle) Знание математической статистики Знание систем контроля версий кода. Будет плюсом: Опыт работы с docker, airflow Умение найти баланс между сложностью и качеством модели. Мы предлагаем: Работу в максимально уютном и современном офисе в Москве или в Краснодаре, или удаленно График работы 5/2 с гибким началом Конкурентоспособную заработную плату Мы любим учиться! А компания всегда поддерживает и способствует профессиональному развитию специалиста Корпоративную технику для успешной и удобной работы Дружескую атмосферу и поддержку команды профессиональных и активных коллег Корпоративные скидки и программы лояльности от наших партнеров.","Python,Hadoop,Linux,SQL,Bash,Spark,Математическая статистика,Алгоритмы","МАГНТ, Розничная сеть",
16731,79141488,Data Scientist middle/middle+ в ML-команду,з/п не указана,3–6 лет,"Полная занятость,полный день","Наша команда занимается построением ML моделей. При реализации кейсов и проведении пилотов находится множество инсайтов, которые помогают делать процессы эффективнее. Для развития этих инсайтов ищем коллегу, в обязанности которого будет входить нахождение решений на стыке ML и классической аналитики Перед командой стоят следующие вызовы: - Прогнозные и причинно-следственные модели - Аудио аналитика телефонных разговоров и записей взаимодействия с клиентами. В том числе перевод аудио в текст, вычленение эмоциональной подоплёки, определения лжецов - Текстовая аналитика записей. В том числе конспект разговоров, вычленение необходимых сущностей, определение лжецов - Гео аналитика клиентов. В том числе где и когда контактировать - Оптимизация бизнес процессов с использованием инструментов process mining Обязанности Фулл стек DS. От идей до оценки эффективности готового продукта. Работа ведётся при регулярном общении с бизнес-заказчиком. Сервис и деплой на python разработчике. Требования щем людей владеющими необходимыми для выполнения описанных функций навыками: Алгоритмами работы с табличными пространственными данными, временными рядами, аудио, текстами, гео процессами (опыт от 2 лет совокупно) Python3, включая стек библиотек для работы с машинным обучением Общением с бизнесом по проектам машинного обучения, ориентацией на бизнес результат, для senior дополнительный опыт управления проектами, в которых участвует несколько команд sql, jupyter, pycharm, git, jira, confluence Условия комфортный офис на Кутузовском проспекте с тренажерным залом, коворкинг-пространствами и кафе полный рабочий день, но гибкий график работы (можно выбрать режим начала работы в промежутке 7:00 - 10:30) ДМС, программы лояльности для сотрудников (льготное кредитование, предложения экосистемы Сбера) комьюнити data-people, множество программ профессионального обучения (курсы, тренинги, конференции, семинары).",,Сбер для экспертов,
16732,78137233,Lead Data Scientist,з/п не указана,более 6 лет,"Полная занятость,полный день",,,Aimers,
16734,71354549,Chief Data Scientist / DS Team Lead,з/п не указана,3–6 лет,"Полная занятость,полный день","Responsibilities: Collaborate, coach, and learn with a growing team of experienced Data Scientists and Data Trainees Collaborate with business partners to develop novel ways to meet objectives utilizing cutting edge techniques and tools Share passion for Data Science with broader enterprise community identify and develop long-term processes, frameworks, tools, methods and standards Effectively communicate the analytics approach and how it will meet and address objectives to business partners Advocate and educate on the value of data driven decision making focusing on the “how and why” of solving problems Lead analytic approaches, integrating work into applications and tools with data engineers, business leads, analysts and developers Create repeatable, interpretable, dynamic and scalable models that are seamlessly incorporated into analytic data products Engineer features by using their business acumen to find new ways to combine disparate internal and external data sources Domain Expertise: Bachelor’s degree required, in quantitative discipline and demonstrated Data Science skill set 4+ years work experience, 1+ year work experience as a team lead Python or R proficiency working with DataFrames and proficiency writing complex SQL queries Proficiency with Machine Learning to solve clustering, classification, regression, anomaly detection, simulation and optimization problems on large scale data sets Proven ability to merge and transform disparate internal & external data sets together to create new features Experience with Big Data technologies preferred — Hadoop, Spark, H20.ai, Cloud AI platforms, containerization Experience with supporting deployment, monitoring, maintenance and enhancement of models preferred Experience with data visualization tools preferred — Tableau, R Shiny, Plotly, etc. We Offer: Competitive salary Advanced benefits package (annual bonus, health insurance, mobile compensation, partial fitness compensation, 3-year saving plan) Professional development and career growth Ability to take part in digital transformation in a large company","Python,Machine Learning,SQL,Big Data,Spark,Data Analysis,Teambuilding,ML",Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
16735,79093164,Middle Data Scientist в продукт МТС Маркетолог (Big Data),з/п не указана,1–3 года,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Middle Data Scientist в ad-hoc команду продукта МТС Маркетолог Описание продукта: В продукте мы помогаем внешним и внутренним клиентам запускать таргетированные рекламные кампании на основе данных Big Data МТС: формируем гипотезы, проводим AB тесты, ищем новые и необычные сегменты для клиентов, проводим Post аналитику рекламных кампаний, постоянно подключаем новые источники данных и работаем с ними. Обязательно: Знание python на продвинутом уровне (ds, ml библиотеки – sklearn/catboost, lgbtm) Опыт работы с Hadoop, Apache Spark, SQL Сильные теоретические знания ML Умение переложить бизнес задачу на язык анализа данных, умение простым языком объяснять сложные вещи, интерпретировать результат (придется работать, как с внешними, так и с внутренними заказчиками) Что предстоит делать? Строить модели предсказания поведения пользователя Работать с базами данных (проводить проверку и приемку витрин для дальнейшей работы по части ML) Документировать процессы и процедуры, связанные с разработкой моделей Проводить А/В тесты, дизайнить эксперименты, вводить культуру проведения A/B тестов в продукте Писать ТЗ для инженеров  Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Python,SQL,Apache Spark,Hadoop,ML,A/B тесты",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
16736,78370985,Data Engineer (Junior/Middle),з/п не указана,1–3 года,"Полная занятость,удаленная работа","У нас все организовано в виде продуктов, имеющих бесконечный срок жизни. Продуктов очень много – несколько сотен. Если делить их по группам – получится так: Клиентский опыт: обобщаем все клиентские взаимодействия с компанией в одну историю, под одним универсальным идентификатором прогнозируем и корректируем общую выручку от клиента на всем периоде жизни с компанией боремся с фродом на стороне клиентских устройств сотовой связи предсказываем отток и next-best-action для клиентов. Управление оборудованием и качеством услуг связи: собираем и анализируем метрики качества предоставления связи выполняем интеллектуальное планирование постройки базовых станций осуществляем предиктивное обслуживание оборудования. Для продуктовых команд: создаем для себя фреймворки и утилиты развиваем сервис мониторинга как единую точку сбора и просмотра метрик.   Обязанности: Анализ требований к витринам данных (взаимодействие с владельцем продукта, BI-разработчиками, data scientist-ами) Поиск и исследование источников данных для последующей интеграции Оценка пригодности, качества исходных данных Разработка ETL процессов на Spark Оркестрация ETL процессов в Airflow Проектирование баз данных Создание конвейеров данных NiFi Мы понимаем, что каждые DE индивидуален. Поэтому даем описание как бы выглядел идеальный кандидат. Все недостающие навыки можно подтянуть у нас. Любит работать в команде и умеет это делать Проработал от 1 года и более в таких областях как: коммуникационные технологии, безопасность, маркетинг и продажи, финансы. Знает SQL на высоком уровне (в т. ч. DDL, табличные выражения, оконные функции) Работал с Hive, PostgreSQL Умеет разрабатывать ETL процессы Spark на Scala (потоковая обработка как преимущество) Пользовался AirFlow или другими оркестраторами – Oozie, Luigi, ну или cron Может что-то написать на Python – в объеме чтобы пользоваться AirFlow или еще круче меет опыт потоковой разработки конвейеров данных в NiFi или Flink нтересуется Flink, пробовал применять его в проектах Умеет проектировать базы данных (знает Data Vault 2.0 например) Понимает принципы работы реляционных СУБД и HDFS меет представление о колоночных и NoSQL СУБД Понимает подходы к работе с качеством данных Применяет системный подход к работе, думает о конечной бизнес-задаче, мыслит логически, уделяет внимание деталям Стек и технологии В своей работе DE используют следующий стек технологий: Экосистема Hadoop – HDFS, YARN, Hive, HBase ETL-процессы – Spark (Scala) Потоковая обработка – NiFi, Flink Брокер сообщений – Kafka Оркестрация ETL процессов – Airflow СУБД – PostgreSQL, Greenplum, Aerospike, Oracle, SQL Server CI/CD – GitLab Условия: В компании существует и растет сообщество DE. Сейчас там около 300 человек с разным уровнем навыков от Junior до Senior. нженеры помогают друг другу бороться с трудностями и развиваться, делятся друг с другом кодом, всякими лайфхаками. Периодически проводятся митапы по инфраструктурным и софтовым темам, где коллеги делятся опытом, помогают разобраться в востребованных темах. Мы готовы оплачивать любые активности по развитию и обучению – конференции, подписки, книги, курсы – все что помогает расти профессионально. Предлагаем всем удаленный формат работы, но можно и гибридный - в зависимости от того, как Вам более удобно.","SCALA,Spark,ETL","билайн: Т, Data, Digital",
16737,79204741,Senior Data Scientist (NLP),з/п не указана,3–6 лет,"Полная занятость,полный день","щем специалиста, которые продумает архитектуру и будет развивать инструмент обработки и классификации неструктурированных текстовых данных о бренде ( упоминания в отзывах, жалобах, опросах, соцсетях , комментариях, СМ и др ) на основе методов машинного обучения.  Обязанности: Техническое лидерство на проекте, управление командой Взаимодействие с заказчиком Анализ тональности отзывов клиентов Анализ и классификация текстовых данных о бренде. Требования: Высшее образование в области компьютерных наук, физики, математики или статистики Опыт работы в должности Data Scientist от 3-х лет Опыт организации работы команды и технического лидерства Опыт общения с заказчиком Хорошие знания в области нейронных сетей, основных нейроархитектур для работы с текстом Практический опыт разработки моделей обработки текстов Отличное знание Python Опыт работы с основными DS-библиотеками для работы с данными: pandas, NumPy, Matplotlib, Seaborn Опыт работы с NLP-библиотеками: pymorphy2, spaCy, NLTK, fastText Опыт работы с DL-фреймворками: TensorFlow, Keras, PyTorch Хорошее знание T-SQL. Условия: Бесценный опыт работы над интересными проектами в сильной команде экспертов. Достойный уровень заработной платы, официальное оформление в аккредитованной Т-компании, социальные гарантии. Комфортные условия: гибкий график работы (удаленно/гибрид/офис), свободный дресс-код. Наши современные офисы расположены в центрах города СПб, Москве, Владимире, Омске, в которых есть зоны отдыха с кикером, настольными играми и игровыми приставками. ДМС + Программа «Кафетерий льгот»: сотрудники за счет компании могут компенсировать расходы на страхование, обучение, спорт, спортивный инвентарь Развитие и обучение: оплата внешних тренингов, семинаров и конференций, корпоративная библиотека.","NLTK,Pymorphy2,TensorFlow,PyTorch,NLP",БиАйЭй-Технолоджиз,"Санкт-Петербург, Фрунзенская, Московский проспект, 94"
16738,78329281,Senior data scientist (экономические показатели),з/п не указана,3–6 лет,"Полная занятость,полный день","Задачи: Разработка моделей для прогнозирования развития проектов, реализуемых на площадке, их интеграция в цифровые продукты и интерпретация результатов моделирования Организация деятельности по выявлению качественных и количественных взаимосвязей между свойствами объектов, анализируемых в проектах Расширение практики использования инструментов продвинутой аналитики (advanced analytics) Разработка и реализация концепции создания центра в области продвинутой аналитики и исследования данных Взаимодействие с дата-офисом в целях развития Т-инфраструктуры и создания центра продвинутой аналитики Оперативное руководство деятельностью команды аналитиков (3-4 ед.), развитие компетенций команды, наставничество Требования: Высшее образование (математика, матметоды в экономике, экономическая статистика) Опыт реализации прикладных исследовательских и консалтинговых проектов по заказу органов власти от 3-х лет Владение Python / R / SQL на уровне уверенного пользователя, самостоятельное написание кода Знание статистических пакетов анализа данных (STATA, EViews, SPSS, MATLAB) Понимание современных инструментов управления данными, BI, аналитикой, ML и DS Развитые презентационные и коммуникационные навыки Английский язык – upper intermediate и выше Наличие публикаций в ведущих научных журналах (социально-гуманитарный блок) Приветствуется менеджерский опыт, готовность брать ответственность за результат команды Проактивность и ориентация на практический результат Учёная степень в области социально-гуманитарных наук будет преимуществом Мы предлагаем: Стать частью динамичной и быстроразвивающейся организации (мы работаем в атмосфере стартапа) Возможность решать интересные и важные государственные задачи федерального масштаба и видеть результаты своей работы Доступ к данным для научных исследований, развитая партнерская сеть с ВУЗами и компаниями-лидерами цифровизации Рабочее взаимодействие с руководством федеральных органов власти и командами членов Правительства РФ Современный офис с коворкингом, митинг-румами и ситуационным центром Программа ДМС",,Аналитический центр при Правительстве Российской Федерации,"Москва, Киевская, Киевская, Кутузовский проспект, 2/1с6"
16739,78928573,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Pudov – производитель продуктов питания и товаров повседневного спроса, лидер российского рынка в категории «Всё для выпечки». Мы трансормируемся из классической в цифровую компанию, внедряем и используем в работе передовые инструменты и современный стек технологий. Приглашаем в команду активного, внимательного и ответственного сотрудника на должность "" Data Scientist"". Готовы рассмотреть кандидатов без опыта работы, но с большим желанием развиваться в сфере Big Data. Обязанности: Анализ имеющихся данных в разных направлениях деятельности компании Оценка качества данных, валидация данных, построении правильной архитектуры данных Организация сбора данных (проработка необходимых параметров отчета, ТЗ на составление кастомизированного отчета для выгрузки данных из системы учета) Построение, обучение, тестирование моделей и алгоритмов для исследования данных с целью получения новых признаков клиентов, зависимостей, гипотез, прогнозов и т.д. нтерпретации данных в отчетах (выводы, графики, зависимости) Участие в подборе и внедрении ML-решений сследование новых алгоритмов и подходов, развитие экспертизы в области data science и machine learning. Требования: Высшее образование Опыт работы с большими массивами данных Активность, инициативность, аналитический склад ума Знание библиотек: Pandas, NumPy, Scikit-learn, TensorFlow, Keras, SciPy, Plotly, Seaborn, PyTorch Знание (линейной алгебры теории вероятности и математической статистики математический анализ и методы оптимизации временные ряды). Мы предлагаем: Мы предлагаем работу в проектах с реальными данными (производство, логистика, продажи, закупки, электронная коммерция, розница), возможность стать частью нашей команды Data Science Обучение от Сбера (нашего партнёра и лидера в области обработки и исследования данных) нтересные задачи, качественный продукт и амбициозные цели Карьерный рост и профессиональное развитие (каждый второй руководитель вырос внутри компании) Всё по ТК РФ: трудоустройство в штат компании, полностью «белая» ЗП, выплаты строго в срок Корпоративные скидки на продукцию компании (для сотрудников), корпоративные праздники, тренинги и обучение Возможность гибридного графика работы (возможность совмещать с учёбой или военной кафедрой) Возможность пройти практику и трудоустроится в Компанию. Добро пожаловать в команду!","Data Scientist,Аналитик,Pandas,NumPy,Scikit-learn,TensorFlow,Keras,SciPy,Plotly,Seaborn,PyTorch",Pudov,"Таганрог, улица Менделеева, 117/6"
16740,79144555,Data engineer,з/п не указана,1–3 года,"Полная занятость,полный день","В Центр поддержки и сопровождения инструментов мониторинга защиты объектов открылся набор java разработчиков. Мы ждем именно твой отклик! Обязанности Анализ исходных данных в различных системах и форматах для решения бизнес-задач (оценка структуры, качества, полноты и применимости данных) Загрузка, очистка и трансформация больших объемов данных из различных источников в базу данных Проектирование и разработка аналитических витрин данных Мониторинг и оптимизация процессов загрузки, преобразования данных и сборки витрин Контроль качества загружаемых данных, разработка автоматизированных инструментов для оценки качества данных Разработка, поддержка и оптимизация инфраструктуры и внутренних сервисов для обработки больших объемов данных Разработка инструментов для автоматизации рутинных задач, связанных с обработкой данных Разработка и поддержка сопроводительной документации и спецификаций данных, развитие и поддержка базы знаний по вопросам работы с данными Предоставление экспертной поддержки внутренним потребителям (data analysts, data scientists) по вопросам, связанным с использованием данных. Требования Опыт работы в качестве Data Engineer / Data Analyst / ETL Developer Знание SQL на продвинутом уровне (аналитические функции, подзапросы, хранимые процедуры, оптимизация производительности) Опыт работы с большими объемами данных Знание основных понятий и концепций из области Data Warehouse Желателен опыт разработки витрин данных Опыт работы со стеком технологий Big Data является большим преимуществом Опыт работы по Agile (SCRUM, Kanban, и т.д.) приветствуется. Условия месторасположения офиса: ул. Академика Сахарова 2а График работы: 8:00-17:00 работа в крупнейшем банке России трудоустройство согласно ТК РФ регулярное корпоративное обучение ДМС, страхование от несчастных случаев и тяжелых заболеваний материальная помощь и социальная поддержка, корпоративная пенсионная программа льготные условия кредитования яркая и насыщенная корпоративная жизнь.",,Сбер для экспертов,
16741,79245437,Senior Data scientist / Machine learning engineer (команда рекомендаций и машинного обучения),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы применяем алгоритмы машинного обучения к рекомендациям контента. Не просто берем готовые решения, но и создаем собственные, пригодные к работе в условиях высоких нагрузок и больших данных. Помимо классического ML, мы используем deep learning и байесовские методы. Типичный пример нашего проекта — система, которая на ходу учится определять перспективность нового контента и аудиторию, среди которой он будет наиболее востребован. щем специалиста, который будет вместе с нами разрабатывать рекомендательную систему, искать возможности для роста и формировать планы по развитию продукта. Вам предстоит: • математически формулировать бизнес-задачи • использовать огромное количество разных данных • создавать гипотезы по улучшению сервиса, внедрять их и проверять работоспособность в офлайне, а в случае удачи искать способы реализации • проводить A/B-тесты и анализировать результаты экспериментов. У нас интересно, потому что вы сможете поработать с разнообразными state-of-the-art решениями в области рекомендательных систем, например: • с продвинутыми методами матричной факторизации для извлечения информации из истории просмотров и поиска • построением текстовых эмбеддингов • методами reinforcement learning • SNA-техниками для анализа социального графа • разработками big data и аналитикой поверх стека Apache Spark • product science для инсайтов и генерирования продуктовых гипотез • анализом границ применимости моделей, техниками explanation для понимания работы моделей и их специфик. Мы ожидаем, что вы: • имеете отличную математическую и алгоритмическую подготовку • знаете методы машинного обучения и умеете грамотно их использовать • работали с рекомендательными системами или интересуетесь ими • уверенно владеете Python, Java или Scala, а также любым из диалектов SQL. Будет плюсом, если вы: • умеете работать с фреймворками big data — Spark, Hadoop • знакомы с байесовскими методами машинного обучения. Приглашаем кандидата, который сможет посещать офис в Санкт-Петербурге или работать в гибридном графике. Ждем ваших откликов. Удачи!","Python,Java,Hadoop,Big Data,Spark,SCALA","VK, ВКонтакте","Санкт-Петербург, Гостиный двор, Невский проспект"
16742,79255519,Data Scientist middle+/senior (Транскодинг),з/п не указана,3–6 лет,"Полная занятость,полный день","Сейчас в Okko создается новый продукт – Видеоплатформа. Это B2B-инструмент для работы с видеоконтентом. Ключевое значение для разработки продукта имеют обработка видео (транскодинг) и оптимизация процессов, связанных с ней. В команду транскодинга мы ищем человека, который сможет сформировать и вывести ML-решения для улучшения продукта, а также найдет баланс между математическими способами решения задач и ML. Обязанности: исследование применимости различных алгоритмов в рекомендательной системе и в системах с применением компьютерного зрения моделирование входных данных интеграция исследованных моделей в системах проведение экспериментов с созданными моделями автоматизация процессов подготовки данных оптимизация потребления ресурсов сервисами, а также повышение утилизации ресурсов и применения ML интеграция сервисов с распределенными системами (Базы данных, Очереди). Требования: высшее техническое/математическое образование знание математической статистики и высшей математики критичны для решения наших задач умение инициализировать новое направление от идеи и построения инфраструктуры до вывода решения в прод для конечных пользователей знание основ статистики понимание классических ML-алгоритмов способность анализировать статьи и имплементировать описываемые алгоритмы базовые знания о Сomputer Vision знание Python желателен опыт работы с видео, изображениями, с рекомендательными системами. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,Machine learning,Сomputer Vision",Okko,"Санкт-Петербург, Беговая, улица Савушкина, 126Б"
16743,79092544,Middle ML Engineer/Data Scientist в Рекомендательную платформу (Big Data),з/п не указана,1–3 года,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Middle ML Engineer/Data Scientist в Рекомендательную платформу Описание продукта: Мы ищем ML-инженера, с которым мы будем вместе развивать платформу рекомендаций в МТС. Мы уже поставляем рекомендаций в онлайн-кинотеатр КОН, в читалку «Строки», в МТС Банк и сервисы по продаже билетов. Сейчас решаем задачи объединения рекомендательных движков в единую платформу и масштабирования на все сервисы компании. Обязательно: опыт от 2-х лет промышленного применения сервисов на базе ML отличное знание Python навыки работы в git (gitlab), NumPy, pandas и асинхронными фреймворками опыт работы с большими данными опыт работы с докером, шедулерами (airflow или любой другой) и sql/nosql базами данных опыт работы с API Большим плюсом будет: опыт в построении рекомендательных систем опыт работы с Hadoop стеком: hadoop, spark, hive опыт работы с MLOps стеком знание особенностей распределённых вычислений и методов обработки данных Что предстоит делать? развивать сервисы поставки рекомендаций автоматизировать процессы внедрять новые алгоритмы и фичи для ML моделей искать точки роста в рекомендациях, которые позволят улучшить бизнес-показатели клиентов решать задачи по А/В тестированию, работать с сегментацией клиентов Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Python,ML,Hadoop,Spark,Hive,MLOps,Git,NymPy,Pandas,Airflow,SQL,NoSQL,API,A/B тесты,Docker",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
16744,77471619,Middle/Senior Data Scientist [команда Поиска],з/п не указана,1–3 года,"Полная занятость,полный день","СберМаркет — технологический онлайн-сервис, который помогает делать покупки не выходя из дома. СберМаркет был создан на основе стартапа Instamart, присоединившегося к экосистеме Сбера в сентябре 2019 года. Наша миссия: экономить время, энергию и деньги людей для чего-то более важного. СберМаркет это: один из лидеров рынка e-grocery в России рост в 11 раз год к году передовые технологии и собственная разработка возможность задавать тренды в своей профессии и быть первопроходцем классная команда и открытая корпоративная культура быстрый рост и самостоятельное управление проектами конкурентная зарплата и надежность Мы хотим, чтобы клиент мог заказать продукты и товары с доставкой через нашу платформу из своих любимых магазинов, поэтому сотрудничаем уже с более 60 федеральными и региональными ретейлерами. Среди наших партнеров крупнейшие торговые сети: METRO, ЛЕНТА, АШАН, О'КЕЙ, Твой Дом и многие другие. Сегодня мы работаем на одном из самых крупных и динамичных потребительских рынков. В СберМаркете по-прежнему живы дух, скорость и независимость стартапа. В то же время мы располагаем силой и мощью крупнейшей в России экосистемы Сбера. Мы находимся в поиске Middle/Senior Data Scientist в команду Поиска.  Удобный поиск - одна из ключевых частей пользовательского опыта, поэтому он выделен в отдельный домен. Для этого нам важно улучшать Поиск с помощью решений на основе машинного обучения. Что предстоит делать: Улучшать одну или несколько компонент Поиска: ranking, suggester, spelling, matching, intent Выдвигать гипотезы и проверять их на данных Обучать модели и заниматься автоматизацией их обновления Оценивать результат в оффлайне и на основе АБ-тестов. Что ждем от кандидата: Для кандидатов уровня Middle и выше: совокупный опыт работы в ML от 2-х лет знание классических алгоритмов ML знание классических и современных алгоритмов NLP уверенное владение Python и базовые знания SQL опыт полного цикла внедрения моделей (сбор данных, обучение и оценка модели, проведение А/Б-тестов, выкатка модели в прод) самостоятельность, проактивность и умение декомпозировать при решении задач. Для кандидатов уровня Senior и выше: предыдущий опыт работы в сфере нформационного поиска/RecSys/NLP/E-commerce на позиции уровня Middle и выше совокупный опыт работы в ML от 3-х лет. Наш стэк: Пишем на Python и SQL Данные храним в ClickHouse, S3 Прототипируем в Jupyter, успешные эксперименты переносим на Airflow + Kubernetes Что мы предлагаем: Смешанный формат: можно работать из офиса в Москве (Садовническая улица, 9А) или удаленно Соц.пакет — ДМС, спорт, промокоды на заказ продуктов или билеты в отпуск Предоставляем технику для работы на ваш выбор Команда: Мы стараемся нанимать тех, с кем нам хорошо, поэтому работой дело не ограничивается Вместе мы занимаемся спортом, ездим на шашлыки, ходим на внешние хакатоны, играем в настолки, ну и бары, куда же без них Возможности для роста и развития: Сбермаркет активно развивается и растет, что дает возможности роста горизонтально, вертикально и диагонально Внешнее и внутреннее менторство. Если вы знаете классного эксперта и хотите обсудить ваш рабочий проект, это приветствуется и финансируется Бюджет на обучение Поддержка участия в хакатонах - команда из опытных хакатонщиков, days off, сервера Корпоративная культура: Открытость: мы умеем давать обратную связь корректно и вовремя Свобода и ответственность: мы верим, что выдающийся результат достижим при максимальной свободе в принятии решений Fail fast: ошибки это “ок”, для инноваций они необходимы, главное не повторять одни и те же и быстро тестировать гипотезы А еще: Мы не работаем ""в стол"", мы сами отвечаем за полный цикл жизни гипотезы - от рисерча в ноутбуке до выкатки на продакшн Мы уделяем большое внимание обучению сотрудников, поэтому в нашей knowledge base можно найти много интересных курсов, книг и записей конференций Мы сами участвуем в конференциях, как спикеры Проводим внутренние митапы и дискуссионные клубы Не боимся экспериментировать с новыми решениями и технологиями У нас Pet friendly офис. Отправляй своё резюме и становись частью огромной дружной команды!","Python,NLP,Pandas,Machine Learning,ML,Data Science",СберМаркет,
16745,77949666,Middle Data Scientist (Северсталь Диджитал),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Мы продолжаем развивать наше ML направление в Северсталь Диджитал, наши модели управляют обжиговыми машинами, помогают производить чугун, определяют неисправное оборудование по изображению и данным с датчиков, детектируют поверхностные дефекты листа, управляют скоростью трех ключевых агрегатов на плоском прокате, в том числе с помощью Reinforcement Learning, прогнозируют рыночные цены на сталелитейную продукцию, экономят мазут и электроэнергию. Наш технологический стек включает в себя: Python 3 со стандартными DS пакетами (numpy, pandas, scikit-learn, xgboost/lightgbm Технологии Big Data (Hadoop, Hive, Spark) Git, Graylog, Grafana, Kubernetes, Docker В твои обязанности будет входить: Собирать данные из внутренних баз данных и работать с внешними источниками информации Применять анализ данных и алгоритмы машинного обучения для решения производственных задач Реализация и поддержка end-to-end продакшн решений (в команде с дата-инженером и разработчиком) Тесное общение с технологами на производстве Взаимодействие с заказчиком и презентация продукта Со временем возможно менторство над 1-2 джунами Командировки на производство в г. Череповец ( не более 10%). Тебе нужно уметь: Писать понятный и воспроизводимый код Формулировать и проверять на данных статистические гипотезы Подбирать предпосылки и алгоритм машинного обучения, соответствующие поставленной бизнес-задаче, выбирать метрики и оценивать работу алгоритма Трансформировать бизнес-постановку задачи в математическую формулировку и код Ожидаем: Опыт самостоятельной реализации DS проектов и готовность о них рассказать Опыт дизайна экспериментов и проведения пилотных испытаний Плюсом будет: Опыт работы с промышленными данными Опыт работы с алгоритмами оптимизации (пакеты gurobi/cplex/pulp) Опыт работы с семействами моделей ARIMA-GARCH Участие в ML-соревнованиях Знание Tensorflow/Pytorch. Тебе нужно знать: Python и пакеты нашего стека SQL на уровне запросов средней сложности Теорию вероятностей и математическую статистику Принципы работы алгоритмов машинного обучения (линейная регрессия, логистическая регрессия, деревья решений, случайный лес, градиентный бустинг, нейронные сети и др.) Мы предлагаем: Работу в профессиональной команде, которая готова делиться знаниями и опытом Офис на м. Войковская, МЦК Балтийская или МЦД Красный Балтиец или удаленная работа График работы 5/2 (40 часов в неделю), гибкое начало дня Официальное трудоустройство Корпоративную мобильную связь, медицинскую страховку и страхование жизни Современное рабочее пространство и уютные зоны отдыха Спортзал и велопарковку Оплату дистанционных курсов и участия в профессиональных конференциях.","Python,Tensorflow,SQL,Machine Learning,Git",Северсталь. IT & Digital,
16746,79110323,Data scientist (Управление рисками корпоративных клиентов),з/п не указана,1–3 года,"Полная занятость,полный день","Мы — амбициозная и дружная команда, ежедневно исследующая данные корпоративных клиентов Сбербанка. Наши модели – двигатель не имеющих аналогов в России продуктов в сфере управления рисками корпоративных клиентов. Сводная статистика о нас: Мы решаем задачи по 8 основным направлениям (от монументального ПВР до всеобъемлющих графов и молодого и амбициозного ESG) 95% наших моделей разрабатываются с применением облачных технологий Мы придерживаемся единого стандарта работы, используем JIRA/Confluence/BitBucket, у нас есть единый бэклог 25% нашей команды имеют западное образование и опыт работы в странах Европы Мы сотрудничаем с передовыми ВУЗами в 3-ёх городах России Просрочка по кредитному продукту на основе наших моделей стремится к 0. В команде с заказчиками мы: Погружаемся в предметную область Прорабатываем постановку задачи щем и исследуем данные Выбираем оптимальные методы моделирования Разрабатываем и верифицируем модели Готовим отчеты о разработке и презентуем результаты Мониторим модели Наслаждаемся результатом. В рамках работы над задачей мы будем: Разрабатывать и улучшать инструменты для машинного обучения (внутренние наработки, библиотеки) спользовать прогнозное моделирование, чтобы оптимизировать бизнес риск метрики Работать в команде с портфельными менеджерами, чтобы понять нужды бизнеса и предложить возможные решения Разрабатывать модели машинного обучения Разрабатывать архитектуру пилотов для тестирования гипотез Прокачивать коллег и развиваться самим. Качественные факторы кандидатов с высоким Feature important: Диплом в области компьютерных наук, статистики, прикладной математики или другой релевантной области Опыт работы от 3х лет с одной или несколькими СУБД: Oracle, MS SQL, Teradata либо СУБД стэка Bigdata Опыт работы с хранилищами данных от 1го года Опыт работы в роли аналитика с функцией подготовки выгрузки данных для заказчика Сильные компетенции в области реляционных СУБД и хранилищ данных: Глубокое понимание статистических подходов и методов (регрессия, свойства распределений, оценка максимального правдоподобия, проверка гипотез и их правильное использование) и опыт их применения Знания и опыт применения алгоритмов машинного обучения (GLM/Regression, Trees, Random Forest, Boosting), а также знание их преимуществ, недостатков и ограничений Приветствуется знание принципов работы нейронных сетей и опыт использования библиотек для их обучения (Keras/PyTorch/TensorFlow) Знание Python и основных DS библиотек Отличные знания английского языка (устный и письменный) как преимущество Опыт в распределённых/параллельных вычислениях с помощью следующих технологий: Hadoop, Spark, Dask и другие как преимущество А ещё у нас есть: Развитая IT архитектура. Мощный GPU кластер, возможность расчётов на суперкомпьютере top30 в мире Работа над передовыми задачами в банковском секторе Постоянное развитие: обучающие курсы от лучших университетов и компаний (МФТ, ВШЭ, NVIDIA и другие), участие в международных конференциях Большую сильную команду Развитое DS community.",,Сбер. Data Science,"Санкт-Петербург, Старо-Петергофский пр., д.30"
16747,78007068,Data scientist,з/п не указана,1–3 года,"Полная занятость,полный день","LC Group - международная, аккредитованная IT-компания. С 2016 года реализуем сложные и амбициозные проекты в разных странах: Мексике, ЮАР и России. Наша компания уже несколько лет развивает и поддерживает собственные продукты: сервисы для клиентов и сотрудников компании. Создаем банковскую систему, которой ежедневного пользуется 152 000 клиентов. Мы сохранили в себе важный плюс от стартапа: гибкость, скорость принятия решений и энтузиазм в достижении поставленных целей! Наша команда насчитывает более 100 единомышленников. Приглашаем присоединиться к нашей команде! Чем предстоит заниматься: Подготовка и валидация данных, документирование пайплайнов Адаптация имплементаций методов машинного обучения под различные бизнес-требования Обучение и валидация дискриминационной способности машинных моделей Решение задач, связанных с применением Байесовой статистики в доказательных целях. Наши ожидания: Твёрдые знания в области классического(неглубокого) машинного обучения и Байесовой (доказательной) статистики Знание основных библиотек для машинного обучения и обработки данных на Python Знание Sql Знание ООП, дисциплинированность, культура и умение поддерживать структурированность кода Английский язык: уверенное чтение и понимание англоязычной документации и профильных статей. Что ты получишь от работы с нами: Атмосферу стабильности и безопасности, так как мы работаем в полном соответствии с ТК РФ Сильную команду, которая любит то, что делает — будет что обсудить и перенять опыт коллег Возможность проявлять инициативу и стать реальным двигателем изменений в компании. Мы всегда готовы обсуждать и реализовывать лучшие идеи Регулярные ревью, ретроспективы на проектах, индивидуальный подход к твоему развитию Прозрачная система грейдов и рыночный уровень заработных плат Комфортный офис на выходе из м. Октябрьская. С нами надёжно: ДМС со стоматологией. Наши сотрудники лечатся в лучших клиниках города. Система корпоративных бенефитов. Широкий выбор скидок с учетом разнообразия предпочтений. Есть возможность изучать английский язык и посещать фитнес-клубы недалеко от офиса. Насыщенная корпоративная жизнь. Регулярные корпоративы и праздники. Обучение за счет компании. Конференции и курсы для повышения профессионального уровня. LC Group — место, где ты можешь создавать технологичный продукт в команде с заинтересованными людьми.",,LC Group,"Новосибирск, Октябрьская, улица Кирова, 48"
16748,79254598,Lead Data Scientist ML/СV,з/п не указана,3–6 лет,"Полная занятость,полный день","В задачи команды Sber AI входит создание промышленных прототипов от коммуникации с заказчиком (вплоть до формулирования задачи) до передачи прототипа на промышленную реализацию. Задачи, которые придется решать, позволят с одной стороны попробовать методы сегодняшнего дня, а с другой не уходить в чистую науку, и увидеть результат своей работы в практических применениях. Основной фокус разрабатываемых прототипов - disrupt который они вносят в существующий бизнес процесс. Например создание системы цифрового агронома - это наша задача, (даже если в моменте прибыль видна только в перспективе), а вот улучшение модели оценки кредитного рейтинга (которой уже 100500 версий) - нет. Обязанности Разрабатывать ML - математические модели в различных проектах Сбер, Участвовать в развертывании решений на промышленные системы Сбер и его клиентов. Требования Аналогичный опыт работы от 4х лет Образование: высшее техническое Работа с данными (ex. как проверить корректность выбора тестового набора) Математическое моделирование (ex. зачем нужна регуляризация) Программирование (ex. конструкции конкретного языка, ООП) Мат.статистика (ex. что такое критерий хи^2) нтерпретация и презентация данных Английский для чтения документации Уверенное владение языками разработки Python, Spark Плюсом будет: Умение вести коммуникацию с заказчиком Опыт ведения промышленной разработки (работа с jira, git и т.п.) Знание DevOps процесса для моделей Английский выше Upper Intermediate Научные работы и опыт участия в научных конференциях (в качестве докладчика, стендиста) (просьба предоставлять ссылки). Условия ипотека выгоднее для каждого сотрудника и льготные условия кредитования бесплатная подписка СберПрайм+ скидки на продукты компаний-партнеров: Okko, Сбер Маркет, Delivery Club, Самокат, Ситимобил, Сбер Еаптека и другие ДМС с первого дня и льготное страхование для близких корпоративная пенсионная программа курсы для будущих родителей, материальная поддержка и тематическое сообщество для молодых мам детский отдых и подарки за счет Компании обучение за счет Компании: онлайн курсы в Виртуальной школе Сбера и неограниченный доступ к библиотеке, обучение в Корпоративном университете, тренинги, митапы и возможность получить новую квалификацию реферальная программа для сотрудников: можно пригласить в команду знакомых профессионалов и получить вознаграждение до 100 тыс. рублей скидки на отдых в лучшем в мире курортном комплексе «Mriya Resort & SPA» в Ялте.",,Сбер для экспертов,
16749,79258367,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","В команду корпоративного поиска и рекомендательной системы Сбера ищем DS Senior с уверенными знаниями NLP. Что нужно сделать: Необходимо улучшить поисковый механизм путем внедрения семантических моделей, для лучшего отбора кандидатов и ранжирования. Принимать участие в разработке архитектуры высоконагруженного решения с быстрым откликом, совместно с командой поиска. Экспериментировать с различными подходами к ранжированию. Решение задач Spell Check, Query Understanding, Query expansion, Ranking дем в сторону BERT Embeddings и правильному дообучению на специфике банка. Что мы предлагаем: Официальное оформление по ТК РФ График работы 5\2, 8-ми часовой рабочий день с возможностью смещения начала-окончания рабочего дня Социальный пакет (ДМС, английский язык, фитнес) Возможность обучения и сертификации за счет компании Дисконт-программа от компаний партнеров Субсидирование ипотечной ставки Крупные и уникальные проекты в развивающейся компании Насыщенная корпоративная жизнь Уровень заработной платы обсуждается в индивидуальном порядке","Python,pandas,NLP,RecSys",Сбер. IT,"Москва, Верхние Котлы, Нагатинская, Новоданиловская набережная, 10"
16750,76954383,Lead data scientist (Анализ цены и Trade in),з/п не указана,3–6 лет,"Полная занятость,полный день","Про направление: наша цель - сделать самый точный инструмент предсказания рыночный цены и ликвидности объектов на рынке недвижимости. Сейчас наши модели используются для одобрения объектов при выдачи ипотеки и активно внедряются на витрину объявлений как инcтрументы оценки для всех пользователей.  Описание задач: Во-первых, мы строим модели, которые позволяют оценивать рыночную стоимость разных типов объектов недвижимости (квартиры на вторичном рынке, новостройки, загородная недвижимость и т.п.), в разных сегментах и срезах. Во-вторых, мы развиваем наш инструмент анализа цены для задач Trade-in и переходим от задачи анализа цены отдельной квартиры к задаче управления портфелем. В команде Trade-in'а накапливается портфель объектов, и задачей команды DS будет улучшать работу сбытовой политики, наполнения портфеля и просчета экономики. Позиция подразумевает функции лида команды: - Выстраивание доверительных отношений с вертикалью разработки и бизнеса, а также смежными командами - Формализация задач от бизнеса - Активное участие в проработке архитектур моделей и исследований внутри команды - Построение системного мониторинга продовых моделей Требования: Практический DS-опыт (от 2 лет). Опыт полного цикла решения ML задачи: предобработка данных, выбор алгоритмов и тюнинг их параметров, оценка качества моделей, визуализация Знание математики (линейная алгебра, мат. статистика, методы оптимизации) Уверенное владение Python (PyData: Pandas, NumPy, SciPy, scikit-learn, pytorch/keras/TensoFlow и т.д.) SQL (window functions, subqueries). Мы используем postgres и clickhouse. Высшее математическое, программистское или техническое образование Понимание алгоритмов машинного обучения: линейные модели, бустинги на деревьях, нейронные сети Будет плюсом: Опыт работы с моделями прогнозирования цены и спроса Мы предлагаем: работу в аккредитованной IT компании конкурентную заработную плату полис ДМС с первого месяца работы корпоративный университет, онлайн-курсы для повышения квалификации, конференции, митапы фитнес-зал в здании офиса льготную программу ипотеки для сотрудников MacBook (или другой ноутбук на выбор) + дополнительные мониторы и т.д. комфортный офис класса А в 5 минутах от станции метро и МЦК Кутузовская гибкое начало рабочего дня и возможность работать в гибридном или удаленном формате.",,Домклик,
16752,77949850,Middle Data Scientist (Северсталь Диджитал),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Мы продолжаем развивать наше ML направление в Северсталь Диджитал, наши модели управляют обжиговыми машинами, помогают производить чугун, определяют неисправное оборудование по изображению и данным с датчиков, детектируют поверхностные дефекты листа, управляют скоростью трех ключевых агрегатов на плоском прокате, в том числе с помощью Reinforcement Learning, прогнозируют рыночные цены на сталелитейную продукцию, экономят мазут и электроэнергию. Наш технологический стек включает в себя: Python 3 со стандартными DS пакетами (numpy, pandas, scikit-learn, xgboost/lightgbm Технологии Big Data (Hadoop, Hive, Spark) Git, Graylog, Grafana, Kubernetes, Docker В твои обязанности будет входить: Собирать данные из внутренних баз данных и работать с внешними источниками информации Применять анализ данных и алгоритмы машинного обучения для решения производственных задач Реализация и поддержка end-to-end продакшн решений (в команде с дата-инженером и разработчиком) Тесное общение с технологами на производстве Взаимодействие с заказчиком и презентация продукта Со временем возможно менторство над 1-2 джунами Командировки на производство в г. Череповец ( не более 10%). Тебе нужно уметь: Писать понятный и воспроизводимый код Формулировать и проверять на данных статистические гипотезы Подбирать предпосылки и алгоритм машинного обучения, соответствующие поставленной бизнес-задаче, выбирать метрики и оценивать работу алгоритма Трансформировать бизнес-постановку задачи в математическую формулировку и код Ожидаем: Опыт самостоятельной реализации DS проектов и готовность о них рассказать Опыт дизайна экспериментов и проведения пилотных испытаний Плюсом будет: Опыт работы с промышленными данными Опыт работы с алгоритмами оптимизации (пакеты gurobi/cplex/pulp) Опыт работы с семействами моделей ARIMA-GARCH Участие в ML-соревнованиях Знание Tensorflow/Pytorch. Тебе нужно знать: Python и пакеты нашего стека SQL на уровне запросов средней сложности Теорию вероятностей и математическую статистику Принципы работы алгоритмов машинного обучения (линейная регрессия, логистическая регрессия, деревья решений, случайный лес, градиентный бустинг, нейронные сети и др.) Мы предлагаем: Работу в профессиональной команде, которая готова делиться знаниями и опытом Офис на м. Войковская, МЦК Балтийская или МЦД Красный Балтиец или удаленная работа График работы 5/2 (40 часов в неделю), гибкое начало дня Официальное трудоустройство Корпоративную мобильную связь, медицинскую страховку и страхование жизни Современное рабочее пространство и уютные зоны отдыха Спортзал и велопарковку Оплату дистанционных курсов и участия в профессиональных конференциях.","Python,Tensorflow,SQL,Machine Learning,Git",Северсталь. IT & Digital,
16754,79090323,Middle/Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Дирекция мониторинга Agile занимается повышением прозрачности change-деятельности Сбера. Мы собираем данные по всем процессам в Банке, анализируем их и предоставляем для каждого уровня управления – от членов Правления Банка до владельцев продуктов – необходимую информацию для принятия решений на нашем дэшборде. Наша команда состоит из бизнес и Т-сотрудников, которые совместно работают над digital-инструментом мониторинга. Мы продолжаем увеличивать охват и глубину мониторинга и поэтому нуждаемся в новых силах. Мы ищем в команду middle/senior data scientist, который вместе с нами будет развивать бизнес-логику нашей системы мониторинга и готов комплектно решать задачи – от поиска проблем, проведения аналитики и подбора вариантов решения с помощью данных до работающих в production витрин, дэшбордов, алгоритмов и ML-моделеи. Обязанности Что нужно делать: - Погружаться в нюансы процессов и участвовать на встречах с пользователями - Разрабатывать прототипы pipeline сбора и обработки данных - Обучать модели машинного обучения и доводить их до production - Рассказывать внутри команды про свое решение и метрики Требования Что нужно уметь: - Обрабатывать и визуализировать данные с помощью Python (pandas, numpy, scipy, matplotlib, etc.) - Готовить витрины с помощью базового SQL (join’ы, оконки) - Писать качественный код: функциональный и ООП (pep 8) - Упаковывать модели в контейнер (Git, Docker, Linux) - Обучать классические модели машинного обучения (sklearn, lightgbm, catboost) - NLP: обрабатывать текстовые данные и применять нейронные сети к ним (nltk, genism, TF-IDF, word2vec, Bert, etc) Будет плюсом: - Знание алгоритмов и структур данных, желание писать качественный код - Умение автоматизации процесса мониторинга качества моделей и их калибровка Что мы ждем от кандидата: - Опыт работы DS от 2 лет - Уверенное знание математической статистики, базовых алгоритмов машинного обучения и NLP алгоритмов - Сильные аналитические навыки – умение найти и собрать релевантные данные, критически их оценить и сделать качественные выводы - Хорошие устные и письменные коммуникационные навыки, умение простым и понятным языком объяснять сложные вещи. Условия - Возможность решать амбициозные и инновационные задачи на пике технологических трендов в крупнейшем банке Восточной Европы - Работа в команде профессионалов - Офис бизнес-класса у метро Кутузовская со спортзалом - Возможности для профессионального развития и самореализации, участие в профильных конференциях и тренингах за счет Банка - Социальный пакет для сотрудников (ДМС, фитнес, льготные условия кредитования).",,Сбер для экспертов,
16755,78107782,Data Analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","MAIN RESPONSIBILITIES: Working in Data Science team Leads the roll out of new or enhanced statistical sample based services. Ensures following best practices in sample based measurements. Consults with internal and external clients and helps provide expert consultation to solve complex data quality related issues. Ability to turn numbers into stories our clients can understand and respond to. Compiling and delivering documentation material such as power point slides for methodology questions and/or frequently asked questions. Works cross team to provide a professional, clear response to all clients. REQUIREMENTS: Master (or equivalent) in Statistics, Math, Economics, Computer Science or a related field Excellent knowledge of statistics and mathematics English - from Intermediate level Exceptional aptitude for data analysis and creative problem-solving R, Python, SQL or similar skills as a plus Proficiency in Excel, PowerPoint and Word A high degree of accuracy and attention to detail A strong communicator who is able to explain technical issues in a non-technical way Broad industry knowledge and methodologies is a benefit Excited by challenges, pro-actively interacting with others WE OFFER: Competitive salary Life and health insurance Corporate laptop and sim-card Work in an international, multicultural environment Access to learning platforms, mentorship programms and educational support to keep developing your skills Peer-to-peer recognition program to enable feedback sharing and reward your achievements Employees are provided access to PrimeZone Corporate Benefits Program (fitness, travel, restaurants, entertainment, etc.) Social and corporate events Office is near Tretyakovskaya metro station (Hybrid working module). ABOUT NIELSENIQ We are the most trusted source for complete consumer intelligence as we have for nearly 100 years. Our ability to provide global retailers, manufacturers and partners with the most comprehensive data, analysis and insights will remain unmatched. We deliver the complete truth. That’s why we are unrelenting in our pursuit of the most comprehensive data sets, measuring all transactions equally to deliver the knowledge people need. Our best-in-class data scientists and analysts simplify the complexity of this information, illuminating powerful insights through clear, compelling stories. We capture the world as it truly is to enable leaders to look forward and empower businesses to make decisions with confidence. Check our current job openings now to begin your NielsenIQ journey.",,NielsenIQ,
16756,78632406,Junior Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","О команде: Кросс-функциональная команда DS/MLE/DA/DE спользуем передовой стек и лучшие практики построения ML систем Держим руку на пульсе современных решений, моделей и подходов O Роли: Data Scientist - это специалист, который обрабатывает и анализирует массивы больших данных, чтобы с использованием алгоритмов машинного обучения найти в них новые связи и закономерности и построить прогнозную алгоритмическую модель, которую можно использовать для решения задач бизнеса. Вам предстоит: Разработать модели машинного обучения под различные бизнес-задачи Работать над улучшением и поддержкой наших существующих решений Оценка влияния новых переменных на предиктивную способность существующих моделей Мы ожидаем от вас: Базовые понятия статистики и алгоритмов ML Базовое владение основными библиотеками на Python (pandas, numpy, matplotlib, seaborn, etc.) Умение применить классические алгоритмы машинного обучения (LR, XGBoost/LGBM/CatBoost) SQL Опыт работы с AirFlow и MlFlow Знания в области deep learning Широкий кругозор в ML и DL алгоритмах Технологии: Языки программирования: Python, Bash. ML-моделирование с помощью: PyCaret, Tensorflow, Scikit-Learn, Catboost и проч. Анализ данных: SQL, BI (Metabase), а также Pandas, Matplotlib, Plotly и проч. Деплой: Docker Compose, Kubernetes, Helm, MLFlow, Jaeger, Sentry Хранилище: совместимые с S3.",,Alif Tech,
16757,78854296,Data Engineer (удалённо),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Компания «АЙ-ТЕКО» — ведущий российский системный интегратор и поставщик информационных технологий для корпоративных заказчиков. Активно действует на рынке IT России с 1997 года, входит в ТОП-400 крупнейших российских компаний, ТОП-10 крупнейших IT-компаний России. В СВЯЗ С АКТВНЫМ РАЗВТЕМ ВНУТРЕННХ ПРОЕКТОВ В КОМПАН ОТКРЫТА ВАКАНСЯ DATA ENGINEER. ТРЕБОВАНЯ: Опыт работы от 1 года и более в таких областях как: коммуникационные технологии, безопасность, маркетинг и продажи, финансы Знание SQL на высоком уровне (в т. ч. DDL, табличные выражения, оконные функции)  Опыт работы с Hive, PostgreSQL  Опыт разработки ETL процессов Spark на Scala (потоковая обработка как преимущество) Опыт использования AirFlow или другими оркестраторами – Oozie, Luigi, ну или cron Знание Python – в объеме чтобы пользоваться AirFlow или еще круче Опыт потоковой разработки конвейеров данных в NiFi или Flink Опыт проектирования базы данных (знает Data Vault 2.0 например) Понимание принципов работы реляционных СУБД и HDFS меет представление о колоночных и NoSQL СУБД нтересуется Flink, пробовал применять его в проектах. ЗАДАЧ: Анализ требований к витринам данных (взаимодействие с владельцем продукта, BI-разработчиками, data scientist-ами) Поиск и исследование источников данных для последующей интеграции Оценка пригодности, качества исходных данных Разработка ETL процессов на Spark Оркестрация ETL процессов в Airflow Проектирование баз данных Создание конвейеров данных NiFi . УСЛОВЯ: Работа в аккредитованной Т-компании Оформление в соответствии с ТК РФ с первого дня работы Возможность работать в удаленном формате Мы заботимся о здоровье наших сотрудников: предоставляем скидки на посещение фитнес-клубов, ДМС с первого месяца работы (включая стоматологию) Работа в команде, использующей гибкий подход к разработке Работа в развивающемся IT-проекте с командой специалистов высокого уровня, возможность развития и обмена опытом.","SQL,NiFi,Spark,Python,Data Vault 2.0,ETL,Airflow,SCALA,PostgreSQL",Ц АЙ-ТЕКО,
16758,78909534,Senior Data Scientist (Комплайнс),з/п не указана,3–6 лет,"Полная занятость,полный день","Отдел исследования данных Управления Комплаенс ищет Senior DS. Основной портфель моделей команды относится к процессу выявления схем легализации доходов, полученных преступным путем. Также развиваем новое направление – ML в процессе контроля финансовых рынков (выявление манипулирования и использования инсайдерской информации). Работаем в основном с табличными данными + текстовые и графовые представления. Чем предстоит заниматься: Лидировать одно из направлений Проводить ревью кода сследовать новые источники данных, формировать новые признаки, проводить их оценку на значимость и стабильность во времени Собирать выборки для обучения и валидации моделей Проверять различные модели для решения задачи (классификация, регрессия, выявление аномалий), выбирать лучшую модель Формировать требования к витринам для команды инженеров Участвовать в пилотировании моделей, давать интерпретацию полученных результатов Анализировать результаты мониторинга работы моделей на Проме Требования: Профильное высшее образование Хорошее знание теории вероятностей и статистики Знание Python и основных библиотек (numpy, pandas, scipy, sklearn) Уверенное владение популярными алгоритмами машинного обучения и библиотеками градиентного бустинга (LightGBM, CatBoost и др.) Опыт разработки нейронных сетей на PyTorch Умение обрабатывать большие объемы данных на PySpark Условия: Бесплатные фитнес залы в офисе ДМС с первого дня и льготное страхование для близких Выгодная ипотека для каждого сотрудника и льготные условия кредитования Скидки на продукты компаний-партнеров Онлайн курсы в Виртуальной школе Сбера и обучение в Корпоративном университете DS&AI community - регулярный обмен знаниями, опытом и лучшими практиками, интерактивные лекции и мастер-классы от ведущих ВУЗов и экспертов технологических компаний","ML,Python,PyTorch",Сбер для экспертов,
16759,78769739,Data Scientist / Дата-сайентист,з/п не указана,1–3 года,"Полная занятость,полный день","Привет! Мы — ООО «Датаномика», решаем проблемы структурирования разнородных данных, которые сложно поддаются анализу, помогаем среднему и малому бизнесу, банкам, ритейлу использовать данные чеков для оценки конъюнктуры спроса и экономических показателей, помогаем банкам повысить качество сервиса финансового планирования и аналитики для клиентов. Сейчас у нас открыта вакансия ""Data Scientist"" на проект в крупный российский Банк. Задачи проекта: Аналитика данных банка (транзакции, переводы, платежи, проводки) и экосистемы (история покупок в приложениях) с целью: Построения бизнес интерпретируемых атрибутов на клиента (спортсмен, автомобилист и т.д.) Формирования полезных фичей для моделей Построения клиентской аналитики. Команда проекта: 9 человек ( 3 DS, 4 DA, 2 DE). Чем предстоит заниматься: Анализом клиентской базы Банка и выделением паттернов клиентского поведения, например: необходимо выделить в клиентской базе Банка потенциальных ВПов (клиентов, с высоким доходом) Анализом текущих випов (используем Greenplum(postgres), Hadoop (spark)) Формированием атрибуты, которые хорошо разделяют випов от других клиентов (используем Greenplum(postgres), Hadoop (spark)) Построением модели (python, pyspark) Выводом результатов модели в пром (scala) Ключевые показатели эффективности: Рост количества атрибутов на клиента Прирост качества моделей склонностей к продуктам Банка и Экосистемы Доп. эффект в пилотах. Необходимые знания и навыки: Опыт работы в аналогичной должности от 2х лет Навыки работы с неструктурированными данными Python Spark/Pyspark Основы машинного обучения Математическая статистика, А/Б, проверка гипотез Будет преимуществом опыт работы с: Нейронными сетями Большими данными. Мы предлагаем: Работа в Т-аккредитованной компании Работа в офисе full time (без удаленного доступа) по адресу: Кутузовский проспект, 32 График работы 5/2, гибкое начало рабочего дня Официальная «белая» зарплата Оформление с первого рабочего дня, полное соблюдение ТК РФ нтересные, амбициозные задачи с достижимым результатом, понятным заказчиком и продуктом Достаточную свободу действий, инструментарий и необходимые ресурсы Регулярное обучение и профильные конференции, современное оборудование для работы.","Python,Математическая статистика,Machine Learning,Big Data,Pyspark,Spark",Datanomica,"Москва, Кутузовская, Кутузовский проспект, 32"
16760,67924416,Senior Data Scientist/ML Engineer SberDevices,з/п не указана,3–6 лет,"Полная занятость,полный день","SberDevices - инновационное направление компании, которое создает умные устройства, виртуальные ассистенты и другие продукты в области NLP, gamedev, computer vision.  Команда поиска ищет Senior Data Scientist/ML Engineer. Мы создаем поисковый движок, который работает со множеством различных данных. Например, у нас есть поиски по видео, музыке и другим доменам. Мы работаем с самыми совеременными технологиями, используем Hadoop, применяем разнообразные методы машинного обучения, улучшаем множество продуктов экосистемы Сбербанка, помогая пользователям найти то, что они хотели.  Если ты всегда хотел работать на стыке науки и технологии, и готов не просто решать технически сложные задачи, но и глубоко погрузиться в тематику машинного обучения, начиная от внедрения уже обученных моделей и заканчивая самостоятельной реализацией новых алгоритмов из последних статей -- то ты наш идеальный кандидат  Обязанности: участие в разработке поискового движка разработка и оптимизация алгоритмов машинного обучения внедрение в продакшн ML решений  Требования: уверенное владение Python на рабочем уровне хорошее знание классических алгоритмов и структур данных базовые знания и желание развиваться в области машинного обучения и анализа данных  Будет плюсом: владение C++ на рабочем уровне опыт реализации и внедрения алгоритмов машинного обучения понимание принципов работы высоконагруженных интернет-сервисов знакомство с алгоритмами обработки больших данных и парадигмой MapReduce  Условия: Самые инновационные, амбициозные проекты и задачи Профессиональное обучение, семинары, тренинги, конференции, корпоративная библиотека ДМС, страхование жизни Свободный дресс-код Гибкий график для оптимального баланса работы и личной жизни Льготные кредиты и корпоративные скидки Конкурентная компенсация (оклад и премии по результатам деятельности).","Python,NLP,Deep Learning,Linux,Docker",СБЕР,
16761,79255279,Senior Data Scientist (Rec. system),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы делаем рекомендательную систему, которая является одним из ключевых ML-сервисов в Okko. Простые задачи мы уже решили, остались интересные. Обязанности: исследование применимости различных алгоритмов в рекомендательной системе моделирование входных данных имплементация исследованных моделей. Требования: знание основ статистики понимание классических ML-алгоритмов опыт и понимание в DL (предпочтительнее pytorch) понимание процесса исследования и внедрения ML-моделей навыки презентации результатов – упрощать несущественные детали, оставляя суть способность проанализировать статьи и имплементировать описываемые алгоритмы знание SOTA в рекомендательных системах знания Python3.7+. Что мы используем: Python (sklearn, catboost, xgboost, seaborn, numpy, scipy, statsmodels) Базы данных и SQL: Trino, ClickHouse, PostgreSQL, Redis, etc. Для автоматизации процессов: Airflow, FlaskAPI/FastAPI, Python демоны BI-инструменты: Splunk Bitbucket, Jira, Confluence. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,deep learning,ML",Okko,
16762,79255262,Senior Data Scientist (Rec. system),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы делаем рекомендательную систему, которая является одним из ключевых ML-сервисов в Okko. Простые задачи мы уже решили, остались интересные. Обязанности: исследование применимости различных алгоритмов в рекомендательной системе моделирование входных данных имплементация исследованных моделей. Требования: знание основ статистики понимание классических ML-алгоритмов опыт и понимание в DL (предпочтительнее pytorch) понимание процесса исследования и внедрения ML-моделей навыки презентации результатов – упрощать несущественные детали, оставляя суть способность проанализировать статьи и имплементировать описываемые алгоритмы знание SOTA в рекомендательных системах знания Python3.7+. Что мы используем: Python (sklearn, catboost, xgboost, seaborn, numpy, scipy, statsmodels) Базы данных и SQL: Trino, ClickHouse, PostgreSQL, Redis, etc. Для автоматизации процессов: Airflow, FlaskAPI/FastAPI, Python демоны BI-инструменты: Splunk Bitbucket, Jira, Confluence. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,deep learning,ML",Okko,"Москва, Баррикадная, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с13"
16763,77986075,Senior/ Middle data scientist (жизненный цикл клиента),з/п не указана,1–3 года,"Полная занятость,полный день","щем Data scientist-а в команду моделирования «Управление жизненным циклом клиента». Фокус разработки на бизнес-моделях для сегментов СМБ и КБ. ОБЯЗАННОСТ: Разработка моделей склонности к продуктам (look-alike, response, uplift) Разработка моделей оттока Разработка моделей кошельков (определение доли продукта на рынке) Развитие инструментов моделирования A/B тестирование Наставничество над младшими сотрудниками. ТРЕБОВАНЯ: Высшее образование (математическое, экономическое, техническое) Опыт в построении рекомендательных моделей от 2-х лет Опыт лидирования младших специалистов Стек: Python, SQL/Spark/Hive, опционально - Airflow Знание классического ML, математической статистики Будет плюсом знание нейронных сетей. УСЛОВЯ: Трудоустройство согласно Законодательству Конкурентная заработная плата Профессиональное обучение и развитие Добровольное медицинское страхование, льготные условия кредитования Корпоративная пенсионная программа, материальная помощь Спортивная жизнь и корпоративные мероприятия Возможность построить карьеру в ведущем банке России.","Python,SQL,Spark,Hive,Airflow,ML,CLTV","ПАО ВТБ, Технологический блок","Москва, Выставочная, Московское центральное кольцо, станция Деловой центр"
16764,77567000,Senior\Middle Data Scientist (Big Data),от 250 000 до 400 000 руб. до вычета налогов,1–3 года,"Полная занятость,полный день","Кто мы: Отдел занимается сбором, анализом и структурированием внешних и внутренних данных, построением, валидацией, внедрением как в real time так и в offline процессы построенных моделей для различных департаментов банка. Мы уже разработали и внедрили в систему принятия решений Банка ряд моделей. В частности, модели с использованием ML/DL/CV для кредитного скоринга (RNN-ки на транзакциях / социальный граф по окружению клиента), выявления мошенников по фотографиям (face detection + face matching), выявление агентского фрода, махинаций с персональными данными, речевая аналитика для автоматизации коммуникации с клиентами, рекомендательные системы и др. Кого мы ищем: В команду Big Data ищем Middle Data Scientist. Что тебя ждет: Проведение Proof-of-Concept по возможности построения моделей, решающих конкретные бизнес-задачи (например, подтвердить возможность выделение из разговора с клиентом конкретной причины недовольства для повторной коммуникации). Оценка ценности новых источников данных для принятия решений об их подключении. Разработка и построение моделей по успешным PoC или новым источникам данных. Продукционализация и поддержка моделей (документирование, мониторинг, контейнеризация, установка на шедулер airflow). Мы ждем от тебя: Уверенное знание математики, алгоритмов машинного обучения, статистики, алгоритмов и структур данных. Уверенное владение sql (Oracle/PostgreSQL). Классический стек на python (pandas, numpy, sklearn, xgboost, etc.) и хотя бы один DL-framework (tensorflow / keras / pytorch). Владение английским на уровне чтения и написания технической документации. Плюсом будет опыт вывода разработанных решений в prod (luigi/airflow для jobов и async/await фреймворков flask, sanic, etc.), а также знание docker, git, bash. Особенно мы ценим наличие опыта и завершенных проектов в computer vision / natural language processing / time series analysis. Мы предлагаем: Возможность создавать новые на банковском рынке решения Новый офис на метро Войковская (БЦ Метрополис) Стандартный график работы 5/2, 8-часовой рабочий день Гибридный формат работы, гибкое начало рабочего дня Оклад + годовой бонус 20% Отсутствие строгого дресс-кода (мы лояльны к любому проявлению личного стиля) Программы поощрения ОТП Мания (когда ты за внутреннюю валюту можешь купить себе как толстовку, так и day-off, например) Welcome pack ДМС (а также возможность его замены на фитнес) Льготные условия по кредитам и депозитам BestBenefits – сервис скидок и привилегий (техника и электроника, рестораны и доставка, обучение, отдых, спорт, красота и здоровье, товары, развлечения, услуги, детские товары и развлечения) Управленческое обучение, развитие навыков личной эффективности, профессиональное развитие Участие в корпоративных и спортивных мероприятиях (он-лайн и офф-лайн) Корпоративная библиотека МФ и Bookcrossing Детские подарки к Новому Году.","Python,SQL,Git","ОТП Банк, АО (OTP bank)","Москва, Балтийская, Войковская, Ленинградское шоссе, 16Ас2"
16765,76829230,Senior Data Scientist (Лимасол/Ереван),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Привет! Мы - крутая команда Click, мы успешно создаем и развиваем IT-продукты на международном рынке. Мы разрабатываем высоконагруженную рекламную платформу, позволяющую рекламодателям и владельцам ресурсов привлекать новых клиентов и пользователей. Мы используем уникальную технология сбора и обработки информации о портретах и предпочтениях посетителей интернет ресурсов, основанную на ML, наши бекэнды принимают десятки тысяч запросов на подбор рекламного предложения каждую секунду, а в DWH хранятся терабайты данных. Мы постоянно растем, и сейчас ищем Senior Data Scientist в нашу команду удаленно или с релокацией в Лимасол или Ереван! Мы предлагаем: Комфортные офисы в Лимассоле и Ереване, помощь с релокацией Возможность удаленной работы, если вы уже переехали 100% официальная заработная плата в соответствии с вашими ожиданиями и опытом Гибкое начало рабочего дня (начало с 10.00 до 12.00, окончание с 19.00 до 21.00) Полный соц. пакет (доплата до 100% оклада при отпускных и больничных) Премии по результатам работы, регулярное performance review Корпоративная техника Оплата посещений профильных конференций, компенсация курсов Сильная команда разработки и тестирования, гибкие подходы к разработке Актуальный стек и гибкость в выборе технологий CI/CD и низкий time to market Широкий спектр задач с использованием supervised, unsupervised и reinforcement learning алгоритмов Насыщенная корпоративная жизнь и мероприятия, о которых с радостью расскажем на интервью! Наши пожелания к кандидату: Python для анализа и визуализации данных и машинного обучения от 3-х лет Знание SQL (написание запросов, понимание принципов организации БД) Знание как работают традиционные алгоритмы, использующиеся для машинного обучения и опыт их практического внедрения и поддержки в производственной среде Навыки работы с количественной информацией, знания теории вероятностей и математической статистики (мы активно применяем их в работе) Умение самостоятельно конвертировать бизнес задачу в алгоритмическую, предложить метрики для оптимизации и различные методы решения. Основные задачи будущего коллеги: Работать над рекомендательными системами, используя современные теоретические наработки - Multi-Armed Bandits, Counterfactual Learning, Factorization Machines, etc. Строить полный цикл системы мониторинга и аналитики ML решений, развивать аналитическую инфраструктуру Планировать, проводить и оценивать результаты A/B-тестов, выдвигать гипотезы Совершенствовать существующие и добавлять новые метрики о состоянии рекламной сети, настраивать и улучшать автоматизированный мониторинг. Оставляйте ваши отклики здесь или в телеграм, будем рады ответить на вопросы и рассказать подробности вакансии!","Python,Математическая статистика,SQL,Статистический анализ,Pandas,Reinforcement Learning,Multi-Armed Bandits",Click,
16766,79090234,Middle/Senior Data Scientist в направление Рекомендательной платформы (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Data Scientist в направление Рекомендательной платформы Описание продукта: Кандидат присоединится к работе команды рекомендательных систем для ""Строки"" в подразделении МТС Big Data. В настоящий момент мы ищем специалистов для создания персональных рекомендаций по жанрам для текстовых и аудио книг. В перспективе планируется сделать лучшие кросс-контентные рекомендательные модели, такие как подбор музыки по ходу прочтения книги, анализ текста книги, выделение облака тегов и эмоциональную окраску текста за счет добавления музыки, соответствующей настроению текста. В ходе проектов работа будет вестись в команде с Data Science Тим лидом, который будет помогать с решением сложных технических кейсов. Обязательно: знание классического ML знание Python, опыт написания кода в прод опыт внедрения ML в прод знание статистики опыт проведения A/B-тестов SQL или Spark (опыт работы с hadoop стеком: hadoop, spark, hive) Linux (bash) GIT API - Airflow Что предстоит делать? создавать рекомендательную систему и выводить ее в прод оценивать ML модели, управлять эффективностью алгоритмов подсчитывать результаты пилотов по запускам инициатив (новая модель, новый триггер) искать инсайты в данных формировать и проверять гипотезы работать с сегментацией Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Data Science,ML,SQL,Python,Linux,Git,Docker,Big Data,Spark,Hadoop,Bash",МТС,
16767,78579913,Data Engineer,з/п не указана,3–6 лет,"Полная занятость,полный день","B2B CLTV - это проект, который позволяет прогнозировать, управлять пожизненной ценностью B2B-клиентов на основе анализа данных и построения моделей машинного обучения (Machine Learning) Обязанности: Анализ требований к витринам данных (взаимодействие с владельцем продукта, BI-разработчиками, data scientist-ами) Поиск и исследование источников данных для последующей интеграции Оценка пригодности, качества исходных данных Разработка ETL процессов на Spark Оркестрация ETL процессов в Airflow Проектирование баз данных Создание конвейеров данных NiFi. Требования: Знание SQL на высоком уровне (в т. ч. DDL, табличные выражения, оконные функции) Опыт работы с Hive, PostgreSQL Умение разрабатывать ETL процессы Spark на Scala (потоковая обработка как преимущество) Опыт AirFlow или другие оркестраторы – Oozie, Luigi, ну или cron Знаете Python Опыт потоковой разработки конвейеров данных в NiFi или Flink нтересуетесь Flink, пробовали применять его в проектах Умеете проектировать базы данных (знает Data Vault 2.0 например) Понимаете принципы работы реляционных СУБД и HDFS меете представление о колоночных и NoSQL СУБД Понимаете подходы к работе с качеством данных Стек и технологии Экосистема Hadoop – HDFS, YARN, Hive, HBase ETL-процессы – Spark (Scala) Потоковая обработка – NiFi, Flink Брокер сообщений – Kafka Оркестрация ETL процессов – Airflow СУБД – PostgreSQL, Greenplum, Aerospike, Oracle, SQL Server CI/CD – GitLab. Условия: ДМС + стоматология после испытательного. Удаленный формат работы на всей территории. Корпоративная мобильная связь. Оплата обучения по квалификации. Билайн академия.",,билайн: Контактные центры,
16768,78507209,Data scientist (math modeling),от 4 000 до 10 000 USD до вычета налогов,1–3 года,"Полная занятость,удаленная работа","О компании: разработка и внедрение финансовых стратегий для широкого спектра классов активов и глобальных рынков. Компания производит высококачественные прогностические сигналы (альфа) с помощью собственной исследовательской платформы, чтобы использовать финансовые стратегии, ориентированные на использование неэффективности рынка. Локация: офис в Армении, Венгрии. Готовность к релокации в эти страны. меется поддержка с релокацией. Команды совместно работают над созданием альфа-версий и финансовых стратегий — основы сбалансированной глобальной инвестиционной платформы. Сотрудников поощряют бросать вызов традиционному мышлению и постоянно совершенствоваться. Это ключевой компонент, позволяющий оставаться лидером в любой отрасли. Цель компании — нанять лучших и самых умных. Компания ценит в первую очередь интеллектуальную мощь и людей, демонстрирующих незаурядный талант. Благодаря тщательным исследованиям и неограниченным размышлениям о том, как применять данные к финансовым рынкам, исследователи находятся в постоянном поиске новых альфа-версий. сследователи используют проверенные процессы для выявления высококачественных прогностических сигналов, которые, по нашему мнению, не обнаружены более широким рынком. Эти сигналы представляют собой математические выражения данных, которые используются в качестве входных данных в количественных моделях. Поскольку мы преследуем нашу цель создания новых альфа-версий, нам нужны исследователи, которые приведут нас к ней. Уникальная инвестиционная платформа является лидером среди аналогов, а используемая методология является передовой. Обязанности: Построение алгоритмических математических моделей Проведение исследований академической литературы по количественным финансам изучение новых данных Применение синергии инновационных методов в прикладной математике, информатике и финансовой экономике. Требования: Соответствующий опыт в области исследований / разработки программного обеспечения (в результате трудоустройства или академической деятельности) Высшее образование (желательно наличие ученой степени) в таких предметных областях, как: математика, финансы или экономика, информатика, физика, инженерия или аналогичные сследовательский склад ума: быть глубоким мыслителем, творческим человеком, настойчивым, умным, инициативным, внимательным к деталям и т. д. Критическое мышление и способность придумывать нестандартные подходы Уверенные навыки программирования (C++ и/или Python) Хорошее знание английского языка (как устного, так и письменного) не ниже уровня Intermediate Сильная рабочая этика. Будет плюсом: Медали международных или региональных олимпиад по математике/программированию/физике Сильный послужной список академических достижений (докторская степень, научные публикации, презентации на конференциях, гранты или награды) Знание финансовой экономики, включая, помимо прочего, теорию портфеля, ценообразование активов, корпоративные финансы, деривативы и т. д. Условия работы: Динамичная работа без рутины в ведущей международной компании Конкурентоспособный компенсационный пакет, который может включать в себя годовые премии и прибавки к заработной плате Поддержка здорового баланса между работой и личной жизнью (гибкое время начала работы, отпуск по уходу за ребенком, творческий отпуск после 5 лет работы и т. д.) Возможность командировок в США и другие страны Регулярные тимбилдинги, конкурсы и корпоративы Медицинская страховка Программа поддержки сотрудников и их родственников по психологическим, юридическим и финансовым вопросам Культура непрерывного обучения: сертификация, онлайн и оффлайн обучение в Армении и за рубежом, занятия английским языком, наставничество в профессиональном развитии.","математика,data science,PHD,финансы,C/C++,MATLAB,Математическое моделирование,Английский язык,Математический анализ,Финансы,Python,kaggel,Английский — B2 — Средне-продвинутый",ITSS,
16769,68115103,Data Scientist (Рекомендательные системы),з/п не указана,1–3 года,"Полная занятость,полный день",,,Сбер. IT,"Москва, Кутузовская, Кутузовский проспект, 32"
16770,79005656,Data analyst,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы команда Digital Apps, и мы занимаемся развитием маркетинговых технологий для Сбербанка. Мы создаем инструменты сквозной аналитики, позволяющие отследить весь пользовательский путь от просмотра баннера до первой транзакции, автоматизировать запуск рекламы в Digital и эффективнее управлять ей. Наша основная цель – быть #1 в привлечение клиентов в цифровом пространстве. Обязанности: проведение анализа и оцифровка предметной области (CJM клиента) описание процесса оформления продукта с точки зрения взаимодействия систем, передачи данных, оценка их структуры, полноты и применимости описание логики выстраивания Data-pipelines, проектирование аналитических витрин данных общение с внутренними и внешними заказчиками с последующей декомпозицией задач поиск, получение доступов к существующим и новым источникам данных предоставление экспертной поддержки внутренним потребителям (data analysts, data scientists) по вопросам, связанным с использованием данных поиск и внедрение новых Martech-инструментов для роста эффективности кампаний. Требования: не менее 3-х лет работы в качестве аналитика опыт анализа/изменения бизнес-процессов знание методов и стандартов обмена данными между информационными системами, умение раскладывать use кейсы на системы и их взаимодействия знание SQL на продвинутом уровне и уверенный Python отличное знание мат статистики и теории вероятности опыт работы с данными веб-аналитических систем, кликстримами, понимание маркетинговых метрик опыт в проектировании DWH, построении модели данных в проектах big data, составления требований знание английского языка на уровне понимания технической литературы. Тех стек: Hadoop, GreenPlum, ClickHouse, Airflow & Spark, BI-инструменты (Superset, Qlik). Условия: работа в офисе класса А на 26 этаже в формате open space: быстрое развитие и level-up в профессии поддержка/ментерство коллег и руководителя в решении задач и в коммуникации регулярное корпоративное обучение гибкое начало дня (с 8 до 10) дружный коллектив и адекватные руководители работа в крупнейшей компании России трудоустройство согласно ТК РФ ДМС.",,Сбер. IT,
16771,78855362,Аналитик данных / Data Analyst / Data Scientist,от 80 000 руб. до вычета налогов,3–6 лет,"Полная занятость,полный день","НАПРАВЛЕНЕ: Анализ речевых и текстовых коммуникаций Уважаемые соискатели, обратите внимание, сотрудник требуется в офис, удаленная работа на постоянной основе невозможна. ОБЯЗАННОСТ: настройка платформы речевой и текстовой аналитики DEERAY под задачи клиента формирование отчетности с учетом потребности Заказчика проектирование, анализ, оптимизация и формирование отчетности (включая дашборды), в том числе в BI-системах формирование и проверка гипотез в рамках анализа клиентских коммуникаций построение глубокой аналитики на основе смысловой и эмоциональной составляющей клиентских коммуникаций (поиск ошибок операторов и кейсов для оптимизации, инициация изменений для сценариев продаж и обслуживания, составление рейтингов / анти-рейтингов, аналитика повторных обращений, аналитика по результатам CSI и NPS и др.) формирование аналитических отчетов к построенной аналитике, отчетности и дашбордам участие в коммуникациях с внешними и внутренними заказчиками участие в развитии продукта по своему направлению помогать в очистке данных и прочих «внутренних» задачах. ТРЕБОВАНЯ К КАНДДАТУ: высокая проактивность, нацеленность на результат и профессиональный рост продвинутый пользователь Excel, Query знание SQL, Phyton не ниже среднего уровня английский не ниже pre-intermediate (A2) высшее образование (желательно по направлению информационных технологий, экономики) умение работать с большими массивами данных практический опыт применения математических и статистических методов анализа грамотная речь (письменная и устная), коммуникационные навыки. БУДЕТ ПРЕМУЩЕСТВОМ, ЕСЛ КАНДДАТ ОБЛАДАЕТ: умением работать в тайминге, знание методологий Agile, Scrum опытом проектирования витрин данных в Yandex DataLens и/или работа с BI-системами опытом работы на аналогичной позиции опытом работы с платформами текстовой и/или речевой аналитики опытом работы с AI/ML-решениями английским upper-intermediate (B2). ЧТО МЫ ПРЕДЛАГАЕМ: оформление согласно ТК РФ, выплаты 10 и 25 числа каждого месяца работа в аккредитованной Т-компании пятидневка, по согласованию с руководителем возможен гибкий график работы или дистанционная работа культура открытости, наставничества и взаимопомощи сложные и интересные задачи возможность предлагать идеи и развивать экспертизу в сфере AI и Big Data влияние на развитие и качество продуктов корпоративное обучение ДМС карьерные перспективы в рамках компании современное оборудование и любовь к инновационным технологиям уютный офис в верхней части города (г. Нижний Новгород) с доступной парковкой, кофемашиной, корпоративной профессиональной библиотекой и многое другое. УСПЕЙТЕ ПРСОЕДНТЬСЯ К КОМАНДЕ DEERAY!","Python,Jupyter Notebook,Business Intelligence Systems,Data Analysis,Анализ данных,Аналитическое мышление,Big Data,ML,MS Excel,ETL,A/B тесты,Mathematical Statistics,SQL,Power Query,Работа в команде,Data Science,Математическая статистика,Регрессионный анализ,Статистический анализ,Git,Английский — B1 — Средний",DEERAY,
16772,77860632,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы сохранили в себе важный плюс от стартапа: гибкость, скорость принятия решений и энтузиазм в достижении поставленных целей! Наша команда насчитывает более 100 единомышленников. Приглашаем присоединиться к нашей команде Data Scientist. Мы ищем человека, который готов работать и развиваться вместе с командой. Чем тебе предстоит заниматься: Разрабатывать системы скоринга для различных стран сследовать поведенческие паттерны и находить зависимости в данных используя статистические методы анализа Моделировать поведения клиентов для решения задач маркетинга Участвовать в разработке архитектуры ML сервисов Оптимизировать и развивать уже существующие пайплайны. Наши ожидания: меешь хорошую математическую подготовку Знаешь основы статистического анализа Понимаешь принципы постановки экспериментов, проверки гипотез меешь опыт работы с Python, библиотеками scikit-learn, numpy, scipy, pandas, gbm фреймворками Владеешь инструментами визуализации данных (seaborn, plotly, matplotlib) Понимаешь микросервисную архитектуру и знаком с инструментами (Docker, Docker Compose) меешь опыт использования и понимаешь основные алгоритмы машинного обучения Понимаешь методологию разработки GitFlow Обладаешь навыками общения и умеешь донести свою точку зрения. Будет твоим преимуществом, если ты: меешь профиль в GitHub или Kaggle, которым не стыдно поделиться меешь опыт вывода моделей в прод и понимаешь их жизненный цикл Применял практики MLOps в реальных проектах меешь опыт участия в конкурсах по анализу данных Знаешь pytorch Закончил ШАД или CSC. Что ты получишь от работы с нами: Атмосферу стабильности и безопасности, так как мы работаем в полном соответствии с ТК РФ Сильную команду, которая любит то, что делает — будет что обсудить и перенять опыт коллег Возможность проявлять инициативу и стать реальным двигателем изменений в компании. Мы всегда готовы обсуждать и реализовывать лучшие идеи Регулярные ревью, ретроспективы на проектах, индивидуальный подход к твоему развитию Прозрачная система грейдов и рыночный уровень заработных плат Возможность гибридного формата работы или удаленки.","Python,Docker,Machine Learning",LC Group,
16773,77860634,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы сохранили в себе важный плюс от стартапа: гибкость, скорость принятия решений и энтузиазм в достижении поставленных целей! Наша команда насчитывает более 100 единомышленников. Приглашаем присоединиться к нашей команде Data Scientist. Мы ищем человека, который готов работать и развиваться вместе с командой. Чем тебе предстоит заниматься: Разрабатывать системы скоринга для различных стран сследовать поведенческие паттерны и находить зависимости в данных используя статистические методы анализа Моделировать поведения клиентов для решения задач маркетинга Участвовать в разработке архитектуры ML сервисов Оптимизировать и развивать уже существующие пайплайны. Наши ожидания: меешь хорошую математическую подготовку Знаешь основы статистического анализа Понимаешь принципы постановки экспериментов, проверки гипотез меешь опыт работы с Python, библиотеками scikit-learn, numpy, scipy, pandas, gbm фреймворками Владеешь инструментами визуализации данных (seaborn, plotly, matplotlib) Понимаешь микросервисную архитектуру и знаком с инструментами (Docker, Docker Compose) меешь опыт использования и понимаешь основные алгоритмы машинного обучения Понимаешь методологию разработки GitFlow Обладаешь навыками общения и умеешь донести свою точку зрения. Будет твоим преимуществом, если ты: меешь профиль в GitHub или Kaggle, которым не стыдно поделиться меешь опыт вывода моделей в прод и понимаешь их жизненный цикл Применял практики MLOps в реальных проектах меешь опыт участия в конкурсах по анализу данных Знаешь pytorch Закончил ШАД или CSC. Что ты получишь от работы с нами: Атмосферу стабильности и безопасности, так как мы работаем в полном соответствии с ТК РФ Сильную команду, которая любит то, что делает — будет что обсудить и перенять опыт коллег Возможность проявлять инициативу и стать реальным двигателем изменений в компании. Мы всегда готовы обсуждать и реализовывать лучшие идеи Регулярные ревью, ретроспективы на проектах, индивидуальный подход к твоему развитию Прозрачная система грейдов и рыночный уровень заработных плат Возможность гибридного формата работы или удаленки.","Python,Docker,Machine Learning",LC Group,
16774,78959208,Data Scientist (Middle),з/п не указана,3–6 лет,"Полная занятость,полный день","Чем нужно будет заниматься: взаимодействие с внутренними заказчиками (формулирование требований, подходов к исследованию/разработке модели и методов оценки конечного результата) анализировать множество источников данных (данные продуктов, транзакции, логи и др.) генерировать фичи и отбирать полезные для моделей строить полноценные ML-пайплайны (классический жизненный цикл ML-моделей) и делать это грамотно имплементация и обучение моделей машинного обучения проверять гипотезы, проводить A/B тестирования и пилотные проекты - оптимизация моделей - работать на внедрение результатов в продакшн. Кто нам нужен: профильное образование (техническое, компьютерные науки, статистика, математика) 3 года опыта профессиональной разработки моделей машинного обучения уверенное знание python опыт практического применения прикладных библиотек (pandas, sklearn, numpy и др.) твердые знания в области мат статистики и машинного обучения знание алгоритмов supervised и unsupervised уверенное знание sql уверенное знание Linux-систем Будет плюсом знание веб-фреймворков (django/flask) опыт работы с Hadoop, Spark, Airflow - пройденные курсы по ds/ml/cv - опыт участия в хакатонах/соревнованиях по машинному обучению - опыт участия в kaggle соревнованиях.","Python,SQL,ML,DS",Газпромбанк,
16775,79089818,Senior Data Scientist в направление рекламной платформы RnD (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior Data Scientist в направление рекламной платформы RnD Описание продукта: Рекламная платформа МТС включает в себя: 1. Программатик. DSP платформа, которая подключена ко всем популярным SSP и рекламным сетям. 2. Медиапланировщик. нструмент планирования маркетингового бюджета, определение наилучшего сплита как по основным каналам, так и внутри каналов. 3. Система аналитики. Аналитика трафика и событий. Построение MTA (Multi touch atributuon), сквозная аналитика. Обязательно: глубокое понимание статистических подходов и методов (регрессия, свойства распределений, оценка максимального правдоподобия, проверка гипотез и их правильное использование) и опыт их применения свободное владение основными библиотеками на Python (pandas, numpy, matplotlib, seaborn, etc.) коммерческий опыт применения классических алгоритмов машинного обучения (LR, RF, XGBoost/LGBM/CatBoost), понимание их преимуществ, недостатков и ограничений высокий уровень владения SQL опыт в распределённых/параллельных вычислениях с помощью следующих технологий: Hadoop, Spark, Dask и другие умение общаться с бизнес-заказчиком, объяснять простым языком полученные результаты и процесс работы алгоритма Желательно: опыт работы в медиа, понимание сферы digital рекламы стремление вникнуть в бизнес соответствующей отрасли диплом в области компьютерных наук, статистики, прикладной математики или другой релевантной анализу данных области английский язык (устный и письменный) на уровне Upper Intermediate опыт применения deep learning алгоритмов в NLP, CV направлениях (для подключения к R&D задачам) Что предстоит делать? собирать и обрабатывать данные из хранилищ компании подготавливать витрины данных, необходимые для разработки моделей машинного обучения. Задача частично закрывается data engineering специалистами разрабатывать модели машинного обучения как для MVP проектов, так и решений, выводящихся в production разрабатывать методологии применения различных ML алгоритмов для решения задач команды. подготавливать рекомендации по внедрению методологий и использованию продуктов для внутренних заказчиков компании проводить консультации и обмениваться идеями с младшими специалистами и коллегами по команде Стек технологий: Python, Pandas, Numpy, Matplotlib, Seaborn, LR, RF, XGBoost/LGBM/CatBoost, Hadoop, Spark, Dask. Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные и международные конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Python,SQL,Математическая статистика,Big Data,Machine Learning,NLP,Hadoop,Spark,Pandas,Numpy,Matplotlib,Seaborn",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
16776,78680130,Data Scientist / ML-инженер,з/п не указана,1–3 года,"Полная занятость,полный день","Медиалогия разрабатывает высоконагруженные системы, которые в режиме реального времени сканируют весь текстовый сегмент нтернета (100+ млн. сообщений в сутки, 1.7 млрд. метрик) и, используя уникальные технологии лингвистического анализа и компьютерного зрения, позволяют осуществлять мгновенный анализ упоминаний наших клиентов в соц.сетях, блогах, форумах и управлять их репутацией. Задачи: Построение и тестирование гипотез Создание моделей для задач NLP и CV Доработка и улучшение существующих моделей Анализ данных из социальных сетей: классификация, кластеризация, выявление аномалий Проведение экспериментов на ""больших данных"" и обработка результатов Требования: Уверенное знание Python и библиотек для работы с данными (numpy, pandas, sklearn, catboost и др.) Умение писать чистый хорошо структурированный код Опыт создания моделей машинного обучения на TensorFlow, PyTorch и др. Умение работать с неструктурированными контентом, правильно оценивать качество моделей Умение работать в команде, хорошие коммуникативные навыки, Желание активно развиваться и браться за самые сложные задачи. Желателен опыт работы с большими данными (Spark, Hadoop) Условия: Белая ЗП, официальное оформление по ТК РФ ДМС с хорошим выбором клиник и международной страховкой Современный офис в 10 мин от м. Дмитровская (БЦ «Савеловский Сити» с массажистом, кикером, турником и PlayStation) или полная удаленка Гибкое начало рабочего дня Возможность посещения профильных мероприятий и карьерное развитие Рядом дизайн-завод Флакон, кафе и магазины.","Python,Adobe Photoshop,Аналитические исследования,Аналитическое мышление,Статистический анализ,Machine Learning,Neural Networks,Deep Learning,Data Science,Data Analysis,Data Mining,Big Data,Анализ данных",Медиалогия,"Москва, Дмитровская, Новодмитровская улица, 2к2"
16777,79012262,Middle/Senior Data scientist (Computer Vision),з/п не указана,3–6 лет,"Полная занятость,полный день","В команду стрима ""AI продукты для бизнеса"" ищем Data Scientist уровня Middle+. На текущий момент в нашей команде 5 DS. Мы разрабатываем несколько продуктов, например платформу СберБизнесБот, представляющую из себя чат-бот для общения с клиентами, или сервис AgroAI для прогнозирования урожайности сельскохозяйственных культур на основе спутниковых снимков. Значительную часть нашей работы составляют проекты для внешних клиентов, которые мы часто выполняем в сотрудничестве со SberAI. Задачи Разнообразные проекты, связанные с NLP, CV, временные ряды Нужно будет разрабатывать много POC и MVP под разные индустрии и задачи, улучшать и дорабатывать уже существующие решения Требования Уверенное знание Python и библиотек numpy, pandas, sklearn, lightgbm Понимание принципов работы классических алгоритмов машинного обучения, их преимуществ, недостатков и ограничений Опыт решения практических NLP и/или CV задач Знакомство с основными архитектурами нейронных сетей Опыт работы с DL фреймворками, предпочтительно с PyTorch Хороший уровень математической подготовки (теория вероятности, статистика) Базовое знание алгоритмов и структур данных Будет плюсом Опыт в решении задач Data Science для бизнеса Хорошее знание git, docker Условия нтересные и масштабные задачи, интеллектуальный вызов и возможность выбрать карьеру по интересам Работу в быстро развивающейся команде Офис в центре Москвы, классную столовую, отсутствие дресс-кода Тренажерный зал премиум-класса в офисе Конкурентоспособную зарплату + годовой бонус + ДМС с первого дня","Python,NLP,Computer Vision,SQL",Сбер. Data Science,
16778,78883017,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Чем занимается Positive Technologies Мы создаем продукты для кибербезопасности. Это решения и технологии, которые защищают от хакеров и помогают проводить расследования инцидентов. Мы разрабатываем сложные высоконагруженные системы, используем алгоритмы машинного обучения, обработки и анализа данных, опенсорс-решения и адаптируем их к нашим задачам. Часть наработок мы публикуем на GitHub. Прежде чем отдавать продукты заказчикам, мы проверяем их на себе. У нас семь офисов в России (в Москве, Санкт-Петербурге, Самаре, Нижнем Новгороде, Томске и два в Новосибирске), поэтому продуктовые команды часто территориально распределены. Нас больше 1500 человек. Мы сейчас ищем Специалиста по машинному обучению в нашу команду Департамента разработки WAF (Web Application Firewall). WAF - это межсетевой экран, который обнаруживает и блокирует атаки, обеспечивает непрерывную защиту приложений, пользователей и инфраструктуры и помогает соответствовать стандартам безопасности. Чем предстоит заниматься: Проектирование математических моделей обнаружения атак на веб-приложения Разработка и прототипирование статистических методов обнаружения аномалий в трафике Поддержка и улучшение существующих алгоритмов машинного обучения в Application Firewall. Что ждём от кандидата: Уверенное знание Python, git Знание основных алгоритмов/методов машинного обучения Владение библиотеками Pytorch, sklearn. Будет плюсом: Знание основных веб-технологий и протоколов Опыт работы с docker, k8s и микросервисной архитектурой. Что ещё, кроме работы? У нас дружелюбная и открытая команда, нет бюрократии и лишних уровней управления. Есть работающая схема профессионального развития сотрудников. А также: Можно работать удалённо или в офисе в минуте от метро Преображенская площадь (на 15 этаже с красивыми видами на Москву) Гибкое начало рабочего дня ДМС со стоматологией, вызовом врача на дом, экстренной госпитализацией Две недели дополнительного отпуска Частичная компенсация спорта В офисе есть спортивная зона с душевыми и массажное кресло Можно присоединиться к футбольной, баскетбольной или волейбольной сборным, для которых мы арендуем спортивные площадки Книги в библиотеку и настольные игры покупаем два раза в год Фрукты и печенье, микромаркет “ВкусВилл” и кофепоинт Есть клубы по интересам (шахматы, клуб инвесторов, мафия по спортивным правилам, винный клуб и другие).","Python,machine learning,web security,sklearn,pytorch,docker",Positive Technologies,
16779,77409086,Data scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Budu – это уникальный medtech сервис по управлению здоровьем, объединяющий технологичную платформу для онлайн-консультаций, сервисы превентивной диагностики и внутреннюю команду экспертов-врачей в собственных клиниках в г. Москве и г. Санкт-Петербурге. Мы создали высокотехнологичный продукт в области ДМС, в рамках которого мы полностью отвечаем за сервис, лечение и сопровождение на всех этапах, а пользователю предоставляем удобный цифровой путь для получения медицинских услуг. Современный цифровой ДМС позволяет сохранить стандарты классической медицины и предоставить клиентам удобный digital сервис. Мы имеем статус резидента «Сколково» и являемся аккредитованной IT компанией. Мы в поиске Data scientist в финансовый департамент. Основные задачи, которые предстоит решать: Полный цикл разработки моделей машинного обучения (регрессионных, классификационных и т.д.) – от подготовки данных до взаимодействия с командой разработки по развёртыванию на production Построение моделей по различным направлениям бизнеса (прогнозирование убыточности, повышение качества клиентского сервиса и т.д.) Формирование метрик продукта, проверка гипотез, выявление закономерностей в данных Написание требований по доработке аналитического хранилища данных (DWH) – по подключению новых источников данных, разработке витрин данных и т.д. Создание документации по аналитическим проектам, презентация результатов работы в понятном для бизнес-заказчиков виде. Нам важно, если ты обладаешь: Опытом работы в анализе данных и/или машинном обучении – не менее 1 года Уверенным знанием Python (NumPy, Pandas, Scikit-learn, Matplotlib и т.д.), SQL (оптимизация запросов, хранимые процедуры, аналитические функции – как плюс) Владением Git Знаниями в области алгоритмов машинного обучения, основ математической статистики и теории вероятностей, понимание основных принципов работы реляционных СУБД. Будет плюсом: Опыт работы в медицинской или страховой компании. Мы предлагаем: Стабильную заработную плату, официальное оформление по ТК РФ с первого рабочего дня ДМС и телемедицина с первой недели работы Страхование НС Неограниченные возможности профессионального и карьерного роста Команду профессионалов и просто хороших людей, которые всегда готовы помочь и поддержать Красивый и уютный офис в центре города в бизнес-квартале «Новоспасский» (м. Павелецкая): выход на набережную, разнообразная инфраструктура с кофейнями, ресторанами и магазинами, а также бесплатный корпоративный транспорт от метро Офисный или гибридный формат работы Удобный график с возможностью «плавающего утра»: можно начать свой рабочий день в любое комфортное время. Мы уверены, что важно никогда не прекращать учиться и развиваться, поэтому дополнительно у нас есть для всех сотрудников: Корпоративный учебный портал с открытым доступом к вебинарам, митапам и тренингам для всех желающих Оплата внешнего обучения и профильных курсов.","Python,SQL,Numpy,Pandas,Scikit-learn,Data Analysis,Matplotlib,Git,машинное обучение",ЦФРОВЫЕ ТЕХНОЛОГ ЗДОРОВЬЯ,"Москва, Пролетарская, Дербеневская набережная, 7с22"
16780,77860633,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы сохранили в себе важный плюс от стартапа: гибкость, скорость принятия решений и энтузиазм в достижении поставленных целей! Наша команда насчитывает более 100 единомышленников. Приглашаем присоединиться к нашей команде Data Scientist. Мы ищем человека, который готов работать и развиваться вместе с командой. Чем тебе предстоит заниматься: Разрабатывать системы скоринга для различных стран сследовать поведенческие паттерны и находить зависимости в данных используя статистические методы анализа Моделировать поведения клиентов для решения задач маркетинга Участвовать в разработке архитектуры ML сервисов Оптимизировать и развивать уже существующие пайплайны. Наши ожидания: меешь хорошую математическую подготовку Знаешь основы статистического анализа Понимаешь принципы постановки экспериментов, проверки гипотез меешь опыт работы с Python, библиотеками scikit-learn, numpy, scipy, pandas, gbm фреймворками Владеешь инструментами визуализации данных (seaborn, plotly, matplotlib) Понимаешь микросервисную архитектуру и знаком с инструментами (Docker, Docker Compose) меешь опыт использования и понимаешь основные алгоритмы машинного обучения Понимаешь методологию разработки GitFlow Обладаешь навыками общения и умеешь донести свою точку зрения. Будет твоим преимуществом, если ты: меешь профиль в GitHub или Kaggle, которым не стыдно поделиться меешь опыт вывода моделей в прод и понимаешь их жизненный цикл Применял практики MLOps в реальных проектах меешь опыт участия в конкурсах по анализу данных Знаешь pytorch Закончил ШАД или CSC. Что ты получишь от работы с нами: Атмосферу стабильности и безопасности, так как мы работаем в полном соответствии с ТК РФ Сильную команду, которая любит то, что делает — будет что обсудить и перенять опыт коллег Возможность проявлять инициативу и стать реальным двигателем изменений в компании. Мы всегда готовы обсуждать и реализовывать лучшие идеи Регулярные ревью, ретроспективы на проектах, индивидуальный подход к твоему развитию Прозрачная система грейдов и рыночный уровень заработных плат Комфортный офис в Академгородке г. Новосибирска. Возможность гибридного формата работы или удаленки.","Python,Docker,Machine Learning",LC Group,
16781,78883018,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Чем занимается Positive Technologies Мы создаем продукты для кибербезопасности. Это решения и технологии, которые защищают от хакеров и помогают проводить расследования инцидентов. Мы разрабатываем сложные высоконагруженные системы, используем алгоритмы машинного обучения, обработки и анализа данных, опенсорс-решения и адаптируем их к нашим задачам. Часть наработок мы публикуем на GitHub. Прежде чем отдавать продукты заказчикам, мы проверяем их на себе. У нас семь офисов в России (в Москве, Санкт-Петербурге, Самаре, Нижнем Новгороде, Томске и два в Новосибирске), поэтому продуктовые команды часто территориально распределены. Нас больше 1500 человек. Мы сейчас ищем Специалиста по машинному обучению в нашу команду Департамента разработки WAF (Web Application Firewall). WAF - это межсетевой экран, который обнаруживает и блокирует атаки, обеспечивает непрерывную защиту приложений, пользователей и инфраструктуры и помогает соответствовать стандартам безопасности. Чем предстоит заниматься: Проектирование математических моделей обнаружения атак на веб-приложения Разработка и прототипирование статистических методов обнаружения аномалий в трафике Поддержка и улучшение существующих алгоритмов машинного обучения в Application Firewall. Что ждём от кандидата: Уверенное знание Python, git Знание основных алгоритмов/методов машинного обучения Владение библиотеками Pytorch, sklearn. Будет плюсом: Знание основных веб-технологий и протоколов Опыт работы с docker, k8s и микросервисной архитектурой. Что ещё, кроме работы? У нас дружелюбная и открытая команда, нет бюрократии и лишних уровней управления. Есть работающая схема профессионального развития сотрудников. А также: Можно работать удалённо или в офисе в минуте от метро Преображенская площадь (на 15 этаже с красивыми видами на Москву) Гибкое начало рабочего дня ДМС со стоматологией, вызовом врача на дом, экстренной госпитализацией Две недели дополнительного отпуска Частичная компенсация спорта В офисе есть спортивная зона с душевыми и массажное кресло Можно присоединиться к футбольной, баскетбольной или волейбольной сборным, для которых мы арендуем спортивные площадки Книги в библиотеку и настольные игры покупаем два раза в год Фрукты и печенье, микромаркет “ВкусВилл” и кофепоинт Есть клубы по интересам (шахматы, клуб инвесторов, мафия по спортивным правилам, винный клуб и другие).","Python,machine learning,web security,sklearn,pytorch,docker",Positive Technologies,
16782,78891888,Middle Data Scientist,з/п не указана,3–6 лет,"Проектная работа/разовое задание,удаленная работа","НЛМК - международная сталелитейная компания с активами в России, США и пяти странах Европы. Производство вертикально интегрировано, это позволяет контролировать всю цепочку создания металлопродукции от добычи сырья до финальной обработки и поставки стали потребителям. В рамках трехлетней стратегии компании мы планируем разработать и внедрить принципиально новые системы, учитывающие лучшие практики мирового опыта учета производства, в микросервисной архитектуре на современном стеке технологий. Сейчас мы в поиске Data Scientist ВАС ЖДЕТ: Анализ доступных источников данных, объективная оценка их качества, поиск способов работы с теми наборами, которые есть в наличии Анализ специализированной и отраслевой литературы с целью обогащения моделей новыми признаками Разработка полного пайплайна моделей машинного обучения (первичная обработка данных, обучение модели, анализ метрик, визуализация, внедрение в сервис, контроль деградации) Оперативное создание / доработка моделей под требования и приоритеты владельца продукта «без ТЗ» Активное участие в тестировании и внедрении сервисов, использующих модели. МЫ ЖДЕМ ОТ ВАС: Знание методов математического моделирования, машинного обучения, статистики, оптимизации. Умение оперативно погрузиться в производственную задачу, изучить нюансы производства и технологий Уверенное владение библиотеками Python (Numpy, Pandas, SciPy, Statsmodels), умение визуализировать данные seaborn, plotly Опыт применения библиотек машинного обучения XGBoost, CatBoost, Scikit-learn. Умение строить ансамбли моделей с использованием sklearn Понимание пайплайна работы с временными рядами, владение библиотеками для генерации признаков Опыт решения оптимизационных задач с использованием scipy, gurobipy и др. Знание методов интерпретации black box моделей (SHAP, Monoforest) и умение применять их на практике будет плюсом Опыт работы с TensorFlow (Keras) или PyTorch, знание основных архитектур нейросетей будет плюсом Опыт работы с GitLab, Jira, Confluence. МЫ ПРЕДЛАГАЕМ: Лучшие практики мирового опыта учета производства, в микросервисной архитектуре на современном стеке. У нас технологическая платформа, на которой внедрено большинство сервисов управления жизненным циклом разработки Договор ГПХ Удаленный график работы Конкурентный уровень заработной платы и ежегодная индексация Возможность принять участие в интересных и сложных проектах с лучшими специалистами индустрии.","Data Analysis,Confluence,Удаленная работа,SQL,Python,Jira,Английский — B2 — Средне-продвинутый",Группа НЛМК Т и Диджитал,
16783,78913351,Data Scientist (математическое моделирование),з/п не указана,3–6 лет,"Полная занятость,полный день","Приглашаем в нашу команду DATA SCIENTIST-а для построения моделей ПВР, взаимодействия с ЦБ, участия в процессе валидации. ПРО БАНК: Росбанк – частный универсальный банк, работающий на российском рынке с 1993 года. Росбанк обслуживает порядка 1,5 млн активных розничных клиентов, около 83 тысяч активных клиентов малого бизнеса и около 10 тысяч активных клиентов корпоративного бизнеса более чем в 60 регионах России. Росбанк входит в ТОП 5 самых надежных российских банков по версии журнала Forbes и включен Банком России в число 13 системно-значимых кредитных организаций России. Наш банк имеет наивысшие кредитные рейтинги российских и международных рейтинговых агентств. ПРО КОМАНДУ: Команда центра математического моделирования занимается построением широкого спектра моделей, включая модели розничных и корпоративных рисков, бизнеса, комплаенса и т.д. щем человека для построения моделей ПВР. ОБЯЗАННОСТ: Активное участие в проекте перехода на ПВР - построение моделей, мониторинг, калибровка, взаимодействие с валидацией Участие в аналитических проектах и исследованиях Реализация проектов, связанных с математическим моделированием. ТРЕБОВАНЯ: Высшее образование по математическому/экономическому/ техническому профилю Опыт построения моделей в Python/ SAS/ R и внедрения в практики Банка Опыт построения PD/LGD моделей Участие в проектах перехода на ПВР (IRB) желательно Знание статистического моделирования и методов машинного обучения (machine learning) Опыт реализации проектов с соблюдением установленных сроков и требований к качеству. УСЛОВЯ: Комбинированный формат или полностью дистанционный формат работы на территории РФ Стабильный и прозрачный доход: зарплата и годовая премия по результатам работы Забота о здоровье сотрудников: программа ДМС, включая стоматологию и страхование при выезде за рубеж, корпоративные спортивные команды и скидки на абонементы в фитнес-клубы Дополнительная оплата за больничный лист: доплата сверх пособия по болезни до оклада (до 5 рабочих дней в год) Личностное развитие и рост: корпоративная электронная библиотека Альпина, возможность прохождения бесплатного обучения и тренингов, участия в регулярных встречах корпоративных клубов и скидки на курсы онлайн школ Скидки и привилегии по кредитам, ипотека на льготных условиях, льготные условия обслуживания и т.п. Программа корпоративных скидок и привилегий Primezone: развлечение, отдых, товары и услуги, обучение Программа волонтерства и благотворительности Сообщества по интересам сотрудников.","ПВР,IRB,PD/LGD",«РОСБАНК»,
16784,78896261,Data scientist (Middle),з/п не указана,1–3 года,"Полная занятость,полный день","В команду «Гео и Графы» кластера «Data Science и клиентская аналитика» корпоративного блока Сбербанка мы ищем специалистов по работе с данными. Вам предстоит работать с графами связей, строить витрины данных, использующиеся для построения моделей и автоматизации, применять алгоритмы машинного обучения для построения моделей. Обязанности · Построение и поддержка аналитических моделей (Python + Spark + Sklearn + LGBM), скоринговых моделей · Feature Engineering: методы оценки значимости и отбора признаков, методы уменьшения размерности · Построение аналитических отчетов по результатам проведенной работы · Обеспечение документирования результатов моделирования для передачи на валидацию · Получение структурированных и неструктурированных данных из различных источников, · сследование источников данных, обеспечение сбора данных · Составление требований для Data Engineer по разработке новых витрин/объектов · Построение и проверка гипотез по запросу Заказчика · Построение моделей машинного обучения исходя из потребностей Заказчика - Умение переводить требования Бизнеса на язык ML Требования · Опыт работы в области Data Science от 2 лет · Хорошее знание алгоритмов машинного обучения, нейронных сетей · Python, библиотеки для работы с ML · Знание банковской предметной области, банковских продуктов · Понимание основ финансовых инструментов · Базовые знания Spark, опыт работы со стеком Hadoop · Знание SQL · Понимание процессов ETL, ELT Как преимущество · Знание Spark, PySpark, использование UDF, особенности написания кода для стека Hadoop · Знание особенностей программирования в распределённых системах · Опыт работы с noSql базами · Обучение моделей на ресурсах GPU(А100/V100)/DGX · Знание SOTA технологий, применение трансформеров, нейронных сетей Условия \- Фиксированный оклад + годовой бонус - ДМС, страхование от несчастных случаев, социальные гарантии - Митапы DS Community банка и корпоративные мероприятия - Участие в различных конференциях для DS/DE - Корпоративное обучение - Комфортный офис в 5 минутах ходьбы от м.Нарвская - В офисе бесплатный фитнес-зал с душевыми кабинами, настольный теннис, кикер",,Сбер для экспертов,
16785,77034579,Senior Data Scientist (Adtech),з/п не указана,3–6 лет,"Полная занятость,полный день","В команду Поведенческих технологий ищем Senior Data Scientist. Наша команда решает задачу поиска релевантных друг другу пользователей и рекламных объявлений. Если пользователь видит только полезную рекламу, а рекламодатель быстро находит нужное число пользователей своего продукта — значит мы хорошо сделали свою работу. Для этого мы собираем множество разнообразных данных о пользователях и строим модели, позволяющие извлекать из данных информацию о краткосрочных и долгосрочных интересах каждого пользователя. менно эта информация используется при определении релевантности рекламного объявления. Мы ищем ведущего разработчика, который поможет переизобрести ключевой сервис генерации интересов пользователя в рамках нашего нового продукта VK Реклама. Это амбициозный проект, планирующий полностью поменять взгляд на таргетирование рекламы. Это означает, что все будет новым: новые бизнес-задачи и цели, новые метрики эффективности, новые критерии релевантности пользователей и объявлений, новая формулировка интересов пользователя, новые данные и модели. В разработке всего этого ты можешь принять участие. Задачи: разработка моделей, предсказывающих интерес пользователя на основе данных его поведения разработка моделей автоматизированного подбора таргетингов рекламных объявлений разработка и валидация метрик оценки качества моделей и интересов формализация процессов сбора разнообразных данных, необходимых для обучения и валидации моделей. Требования: Мы ждем, что кандидат: любит и умеет решать новые проблемы, превращая их в четко сформулированные задачи умеет формулировать гипотезы и проверять их при помощи данных умеет аргументировать при помощи метрик, а при отсутствии метрик умеет их разработать и провалидировать имеет хорошее понимание линейной алгебры, теории вероятностей и статистики экспертно владеет Python и SQL (Scala, Go — будут плюсом) знает ML-алгоритмы, имеет опыт обучения эмбеддингов и ранжирующих моделей работал с Hadoop (Spark, Hive, HDFS) и Kafka (Luigi, Airflow — будут плюсом). Будет плюсом: наличие опыта использования NLP моделей: LSTM, Transformers, BERT, etc. наличие опыта использования RecSys моделей: FM, ALS, LDA, etc. в курсе современных статей с ведущих конференций (KDD, RecSys, NIPS, WWW, CIKM, ICML).","Machine learning,Hadoop,Adtech,Python,ML,NLP,Алгоритмы","VK, ВКонтакте","Москва, Аэропорт, Ленинградский проспект, 39с79"
16786,78896775,Data Scientist (Геоаналитика),з/п не указана,1–3 года,"Полная занятость,полный день","Описание продукта: Продукт «Геоаналитика» - аналитическая веб-платформа на основе технологий big data и искусственного интеллекта. Позволяет бизнесу получить актуальную информацию о финансовом поведении населения локации, о конкурентах, смоделировать прогноз товарооборота для планируемых торговых объектов. Обязанности сследование данных заказчика, обогащение данных Обработка данных: подготовка, очистка Генерация признаков, интеллектуальный отбор признаков Подготовка прототипов решений, прогнозных моделей сследование лучших практик решения задач прогнозирования Участие в автоматизации работы моделей Взаимодействие со смежными командами Требования Высшее техническое образование Опыт работы на позиции Data Scientist от 2ух лет Знание основных алгоритмов и метрик машинного обучения Ключевые навыки: Python, SQL, ML. Уверенное знание Python и библиотек numpy, pandas, sklearn Практические навыки feature engineering, selection Аналитические способности и логическое мышление Умение работать в команде на результат Умение объяснять и адаптировать сложные системы и технические термины к ясной лаконичной форме для нетехнических специалистов Будет плюсом Опыт работы с геоданными Образование - МФТ, МГУ, Сколтех, ВШЭ Умение работать с Confluence, Jira, Nexus, Bitbucket Опыт работы с Unix shell Практические навыки работы с DL библиотеками PyTorch, TensorFlow Навыки работы с git, docker Условия Офис «Sbergile Home» рядом с м. Кутузовская. Бесплатный фитнес-зал, настольные игры на этажах Бесплатная подземная парковка ДМС с первого дня Формат работы: офис Создание продуктов для Корпоративных клиентов Профессиональный рост в молодой и сильной команде","Python,SQL,ML,Машинное обучение",Сбер. Data Science,
16787,79041835,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","В команду проекта разработки системы финансового мониторинга ищем Senior Data Scientist. Чем предстоит заниматься: Построение и поддержка аналитических моделей Построение и проверка гипотез по запросу Заказчика Построение моделей машинного обучения исходя из потребностей Заказчика Поддержка и улучшение существующих алгоритмов машинного обучения Составление аналитических отчетов по результатам проведенной работы Коммуникации с командой разработки и представителями Заказчика. Что мы хотим видеть в кандидате: Высшее образование в области математики (прикладная математика, математическое моделирование и т.п.) Опыт работы в данной роли от 3-х лет Опыт программирования на Python Опыт работы с SQL Умение работать с большими данными, знание методов обработки данных и их структурирования Уверенное владение pandas, numpy, scikit-learn, xgboost, catboost, pytorch Опыт работы с нейронными сетями в сфере обработки временных рядов и текстовых данных. Что мы предлагаем: Работу в аккредитованной IT-компании в полном соответствии с ТК РФ Гибкий рабочий график с возможностью иногда работать удаленно ДМС или компенсацию спорта на выбор Скидки на покупку техники Скидки на изучение английского языка Корпоративные выплаты в случае важных семейных событий Дополнительные оплачиваемые выходные Участие в профильных конференциях и курсах за счет компании Дополнительные льготы, предусмотренные в компании.","Python,SQL,Pandas,Numpy,Machine Learning,Data Science,Математический анализ,Математическая статистика,Математическое моделирование",ТекФорс нжиниринг,"Москва, Октябрьская, улица Крымский Вал, 3с2"
16788,77519035,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Чем предстоит заниматься: Разработкой, валидацией, актуализацией моделей кредитного скоринга Оценкой новых источников данных с целью улучшить качество существующих моделей Мониторингом и контролем качества работающих в проде моделей Разработкой моделей в областях коллекшн, антифрод, поиска аномалий, NLP Участием в разработке текущей аналитической системы. Мы ждем, что у тебя есть: Знание и опыт работы с Python и основными библиотеками анализа данных Знание SQL Знание основ статистического анализа. Формулирование гипотез, проведение A/В-тестов Понимание алгоритмов машинного обучения. Опыт построения скоринговых моделей и оценки их эффективности. Будет плюсом: спользование ETL инструментов (Airflow) Знание git, docker Опыт работы в банковском/финансовом секторе Желание развиваться в сфере Финтеха, инициативность. Что мы предлагаем: Официальное трудоустройство и белую заработную плату Оплачиваемые обучающие курсы, в том числе занятия английским языком в Skyeng Поддержку здоровья: ДМС, корпоративный спорт, йогу в офисе Фруктовые понедельники для поддержания тонуса и тематические пятницы для поднятия настроения.",,Финтех Айкью,"Новосибирск, Красноярская улица, 35"
16789,77860633,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы сохранили в себе важный плюс от стартапа: гибкость, скорость принятия решений и энтузиазм в достижении поставленных целей! Наша команда насчитывает более 100 единомышленников. Приглашаем присоединиться к нашей команде Data Scientist. Мы ищем человека, который готов работать и развиваться вместе с командой. Чем тебе предстоит заниматься: Разрабатывать системы скоринга для различных стран сследовать поведенческие паттерны и находить зависимости в данных используя статистические методы анализа Моделировать поведения клиентов для решения задач маркетинга Участвовать в разработке архитектуры ML сервисов Оптимизировать и развивать уже существующие пайплайны. Наши ожидания: меешь хорошую математическую подготовку Знаешь основы статистического анализа Понимаешь принципы постановки экспериментов, проверки гипотез меешь опыт работы с Python, библиотеками scikit-learn, numpy, scipy, pandas, gbm фреймворками Владеешь инструментами визуализации данных (seaborn, plotly, matplotlib) Понимаешь микросервисную архитектуру и знаком с инструментами (Docker, Docker Compose) меешь опыт использования и понимаешь основные алгоритмы машинного обучения Понимаешь методологию разработки GitFlow Обладаешь навыками общения и умеешь донести свою точку зрения. Будет твоим преимуществом, если ты: меешь профиль в GitHub или Kaggle, которым не стыдно поделиться меешь опыт вывода моделей в прод и понимаешь их жизненный цикл Применял практики MLOps в реальных проектах меешь опыт участия в конкурсах по анализу данных Знаешь pytorch Закончил ШАД или CSC. Что ты получишь от работы с нами: Атмосферу стабильности и безопасности, так как мы работаем в полном соответствии с ТК РФ Сильную команду, которая любит то, что делает — будет что обсудить и перенять опыт коллег Возможность проявлять инициативу и стать реальным двигателем изменений в компании. Мы всегда готовы обсуждать и реализовывать лучшие идеи Регулярные ревью, ретроспективы на проектах, индивидуальный подход к твоему развитию Прозрачная система грейдов и рыночный уровень заработных плат Комфортный офис в Академгородке г. Новосибирска. Возможность гибридного формата работы или удаленки.","Python,Docker,Machine Learning",LC Group,
16790,79012262,Middle/Senior Data scientist (Computer Vision),з/п не указана,3–6 лет,"Полная занятость,полный день","В команду стрима ""AI продукты для бизнеса"" ищем Data Scientist уровня Middle+. На текущий момент в нашей команде 5 DS. Мы разрабатываем несколько продуктов, например платформу СберБизнесБот, представляющую из себя чат-бот для общения с клиентами, или сервис AgroAI для прогнозирования урожайности сельскохозяйственных культур на основе спутниковых снимков. Значительную часть нашей работы составляют проекты для внешних клиентов, которые мы часто выполняем в сотрудничестве со SberAI. Задачи Разнообразные проекты, связанные с NLP, CV, временные ряды Нужно будет разрабатывать много POC и MVP под разные индустрии и задачи, улучшать и дорабатывать уже существующие решения Требования Уверенное знание Python и библиотек numpy, pandas, sklearn, lightgbm Понимание принципов работы классических алгоритмов машинного обучения, их преимуществ, недостатков и ограничений Опыт решения практических NLP и/или CV задач Знакомство с основными архитектурами нейронных сетей Опыт работы с DL фреймворками, предпочтительно с PyTorch Хороший уровень математической подготовки (теория вероятности, статистика) Базовое знание алгоритмов и структур данных Будет плюсом Опыт в решении задач Data Science для бизнеса Хорошее знание git, docker Условия нтересные и масштабные задачи, интеллектуальный вызов и возможность выбрать карьеру по интересам Работу в быстро развивающейся команде Офис в центре Москвы, классную столовую, отсутствие дресс-кода Тренажерный зал премиум-класса в офисе Конкурентоспособную зарплату + годовой бонус + ДМС с первого дня","Python,NLP,Computer Vision,SQL",Сбер. Data Science,
16791,77034579,Senior Data Scientist (Adtech),з/п не указана,3–6 лет,"Полная занятость,полный день","В команду Поведенческих технологий ищем Senior Data Scientist. Наша команда решает задачу поиска релевантных друг другу пользователей и рекламных объявлений. Если пользователь видит только полезную рекламу, а рекламодатель быстро находит нужное число пользователей своего продукта — значит мы хорошо сделали свою работу. Для этого мы собираем множество разнообразных данных о пользователях и строим модели, позволяющие извлекать из данных информацию о краткосрочных и долгосрочных интересах каждого пользователя. менно эта информация используется при определении релевантности рекламного объявления. Мы ищем ведущего разработчика, который поможет переизобрести ключевой сервис генерации интересов пользователя в рамках нашего нового продукта VK Реклама. Это амбициозный проект, планирующий полностью поменять взгляд на таргетирование рекламы. Это означает, что все будет новым: новые бизнес-задачи и цели, новые метрики эффективности, новые критерии релевантности пользователей и объявлений, новая формулировка интересов пользователя, новые данные и модели. В разработке всего этого ты можешь принять участие. Задачи: разработка моделей, предсказывающих интерес пользователя на основе данных его поведения разработка моделей автоматизированного подбора таргетингов рекламных объявлений разработка и валидация метрик оценки качества моделей и интересов формализация процессов сбора разнообразных данных, необходимых для обучения и валидации моделей. Требования: Мы ждем, что кандидат: любит и умеет решать новые проблемы, превращая их в четко сформулированные задачи умеет формулировать гипотезы и проверять их при помощи данных умеет аргументировать при помощи метрик, а при отсутствии метрик умеет их разработать и провалидировать имеет хорошее понимание линейной алгебры, теории вероятностей и статистики экспертно владеет Python и SQL (Scala, Go — будут плюсом) знает ML-алгоритмы, имеет опыт обучения эмбеддингов и ранжирующих моделей работал с Hadoop (Spark, Hive, HDFS) и Kafka (Luigi, Airflow — будут плюсом). Будет плюсом: наличие опыта использования NLP моделей: LSTM, Transformers, BERT, etc. наличие опыта использования RecSys моделей: FM, ALS, LDA, etc. в курсе современных статей с ведущих конференций (KDD, RecSys, NIPS, WWW, CIKM, ICML).","Machine learning,Hadoop,Adtech,Python,ML,NLP,Алгоритмы","VK, ВКонтакте","Москва, Аэропорт, Ленинградский проспект, 39с79"
16792,78913351,Data Scientist (математическое моделирование),з/п не указана,3–6 лет,"Полная занятость,полный день","Приглашаем в нашу команду DATA SCIENTIST-а для построения моделей ПВР, взаимодействия с ЦБ, участия в процессе валидации. ПРО БАНК: Росбанк – частный универсальный банк, работающий на российском рынке с 1993 года. Росбанк обслуживает порядка 1,5 млн активных розничных клиентов, около 83 тысяч активных клиентов малого бизнеса и около 10 тысяч активных клиентов корпоративного бизнеса более чем в 60 регионах России. Росбанк входит в ТОП 5 самых надежных российских банков по версии журнала Forbes и включен Банком России в число 13 системно-значимых кредитных организаций России. Наш банк имеет наивысшие кредитные рейтинги российских и международных рейтинговых агентств. ПРО КОМАНДУ: Команда центра математического моделирования занимается построением широкого спектра моделей, включая модели розничных и корпоративных рисков, бизнеса, комплаенса и т.д. щем человека для построения моделей ПВР. ОБЯЗАННОСТ: Активное участие в проекте перехода на ПВР - построение моделей, мониторинг, калибровка, взаимодействие с валидацией Участие в аналитических проектах и исследованиях Реализация проектов, связанных с математическим моделированием. ТРЕБОВАНЯ: Высшее образование по математическому/экономическому/ техническому профилю Опыт построения моделей в Python/ SAS/ R и внедрения в практики Банка Опыт построения PD/LGD моделей Участие в проектах перехода на ПВР (IRB) желательно Знание статистического моделирования и методов машинного обучения (machine learning) Опыт реализации проектов с соблюдением установленных сроков и требований к качеству. УСЛОВЯ: Комбинированный формат или полностью дистанционный формат работы на территории РФ Стабильный и прозрачный доход: зарплата и годовая премия по результатам работы Забота о здоровье сотрудников: программа ДМС, включая стоматологию и страхование при выезде за рубеж, корпоративные спортивные команды и скидки на абонементы в фитнес-клубы Дополнительная оплата за больничный лист: доплата сверх пособия по болезни до оклада (до 5 рабочих дней в год) Личностное развитие и рост: корпоративная электронная библиотека Альпина, возможность прохождения бесплатного обучения и тренингов, участия в регулярных встречах корпоративных клубов и скидки на курсы онлайн школ Скидки и привилегии по кредитам, ипотека на льготных условиях, льготные условия обслуживания и т.п. Программа корпоративных скидок и привилегий Primezone: развлечение, отдых, товары и услуги, обучение Программа волонтерства и благотворительности Сообщества по интересам сотрудников.","ПВР,IRB,PD/LGD",«РОСБАНК»,
16793,77316163,Data Scientist (DMAG),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","О проекте: Мы разрабатываем методы детектирования от составления обучающей выборки и выявление признаков, до реализации и контроля качества на production системах. Разработанные методы далее используются во многих продуктах Лаборатории Касперского непосредственно защищая наших пользователей. С примерами задач команды можно ознакомиться по ссылкам: How to improve SOC analyst efficiency using ML - DataFest. ML & Security track - https://www.youtube.com/watch?v=DPzdb9Uivwc&feature=youtu.be Краткий ликбез по ML метрикам и их связи с бизнес-метриками - LeadDS meetup - https://www.youtube.com/watch?v=pDMgvhsUPJM&feature=youtu.be Monotonic models for real-time dynamic malware detection - whitepaper - https://openreview.net/pdf?id=rkjatuyvM Чем предстоит заниматься: Классификация исполняемых файлов как по статическим признакам, так и по их поведению Анализ android/mac файлов Распознавание вредоносных интернет ресурсов основываясь на статистических данных, графах связей IP адресов Кластеризация, быстрый поиск похожих вредоносных объектов.  Мы используем xgboost, различные варианты нейросетей, графовые подходы и locality sensitive hashing. Объемы данных варьируются до сотен миллионов объектов, сотен терабайт данных. Для хранения больших данных мы используем HDFS, для обработки pyspark. Для обучения нейросетей у нас есть свой GPU кластер на базе kubeflow. Что требуется от вас: Ведение DS проектов от начальных до заключительных стадий Участие в генерации и проверке гипотез по улучшению качества текущих алгоритмов и экспериментов с новыми подходами Хорошее знание моделей машинного обучения и понимания их внутренностей (например, зачем нужен градиент в градиентном бустинге) Уверенные навыки в python Желательно знание pyspark, pytorch или tensorflow. А еще мы предоставляем возможность: Регулярного участия профильных ML конференциях Внутренние семинары по ML раз в 2е недели Возможна частично удаленная или полностью удаленная работа.","Machine Learning,Spark,docker,Python",Лаборатория Касперского,
16794,76461371,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Анализ данных с целью формулирования гипотез для проверки Участие в проверке гипотез с использованием ML Построение моделей статистического анализа Строить и валидировать модели машинного обучения (акцент на развитие рекомендательных систем и прогнозирование) Участие во внедрении DS-решений в бизнес-процессы нтерпретировать и описывать результаты в форме отчета Участие в выводе моделей по подтвержденным гипотезам в прод Быть драйвером нового направления в продукте! Требования: Опыт работы в качестве data scientist от 2 лет Уверенное владение Python и основными ML-библиотеками (NumPy, Pandas, Scikit-learn, LightGBM, SciPy, PyTorch, CatBoost, XGBoost, Random forest, деревья решений и т.п.) Опыт работы с базовыми алгоритмами ML, понимание преимуществ, недостатков и отличий Опыт разработки нейронных сетей Хорошее знание SQL и умение разбираться в источниках Умение объяснять и обосновывать выбранный способ решения задачи Хорошее знание теории вероятностей и математической статистики Опыт работы с большими данными Условия: Работа в развивающейся IT организации в ведомстве Департамента образования и науки города Москвы Оформление по ТК РФ График работы 5/2 с 09.30 до 18.30 (возможно смещение графика работы после испытательного срока по решению непосредственного руководителя) Возможен гибридный формат работы (удаленно/в офисе) после испытательного срока по решению непосредственного руководителя Работа в аккредитованной IT организации","SQL,Аналитическое мышление,Data Analysis,Аналитические исследования,ML,Data Scientist,Python",ГАУ Города Москвы Центр цифровизации образования,"Москва, Улица 1905 года, улица Пресненский Вал, 1"
16795,77408771,Data Scientist (Computer Vision),з/п не указана,3–6 лет,"Полная занятость,полный день","В связи с расширением портфеля задач мы открываем вакансию Data Scientist (Computer Vision) Обязанности: Разработка собственных новых решений(Не поддержка существующих). Полный цикл внедрения модели от разработки прототипа до промышленного внедрения. Обнаружение нарушений в технологических процессах. Классификация объектов по изображениям, поиск дубликатов. Требования: 3-4 реализованных продакшн решения с использованием Computer Vision. Умение решать задачи классификации, детектирования и сегментации как классическими методами CV, так и с использованием нейронных сетей. Понимание областей применения различных архитектур нейронных сетей. Технологии: Python OpenCV TensorFlow/PyTorch","Python,PyTorch,OpenCV,Computer Vision,Tensorflow",БиАйЭй-Технолоджиз,
16796,78381745,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Контур — экосистема для бизнеса. Каждая четвертая компания в стране решает бизнес-задачи, используя наши сервисы. Мы автоматизируем документооборот, бухгалтерию и отчетность. Делаем эти процессы простыми и быстрыми, а сервисы — удобными для клиента.  Data Science в Контуре помогает оптимизировать внутренние процессы и добавляет ценности в продукты. Например, чат-бот Сирена экономит около 25% времени консультантов техподдержки в чатах, а технология распознавания речи обрабатывает тысячи лет записей в год. Мы постоянно следим за прогрессом в технологиях и разрабатываем новые методы и алгоритмы, чтобы сделать инновации доступными для использования в продуктах и процессах компании. В Центре искусственного интеллекта представлены разные роли: есть дата сайентисты, разработчики и аналитики данных, девопсы, QA-специалисты, системные аналитики, проджекты и продакт-менеджеры. Свое железо (V100/A100) и асессорская служба позволяют нам не ограничивать себя при работе с чувствительными данными, а также крутая инфраструктурная команда создает, улучшает и развивает инструменты MLOps на любой вкус от ресерча до прода. Мы ищем Senior Data Scientist в направление оптимизации процессов продаж и маркетинга. Нам нужен человек, который разовьет направление продаж и маркетинга с точки зрения машинного обучения: составит дорожную карту применения Data Science в процессах продаж согласует с бизнесом и приоритизирует сам проверит и доведет до продакшена гипотезы, и, как результат, повысит эффективность продаж и маркетинга. Примеры задач, которые уже решали Речевая аналитика (после ASR): оценка эффективности работы менеджеров по продажам на основании анализа текста звонков. Работа с конверсией: оценка вероятности оплаты клиентом счета по сделке по набору параметров. Что ожидаем от вас Опыт работы в аналогичной роли от двух лет. Опыт решения задач и понимание работы алгоритмов NLP и Classic ML. Умение общаться на языке заказчика, погружаться в продуктовый контекст. Умение работать в команде. Опыт декомпозиции, приоритизации больших задач. Опыт доведения задач до продакшена. Желательно иметь опыт доведения задачи от формулировки на языке бизнеса до прода (от начала до конца) работы с высокой неопределенностью: прокапывание проблематики, осознанный выбор решения. Технологии Python, SQL. GitLab. Docker, Kubernetes, AirFlow. Classic ML, языковые модели (BERT etc.). Мы предлагаем Зарплата зависит от ваших технических знаний и навыков. Пересматриваем ее два раза в год. Нам важно, чтобы вам было комфортно: непринципиально, где вы находитесь и во сколько начинаете рабочий день, главное – выполненные задачи. Умеем работать в команде, находясь в разных точках мира (Таллин, Ташкент, Астана, Лимассол, Екатеринбург, Москва и т. д.). Мы поддерживаем участие в конференциях, митапах и обучающих проектах. Наши деврелы помогут написать статью на Хабр, снять видео или подготовиться к выступлению на конференции. У нас сильное инженерное сообщество: регулярно проводим техническую конференцию КонфУР, обмениваемся опытом между командами, проводим дизайн-ревью с экспертами в разных технологиях. Всегда найдется, с кем посоветоваться. А еще у нас есть инженерный совет. Он придумывает и реализует проекты, которые улучшают жизнь инженеров в компании. Максимум горизонтальных связей в коллективе, чтобы быстрее договариваться и решать рабочие задачи. Присоединяйтесь :)","NLP,Machine Learning,Python,Data Science",Контур,
16797,76916740,Data Scientist (Middle+/Senior),з/п не указана,1–3 года,"Полная занятость,полный день","Приглашаем в ML команду специалистов в области классического ML. Команда распределенная, основные ячейки находятся в Новосибирске, Томске, СПб и также по всей России. Сейчас нас 100+ человек. Активно расширяем команду, которая работает над проектами: оценка платежеспособности клиента поиск аномального и фродерского поведения идентификация пользователей постпроцессинг данных. Задачи, которыми тебе предстоит заниматься: выгрузка данных из БД, парсинг логов сервисов обработка и подготовка данных с использованием Python создание и проверка признаков оценка качества и анализ данных доработка пайплайна расчета признаков для транзакций/заявок обучение классических ML моделей доставка моделей до боя, мониторинг моделей на бою доработка внутренних библиотек общение с бизнес-заказчиком анализ экономического эффекта изменений логики принятия решений. Что для нас важно: опыт работы с задачами машинного обучения/ опыт работы с данными в проектах, желательно по статистической обработке от 2-х лет опыт разработки на Python опыт работы с библиотеками pandas, numpy, sklearn, catboost уверенные навыки использования Linux, Jupyter notebook, git, SQL знание основных моделей машинного обучения: деревья решений на градиентном бустинге, логистическая регрессия с регуляризацией, метод ближайших соседей и др. методов снижения размерности и кластеризации навыки визуализации результатов опыт самостоятельного ведения темы: дизайн, постановка задачи, проведение и оценка результатов А/Б тестов, оценка результата работы по задаче для позиции уровня senior: ожидаем опыт ведения более обширной темы (от идеи до прода), опыт ревью кода мидлов/опыт лидства команды доп. навыки: базовые навыки в airflow, pyspark, dvc. Мы предлагаем: Понятную траекторию роста (performance review, карьерные консультации, индивидуальная карта развития и т.д.) Обучение и развитие за счёт ресурсов компании (Учебный центр, корпоративная библиотека, оплата внешнего обучения) Социальный пакет (ДМС с первого рабочего дня, скидки от партнёров, детская программа, поддержка спорта, корпоративный транспорт и т.д.) Насыщенная корпоративная жизнь (радио, подкасты, кибертурнир, собственные мероприятия и участие в крупных событиях отрасли) Возможность быть преподавателем, наставником, автором корпоративного блога, спикером – каждый выбирает то, что подходит именно ему Официальное трудоустройство с первого дня, полностью белая зарплата.",,Центр финансовых технологий,
16798,76576075,Senior Data Scientist,з/п не указана,более 6 лет,"Полная занятость,полный день","О команде: Кросс-функциональная команда DS/MLE/DA/DE спользуем передовой стек и лучшие практики ведения проектов Держим руку на пульсе современных решений, моделей и подходов Работаем по Scrum  Вам предстоит: Разработка e2e data-сервисов на основе ML-моделей с целью снижения Cost of Risk Разработка online-моделей для оценки уровня дефолтности новых клиентов, Разработка offline-поведенческих моделей для управления тарифами B2B и B2C сервисов Регулярная проверка новых источников данных для снижения Cost of Risk Курирование процесса MLOps в смежных командах для операционализации дата-сервисов Курирование процессов построения DWH/DMP Расчет финансового эффекта от моделей Мы ожидаем от вас: Опыт работы в финтех компании 3+ лет Знание Python Знание принципов работы как глубоких нейронных сетей, так и классических ML-алгоритмов Понимание статистических подходов и опыт их применения при решении практических задач Навыки построения полного цикла ML-решений: Cбор и подготовка данных Feature selection & engineering Тренировка/валидация/тестирование ML-моделей Проведение A/B тестирований Навыки прототипирования и оценки алгоритмов из исследовательских и научных статей нициативность. Умение высказывать мнение, доносить его до коллег и принимать ответственные решения Плюсом будет: Опыт работы в NLP Опыт работы с FastAPI/Sanic, DVC/MLFlow/W&B Опыт работы с causal inference-моделями для uplift Опыт работы с маркетинговыми и продуктовыми метриками (ROMI, CAC, Retention) Технологии: Языки программирования: Python, Bash. ML-моделирование с помощью: PyCaret, Tensorflow, Scikit-Learn, Catboost и проч. Анализ данных: SQL, BI (Metabase), а также Pandas, Matplotlib, Plotly и проч. Деплой: Docker Compose, Kubernetes, Helm, MLFlow, Jaeger, Sentry Хранилище: совместимые с S3.",,Alif Tech,
16799,70243733,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","О команде и продукте В дирекции Data & Analytics в отделе Data Science открыты позиции в 2 направлениях: 1) Команда прайсинга: разрабатываем систему динамического ценообразования: строим модели прогнозирования продаж и решаем сложные оптимизационные задачи по подбору оптимального набора цен. 2) Команда поиска, навигации и ранжирования: на развитие машинного обучения в рекламной платформе. Прогнозируем вероятность клика по товарам и баннерам, определяем оптимальный размера ставки, занимаемся персонализацией рекламных предложений. спользуемый стэк технологий: Big data (Hadoop, PySpark, Hive), Python, Catboost, Airflow, Docker, SQL, PyTorch. Почему у нас классно: Хорошо выстроенные процессы: квартальное планирование по методологии OKR, двухнедельные спринты, регулярные стендапы и проектные встречи для синхронизации. Сильная команда middle и senior специалистов, развитое DS-сообщество, где есть возможность обмениваться знаниями на внутренних митапах У нас представлен полный жизненный цикл разработки data-driven продуктов с применением ML — от идеи и генерации гипотез до запуска АБ тестов. В части разработки онлайн-сервисов и деплоя моделей нам помогает команда инженеров. Чем вам предстоит заниматься: скать инсайты в данных и определять точки роста продукта Разрабатывать и проверять продуктовые гипотезы Работать в тесном сотрудничестве с разработчиками для вывода моделей в продакшн. Мы ожидаем: Опыт в области анализа данных и машинного обучения (от 2 лет) Опыт работы с SQL, Hadoop, Hive, Spark Владение Python, Linux, методами работы с большими данными Опыт работы как минимум с 2 ML библиотеками: Scikit-learn, Vowpal Wabbit, XGBoost, Cat Boost, TensorFlow, Spark ML Знания теории вероятностей и математической статистики Знания в области машинного обучения, прогнозного моделирования и методов статистического анализа Знание алгоритмов и структур данных Высшее образование в области прикладной математики, информационных технологий, информатики и т.п Английский язык на уровне технического чтения и профессионального общения. Будет плюсом: Deep learning для компьютерного зрения или NLP. Как мы работаем: Пишем на Python 3.6+ и PySpark 3.0 Для ресерча доступны два сервера (80 cores, 650Gb RAM), на которых развернут JupyrerHub и есть доступ к Hadoop-кластеру Код с логикой ML-пайплайнов упаковываем в Docker и выкатываем, используя CI/CD-инструменты с запуском code style проверок и тестов спользуем Airflow для управления ML-пайплайнами и запуском их по расписанию В командах есть культура code review как для изменений по части продакшен-пайплайнов, так и для ресерч-задач Регулярно проводим командные брейнштормы с целью генерации новых идей по развитию наших data-driven продуктов В компании внедрена культура принятия решений на основании данных и все изменения тестируем через АБ-эксперименты. Мы предлагаем: Официальное оформление, белую заработную плату Гибкий график работы, есть возможность удобно планировать рабочее и личное время, а также работать удаленно Расширенную ДМС программу со стоматологией Скидки на весь каталог сайта Lamoda Обмен знаниями внутри компании - мы организуем внутренние митапы и являемся площадкой для различных сообществ Возможность посещать конференции в качестве слушателей и докладчиков (для желающих профессионально подготовиться к выступлениям с докладами или презентациями у нас есть Speakers Club) Вовлеченный в процессы менеджмент: наше руководство понимает и учитывает все особенности IT-разработки и готово услышать ваши крутые идеи Уютный офис в Москве (МЦК Хорошёво/м. Полежаевская) с настольным теннисом, кикером, тренажерным залом и йогой.",,Lamoda Tech,"Москва, Полежаевская, Хорошево, проспект Маршала Жукова, 1с1"
16800,78307298,Middle Data Scientist (Sber AI Lab),от 217 750 до 326 625 руб. до вычета налогов,1–3 года,"Полная занятость,полный день","В Центр AI инструментов лаборатории искусственного интеллекта Сбера (AI Lab), занимающийся разработкой в области технологий AutoML и RecSys, требуется специалист, который поможет решать бизнес задачи банка с использованием наших библиотек, а так же развивать инструменты с учетом своего практического опыта. AI Lab - особое подразделение Сбера, нацеленное на наукоемкие AI проекты и создание новых технологий (в том числе и open-source). Обязанности Чем вы будете заниматься: Пилоты с бизнес заказчиками – полный цикл разработки модели, включая: постановка задачи в терминах МЛ, определение МЛ/бизнес метрик, обучение/валидация моделей, сопровождение внедрения Участие в разработке open-source библиотек. Доработка существующего функционала (повышение качества моделей/скорости работы, bugfix). Создание нового, покрывающего ранее недоступные виды задач. Участие в исследованиях и написании статей в журналы Q1/конференции A/A* Взаимодействие с прикладными командами по внедрению разработанных инструментов в банковскую инфраструктуру Требования Мы ожидаем от вас: Хорошее знание Python (в том числе опыт работ с Python ML+DL фреймворками sklearn, numpy, pandas, pytorch) Опыт работы со Spark Высокая техническая грамотность (алгоритмический базис, опыт решения архитектурных проблем) Опыт работы с Linux, базовое умение пользоваться Linux shell Хорошее понимание ML/DL алгоритмов Опыт промышленной разработки моделей Высокие результаты в соревнованиях (Kaggle и прочее), как плюс алист по Ml/DL в группу ML 2.0 Условия Работа преимущественно в офисе (возможен вариант 20% удаленно) офис метро Кутузовская Масштабные проекты, участие в международных конференциях Высококвалифицированный коллектив Конкурентный уровень заработной платы, а также годовые премии по результатам работы Участие в развитии и создании open-source продуктов, а также возможность совмещать работу с соревнованиями на Kaggle и написанием научных статей Корпоративное обучение, льготные условия кредитования, бесплатный спортзал и другие плюшки",,Сбер для экспертов,
16801,78891888,Middle Data Scientist,з/п не указана,3–6 лет,"Проектная работа/разовое задание,удаленная работа","НЛМК - международная сталелитейная компания с активами в России, США и пяти странах Европы. Производство вертикально интегрировано, это позволяет контролировать всю цепочку создания металлопродукции от добычи сырья до финальной обработки и поставки стали потребителям. В рамках трехлетней стратегии компании мы планируем разработать и внедрить принципиально новые системы, учитывающие лучшие практики мирового опыта учета производства, в микросервисной архитектуре на современном стеке технологий. Сейчас мы в поиске Data Scientist ВАС ЖДЕТ: Анализ доступных источников данных, объективная оценка их качества, поиск способов работы с теми наборами, которые есть в наличии Анализ специализированной и отраслевой литературы с целью обогащения моделей новыми признаками Разработка полного пайплайна моделей машинного обучения (первичная обработка данных, обучение модели, анализ метрик, визуализация, внедрение в сервис, контроль деградации) Оперативное создание / доработка моделей под требования и приоритеты владельца продукта «без ТЗ» Активное участие в тестировании и внедрении сервисов, использующих модели. МЫ ЖДЕМ ОТ ВАС: Знание методов математического моделирования, машинного обучения, статистики, оптимизации. Умение оперативно погрузиться в производственную задачу, изучить нюансы производства и технологий Уверенное владение библиотеками Python (Numpy, Pandas, SciPy, Statsmodels), умение визуализировать данные seaborn, plotly Опыт применения библиотек машинного обучения XGBoost, CatBoost, Scikit-learn. Умение строить ансамбли моделей с использованием sklearn Понимание пайплайна работы с временными рядами, владение библиотеками для генерации признаков Опыт решения оптимизационных задач с использованием scipy, gurobipy и др. Знание методов интерпретации black box моделей (SHAP, Monoforest) и умение применять их на практике будет плюсом Опыт работы с TensorFlow (Keras) или PyTorch, знание основных архитектур нейросетей будет плюсом Опыт работы с GitLab, Jira, Confluence. МЫ ПРЕДЛАГАЕМ: Лучшие практики мирового опыта учета производства, в микросервисной архитектуре на современном стеке. У нас технологическая платформа, на которой внедрено большинство сервисов управления жизненным циклом разработки Договор ГПХ Удаленный график работы Конкурентный уровень заработной платы и ежегодная индексация Возможность принять участие в интересных и сложных проектах с лучшими специалистами индустрии.","Data Analysis,Confluence,Удаленная работа,SQL,Python,Jira,Английский — B2 — Средне-продвинутый",Группа НЛМК Т и Диджитал,
16802,77737078,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Литрес – лидер рынка электронных книг в России и СНГ. Мы создаем книжные продукты уже более 17 лет. Каждый месяц 12,5 млн человек покупают, читают или слушают книги у нас. В группу компаний входят: онлайн-магазин litres., приложения «Литрес: Читай и Слушай онлайн» и «Литрес: Слушай аудиокниги», сервис для чтения по подписке MyBook, платформа для новых авторов «Литрес: Самиздат» и для чтецов – «Литрес: Чтец», социальная сеть для читателей LiveLib, приложение с аудиокнигами «Звуки Слов» и другие сервисы. Мы учредили первую в России премию в области электронных и аудиокниг «Электронная буква». Чем предстоит заниматься: Твоя цель - построить вместе с нами масштабируемое решение, которое будет предвосхищать ожидания пользователей, наших читателей и авторов, предоставляя им персонализированный контент, подсказки и аналитику. Мы хотим собрать это решение с нуля и с твоей помощью. Ядро такой системы - это алгоритмы машинного обучения, которые рассчитывают предпочтения миллионов конечных пользователей. Работая в нашей команде, ты будешь участвовать в исследовании, разработке, тестировании и внедрении алгоритмов классического и глубокого обучения в части рекомендаций. Наш стек: Python 3.10, Gitlab CI, MyPy, Flake, Black и интеграционные тесты на PyTest. Сервисы на FastAPI в тех же пайплайнах собираются в образ Docker и деплоятся в кластер Kubernetes. Данные мы храним и используем в MySQL, PostgreSQL, ClickHouse, Redis, Memchached. Мониторинги - Sentry, Prometheus, Grafana. Для проб моделей и тестов кода есть свои и облачные ресурсы с CPU и GPU. Справедливо и для production окружения. Сейчас у нас ~4000 rps на существующей системе и ожидания к новой системе как от хайлоад систем. Мы ожидаем от вас: Владение асинхронным Python и современным фреймворком веб-разработки на его основе (fastapi) Опыт разработки и проектирования функционала REST API Опыт работы с БД (Mysql/PostgreSQL). Уверенное владение SQL (в т.ч. оконные функции) и NoSQL (Redis, memcached) Опыт работы с Gitlab CI, k8s Знания теории вероятностей и статистики (распределения, проверка гипотез) Экспертные знания алгоритмов машинного обучения (наиболее интересны алгоритмы продуктовых рекомендаций) Практический опыт полного цикла решения ML задач: предобработка данных, выбор алгоритмов и тюнинг их параметров, оценка качества моделей, визуализация и т.д. Хорошее знание Python и ключевых DS-фреймворков (pandas, scipy, sklearn, catboost, lightgbm, желателен pyspark) Опыт написания качественного production кода, навыки работы с Git Условия: Комфортный офис в Москва-Сити башне «Меркурий» Официальное оформление по ТК РФ, стабильную белую заработную плату + ежеквартальную премию Удалённый, гибридный или офисный формат работы, стандартную рабочую неделю пн-пт (с гибким началом времени дня) После успешного прохождения испытательного срока: ДМС со стоматологией, ""Добросервис"" с неограниченной юридической и психологической консультацией, фитнес, курсы английского языка. Постоянные скидки от наших партнёров и многое другое Частичную компенсацию парковки Неограниченный доступ ко всем электронным и аудиокнигам Оплату профильных курсов, участие в конференциях Веселые и запоминающиеся корпоративы на природе и в офисе: играем в настолки, xbox и настольный теннис прямо в офисе. Заказываем пиццу каждую последнюю пятницу месяца Отсутствие дресс-кода :)","Python,REST API,SQL",Литрес,"Москва, Выставочная, Деловой центр, 1-й Красногвардейский проезд, 15"
16803,78758907,Data Scientist middle/senior,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","X5 Group - лидер офлайн- и онлайн-рынка продуктов питания. Мы управляем портфелем брендов сетевых магазинов «Пятёрочка», «Перекрёсток», «Карусель», «Чижик», цифровыми бизнесами «Перекрёсток Впрок», «Около», 5Post, а также собственными службами логистики, прямого импорта и рядом цифровых сервисов для партнёров. Х5 Технологии — это отдельная бизнес-единица Х5 Group, которая отвечает за создание комплексных цифровых решений для бизнес-единиц Х5, и решает задачи и бек- и фронт-офисных функций компании. Наша команда — это 3000+ специалистов по информационным технологиям и большим данным. Мы разрабатываем решения, которые помогают десяткам миллионов людей покупать любимые продукты свежими и по лучшей цене каждый день. Мы доказываем, что супермаркет — это тоже цифровой проект, в котором есть место большим данным, машинному зрению, мобильным приложениям и многому другому. Big Data является одним из приоритетных направлений нашей компании. В 2017 году, в рамках компании создан новый департамент по разработке продуктов на основе Big Data. Наша основная задача сейчас - создать инструменты для более качественного изучения трендов среди наших покупателей. Стек: Python, Airflow, Spark, Hive, Jupyter, MLFlow, pyTorch, Keras, Tensorflow, PostgreSQL, Kubernetes, Git Чем предстоит заниматься: Участвовать в разработке продуктивных систем Строить модели машинного обучения, улучшать качество прогноза Заниматься аналитикой и проверкой гипотез Развивать инструменты для проведения A/B тестов Писать код, проводить code-review Предлагать способы оптимизации и совершенствования существующих инструментов Что ждем от кандидата: Знание Python (Scala/Java могут оказаться плюсом) Знание классических алгоритмов и структур данных Знание теоретических и практических продвинутых методов машинного обучения Знание SQL, знакомство с hadoop-стэком (кандидаты уровня middle должны понимать, как выглядит план запросов и что происходит ""под капотом"") A/B тесты, генерация и проверка гипотез (будет плюсом опыт с variance reduction, CUPED, линеаризацией и методом бакетов) Опыт работы с (docker, kubernetes, pyspark, kafka, postgres, airflow) Наличие опыта вывода разработанных решений в прод Мы предлагаем: Гибкий график работы (с 8/9/10 утра) / График работы: 5/2, с 9:00 до 18:15 (в пятницу — до 17:00) возможность работать удалённо или ездить в офис на м. Волгоградский проспект или м. Добрынинская возможность роста: план развития, регулярная обратная связь, 2 раза в год оценка персонала яркую корпоративную жизнь с большим количеством мероприятий и возможностей для творческой реализации: X5 Tech Bar, регулярные внутренние митапы, демо-дни, открытые микрофоны, обмен опытом через внутренние комьюнити, день IT-специалиста, программы корпоративного волонтерства, корпоративное предпринимательство X5 Idea Challenge широкий пакет ДМС (включая выезд за рубеж и стоматологию), страхование жизни и здоровья забота о благополучии сотрудников: регулярная онлайн-йога, ежедневные онлайн-зарядки по утрам, ЗОЖ-марафоны. программа привилегий Prime-zone (скидки на товары и услуги и специальные предложения от компаний-партнёров) материальную помощь сотрудникам, попавшим в сложную жизненную ситуацию Присоединяйся к одной из самых быстрорастущих цифровых команд России! Узнай о нас больше в соц. сетях #X5TECH","Python,Hadoop,Big Data,Machine Learning",X5 Tech,
16804,78260367,Data Scientist,от 250 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Renue — IT-компания из Екатеринбурга. Мы специализируемся на разработке масштабных проектов для государственных и крупных IT-компаний в России и СНГ. Каждый наш новый проект - уникальный, потому что мы занимаемся заказной разработкой (B2G), работаем с highload системами, сервис-ориентированной архитектурой и используем современные фреймворки и технологии. Сейчас мы формируем команду и ищем Data Scientist. Пишем пилотную версию чат-бота для ФНС (Федеральная налоговая служба). Это платформа поставки данных. В текущей версии нас ничего не ограничивает для выбора технологий. Для ускорения разработки мы выбрали готовую платформу для построения чат-бота Rasa. О проекте: ВПД (Внешняя поставка данных) - это пилот и некоторая оптимизация работы пользователей: помощь выполнения сценариев чат-бота для неавторизованных пользователей поиск некоторой информации внутри системы для авторизованных пользователей (распознавание намерений, поиск сущностей). Ближайшие планы: в июне 2023г выпустить пилот, далее развивать проект (выстраивать систему аналитики, обучения и переобучения и т.д.). Перспективы. В следующем году планируется большой контракт на создание публичного чат-бота для одной из федеральных инстанций. У него будет два интерфейса: web и Telegram. Поскольку проект масштабный, пользователей и сценариев будет много. Тебе предстоит: сбор, очистка, обработка и систематизация структурированных и неструктурированных производственных данных из различных источников формирование и проверка гипотез для оптимизации производственных процессов разработка математических моделей и алгоритмов машинного обучения для решения задач прогнозирования числовых рядов, обнаружения аномалий в данных, моделирования и оптимизации производственных процессов формирование и проверка гипотез для улучшения моделей разработка программных средств для взаимодействия математических моделей и моделей машинного обучения с остальными модулями программной системы предоставление аналитических выводов и предложений на основе полученной информации описание исследований, формирование отчетов по их итогам. Ты отлично справишься с задачами nlp, если: имеешь промышленный опыт работы (от постановки задачи до внедрения) в области DS/ML от 3-х лет умеешь решать nlp задачи классификации и кластеризации отлично владеешь Python (DS/ML библиотеки). Мы предлагаем: трудоустройство с первого дня, зарплата белая формат работы на твой выбор: удаленная работа или работа в офисе в центре Екатеринбурга, или гибрид работа в команде с прямыми короткими коммуникации. Мы против формализма и бесконечных совещаний гибкий рабочий график. Мы начинаем во сколько удобно и не считаем часы за работой, готовы к сдвигам в графике, если это не мешает взаимодействию и результату расширенная программа ДМС (с стоматологией, вызовом врача на дом, массажем и телемедициной) развивающая среда: ты сможешь проходить курсы за счёт компании, ездить на IT-конференции, чтобы послушать других или выступить самому помним о праздниках, дарим подарки сотрудникам, веселимся вместе на корпоративах.","Machine Learning,Python,Data Analysis,NLP",Ренью,"Екатеринбург, Площадь 1905 года, улица Хохрякова, 3А"
16806,78453114,"Разработчик data scientist (python, TensorFlow)",от 60 000 руб. до вычета налогов,1–3 года,"Полная занятость,полный день","О нас: Мы разрабатываем решения в области автоматизации медицинского документооборота и не только более 20 лет. Наши продукты: Комплекс Программных Средств ""Виста-Мед"" vistamed.ru Личный кабинет пациента iOS vistamed Мессенджер ТАДАМ iOS/Android/Web А так же десятки специализированных программных продуктов. Вашими задачами будут: Разработка нейросети с использованием алгоритма TensorFlow для распознавания фото и видео данных Участие в разработке нейросети чат-бота для медицины. Анализ временных рядов Предсказание временных рядов Владение библиотеками: pandas, matplotlib, numpy, sklearn Бонусом будет: Владение Python2/3",,Виста,"Санкт-Петербург, набережная Обводного Канала, 93а"
16808,67411146,"Data Scientist, Ранжирование поиска",з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Наша команда занимается разработкой сервисов для поиска на сайте Ozon: находим и ранжируем товары, формируем поисковые подсказки, исправляем опечатки. Наш стек: Python, xgboost, CatBoost, lightGBM, Pytorch, Airflow, Hadoop stack (pySpark, yarn, hive, hdfs), ClickHouse. Вам предстоит: Создавать и улучшать алгоритмы ранжирования товаров на сайте (learning to rank). Решать ML-задачи от идеи до реализации в production: изучение статей, поиск и обработка данных, обучение и валидация моделей, автоматизация расчётов. Заниматься персонализацией результатов поиска для пользователей. Автоматическое понимание и обогащение текстовых запросов пользователей. Работать с действительно большими данными поисковых логов на hadoop-инфраструктуре (~3.5 млрд пользовательских событий в день). Развивать инфраструктуры и архитектуры поискового ранжирования: масштабирование системы добавления фичей, автоматизация сбора датасетов и переобучения. Мы ожидаем: Хорошее знание Python. Опыт решения production DS-задач в интернет-бизнесе (желателен опыт с задачами ранжирования или рекомендаций). Наличие фундаментальной математической базы, знание алгоритмов. Опыт работы с большей частью нашего стека технологий. Мы предлагаем: В первую очередь интересные задачи. Примеры проблем, с которыми борется наша команда: ""холодный старт"" товаров и запросов (как понять, куда поставить товар в выдаче, когда у нас нет по нему статистики) позиционный и другие bias в ранжировании (товары, которые стоят выше, видят чаще, поэтому у них больше ""хорошей"" статистики) релевантность vs заказы: (зачастую люди покупают мелочевку и аксессуары, но хотят видеть в топе основные и дорогие товары) предсказание категории, типа товара и других сущностей по тексту запроса. Динамичный и быстроразвивающийся бизнес, ресурсы, возможность сделать вместе лучший продукт на рынке e-commerce. Свободу действий в принятии решений. Достойный уровень заработной платы. Профессиональную команду, которой мы гордимся. Возможность развиваться вместе с нашим бизнесом.","Python,data science,Разработка поисковых технологий,IT",Ozon нформационные технологии,"Москва, Деловой центр, Деловой центр, Международная, Пресненская набережная, 10"
16809,78260313,Data Scientist,от 250 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Renue — IT-компания из Екатеринбурга. Мы специализируемся на разработке масштабных проектов для государственных и крупных IT-компаний в России и СНГ. Каждый наш новый проект - уникальный, потому что мы занимаемся заказной разработкой (B2G), работаем с highload системами, сервис-ориентированной архитектурой и используем современные фреймворки и технологии. Сейчас мы формируем команду и ищем Data Scientist. Пишем пилотную версию чат-бота для ФНС (Федеральная налоговая служба). Это платформа поставки данных. В текущей версии нас ничего не ограничивает для выбора технологий. Для ускорения разработки мы выбрали готовую платформу для построения чат-бота Rasa. О проекте: ВПД (Внешняя поставка данных) - это пилот и некоторая оптимизация работы пользователей: помощь выполнения сценариев чат-бота для неавторизованных пользователей поиск некоторой информации внутри системы для авторизованных пользователей (распознавание намерений, поиск сущностей). Ближайшие планы: в июне 2023г выпустить пилот, далее развивать проект (выстраивать систему аналитики, обучения и переобучения и т.д.). Перспективы. В следующем году планируется большой контракт на создание публичного чат-бота для одной из федеральных инстанций. У него будет два интерфейса: web и Telegram. Поскольку проект масштабный, пользователей и сценариев будет много. Тебе предстоит: сбор, очистка, обработка и систематизация структурированных и неструктурированных производственных данных из различных источников формирование и проверка гипотез для оптимизации производственных процессов разработка математических моделей и алгоритмов машинного обучения для решения задач прогнозирования числовых рядов, обнаружения аномалий в данных, моделирования и оптимизации производственных процессов формирование и проверка гипотез для улучшения моделей разработка программных средств для взаимодействия математических моделей и моделей машинного обучения с остальными модулями программной системы предоставление аналитических выводов и предложений на основе полученной информации описание исследований, формирование отчетов по их итогам. Ты отлично справишься с задачами nlp, если: имеешь промышленный опыт работы (от постановки задачи до внедрения) в области DS/ML от 3-х лет умеешь решать nlp задачи классификации и кластеризации отлично владеешь Python (DS/ML библиотеки). Мы предлагаем: трудоустройство с первого дня, зарплата белая формат работы на твой выбор: удаленная работа или работа в офисе в центре Екатеринбурга, или гибрид работа в команде с прямыми короткими коммуникации. Мы против формализма и бесконечных совещаний гибкий рабочий график. Мы начинаем во сколько удобно и не считаем часы за работой, готовы к сдвигам в графике, если это не мешает взаимодействию и результату расширенная программа ДМС (с стоматологией, вызовом врача на дом, массажем и телемедициной) развивающая среда: ты сможешь проходить курсы за счёт компании, ездить на IT-конференции, чтобы послушать других или выступить самому помним о праздниках, дарим подарки сотрудникам, веселимся вместе на корпоративах.","Machine Learning,Python,Data Analysis,NLP",Ренью,"Екатеринбург, Площадь 1905 года, улица Хохрякова, 3А"
16810,78260411,Data Scientist,от 250 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Renue — IT-компания из Екатеринбурга. Мы специализируемся на разработке масштабных проектов для государственных и крупных IT-компаний в России и СНГ. Каждый наш новый проект - уникальный, потому что мы занимаемся заказной разработкой (B2G), работаем с highload системами, сервис-ориентированной архитектурой и используем современные фреймворки и технологии. Сейчас мы формируем команду и ищем Data Scientist. Пишем пилотную версию чат-бота для ФНС (Федеральная налоговая служба). Это платформа поставки данных. В текущей версии нас ничего не ограничивает для выбора технологий. Для ускорения разработки мы выбрали готовую платформу для построения чат-бота Rasa. О проекте: ВПД (Внешняя поставка данных) - это пилот и некоторая оптимизация работы пользователей: помощь выполнения сценариев чат-бота для неавторизованных пользователей поиск некоторой информации внутри системы для авторизованных пользователей (распознавание намерений, поиск сущностей). Ближайшие планы: в июне 2023г выпустить пилот, далее развивать проект (выстраивать систему аналитики, обучения и переобучения и т.д.). Перспективы. В следующем году планируется большой контракт на создание публичного чат-бота для одной из федеральных инстанций. У него будет два интерфейса: web и Telegram. Поскольку проект масштабный, пользователей и сценариев будет много. Тебе предстоит: сбор, очистка, обработка и систематизация структурированных и неструктурированных производственных данных из различных источников формирование и проверка гипотез для оптимизации производственных процессов разработка математических моделей и алгоритмов машинного обучения для решения задач прогнозирования числовых рядов, обнаружения аномалий в данных, моделирования и оптимизации производственных процессов формирование и проверка гипотез для улучшения моделей разработка программных средств для взаимодействия математических моделей и моделей машинного обучения с остальными модулями программной системы предоставление аналитических выводов и предложений на основе полученной информации описание исследований, формирование отчетов по их итогам. Ты отлично справишься с задачамиnlp, если: имеешь промышленный опыт работы (от постановки задачи до внедрения) в области DS/ML от 3-х лет умеешь решать nlp задачи классификации и кластеризации отлично владеешь Python (DS/ML библиотеки). Мы предлагаем: трудоустройство с первого дня, зарплата белая формат работы на твой выбор: удаленная работа или работа в офисе в центре Екатеринбурга, или гибрид работа в команде с прямыми короткими коммуникации. Мы против формализма и бесконечных совещаний гибкий рабочий график. Мы начинаем во сколько удобно и не считаем часы за работой, готовы к сдвигам в графике, если это не мешает взаимодействию и результату расширенная программа ДМС (с стоматологией, вызовом врача на дом, массажем и телемедициной) развивающая среда: ты сможешь проходить курсы за счёт компании, ездить на IT-конференции, чтобы послушать других или выступить самому помним о праздниках, дарим подарки сотрудникам, веселимся вместе на корпоративах.","Machine Learning,Python,Data Analysis,NLP",Ренью,"Екатеринбург, Площадь 1905 года, улица Хохрякова, 3А"
16811,78935821,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Requirements: 4+ years of data science experience with at least 2 years of experience in retail and CPG domain Proven knowledge and experience of Python and SQL Knowledge of statistics and machine learning (including but not limited to classical ML and time series forecasting, etc.) Proven experience of LightGBM or similar ML libraries (e.g. XGBoost, CatBoost, scikit-learn, ...) is highly desirable Software Engineering experience and experience working on large-scale ML projects highly desirable Great presentation and storytelling skills, proven interpersonal skills. Responsibilities: Support startups with data science research and development. Participate in internal products development. Benefits: Projects in Western Europe and America. Career and professional growth. Product development. Full cycle projects. Corporate-funded training (functional training, foreign languages). Benefits (football, basketball, swimming pool, health insurance, sports compensation, corporate presents and events). Friendly team. Long term full time employment Stable pay (100% official). Flexible working hours Mentor's support and guidance to help you grow as a developer.","Python,Data Mining,MATLAB,Data Analysis,MS SQL,Machine learning,Time Series Analysis,Data Science,Английский — B1 — Средний",LeverX International,
16812,78405363,Аналитик данных / Data Scientist,от 150 000 руб. на руки,1–3 года,"Полная занятость,полный день","Обязанности: Проверять продуктовые гипотезы и готовить Ad-hoc аналитику для поддержки принятия бизнес-решений. зучать поведение пользователей, формулировать гипотезы по улучшению их опыта. Планировать эксперименты вместе с командами маркетинга и продаж, проводить их и подводить итоги. Подготовка презентаций, ведение регулярных отчетных таблиц, загрузка и контроль входных - выходных данных. Анализ, оформление, подготовка аналитических записок. Разработка формул для расчетов. Мы ожидаем от вас: Высшее образование (обязательно с математическим или техническим уклоном). Опыт работы с OLAP-кубами, большими массивами данных. Опыт работы с неструктурированными данными. Продвинутое использование Microsoft Excel, Microsoft PowerBI. Продвинутое использование Python, Jupiter notebook, Scikit-learn, Pandas, Keras, Catboost. Опыт предобработки данных. Опыт исследовательского анализа данных. Опыт статистического анализа данных. Опыт применения машинного обучения в бизнесе. Вы знакомы с продуктовыми метриками и представляете, как их используют. Знаете SQL и применяли его для решения практических задач (желательно, по возможности). Умеете автоматизировать рутинные задачи с помощью программирования (желательно, по возможности). Грамотно излагаете свои мысли. Условия: Оклад обсуждается после финального собеседования с успешным кандидатом. График работы 5/2 10:00 - 19:00 (формат работы обсуждается). нтересные задачи в Компании с известным брендом на рынке элитной недвижимости. Дружный коллектив профессионалов.","Ad Hoc Analysis,Python,Olap (online analytical processing),База данных: Olap,Аналитическое мышление,Анализ данных,Jupiter,Pandas,PowerBI,Английский — B1 — Средний",Kalinka - Realty,"Москва, 1-й Казачий переулок, 7"
16813,78825971,Data scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","СберМобайл - MVNO мобильный оператор связи от Сбербанка ищет Аналитика больших данных Задачи: сследовать паттерны поведения клиентов, находить точки роста, изучать ретеншен Совместно с продуктовой командой искать новые направления развития продукта Формировать кластеризацию клиентской базы Формулировать и проверять гипотезы улучшающие ключевые метрики, оценивать бизнес-эффект от вносимых изменений Проектировать, сопровождать и оптимизировать систему аналитики для различных продуктов Участвовать в аналитических исследованиях, необходимых для запуска и внедерения новых продуктов Разрабатывать и поддерживать дашборды и системы метрик Строить модели клиентского поведения. Требования: Высшее образование (математика, статистика, аналитика данных) Знание продуктовых метрик телеком рынка Опыт работы в области анализа данных (воронки, когортный анализ, A/B-тесты) Знание мат. статистики, понимание основ теории вероятности Опыт понятной визуализации статистических данных и подготовки презентаций Эксперт SQL, Python Понимание основ data science и машинного обучения Умение работать в режиме многозадачности, внимательность к деталям, умение работать в тесной связке с бизнес заказчиком (продукт), способность находить зависимости, уметь объяснять отклонения.  Условия: Данная вакансия не предполагает сотрудников в подчинении График работы 5/2 с 9.00, 9.30 или 10.00, в пятницу сокращенный рабочий день на 1 час 15 минут Официальная заработная плата обсуждается с успешными кандидатами на собеседовании (оклад + ежеквартальные и годовые премии) спытательный срок 3 месяца ДМС после испытательного срока (поликлиническое обслуживание, обследование со сдачей анализов, страховка за рубежом, возможность прикрепления родственников, психологические консультации, +1 день к отпуску за прохождение чек-апа) Компенсация 50% фитнеса и английского языка после испытательного срока Частичная компенсация парковки Дисконт-программы от компаний-партнеров (фитнес, страхование, туризм) Льготное кредитные и ипотечные программы Социальные льготы Оплата участия в спортивных мероприятиях Возможность обучение за счет Компании Офис 5-7 минут пешком от м. Кутузовская, парк Победы , 10 минут .","Бюджетирование,Подготовка презентаций,MS Excel,Финансовый анализ",Сбербанк-Телеком,"Москва, Поклонная улица, 3к2"
16814,78120333,"Data Scientist, Товарные рекомендации",з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Наша команда занимается персонализированным подбором контента для пользователей с целью повышения прибыльности компании. Наш сервис с runtime движком на Golang включает в себя онлайн ML: мы учитываем текущий товар, состояние корзины и другие факторы при ранжировании товаров. Data Scientist у нас – это сотрудник широкого профиля, занимающийся полным циклом вывода в production: от проверки идеи на Spark и Python до разработки новой части системы на Golang.  В отделе нет менеджеров, а решения принимаются на основе эмпирических данных. Члены команды закончили лучшие университеты и (или) имеют значительный опыт и знания, которые вы сможете перенять. Performance Review зависит от объективных измеримых критериев, следуя которым вы сможете профессионально расти предсказуемым образом. Наш стек: Python, Airflow, Golang, Hadoop stack (pySpark, yarn, hive, hdfs). Вам предстоит: Заниматься анализом данных на Python, Spark. Заниматься продуктовой аналитикой. Писать runtime движок на Golang. Мы ожидаем: Хорошее знание Python и Golang, или иметь желание быстро их изучить. Понимание алгоритмов ML. DL как плюс. Умение решать leetcode-medium. Наличие фундаментальной математической базы, знание алгоритмов. Знание и опыт работы на практике с большей частью нашего стека технологий. Мы предлагаем: Динамичный и быстроразвивающийся бизнес, ресурсы, возможность сделать вместе лучший продукт на рынке e-commerce. Свободу действий в принятии решений. Достойный уровень заработной платы. Профессиональную команду, которой мы гордимся. Возможность развиваться вместе с нашим бизнесом.","Python,pytorch,hadoop,data science,Разработка поисковых технологий,IT",Ozon нформационные технологии,"Москва, Деловой центр, Деловой центр, Международная, Пресненская набережная, 10"
16815,78834164,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Чем предстоит заниматься: Разработкой регрессионных и авторегрессионных моделей, предсказанием временных рядов (Python) Разработкой математической библиотеки обработки и прогнозирования данных в команде разработчиков (Python) Анализом, подготовкой, обработкой данных (SQL, Python) Мы ожидаем от тебя: Опыт владения современными методами машинного обучения Знания в области математики (в частности, линейной алгебры), статистики и методов оптимизации Уверенное знание инструментов разработки: Python, SQL Опыт разработки статистических и регрессионных моделей и ML в Python Знания стандартных библиотек для обработки и анализа данных: Pandas, NumPy, SсiPy, scikit-learn, Keras/TensoFlow Мы предлагаем: Трудоустройство в аккредитованную Т компанию Достойную твоего профессионального уровня заработную плату (уровень вознаграждения обсуждается индивидуально по результатам интервью) Годовую премию по результатам деятельности, дополнительную материальную мотивацию (премии от руководителя) Качественная программа ДМС со стоматологией с первого месяца работы услуги телемедицины, консультации психолога, страхование жизни и здоровья в том числе за границей, льготные условия страхования для близких и возможность расширить перечень клиник по опции Flexible benefits Неограниченный доступ к образовательному контенту на портале знаний от корпоративного университета Подписка на лучшие электронные библиотеки с подборками IT-литературы (и не только) Собственный центр профессионального развития, в котором проводятся комплексные программы обучения hard skills Внутренние демодни, коуч-дни, питчи – то, что поможет продвигать и совершенствовать проекты и собственные идеи Корпоративные скидки для изучения английского языка в малых группах онлайн и офлайн Регулярные карьерные марафоны, индивидуальные карьерные консультации и планы развития Общение вне рабочих рамок – независимо от того, в каком городе ты работаешь! От участия в корпоративных спортивных сообществах до онлайн-экскурсий и неформальных встреч в формате Random coffee В «Газпром нефть» ты можешь: • Получить уникальный профессиональный опыт • Создавать смелые проекты с нуля и наблюдать за их влиянием на целую отрасль • Быть вместе с теми, кого вдохновляют сверхсложные задачи • Сочетать несколько ролей, быть частью нескольких команд или участвовать в кросс-функциональных командах • спользовать возможности компании-лидера для своей самореализации и убедиться, что любой профессиональный опыт важен • Быть среди тех, кто создает первую в России цифровую платформу для управления промышленной компанией нового поколения","Python,ML,MS SQL,Pandas,NumPy,SсiPy",Газпром нефть,
16816,76815798,Lead data scientist,от 300 000 до 350 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Дром — автомобильный интернет-портал федерального уровня, содержащий в себе обширную базу информации по автомобилям. Аудитория Дрома и наших смежных проектов — более 3,5 миллионов пользователей в сутки. Дром входит в ТОП-3 автомобильных классифайдов России, являясь лидером на рынке во многих регионах. Ежегодно по объявлениям с Дрома совершается более 1,5 млн реальных сделок по продаже автомобилей. Наш стек: Python, Java, PyTorch, Catalyst, CatBoost, LightGBM, MySQL, PostgreSQL, ClickHouse, scyllaDB, Redis, Luigi, Docker, Kubernetes, GitLab CI, Grafana. Задачи: RecSys. Улучшать качество ранжирования объявлений в персонализированной ленте рекомендаций Оптимизировать скорости и потребление ресурсов при инференсе Помогать в улучшении инфраструктуры и внедрять современные инженерные практики для наших сервисов Управлять командой из 4+ ML разработчиков Помогать продуктовой команде находить новые направления и улучшать качество наших продуктов при помощи ML решений. Что мы ожидаем от вас: Опыт в индустрии по направлению ML 3+ лет Экспертизу в RecSys Опыт активного участия в проектах на всех этапах: от постановки задачи до внедрения на продакшн Наличие минимального опыта управления разработкой в небольшой команде или менторства новичков Python. Умение спроектировать небольшое приложение и написать поддерживаемый/production ready код. Будет плюсом, если вы: меете практический опыт решения задач схожих с нашими Сталкивались ранее с MLOps или инфраструктурными задачами Выкатывали ваши сервисы в k8s меете бэкграунд backend SWE Уже ранее работали в продуктовой компании. Особенности работы: Распределенная команда. Находимся в трех разных часовых поясах с большой разницей во времени: Владивосток +7 МСК, Новосибирск/Томск +4 МСК, Москва Мы не только обучаем модели, но и занимаемся их внедрением: создание микросервисов, манифестов k8s, автоматизация пайплайнов. Плотно сотрудничаем с DevOps для того, чтобы сделать процесс доставки моделей в прод удобным. Мы предлагаем: Широкий спектр задач: RecSys, в меньшей степени CV, OCR иASR, антифрод, матчинг, ускорение А/Б тестирования. Можно “затащить” и новое для нас направление, если оно будет приносить пользу продукту Возможность влиять на продукт, которым пользуются миллионы пользователей При желании возможно менять компанию и процессы в ней Работа в удобном режиме офис/удаленка MacBook Pro в день трудоустройства Оплата обучения и посещение конференций Полностью официальная зарплата, оформление по ТК РФ Стабильные пересмотры зарплаты по итогам performance review.","машинное обучение,алгоритмы,computer vision,Python",Дром,
16817,78894061,Senior/middle Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Наша команда занимается обучением SOTA моделей для решения задач NLP и PLP. В NLP мы занимаемся SOTA подходами в ODQA. Пытаемся обучить диалоговые модели, которые умеют поболтать и в ODQA (like ChatGPT). В PLP пытаемся разработчикам облегчить жизнь.Мы, совместно с командой из SberWorks, делаем плагины для сред разработки. Разработали плагин автозавершения кода для VSCode, PyCharm, IDEA . Пока сосредоточены на Python, Java, JS, но список будет расширяться. В Сбере уже более 1000 строк кода пишут наши модели. Мы целимся превзойти результаты Copilot, TabNine. Если вы имеете амбиции добиться результатов в NLP/PLP и имеете много идей, что нового попробовать в этой области, то давайте к нам! Что ожидаем от кандидата? хорошие теоретические знания в DL знание последних достижений в области NLP/PLP. Постоянно следите за последними пейперами умение формулировать эксперименты с научной строгостью, обосновывать их и проводить самостоятельно опыт тюна моделей на различные задачи NLP/PLP опыт обучения трансформеров с нуля. распределенное обучения моделей (horovod, torch.distibuted) стандартные библиотеки для DL и NLP (PyTorch, TensorFlow, Transformers) увлеченность NLP/PLP и DL Дополнительно плюсом будет: участие в соревнованиях по ML сабмиты на лидербордах по NLP/PLP публикации формулирование экспериментов обучение моделей на кластере оценка качества моделей подготовка прототипов оптимизация инференса моделей Что мы предлагаем: оформление по ТК РФ возможность работать удалённо или в офисе социальный пакет (ДМС) возможность посещения конференций, обучения и сертификации за счет компании Льготное кредитование и ипотека офис: Москва, Кутузовский 32.","Python,NLP,C++,ML",Сбер. IT,"Москва, Кутузовская, Кутузовский проспект, 32"
16818,78627603,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Чем предстоит заниматься: разрабатывать витрины данных разрабатывать математические модели прогнозирования поведения клиентов, LTV, NBO проводить А/В тесты, создавать метрики для анализа их результатов поддерживать внедрение и мониторинг разработанных моделей формировать документацию о результатах моделирования формировать и проверять гипотезы по увеличению ценности клиентской базы взаимодействовать с командами Т и управления данными в части контроля качества данных Наши ожидания: обладаете навыками проведения анализа данных на языке Python / R (исследовательский и статистический анализ данных, проверка статистических гипотез, A/B анализ) умеете работать c большими массивами данных (более 10 млн строк) обладаете опытом работы с реляционными базами данных Oracle, MS-SQL (умение писать сложные запросы SQL, процедуры, триггеры, jobs) владеете навыками построения и сопровождения моделей машинного обучения (кластеризация, классификация, регрессия прогнозирование временных рядов и последовательностей действий, модели LTV (life time value) и NBO (Next best offer)) умеете подготавливать и эффективно презентовать выводы и итоги аналитических исследований Технологический стек: Python/R, SQL, no-SQL, Oracle, Jupyter – notebook TensorFlow, Keras, Scikit-learn, NumPy, Pandas, SHAP, catboost, MICE, Caret, H2O, Airflow Мы предлагаем: официальное трудоустройство по ТК РФ возможность работать удалённо на территории РФ возможность самостоятельно определять методы и архитектуру белая заработная плата два раза в месяц ежегодный отпуск, больничный, льготное ДМС с первого дня работы возможность построить карьеру в стабильном банке льготные условия по кредитной карте, кредиту и ипотеке скидки до 70% на покупки от 500 лидеров рынка через корпоративный агрегатор","Oracle Pl/SQL,SQL,Работа с базами данных,ORACLE,База данных: Oracle,Python",БАНК УРАЛСБ,
16819,78823109,Data Scientist (Рекомендательная система),з/п не указана,3–6 лет,"Полная занятость,полный день",,,Сбер. IT,
16820,78272528,Data-Scientist (Junior/Middle/Senior) в лабораторию нейронаук,з/п не указана,1–3 года,"Полная занятость,полный день","Мы R’n’D-поздразделение. Лаборатория помогает Банку выращивать метрики и улучшать продукт за счет нейронаучного/психологического взгляда на клиента. Как правило, к нам приходят когда все стандартные методы испробованы и нужен свежий взгляд на явление / ситуацию (новые способы повышения метрик, анализ резкого изменения поведения в продукте и т.д.). Мы занимаемся моделированием поведения, определением потребностей и обогащением профиля клиента. Разрабатываем решения для персонализации продуктовых предложений и коммуникаций с клиентами на стыке AI-технологий, нейронаук, поведенческой экономики, маркетинга и банковского бизнеса. Работаем со всей BigData экосистемы. Взаимодействуем с большинством команд Сбера и бизнес-юнитами. Мы команда с атмосферой стартапа, но с масштабом корпорации.. Обязанности Нам нужен человек для поиска закономерностей в временных рядах. У банка огромная база транзакционных данных и мы будем исследовать, как меняются психологические признаки человека во времени. А также строить модель для их описания в настоящем и будущем. А еще ты будешь вместе с нами: Строить предиктивные модели: от регрессий до нейронных сетей. Работать с разными типами данных: текст, графы, картинки, временные ряды - на R&D проектах, основанных на сложной предметной области и методология психотипирования, принятой в Лаборатории. скать инсайты в больших объемах неоднородных данных. зучать и предсказывать поведения пользователей. скать паттерны онлайн поведения и особенностей в письменной и устной речи. Участвовать в постановке задач для DE лаборатории на получение данных. Требования Опыт работы в роли data-scientist от 1го года для junior, 2х лет для middle и 4х лет для senior. Понимание и опыт практического применения математической статистики, теории вероятностей и методов машинного обучения. Знание SQL и Python (pandas, scikit-learn, catboost, torch, keras, tenserflow, automl). Понимание работы используемых моделей и подходов или готовность разобраться по документации и статьям. Здоровая нацеленность на результат, проактивность. Критикуешь - предлагай, мы открыты для новых идей. Стремление находить решения самостоятельно, а если долго не получается - суметь оторваться и попросить помощи. Умение понятно для бизнеса изложить суть разработанного алгоритма, качественно представить, визуализировать и задокументировать свои результаты. Навык планирования и оценки сроков выполнения работ. Хорошие коммуникативные и аналитические навыки. Умение и желание полноценно разобраться в задаче, Задавать вопросы, предлагать свои решения. Будет плюсом Умение готовить временные ряды для моделей машинного обучения, опыт эконометрики. Знание стека Hadoop/Hive/Spark и опыт работы с большими объемами данных. Опыт использования Clickhouse. Опыт использования и выкатывания моделей в продакшен. Профиль на github со своими pet-projects. Участие в AI-соревнованиях. Условия Дружная разносторонняя команда. Уникальные масштабные проекты и сложные разноплановые задачи. Участие в различных конференциях, митапы DS Community банка и корпоративные мероприятия. Обучение за счёт банка (онлайн и офлайн, в т. ч. на внешних платформах). ДМС, спортзал, сниженные ставки по кредитам, дисконт-программы от множества компаний-партнеров. Возможность принять участие в других крупных и уникальных проектах экосистемы. Офис на Кутузовском проспекте. Гибкий график 5/2.",,Сбер для экспертов,
16821,76939405,Data scientist (Middle+\Senior),з/п не указана,3–6 лет,"Полная занятость,полный день","Привет, к себе в команду ищем аналитика данных, формат работы: гибридный или удаленный только по РФ. Сейчас открыто несколько ставок на следующие проекты: продвижение кредитно-платежных продуктов (кредитные продукты, рисковые скоринги, автоплатежи и т.д.) персонализация тарифного плана: формирование наполнения тарифа по профилю абонента Чем предстоит заниматься Разработка моделей, углубленная аналитика, генерирование и проверка гипотез с целью формирования персонализированных предложений абонентам, прогноза спроса, трафика, выручки, удовлетворенности абонентов и других ключевых событий, влияющих на успешность нашей Компании Написание production-ready кода для быстрого деплоя пайплайна через MLOps Настройка мониторинга моделей и логики регулярного дообучения Оценка эффективности реализованных проектов (как технической, так и экономической), оценка потенциала проектов в процессе разработки Постановка задач на junior и middle дата-сайнтистов, обеспечение качества разработанных ML продуктов (версионирование, документация, code review, мониторинг и т.д. в соответствии с принятыми в подразделении регламентами и SLA) Что для этого нужно Знания в области математики, теории вероятности, мат. статистики (высшее образование, наличие ученой степени будет дополнительным плюсом) Наличие успешно завершенных проектов с использованием технологий анализа данных и машинного обучения Знание алгоритмов машинного обучения, принципов их работы, ключевых особенностей и ограничений Отличное владение инструментами анализа данных, библиотеками машинного обучения Необходимый стэк: Python, PySpark, Hadoop, SQL, Airflow, MLFlow Опыт работы в области Data Science от 3х лет","SQL,Hadoop,Python,Pyspark,Airflow","МегаФон, IT","Москва, Маяковская, Новослободская, Чеховская, Оружейный переулок, 41"
16822,76815797,Lead data scientist,от 300 000 до 350 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Дром — автомобильный интернет-портал федерального уровня, содержащий в себе обширную базу информации по автомобилям. Аудитория Дрома и наших смежных проектов — более 3,5 миллионов пользователей в сутки. Дром входит в ТОП-3 автомобильных классифайдов России, являясь лидером на рынке во многих регионах. Ежегодно по объявлениям с Дрома совершается более 1,5 млн реальных сделок по продаже автомобилей. Наш стек: Python, Java, PyTorch, Catalyst, CatBoost, LightGBM, MySQL, PostgreSQL, ClickHouse, scyllaDB, Redis, Luigi, Docker, Kubernetes, GitLab CI, Grafana. Задачи: RecSys. Улучшать качество ранжирования объявлений в персонализированной ленте рекомендаций Оптимизировать скорости и потребление ресурсов при инференсе Помогать в улучшении инфраструктуры и внедрять современные инженерные практики для наших сервисов Управлять командой из 4+ ML разработчиков Помогать продуктовой команде находить новые направления и улучшать качество наших продуктов при помощи ML решений. Что мы ожидаем от вас: Опыт в индустрии по направлению ML 3+ лет Экспертизу в RecSys Опыт активного участия в проектах на всех этапах: от постановки задачи до внедрения на продакшн Наличие минимального опыта управления разработкой в небольшой команде или менторства новичков Python. Умение спроектировать небольшое приложение и написать поддерживаемый/production ready код. Будет плюсом, если вы: меете практический опыт решения задач схожих с нашими Сталкивались ранее с MLOps или инфраструктурными задачами Выкатывали ваши сервисы в k8s меете бэкграунд backend SWE Уже ранее работали в продуктовой компании. Особенности работы: Распределенная команда. Находимся в трех разных часовых поясах с большой разницей во времени: Владивосток +7 МСК, Новосибирск/Томск +4 МСК, Москва Мы не только обучаем модели, но и занимаемся их внедрением: создание микросервисов, манифестов k8s, автоматизация пайплайнов. Плотно сотрудничаем с DevOps для того, чтобы сделать процесс доставки моделей в прод удобным. Мы предлагаем: Широкий спектр задач: RecSys, в меньшей степени CV, OCR и ASR, , антифрод, матчинг, ускорение А/Б тестирования. Можно “затащить” и новое для нас направление, если оно будет приносить пользу продукту Возможность влиять на продукт, которым пользуются миллионы пользователей При желании возможно менять компанию и процессы в ней Работа в удобном режиме офис/удаленка MacBook Pro в день трудоустройства Оплата обучения и посещение конференций Полностью официальная зарплата, оформление по ТК РФ Стабильные пересмотры зарплаты по итогам performance review.","машинное обучение,алгоритмы,computer vision,Python",Дром,
16823,78497569,"Data Scientist, Ранжирование поиска",з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Наша команда занимается разработкой сервисов для поиска на сайте Ozon: находим и ранжируем товары, формируем поисковые подсказки, исправляем опечатки. Наш стек: Python, xgboost, CatBoost, lightGBM, Pytorch, Airflow, Hadoop stack (pySpark, yarn, hive, hdfs), ClickHouse. Вам предстоит: Создавать и улучшать алгоритмы ранжирования товаров на сайте (learning to rank). Решать ML-задачи от идеи до реализации в production: изучение статей, поиск и обработка данных, обучение и валидация моделей, автоматизация расчётов. Заниматься персонализацией результатов поиска для пользователей. Автоматическое понимание и обогащение текстовых запросов пользователей. Работать с действительно большими данными поисковых логов на hadoop-инфраструктуре (~3.5 млрд пользовательских событий в день). Развивать инфраструктуры и архитектуры поискового ранжирования: масштабирование системы добавления фичей, автоматизация сбора датасетов и переобучения. Мы ожидаем: Хорошее знание Python. Опыт решения production DS-задач в интернет-бизнесе (желателен опыт с задачами ранжирования или рекомендаций). Наличие фундаментальной математической базы, знание алгоритмов. Опыт работы с большей частью нашего стека технологий. Мы предлагаем: В первую очередь интересные задачи. Примеры проблем, с которыми борется наша команда: ""холодный старт"" товаров и запросов (как понять, куда поставить товар в выдаче, когда у нас нет по нему статистики) позиционный и другие bias в ранжировании (товары, которые стоят выше, видят чаще, поэтому у них больше ""хорошей"" статистики) релевантность vs заказы: (зачастую люди покупают мелочевку и аксессуары, но хотят видеть в топе основные и дорогие товары) предсказание категории, типа товара и других сущностей по тексту запроса. Динамичный и быстроразвивающийся бизнес, ресурсы, возможность сделать вместе лучший продукт на рынке e-commerce. Свободу действий в принятии решений. Достойный уровень заработной платы. Профессиональную команду, которой мы гордимся. Возможность развиваться вместе с нашим бизнесом.","Python,data science,Разработка поисковых технологий,IT",Ozon нформационные технологии,"Санкт-Петербург, Херсонская улица, 12-14"
16824,78265110,Senior Data Scientist,от 300 000 руб. на руки,3–6 лет,"Полная занятость,полный день",,,Сеть Партнерств,
16825,78097457,Junior Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день",,,«UZUM TECHNOLOGIES».,
16826,78680130,Data Scientist / ML-инженер,з/п не указана,1–3 года,"Полная занятость,полный день","Медиалогия разрабатывает высоконагруженные системы, которые в режиме реального времени сканируют весь текстовый сегмент нтернета (100+ млн. сообщений в сутки, 1.7 млрд. метрик) и, используя уникальные технологии лингвистического анализа и компьютерного зрения, позволяют осуществлять мгновенный анализ упоминаний наших клиентов в соц.сетях, блогах, форумах и управлять их репутацией. Задачи: Построение и тестирование гипотез Создание моделей для задач NLP и CV Доработка и улучшение существующих моделей Анализ данных из социальных сетей: классификация, кластеризация, выявление аномалий Проведение экспериментов на ""больших данных"" и обработка результатов Требования: Уверенное знание Python и библиотек для работы с данными (numpy, pandas, sklearn, catboost и др.) Умение писать чистый хорошо структурированный код Опыт создания моделей машинного обучения на TensorFlow, PyTorch и др. Умение работать с неструктурированными контентом, правильно оценивать качество моделей Умение работать в команде, хорошие коммуникативные навыки, Желание активно развиваться и браться за самые сложные задачи. Желателен опыт работы с большими данными (Spark, Hadoop) Условия: Белая ЗП, официальное оформление по ТК РФ ДМС с хорошим выбором клиник и международной страховкой Современный офис в 10 мин от м. Дмитровская (БЦ «Савеловский Сити» с массажистом, кикером, турником и PlayStation) или полная удаленка Гибкое начало рабочего дня Возможность посещения профильных мероприятий и карьерное развитие Рядом дизайн-завод Флакон, кафе и магазины.","Python,Adobe Photoshop,Аналитические исследования,Аналитическое мышление,Статистический анализ,Machine Learning,Neural Networks,Deep Learning,Data Science,Data Analysis,Data Mining,Big Data,Анализ данных",Медиалогия,"Москва, Дмитровская, Новодмитровская улица, 2к2"
16827,69631571,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Дорогой кандидат, мы - динамично растущая команда экспертов в области построения рекомендательных систем Наша главная цель - построить современную, масштабируемую платформу, которая будет постоянно предвосхищать и превосходить ожидания пользователей, предоставляя им персонализированные рекомендации на всем клиентском пути в экосистеме Сбер Наша платформа будет обслуживать широкий круг потребителей и строить персональные рекомендации во всех сферах бизнеса, таких как музыка (Звук), фильмы (ОККО), онлайн торговля (СберМаркет, СберМегаМаркет), медицина (еАптека) и многих других, которые присутствуют в быстро растущей экосистеме Если ты мечтаешь поучаствовать в создании такой рекомендательной системы, то тебе к нам! нтеллектуальное ядро такой системы - это алгоритмы машинного обучения, которые анализируют по-настоящему большие данные, и в реальном времени рассчитывают предпочтения миллионов конечных пользователей. Работая в нашей команде, ты будешь участвовать в исследовании, разработке, тестировании и внедрении самых передовых алгоритмов классического и глубокого обучения в части рекомендаций. Ты получишь опыт внедрения таких алгоритмов в реальной индустриальной экосистеме, начиненной большими данными и работающей с высокими нагрузками при их обработке Мы ищем: Middle/Senior Data Scientist в команду единой рекомендательной платформы для компаний экосистемы Сбер. Что предстоит делать: Разработка ML пайплайнов для формирования персональных рекомендаций и их продуктизация сследование современных подходов к рекомендациям Постановка и реализация гипотез по улучшению бизнес метрик Оптимизация существующих пайплайнов. Стек технологий: Для разработки используем: Python, PySpark, Pandas, PyTorch, RecBole, Scikit-learn, AirFLow, MLFlow и др. Для организации работы: Jira, Confluence, Git. Что для нас важно: Практический опыт полного цикла решения ML задачи: предобработка данных, выбор алгоритмов и тюнинг их параметров, оценка качества моделей, визуализация Знание математики (линейная алгебра, мат. статистика, методы оптимизации) Опыт работы с Python библиотеками для DL (PyTorch / TensorFlow), ML (Scikit-learn / XGBoost / CatBoost) и анализа данных (Pandas / NumPy / SciPy). Будет плюсом: Опыт реализации production DS проектов в области продуктовых рекомендаций (для senior – обязательно) Опыт работы с Spark, Airflow Опыт реализации online inference в условиях высокой нагрузки. Мы предлагаем: Стабильный доход и социальная поддержка сотрудников Расширенный ДМС с первого дня работы для сотрудников и льготная медицинская страховка для близких Бесплатная подписка СберПрайм+, скидки на продукты компаний-партнеров Корпоративная пенсионная программа Корпоративное обучение за счет компании Реферальная программа для сотрудников: можно пригласить в команду знакомых профессионалов и получить вознаграждение до 100 тыс. рублей Крупнейшее DS&AI community — более 600 DS-специалистов банка Дайджест о самых последних разработках в области DS&AI и отчеты с крупнейших конференций мира Мощное железо, дополнительные мониторы и всё, что нужно для продуктивной работы Работу по Agile с лучшими из IT индустрии: 2000 продуктовых команд и возможность внутреннего перемещения Возможность выбрать удобный формат работы: гибрид или офис Комфортный офис, бесплатные снеки, спортзалы с бассейнами Офис: г. Нижний Новгород, ул. Бекетова 13Б.",,Сбер. IT,
16828,73751357,Senior Data Scientist (разработка Скоринговых моделей),з/п не указана,1–3 года,"Полная занятость,полный день","В команду, которая занимается разработкой скоринговых моделей, ищем коллегу уровня middle и выше, желательно с опытом работы в банке. Периметр клиентов для разработки моделей: малый и средний бизнес, КБ, Банки, Суверены, Субъекты, Проектное финансирование, Девелопмент. Обязанности: осуществлять разработку новых и модификацию существующих скоринговых моделей осуществлять расчет (оценку) экономического эффекта от внедрения скоринговых моделей готовить аналитические записки и материалы, отчеты о разработке скоринговых моделей принимать участие в подготовке и согласовании проектной документации на разработку/ доработку C согласовывать функциональные требования и технические задания по доработке информационных систем Банка в части процесса принятия решений в процессах, использующих статистические модели. Требования: высшее образование (математическое / физико-математическое) опыт работы не менее 2 лет по направлению анализа данных и моделирования владение одним из языков/инструментов анализа данных (предпочтителен Python) и структурированных запросов для работы с данными (T-SQL, Impala, Hive, Spark SQL) фундаментальные знания в области финансовой математики, теории вероятностей, математической статистики, алгоритмов машинного обучения и их реализации в среде Python или R Условия: трудоустройство согласно Законодательству конкурентная заработная плата профессиональное обучение и развитие добровольное медицинское страхование, льготные условия кредитования корпоративная пенсионная программа, материальная помощь спортивная жизнь и корпоративные мероприятия возможность построить карьеру в ведущем банке России.","Python,SQL,Математическое моделирование,Математический анализ,R,Miner,Teradata","ПАО ВТБ, Технологический блок",
16829,77132650,"Data Scientist, Поисковые подсказки",з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Наша ультимативная цель – сделать подсказки максимально релевантными для пользователя и покрыть как можно больше запросов, чтобы сделать пользовательский опыт еще лучше и увеличить интерактив на поисковых страницах. Для этого мы разрабатываем и улучшаем технологии базового поиска и ML переранжирования подсказок, меняем их наполнение и функциональность. Мы ищем человека, который поможет команде с исследованием различных гипотез, проведением экспериментов, обучением ML моделей и внедрением их в продакшен. Наш стек: Python, lightGBM, Airflow, Hadoop stack (pySpark, yarn, hive, hdfs), ClickHouse. Вам предстоит: Создавать и улучшение алгоритмов ранжирования поисковых подсказок (learning to rank). Заниматься персонализацией поисковых подсказок для пользователей. Работать с текстовыми данными – фильтрация, обогащение, разбор запросов пользователей. Заниматься ML-задачами от идеи до реализации в production: изучение статей, поиск и обработка данных, обучение и валидация моделей, автоматизация расчётов. Строить новые и развивать уже существующие пайплайны обработки очень больших данных на hadoop-инфраструктуре (~3.5 млрд пользовательских событий в день), обучать и заниматься валидацией ML моделей. Мы ожидаем: Хорошее знание Python. Опыт решения production DS-задач (желателен опыт с задачами ранжирования или рекомендаций) – от гипотезы до рабочей модели в проде. Наличие фундаментальной математической базы, знание алгоритмов, математической статистики. Опыт работы с распределенными вычислениями (Spark, Hadoop). Будет плюсом: Понимание принципов построения распределенных высоконагруженных систем. Опыт работы с поисковыми движками (lucene, elasticsearch). Опыт построения ETL пайплайнов обработки больших данных на Spark. Мы предлагаем: В первую очередь интересные задачи. Динамичный и быстроразвивающийся бизнес, ресурсы, возможность сделать вместе лучший продукт на рынке e-commerce. Свободу действий в принятии решений. Достойный уровень заработной платы. Профессиональную команду, которой мы гордимся. Возможность развиваться вместе с нашим бизнесом.","Python,data science,Разработка поисковых технологий,IT",Ozon нформационные технологии,"Москва, Деловой центр, Деловой центр, Международная, Пресненская набережная, 10"
16830,78506773,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","В связи с расширением команды Департамента математической оптимизации и моделирования ищем специалиста на позицию Data Scientist (Middle, Senior). Наш Департамент создает сервисы, которые оптимизируют процессы компаний. У нас интересные задачи: Прогнозирование спроса, эластичность спроса по цене Поиск фрода Вероятность ухода клиента Раннее обнаружение аномалий по датчикам Скоринговая модель. Чем предстоит заниматься: Сбор и обработка данных из корпоративных информационных хранилищ Обучение предиктивных моделей Прогнозирование временных рядов A/B тестирование Участие во внедрении ML-решений Спектр задач — от разовых rnd исследований до проектного создания решений и последующей эксплуатацией. Необходимый опыт и знания: Знание ML методов Отличное знание Python или R или Matlab Знание SQL Знание математической статистики Опыт работы data scientist от 3 лет Будет преимуществом успешный опыт: прогнозирования спроса, применения глубоких нейронных сетей к табличным данным. Мы предлагаем: Бесценный опыт работы над интересными проектами в сильной команде экспертов. Достойный уровень заработной платы, официальное оформление в аккредитованной Т-компании, социальные гарантии. Комфортные условия: гибкий график работы (удаленно/гибрид/офис), свободный дресс-код. Наши современные офисы расположены в центрах города СПб, Москве, Владимире, Омске, в которых есть зоны отдыха с кикером, настольными играми и игровыми приставками. ДМС + Программа «Кафетерий льгот»: сотрудники за счет компании могут компенсировать расходы на страхование, обучение, спорт, спортивный инвентарь Развитие и обучение: оплата внешних тренингов, семинаров и конференций, корпоративная библиотека.","Прогнозирование,Machine Learning,Mathematical Statistics,Data Science",БиАйЭй-Технолоджиз,"Санкт-Петербург, Фрунзенская, Московский проспект, 94"
16831,76815796,Lead data scientist,от 300 000 до 350 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Дром — автомобильный интернет-портал федерального уровня, содержащий в себе обширную базу информации по автомобилям. Аудитория Дрома и наших смежных проектов — более 3,5 миллионов пользователей в сутки. Дром входит в ТОП-3 автомобильных классифайдов России, являясь лидером на рынке во многих регионах. Ежегодно по объявлениям с Дрома совершается более 1,5 млн реальных сделок по продаже автомобилей. Наш стек: Python, Java, PyTorch, Catalyst, CatBoost, LightGBM, MySQL, PostgreSQL, ClickHouse, scyllaDB, Redis, Luigi, Docker, Kubernetes, GitLab CI, Grafana. Задачи: RecSys. Улучшать качество ранжирования объявлений в персонализированной ленте рекомендаций Оптимизировать скорости и потребление ресурсов при инференсе Помогать в улучшении инфраструктуры и внедрять современные инженерные практики для наших сервисов Управлять командой из 4+ ML разработчиков Помогать продуктовой команде находить новые направления и улучшать качество наших продуктов при помощи ML решений. Что мы ожидаем от вас: Опыт в индустрии по направлению ML 3+ лет Экспертизу в RecSys Опыт активного участия в проектах на всех этапах: от постановки задачи до внедрения на продакшн Наличие минимального опыта управления разработкой в небольшой команде или менторства новичков Python. Умение спроектировать небольшое приложение и написать поддерживаемый/production ready код. Будет плюсом, если вы: меете практический опыт решения задач схожих с нашими Сталкивались ранее с MLOps или инфраструктурными задачами Выкатывали ваши сервисы в k8s меете бэкграунд backend SWE Уже ранее работали в продуктовой компании. Особенности работы: Распределенная команда. Находимся в трех разных часовых поясах с большой разницей во времени: Владивосток +7 МСК, Новосибирск/Томск +4 МСК, Москва В Москве на данный момент только удаленка, в перспективе планируется открытие офиса Мы не только обучаем модели, но и занимаемся их внедрением: создание микросервисов, манифестов k8s, автоматизация пайплайнов. Плотно сотрудничаем с DevOps для того, чтобы сделать процесс доставки моделей в прод удобным. Мы предлагаем: Широкий спектр задач: RecSys, в меньшей степени присутствуют CV, OCR и ASR, антифрод, матчинг, ускорение А/Б тестирования. Можно “затащить” и новое для нас направление, если оно будет приносить пользу продукту Возможность влиять на продукт, которым пользуются миллионы пользователей При желании возможно менять компанию и процессы в ней Работа в удобном режиме офис/удаленка MacBook Pro в день трудоустройства Оплата обучения и посещение конференций Полностью официальная зарплата, оформление по ТК РФ Стабильные пересмотры зарплаты по итогам performance review.","машинное обучение,алгоритмы,computer vision,Python",Дром,
16832,78905162,Data Engineer в Data Lake,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы являемся частью централизованной аналитической платформы данных - Analytical Data Platform, которая включает в себя Data Lake (Hadoop) и аналитическое DWH (Green Plum).  В рамках нашего продукта мы решаем вопрос по стандартизации и автоматизации разработки загрузки/обработки ""сырых"" данных, за качество данных в бизнес слое DWH. Поддерживаем Hadoop и сервисы вокруг него.  Перед нами стоит задача развития современной аналитической платформы, включающей инструменты по сбору, хранению, обработке и анализу данных. Подразделения банка имеют возможность использовать разработанные нашей командой инструменты, процессы и интерфейсы для быстрой и независимой разработки для решения своих прикладных бизнес-задач, связанных с анализом данных. Пользователи нашей платформы - разработчики из продуктовых команд, решающие прикладные задачи ETL для автоматизации бизнес-процессов, Data Scientist'ы и аналитики, которые анализируют с помощью разных инструментов данные, хранящиеся в Data Lake, строят дашборды, обучают и применяют к новым данным модели машинного обучения.  Наш текущий стек: RHEL, Hadoop (а именно HDFS, YARN, Hive), Spark2/3, PostgreSQL, Airflow, NiFi, Zabbix, Rundeck, Jira/Confluence, Gitlab, Ansible, Docker, Grafana. Чем будешь заниматься в рамках своей экспертизы: заниматься ""платформизацией"" используемого стека с целью максимальной автоматизации и оптимизации процесса параллельной независимой разработки на платформе (скрытие сложности реализации низкоуровнего ПО типа Hadoop или Airflow за определенным уровнем абстракции путем разработки интерфейсов, процессов, CI/CD пайплайнов, соглашений, документации и т.д., чтобы продуктовые разработчики могли сосредоточиться на решении прикладных задач) прорабатывать архитектурные вопросы взаимодействия существующих и добавляемых компонентов платформы как между собой, так и с внешними системами (источники, потребители) оказывать поддержку разработчикам Data Lake из продуктовых команд эпизодически решать прикладные задачи на платформе для понимания опыта разработчиков из продуктовых команд - построение ETL-пайплайнов для загрузки в/из Data Lake с использованием платформенных инструментов осуществлять поддержку и решать инциденты в прод-контуре (в том числе от пользователей) проводить RnD, изучать новое open-source ПО (соответствует ли оно нашим стандартам и действительно ли закрывает выявленные потребности). Эта вакансия для тебя, если ты: работал с SQL и имеешь опыт написания запросов, тебя не пугают: join’ы, агрегатные функции, подзапросы, оконные функции имеешь опыт работы с любой из ""классических"" РСУБД (Oracle, MS-SQL PostgreSQL) в качестве разработчика/администратора писал код на Python или любом другом языке программирования общего назначения изучал HDFS и Hadoop, пробовал разворачивать дистрибутив Hadoop дома или в облаке использовал Hadoop, знаешь, как работает YARN, как эффективно хранить данные на HDFS, писал запросы в Hive писал код на Spark и можешь считать данные сервиса, используя его Rest API, отсортировать, отфильтровать их и сохранить результат на HDFS знаком с различными типами СУБД (SQL, NoSQL) и профилями использования (OLAP, OLTP) и можешь аргументированно выбрать оптимальный тип СУБД под задачу имеешь опыт работы с Airflow или любым другим оркестратором плотно работал с Hadoop в качестве разработчика/Data Engineer’а можешь определить для решения какой задачи выбор того или иного инструмента архитектурно более правильный можешь ставить задачи, планировать работу, общаться с заказчиками, быть наставником для менее опытных коллег Будет преимуществом, если ты: знаком с банковской предметной областью имеешь опыт разработки/внедрения систем класса DWH можешь деплоить приложения в Docker разбираешься в CI/CD практиках и инструментах можешь продемонстрировать один из своих проектов на GitHub умеешь писать на Java или Scala (на последней - применительно к использованию в связке со Spark). Что предлагаем: кросс-функциональные команды: владелец сервиса является неотъемлемым членом команды, непосредственно участвующим во всех процессах создания вверенного ему сервиса и жизни команды комфортную культуру открытости и отзывчивости сильные профессиональные IT-сообщества отсутствие бюрократии и дресс-кода гибридный формат работы (дом/офис) или полностью удаленный формат возможность проходить внутреннее и внешнее обучение понятную структуру дохода ДМС со второй недели работы со стоматологией и массажем в РФ страхование жизни и выезжающих за рубеж, страхование в направлении онкологии специальные предложения по вкладам и кредитам скидки от компаний-партнеров по программе Prime Zone в РФ доплату за 14 дней в году по больничному листу до оклада (после испытательного срока) доплату к отпускам, оформленным в январе и мае 3 оплачиваемых отгула в год.",,Райффайзен Банк,
16833,78959033,Data Scientist (Senior),з/п не указана,3–6 лет,"Полная занятость,полный день","Чем нужно будет заниматься: осуществлять управление разработкой новых и модификацией существующих моделей взаимодействие с внутренними заказчиками (формулирование требований, подходов к исследованию/разработке модели и методов оценки конечного результата) расчет экономического эффекта разрабатываемых моделей анализировать множество источников данных (данные продуктов, транзакции, логи и др.) генерировать фичи и отбирать полезные для моделей постановка задач разработчикам на построение промышленных витрин строить полноценные ML-пайплайны (классический жизненный цикл ML-моделей) и делать это грамотно имплементация и обучение моделей машинного обучения исследование возможностей повышения эффективности прогнозных моделей проверять гипотезы, проводить A/B тестирования и пилотные проекты оптимизация моделей работать на внедрение результатов в продакшн. Кто нам нужен: профильное образование (техническое, компьютерные науки, статистика, математика) 5 лет опыта профессиональной разработки моделей машинного обучения уверенное знание python опыт практического применения прикладных библиотек (pandas, sklearn, numpy и др.) твердые знания в области мат статистики и машинного обучения знание алгоритмов supervised и unsupervised уверенное знание sql уверенное знание Linux-систем Будет плюсом знание веб-фреймворков (django/flask) опыт работы с Hadoop, Spark, Airflow - пройденные курсы по ds/ml/cv - опыт участия в хакатонах/соревнованиях по машинному обучению - опыт участия в kaggle соревнованиях.","Python,SQL,ML,DS",Газпромбанк,
16834,78740551,Data Scientist (HR-модели),з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Разработка моделей в направлении Human Resources. Построение моделей влияния обучения на эффективность, выявление факторов, влияющих на выполнение KPI. Разработка математической модели инструментария влияния на повышение эффективности сотрудников. Требования: Уверенное знание статистического анализа Опыт разработки интерпретируемых моделей  Опыт работы с табличными данными  Желателен опыт работы с графами, текстовой аналитикой (NLP) Продвинутое знание Python и стандартного DS стэка: sklearn, pandas, xgboost, tensorflow/pytorch Уверенное знание и владение SQL. Стэк: Hadoop, Impala Умение работать с зашумленными данными, проверка качества данных Проработка A/B тестирования гипотез Опыт разработки и доведения до прода моделей в коммерческих проектах Опыт командной работы (мы используем git, jira).","Python,SQL,Git,Atlassian Jira,Анализ данных",Газпромбанк,
16835,78936721,Data Engineer (ДАДМ),з/п не указана,3–6 лет,"Полная занятость,полный день","Вместе с нами ты будешь: Заниматься проектированием и разработкой витрин данных для анализа и моделирования Заниматься мониторингом и оптимизацией процессов сборки витрин Заниматься загрузкой и обработкой данных из различных источников Заниматься поддержкой и развитием базы знаний Предоставлять экспертную поддержку внутренним потребителям(data analysts,data scientists) Какие знания и навыки для нас важны: Знание SQL Хорошее знание устройства Hadoop,Spark,Hive/Impala Опыт разработки на Python/Scala/Java Понимание основных концепций DWH Понимание базовых команд Git и основных принципов работы Будет плюсом: Опыт работы с банковскими данными Опыт работы с различными СУБД в роли разработчика/аналитика витрин данных Опыт работы с Airflow","DWH,Hadoop,Hive,Git,Python,SCALA,SQL","ннотех, Группа компаний",
16836,78756004,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Вакансия с релокацией на Кипр! Наш клиент - международная компания, которая разрабатывает надежные и актуальные IT-решения для b2c и b2b сегмента находится в поисках Data-scientist: Чем предстоит заниматься: Применение алгоритмов машинного обучения для создания прогностических моделей, определение оптимальных параметров модели и оценка их производительности. сследование и выявление закономерностей, трендов и зависимостей в данных с использованием статистических методов и визуализаций. Проведение работы с различными источниками данных, обработка пропущенных значений, удаление выбросов и преобразование данных для последующего анализа. Подготовка и представление результатов анализа и моделирования для коллег и руководства, включая разработку документации, демонстраций и презентаций. Мониторинг и оптимизация моделей: Отслеживание и анализ производительности развернутых моделей машинного обучения и их оптимизация на основе полученных результатов. Участие в разработке стратегий и подходов к управлению данными, включая вопросы конфиденциальности, безопасности и качества данных. Требования: Опыт работы с библиотеками для анализа данных и машинного обучения: NumPy, pandas, sklearn, scipy, matplotlib, TensorFlow или PyTorch. Английский язык - не ниже В2 Понимание проведения A/B тестирования. Понимание классических методов и алгоритмов машинного обучения, опыт их применения на практике. Базовые знания SQL запросов. Опыт прикладной разработки на Python будет являться большим плюсом. Условия: Белую заработную плату на уровне Ваших профессиональных навыков и пожеланий Помощь с релокацией на Кипр г. Лимассол (авиабилеты, трансфер, визовое сопровождение за счет компании) Офисный формат работы, бесплатные обеды нтересные задачи, перспективные проекты, продвинутые технологии Работу в русскоязычной команде.",,Employcity,
16837,78576605,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","щем Data Scientist'а в региональный центр компетенций по аналитике для направления ценообразования. Обязанности построение моделей машинного обучения в области клиентской аналитики анализ характеристик пользовательского поведения при объёмах данных на уровне десятков миллионов наблюдений контроль и совершенствование применяемых технологий машинного обучения интеграция источников данных и моделей в бизнес-процессы Банка Требования знание математической статистики, теории вероятностей и желание развиваться в этом направлении знание принципов машинного обучения и желание развиваться в этом направлении опыт получения и обработки сырых данных умение анализировать большие объемы данных, видеть скрытые тенденции и закономерности и описывать их хорошее знание Python и пакетов для научных вычислений знание английского языка на уровне чтения профессиональной литературы Приветствуется: опыт участия в соревнованиях по машинному обучению хорошая алгоритмическая подготовка опыт разработки и внедрения информационных систем Условия структура дохода: оклад + годовой бонус обучение и возможность развиваться профессионально заботу о здоровье: ДМС с первого дня и бесплатный фитнес льготные ставки по потребительским кредитам и ипотеке «ДомКлик» бесплатная подписка СберПрайм+",,Сбер для экспертов,
16838,78625975,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","RUTUBE - Крупнейший российский видеохостинг, где собраны различные категории видео: премьерные выпуски шоу и сериалов, прямые эфиры телеканалов, фильмы и мультфильмы, контент видеоблогеров. Мы стремимся сделать лучший видеосервис на базе высокотехнологичных решений, исследований и аналитики, который позволит смотреть качественный лицензионный контент, адаптированный под каждого пользователя. Сейчас нам требуется Senior Data Science, способный быстро погрузиться в новые задачи и усилить нашу команду. Что ты будешь делать: Полный цикл обучения ML моделей, включая подготовку данных для разметки и внедрение моделей в продакшн Разработка CV/NLP/Speech моделей в следующих бизнес-направлениях: Рекомендации: фильтрация контента, развитие инструментов ранжирования и персонализации, механизмов валидации Модерация: анализ видео и комментариев на предмет наличия нарушений авторских прав, откровенного контента, рекламы казино и т.д. Поиск: усовершенствование механизмов поиска с целью выдачи более релевантных результатов Speech-To-Text для транскрибации видео и автогенерации субтитров Взаимодействие с заряженными владельцами продуктов (рекомендации, модерация, поиск) в целях формирования бэклога и развития ML направления для достижения бизнес-результатов Рисерч по использованию SOTA методов (трансформеры для задач обработки текста, речи и видео) Анализ данных, формулировка гипотез и дизайн экспериментов Поиск путей улучшения качества работы текущих моделей Возможность влиять на реальный результат. Что ты уже умеешь: Высшее образование в областях: математика, физика, информатика Знания классического и нейросетевого ML Знания современных технологий компьютерного зрения (CNN, YOLO, U-Net, ViT) и/или методов обработки естественных языков (Word2Vec, fasttext, RNN, трансформеры) Практический опыт работы с PyTorch или TensorFlow Уверенный Python, Linux, SQL, Git Коммуникабельность, умение находить компромиссы и аргументировано отстаивать свою точку зрения Уверенный английский для изучения научной литературы. Будет плюсом: Опыт работы с поисковыми движками Опыт работы с Docker и K8s Опыт использования решений для взаимодействия с backend (PostgreSQL/kafka/rest api/rabbit mq и т.п.). Что мы предлагаем: Опыт работы над крупнейшем видеосервисом страны Работу в команде профессионалов и творческих людей Достойный уровень дохода (обсуждается индивидуально с каждым кандидатом) Мы оформим ДМС не дожидаясь окончания испытательного срока Фрукты, овощи, вкуснейший кофе каждый день Гибкое начало рабочего дня (гибридный формат 2-3 дня в офисе) Уютный офис в шаговой доступности от метро Сокол БЦ Алкон.","Python,SQL,Git,Linux,Математическая статистика,PostgreSQL,PyTorch,NLP,Kafka,Bash,Docker,Machine Learning,RabbitMQ,Tensorflow,Word2Vec",Rutube,"Москва, Аэропорт, Красный Балтиец, Сокол, Ленинградский проспект, 72к4"
16839,78962457,Senior/ Team Lead Data Scientist в ML-команду,з/п не указана,1–3 года,"Полная занятость,полный день","Наша команда занимается построением ML моделей. При реализации кейсов и проведении пилотов находится множество инсайтов, которые помогают делать процессы эффективнее. Для развития этих инсайтов ищем коллегу, в обязанности которого будет входить нахождение решений на стыке ML и классической аналитики Перед командой стоят следующие вызовы: - Прогнозные и причинно-следственные модели - Аудио аналитика телефонных разговоров и записей взаимодействия с клиентами. В том числе перевод аудио в текст, вычленение эмоциональной подоплёки, определения лжецов - Текстовая аналитика записей. В том числе конспект разговоров, вычленение необходимых сущностей, определение лжецов - Гео аналитика клиентов. В том числе где и когда контактировать - Оптимизация бизнес процессов с использованием инструментов process mining Обязанности Фулл стек DS От идей до оценки эффективности готового продукта. Работа ведётся при регулярном общении с бизнес-заказчиком. Управление командой проекта DS Требования Владение алгоритмами работы с табличными пространственными данными, временными рядами, аудио, текстами, гео процессами (опыт от 2 лет совокупно) Python3, включая стек библиотек для работы с машинным обучением Общением с бизнесом по проектам машинного обучения, ориентацией на бизнес результат sql, jupyter, pycharm, git, jira, confluence Будет плюсом опыт управления проектами, в которых участвует несколько команд Условия комфортный офис на Кутузовском проспекте с тренажерным залом, коворкинг-пространствами и кафе полный рабочий день, но гибкий график работы (можно выбрать режим начала работы в промежутке 7:00 - 10:30) ДМС, программы лояльности для сотрудников (льготное кредитование, предложения экосистемы Сбера) комьюнити data-people, множество программ профессионального обучения (курсы, тренинги, конференции, семинары).",,Сбер для экспертов,
16840,78081929,Старший научный сотрудник / Data Scientist / AI researcher / Цифровые двойники / Big Data,от 100 000 до 120 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Академии ГПС МЧС России – ведущая образовательная организация пожарно-технического профиля, занимающаяся подготовкой специалистов в области комплексной безопасности и прикладными научными исследованиями. Академия расположена в 10 минутах пешком от станции метро «ВДНХ». Мы ищем старшего научного сотрудника для проведения прикладных исследований по одному из следующих направлений: - прикладные особенности применения больших данных, искусственного интеллекта и нейронных сетей в задачах обеспечения пожарной (техносферной) безопасности. - создание теоретических (практических) основ применения цифровых двойников для нужд МЧС России Образование: высшее техническое, ученая степень кандидата технических наук (преимущество), опыт программирования (приоритет). Ключевые навыки: уровень знаний самостоятельное проведение исследований большие данные, искусственный интеллект, нейронные сети, цифровые двойники. Обязанности: - проведение научных исследований по тематике НО Условия: график работы 5/2, метро ВДНХ, заработная плата 100-120 т.р., оформление по ТК РФ, бронь от мобилизации","уровень знаний,самостоятельное проведение исследований,большие данные,искусственный интеллект,нейронные сети,цифровые двойники",Академия ГПС МЧС России,"Москва, ВДНХ, улица Бориса Галушкина, 4"
16841,78736467,Разработчик-исследователь / Data Scientist в Data Office,з/п не указана,3–6 лет,"Полная занятость,полный день","Data Office — центральный хаб данных VK. Мы создаём дата-продукты, делаем единую точку входа для всей аналитики в VK и автоматизируем различные сценарии работы с данными. Мы находимся в поиске самостоятельного специалиста по большим данным и машинному обучению, который будет помогать нам создавать новые дата-продукты и развивать существующие. Вам предстоит: исследовать данные, заниматься ad-hoc аналитикой, сегментацией/кластеризацией, антифродом и так далее разрабатывать и тестировать новые признаки строить и оптимизировать ML-модели создавать метрики оценки качества дата-продуктов разрабатывать продакшен-пайплайны для процессинга данных, в том числе с использованием ML. У нас интересно, потому что: мы анализируем данные, выдвигаем, разрабатываем и тестируем гипотезы по улучшению продуктовых метрик вы сможете узнать, как устроены все продукты VK, поработать с их данными и реализовать с нуля новые проекты. Мы ожидаем, что вы: обладаете хорошей математической подготовкой знаете классические алгоритмы и структуры данных уверенно владеете Python и SQL разбираетесь в алгоритмах и метриках ML, работали с ML-библиотеками знаете Luigi или Airflow работали с Hadoop (Spark, Hive, HDFS) уверенно взаимодействуете с командной строкой в Linux. Приглашаем специалиста, который сможет посещать офис в Москве или Санкт-Петербурге, работать в комбинированном режиме или удалённо. Ждем ваших откликов. Удачи!",,"VK, ВКонтакте",
16842,78900581,Team lead \ Senior Data Scientist (команда перспективных алгоритмов машинного обучения),з/п не указана,3–6 лет,"Полная занятость,полный день","Департамент анализа данных и моделирования создан в 2019 году для стратегического развития функции анализа данных в ВТБ. В команду, которая специализируется на разработке перспективных алгоритмов машинного обучения ищем Senior \ TeamLead DS.  ОБЯЗАННОСТ: разрабатывать модели машинного обучения построение моделей на основе временных рядов построение моделей на графах построение look-alike моделей задачи по работе с текстом, табличными данными, графами связанности управление командой: постановка задач, контроль сроков исполнения. Требования: наличие управленческого опыта или опыта наставничества высшее математическое или техническое образование знания основ теории алгоритмов, теории вероятностей, математического анализа, математической статистики опыт в области CV не менее 1 года. понимание архитектур сверточных и рекуррентных нейросетей опыт обучения (дообучения) нейросетей/трансформеров для решения узких задач, понимание требуемых мощностей и временных затрат, затрат на подготовку данных навыки работы с Python, PyTorch, Pandas, Numpy, OpenCV приветствуются опыт использования HuggingFace, MxNet навыки работы с Git и с Conda окружениями знания основ SQL приветствуются знакомство со Spark хорошие коммуникационные навыки для эффективного взаимодействия в команде. Условия: трудоустройство согласно Законодательству конкурентная заработная плата профессиональное обучение и развитие добровольное медицинское страхование, льготные условия кредитования корпоративная пенсионная программа, материальная помощь спортивная жизнь и корпоративные мероприятия возможность построить карьеру в ведущем банке России.","Python,Spark,Hadoop,Hive,ML,SQL,Pytorch","ПАО ВТБ, Технологический блок",
16843,78667528,Middle/Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","* Обязательное условие рассмотрения Вашей кандидатуры - это успешное прохождение профессионального тестирования. В сопроводительном письме, вам необходимо отправить текст ""Готов пройти тест"". Кого мы ищем? Data Scientist, который будет заниматься проведением аналитических работ в своем направлении, построением прогнозов и прогнозных моделей, а также выявлять проблемы и находить узкие места, с которыми сталкивается бизнес и через анализ данных предлагать способы решения. Чего мы ждем: Отличные знания высшей математики, теории вероятности и математической статистики Желание решать аналитические задачи для получения практически полезных выводов Знание классических алгоритмов и структур данных, опыт работы с базами данных Знания и навыки практического применения методов статистического анализа данных Знания Excel, SQL, python (обязателен уровень не ниже middle) и библиотек для машинного обучения (Scikit-learn, Pandas) Знания: spark, scala, pytorch - будет преимуществом. Причины пойти к нам:","SCALA,SQL,Математический анализ,Статистический анализ,Статистика,Математическое моделирование,Pandas","Beeline, ТМ",
16844,78642657,Data Scientist (MyTracker),з/п не указана,1–3 года,"Полная занятость,полный день","Отдел Предиктивной аналитики внутри трекера решает широкий спектр задач от развития собственной маркетинговой антфирод-системы (Fraud Scanner) до создания системы персонализированных офферов (Personalize). Мы создаем продукты и прогнозы начиная от идеи до ее реализации в интерфейсе MyTracker. Задачи: R&D и анализ данных (поиск корреляций, зависимости, работа с аномалиями, представление результатов и прочее), построение и реализация алгоритмов машинного обучения представление результатов R&D в понятном для команды виде анализ поступающего графика на наличие аномалий и построение предиктивных моделей для работы антифрод-алгоритмов имплементация моделей для работы в production, разработка мониторингов и оповещений по работе моделей. Требования: опыт решения реальных задач с применением алгоритмов машинного обучения (задачи регрессии, классификации, ранжирования) в production и их поддержка опыт работы в команде с 3+ ML-специалистами математика, теория вероятностей, матстатистика опыт в программировании на Python (знание основных конструкций языка, умение разбираться в чужом коде, знания ООП) стек Python (pandas/scipy/catboost/sklearn). Будет плюсом: SQL диалект Clickhouse разработка антифрод-систем умение проводить A/B-тесты Linux и Bash.","Python,Анализ данных,Machine learning,Linux,Bash,Git,SQL,Clickhouse",VK,"Москва, Аэропорт, Ленинградский проспект, 39с79"
16845,78934453,Senior Data Scientist (NLP),з/п не указана,3–6 лет,"Полная занятость,полный день","Наша команда строит и помогает строить продукты на основе LLM. В данный момент мы нацелены на создание general помощника (русская версия ChatGPT) + улучшение ассистентов на номере 900, в Сболе и на наших устройствах. Мы являемся именно продуктовой командой и весь ресерч будет в сторону продуктивизации. з-за конкуренции лидеры в обучении LLM перестали публиковать подробные статьи, поэтому в работе будет очень много креативности и придумывания новых подходов. Для всех этих экспериментов у нас в ближайшем времени появится новый кластер с большим числом A100'ых. Обязанности довести качество до ChatGPT на русском и дальше обогнать его помогать решать бизнес задачи с помощью нашей технологии сначала для внутренних клиентов в Сбере, а потом и внешним придумывать и внедрять новые применения для ллмок помогать выводить в прод все, что мы обучим постоянно держаться up-to-date со свежими статьями Требования Python, алгоритмы, математика знания в DL, опыт обучения просто моделей и больших моделей опыт обучения моделей для прода понимание текущего состояния эволюции больших лмок C++ & CUDA публикации Условия задачи, находящиеся на острие инноваций команда отзывчивых профи и гуру, которые всегда помогут фидбек и возможность увидеть результаты своей работы в продукте своя digital-платформа для развития ключевых IT-компетенций, внутренние и внешние конференции и проф. сообщества Сбера много корпоративных плюшек: расширенная программа ДМС (возможность подключения родственников), страхование жизни, специальные условия по кредитам/ипотеке, скидки от компаний-партнёров знаменитый офис на Кутузовском проспекте с парковкой, спортзалом, массажными креслами и возможностью выбора формата работы (офис, гибрид или удалёнка) атмосфера стартапа и надёжность гиганта.",,Сбер для экспертов,
16846,78259023,Data Scientist,от 200 000 до 250 000 руб. до вычета налогов,3–6 лет,"Полная занятость,удаленная работа",,,ндустриальные Рекомендательные нформационные Системы,
16847,78125714,Data scientist,з/п не указана,1–3 года,"Полная занятость,полный день",,,LIME RUSSIA,"Новосибирск, Октябрьская, улица Кирова, 48"
16848,77445276,Middle Data Scientist (Аналитическая обработка данных),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Компания MagnitTech— это опытная команда IT, которая создает экосистему современных цифровых продуктов Магнит: доставка продуктов, лекарств, инструменты для обеспечения лояльности клиентов, специальные проекты и продукты для внутренних нужд. Чем предстоит заниматься: Развивать инструменты оптимизации регулярного ценообразования Развивать модели прогнозирования регулярных продаж Проводить А/Б тесты и анализировать большие данные Осуществлять постановку технических задач на изменение подсистем, разработки новых инструментов аналитики Создавать концепт, тестировать и внедрять инструменты аналитики. Мы ожидаем: Знание классических ML-алгоритмов и нейросетей Опыт проведения АБ-тестов и уверенное знание статистики Опыт работы с большим объемом данных Уверенное владение стандартным стеком python-библиотек (sklearn, pandas, numpy, matplotlib, LightGBM и т.д.) Уверенное знание SQL. Мы предлагаем: Работу в максимально уютном и современном офисе в Москве или в Краснодаре, или удаленно График работы 5/2 с гибким началом Конкурентоспособную заработную плату Мы любим учиться! А компания всегда поддерживает и способствует профессиональному развитию специалиста Корпоративную технику для успешной и удобной работы Дружескую атмосферу и поддержку команды профессиональных и активных коллег Корпоративные скидки и программы лояльности от наших партнеров.","Python,SQL,A/B тесты,ML","МАГНТ, Розничная сеть",
16849,75546387,Data Scientist (Почта),з/п не указана,1–3 года,"Полная занятость,полный день","Сегодня огромную часть повседневных задач мы решаем через интернет — начиная от заказа такси и заканчивая покупкой продуктов. Уникальным идентификатором для подобных сервисов является электронная почта, которая собирает в себе огромное количество информации об их использовании. Мы считаем, задача современной почты заключается в том, чтобы эту информацию отфильтровать, структурировать и предоставить пользователю в наиболее удобном виде. Это «умная» часть новой Почты. Центром новой концепции является пользователь, а сам сервис выстраивается вокруг его потребностей, делая взаимодействие с потоком данных проще и понятнее. При помощи машинного обучения мы научили Почту рекомендовать ответы на письма, которые не требуют развернутого ответа, отделять рассылки от важных писем, а среди важных — выделять смысловые категории (финансы, путешествия, билеты, регистрации, заказы). Также Почта научилась выделять из писем информацию о промоакциях и скидках, группировать авиабилеты по номеру брони и объединять в одну цепочку письма с одинаковым номером заказа, чтобы разные покупки не смешивались друг с другом. Сейчас мы ищем программиста-исследователя, который присоединится к команде машинного обучения и будет вместе с нами работать над новыми продуктовыми фичами, делая Почту еще более удобным и современным продуктом. Что необходимо будет делать: отвечать за реализацию продуктовых задач с применением машинного обучения генерировать идеи, проводить эксперименты и внедрять их в production следить за прогрессом в машинном обучении и реализовывать подходящие алгоритмы. Для выполнения поставленных задач потребуется: отличное знание основ машинного обучения 2–3 года опыта разработки с использованием Python/C++ уверенное знание теории вероятностей и математической статистики понимание структур данных и алгоритмов знание современных алгоритмов обработки естественного языка (word embeddings, LSTM, Transformers, etc.) опыт работы с библиотеками для глубокого обучения (Pytorch, TensorFlow, Keras, etc.). Будет плюсом: отличные коммуникативные навыки опыт разработки микросервисных архитектур знание стека технологий Hadoop (HBase, Pig, Spark) хорошее знание C++/LUA опыт использования Docker/Kubernetes.","Python,Tensorflow,Machine Learning,Deep Learning","VK, Почтовые сервисы","Москва, Аэропорт, Ленинградский проспект, 39с79"
16850,78878339,Lead Data Scientist NLP,з/п не указана,3–6 лет,"Полная занятость,полный день","В задачи команды Sber AI входит создание прототипов моделей от коммуникации с заказчиком (формулирование задачи) до передачи прототипа на промышленную реализацию. Наши задачи - не многолетний «долгострой», как поддержка и улучшение промышленной системы, а практические R&D проекты с обозримым горизонтом из разных доменов ML/DS. Решение этих задач позволяет с одной стороны применять современные ML методы, а с другой - не уходить в чистую науку и увидеть результат своей работы на практических данных. Основной фокус разрабатываемых прототипов – disrupt, который они вносят в существующие бизнес-процессы. Обязанности Вам предстоит: Управление командой из 4х человек Разрабатывать ML-модели в различных проектах Сбера и его клиентов, например: NLP-задачи (генеративные модели, парафразер, узкоспециализированный чат-бот) Табличные задачи (регрессия временных рядов, классификация аномалий, кластеризация табличных и текстовых эмбеддингов транзакций) Участвовать в развертывании решений на пром. Требования Требуемые навыки: Аналогичный опыт работы от 5 лет, из них 2-3 года в управлении командой Образование: высшее техническое DS-специализация в доменах: NLP и табличный ML Уверенное программирование на Python от 3х лет (будет онлайн кодинг) Работа с данными (ex. как проверить корректность выбора тестового набора) Знание классических и современных методов ML (ex. зачем нужна регуляризация) Математическая статистика (ex. что такое критерий хи^2) нтерпретация и презентация данных Английский на уровне чтения статей по ML и документации Опыт командной разработки (работа с jira и git). Плюсом будет: Знание основ DevOps для ML-моделей Английский выше Upper Intermediate Научные работы и опыт участия в научных конференциях (устный/стендовый доклад, просьба предоставлять ссылки). Условия ипотека выгоднее для каждого сотрудника и льготные условия кредитования фитнес залы в офисах бесплатная подписка СберПрайм+ скидки на продукты компаний-партнеров: Okko, Сбер Маркет, Delivery Club, Самокат, Сбер Еаптека и другие ДМС с первого дня и льготное страхование для близкихкорпоративная пенсионная программа курсы для будущих родителей, материальная поддержка и тематическое сообщество для молодых мам детский отдых и подарки за счет Компании обучение за счет Компании: онлайн курсы в Виртуальной школе Сбера и неограниченный доступ к библиотеке, обучение в Корпоративном университете, тренинги, митапы и возможность получить новую квалификацию реферальная программа для сотрудников: можно пригласить в команду знакомых профессионалов и получить вознаграждение до 100 тыс. рублей скидки на отдых в лучшем в мире курортном комплексе «Mriya Resort & SPA» в Ялте.",,Сбер для экспертов,
16852,78656512,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","«Finbridge» – старейшая и крупнейшая в России группа финансовых компаний. Мы создаем удобные, безопасные, цифровые продукты, позволяющие людям и компаниям эффективно решать вопросы кредитования, совершения платежей, управления своим капиталом, развития и запуска собственного бизнеса. Почему мы лучшая компания для тебя? стабильность продвинутое обучение корпоративная культура забота о людях. Сейчас у нас открыт конкурс на вакансию Data Scientist. Рабочие задачи: звлечение, очистка, анализ и обработка данных для дальнейшей генерации фичей Построение и валидация моделей машинного обучения в различных предметных областях: банковские риски, различные виды мошенничества и т.п. Мониторинг стабильности работы моделей и их качества. Наши ожидания: Уверенное знание python и библиотек для анализа и визуализации данных (pandas, numpy, scipy, matplotlib, plotly) Понимание основных алгоритмов и метрик машинного обучения Практические навыки работы с библиотеками для машинного обучения (scikit-learn, XGBoost, CatBoost) Хорошее знание SQL, опыт работы с БД, опыт написания запросов средней сложности Знание математической статистики и теории вероятностей. Будет плюсом: Знания в области Deep Learning Практические навыки работы с DL фреймворками (PyTorch, TensorFlow) Умение работать с git Участие на Kaggle. Мы предлагаем: Работа в международной компании ТОП-3 отрасли, более 10 лет на рынке Оформление по ТК РФ Финансовую мотивацию: оклад + премия График работы 5/2 с 09:00 до 18:00, праздничные дни - выходные Развитая корпоративная культура: корпоративный портал «Finbridge», компенсация изучения английского языка, скидка 15% в ""Гемотест"", коллективные поездки и прочие интересные мероприятия Обучение и наставничество, полноценный ввод в должность со стороны Руководителя. Удаленный формат работы. Если в описании вакансии ты увидел себя, то скорее откликайся! Мы с тобой свяжемся!",,Finbridge,
16853,78663746,Data Scientist / ML-инженер (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Мы ищем Data Scientist’ов и ML-инженеров в следующие продукты: Рекламная платформа RnD (Senior) В настоящий момент в команде основной фокус бизнес задач приходится на разработку маркетинговых продуктов – применение алгоритмов классификации, регрессии и рекомендательных систем для оптимизации медиа инвестиций. Перечень инициатив очень широкий – от задач стратегического планирования медиа бюджетов до оптимизации биддинговых стратегий в перформанс инструментах. МТС Travel (Senior/Lead) MTS Travel - молодая дочерняя компания МТС, которая создает и развивает сервисы для путешественников по России и миру. Ее цель - стать №1 на рынке онлайн-бронирования отелей в РФ. MTS Big Data помогает сервису создавать и усиливать конкурентные преимущества через работу с большими данными. Рекомендательная Платформа - Строки ( Senior) Команда занимается созданием персональных рекомендаций по жанрам для текстовых и аудио книг. В перспективе планируется сделать лучшие кросс-контентные рекомендательные модели, такие как подбор музыки по ходу прочтения книги, анализ текста книги, выделение облака тегов и эмоциональную окраску текста за счет добавления музыки, соответствующей настроению текста. Scoring Platform (Senior) Мы создаем скоринговую платформу, которая должна сократить и упростить путь от сбора данных до получения нашим клиентом вероятностной оценки в виде сервиса в личном кабинете. Маркетолог (Senior) Маркетолог - self service продукт. Маркетолог является самым крупным В2В продуктом по выручке в МТС. Мы занимаемся не только классическим вариантом телеком-рекламы, но также имеем собственный DCP, каналы, my target. Мы делаем модели, которые помогают клиентам сократить время и улучшить показатели. Обязательно: опыт работы от 2-х лет в области анализа данных и машинного обучения понимание, как работают ML-алгоритмы и не будете тратить время на эксперименты с заведомо плохими решениями понимание, когда нужно остановиться и использовать вместо ML более простые и быстрые подходы у вас продвинутые знания Python, в т.ч. основных ml-библиотек умение делать препроцессинг данных на SQL или PySpark умение работать с git есть базовые навыки работы в Linux/Unix знание минимум один из классических языков C, Java, Scala, C/C++/C# и есть опыт программирования в прошлом опыт вывода ml-решений в продакшн Что предстоит делать? выгружать и готовить/обрабатывать данные (находить аномалии и инсайты) перебирать гиперпараметры ml-моделей, пока кросс-валидация не даст нормальный результат :) дорабатывать ml-модели из стандартных библиотек проверять бизнес гипотезы в offline и готовить дизайн A/B тестов доводить модель до прода совместно с разработчиками Что вы найдете в команде Big Data? Стек технологий: работаем с данными на классическом hadoop-стеке (Spark, Hive) разрабатываем на python3: R&D делаем в Jupyter, продуктивизируем в PyCharm обучаем модели на отдельных мощных машинах с видеокартами Tesla V100 используем собственные разработки для скоринга больших данных и MLFlow для экспериментов храним код в gitlab, CI/CD в Jenkins, процессы запускаем в Airflow Команда: в команде Data Science сейчас 30 человек (во всей Big Data МТС более 300 человек). Все DS поделены на группы со своими лидами - есть группа рекомендательных систем, скоринга и другие. Каждую неделю мы обмениваемся опытом на совместных синках. DS работают в продуктах со своей автономной командой, в которой есть все роли: аналитики, DE, DS, разработчики, девопсы, менеджеры продукта. Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Python,Machine Learning,Data Science,Математическая статистика,Git",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
16854,78936789,Data Engineer (ДАДМ),з/п не указана,3–6 лет,"Полная занятость,полный день","Вместе с нами ты будешь: Заниматься проектированием и разработкой витрин данных для анализа и моделирования Заниматься мониторингом и оптимизацией процессов сборки витрин Заниматься загрузкой и обработкой данных из различных источников Заниматься поддержкой и развитием базы знаний Предоставлять экспертную поддержку внутренним потребителям(data analysts,data scientists) Какие знания и навыки для нас важны: Знание SQL Хорошее знание устройства Hadoop,Spark,Hive/Impala Опыт разработки на Python/Scala/Java Понимание основных концепций DWH Понимание базовых команд Git и основных принципов работы Будет плюсом: Опыт работы с банковскими данными Опыт работы с различными СУБД в роли разработчика/аналитика витрин данных Опыт работы с Airflow","DWH,Hadoop,Hive,Git,Python,SCALA,SQL","ннотех, Группа компаний",
16855,78400616,Middle Data scientist,от 100 000 до 150 000 руб. на руки,3–6 лет,"Полная занятость,удаленная работа","Мы создали RANKS.pro — Систему оценки инвестиционной привлекательности акций. Мы анализируем более 50 000 компаний по всему миру с помощью Data Science. Проект динамично развивается командой профессионалов, для реализации новых проектов мы ищем опытного Data scientist'а, заинтересованного в быстром росте и долгосрочном сотрудничестве. Обязанности: Построение, оптимизация и оценка качества ML-моделей на больших наборах рыночных и финансовых данных. Выдвигать и проверять гипотезы относительно данных для использования в ML-моделях. Сопоставление математических метрик с бизнес-метриками Общение с аналитиками и совместный поиск улучшения моделей Постановка задач и их планирование Умение работать в команде Требования: Знание классических ML-методов регрессии, классификации, кластеризации (линейная регрессия, логистическая, деревья решений, градиентный бустинг, kNN) Знание математической статистики Отличное знание Python и опыт работы с Pandas, sklearn, XGBoost, CatBoost, matplotlib, seaborn Знание SQL (умение писать несложные запросы)  Будет преимуществом: Высшее образование (математическое/экономическое/техническое) Опыт в Data Science и промышленной разработке Опыт работы с финансовыми инструментами фондовой бирж Опыт работы в финтех-стартапах/IT-блоках банков нтерес к инвестициям Условия: Удалённая работа с официальным трудоустройством по ТК РФ или по контракту с НПД (самозанятые) Перспективы диктуются вашими амбициями и успехами Работа непосредственно с основателями IT-стартапа, обучение с наставником на начальном этапе Работа в команде без лишней бюрократии и с большой свободой действий","Python,Математическая статистика,SQL,Pandas,Машинное обучение",Ранкс,
16856,78692078,Data Scientist в команду Товарных Рекомендаций,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы ищем Data Scientist в команду Товарных рекомендаций для разработки рекомендательных алгоритмов. Результат вашей работы будет напрямую влиять на общую выручку компании. Вам предстоит: - Разрабатывать алгоритмы рекомендаций карточек товаров - Повышать релевантность рекомендаций для увеличения средней корзины пользователя - Взаимодействовать со смежными командами менеджеров, аналитиков и разработчиков. Мы ждем, что вы: - меете опыт работы в DS от 3-х лет - Работали с рекомендательными системами - Уверенно пишете на Python - Обладаете глубокими знаниями в ML и DL. Мы предлагаем: - Возможность создавать крутые продукты в крупнейшей компании - Гибридный или удаленный формат работы - Гибкое начало рабочего дня - Конкурентную заработную плату - спользование современного технологического стека - Гибкие бизнес-процессы, минимум бюрократии и согласований - Максимум возможностей для профессиональной самореализации.","Python,Pandas,NumPy,SkiPy,Scikit-learn,PostgreSQL,Greenplum,Clickhouse,Vertica,XGBoost,PyTorch",WILDBERRIES,
16857,78754613,Data scientist (Центр валидации моделей розничного бизнеса),з/п не указана,1–3 года,"Полная занятость,полный день","Наша команда занимается оценкой и управлением модельного риска. Наши сотрудники участвуют в проектах по улучшению предиктивных моделей, моделей машинного обучения и оптимизации их применения в бизнес-процессах Сбера. Мы создаем инструменты для мониторинга, управления и снижения модельного риска по всем бизнес-направлениям. Чем интересна данная позиция? Участие в построении системы управления капиталом крупнейшего российского Банка Работа с самыми совершенными риск-моделями на российском рынке, влияющими на кредитные решения и величину капитала Банка нтересный опыт взаимодействия с множеством смежных подразделений Банка Продвинутый уровень Data Science (включая сложные неинтерпретируемые модели) Разработка автоматизированной системы мониторинга и платформенных сервисов валидации Множество задач по построению и совершенствованию бизнес-процессов (работа на стыке DS и менеджмента) Мы: Валидируем модели Сбера, способные значимо повлиять на финансовый результат, в том числе регуляторные модели, использующиеся для оценки капитала Банка и влияющие на общий Риск-аппетит Банка. Валидация – процесс всесторонней оценки разработанной статистической модели на предмет ее соответствия поставленным бизнес-требованиям и мировым практикам, качества используемого статистического алгоритма, а также потенциала улучшения модели. Модели стекаются к нам со всех уголков необъятного Сбера. Разрабатываем и автоматизируем методы для валидации моделей различных классов (в свете усложнения моделей Сбера особенно актуально) Строим систему отчетности для управления модельным риском Строим платформу для онлайн-мониторинга и автовалидации моделей Что будешь делать ты? Разбираться в структуре различных моделей DS, тестировать корректность модели, челленджить подход разработчика, разрабатывать альтернативные алгоритмы (внутренний Kaggle), оценивать применимость подхода с учетом имеющихся норм и макроэкономической конъюнктуры сследовать подходы к моделированию и валидации различных классов моделей, определять их методологию, применять передовые технологии и распространять наработки Автоматизировать алгоритмы валидации для внедрения в процессы автомониторинга Участвовать в практическом управлении моделями оценки капитала, разработке методологии их валидации и осуществлении их мониторинга Что мы ожидаем от кандидатов: Знание машинного обучения и статистического анализа (интересен любой опыт) Знание мат. статистики, алгоритмов, структур данных Знание Python и/или R и основных библиотек анализа данных Знание SQL, навыки работы с базами данных Опыт работы в рисках, знание основ управления рисками в Банке Коммуникабельность, умение эффективно вести переговорный процесс с подразделениями Банка Большой плюс: опыт работы с регуляторными моделями Basel Большой плюс: опыт модельной аналитики и управления модельным стэком в бизнес-процессе Чем мы отличаемся от других? Наша основная функция – валидация, но это включает в том числе и разработку альтернативных алгоритмов, ты научишься не только разрабатывать модели, но и тестировать их и смотреть на них с позиции владельца бизнес-процесса У нас можно познакомиться со всем многообразием моделей в экосистеме Сбера – работа не ограничивается рисковыми и регуляторными моделями Basel. В моделировании же, как правило, DS привязан к конкретной предметной области. У нас много работы не только в моделировании и валидации, но и в исследовательской деятельности по количественной оценке модельного риска Почему у нас интересно: Очень сильная команда (МГУ, МФТ, ВШЭ, РЭШ) Очень интересные задачи (на подумать, с *) на стыке ML, математики и бизнеса, fit-predict тут не пройдет, придется много узнавать, выяснять и думать Внушительный и разнообразный ландшафт моделей, много работы ""под капотом"" Возможность познакомиться с применением моделей в самых разнообразных бизнес-процессах, расширить «модельный кругозор» Условия работы: Работа с современным стеком технологий Возможность обучения за счет компании Регулярные DS-митапы, большое внутреннее DS сообщество Спортзал в офисе",,Сбер. Data Science,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
16858,78568157,Data Scientist (главный исследователь данных по КАСКО),з/п не указана,1–3 года,"Полная занятость,полный день","СТРАХОВОЙ ДОМ ВСК ПРГЛАШАЕТ В КОМАНДУ УПРАВЛЕНЯ ТАРФКАЦ  РСК-ТЕХНОЛОГЙ ГЛАВНОГО ССЛЕДОВАТЕЛЯ ДАННЫХ (DATA-SCIENTIST) ОБЯЗАННОСТ: Разработка ML - математических моделей предсказывающих сумму потенциального убытка по автострахованию КАСКО. Полный цикл построения математических моделей от подготовки данных до расчёта финансового результата и подготовки технического задания на внедрение. Подготовка аналитики по портфелю компании. Участие в различных проектах компании по широкому кругу задач блока андеррайтинга в рамках своей функциональной компетенции. ТРЕБОВАНЯ: Высшее образование (МГУ, МФТ, ВШЭ, МГТУ, МФ). Знание методов машинного обучения. Опыт обработки больших объемов данных. Знания SQL, Python (уровень не ниже middle), Statsmodels и библиотек для ML (CatBoost, GLM, Pandas). Опыт работы от 1 года в data science. Опыт работы в финансовом секторе (страховые компании, банки) будет дополнительным преимуществом для соискателей. Уверенные знания высшей математики, теории вероятностей и базовые знания статистики. Знания и навыки практического применения методов статистического анализа данных. УСЛОВЯ: Работа в крупной и стабильной компании. Официальное трудоустройство по ТК РФ. Корпоративное добровольное медицинское страхование (ДМС со стоматологией с первого дня работы в компании). Скидки на страховые продукты. Спорт, обучающие мероприятия. Заработная плата оклад + квартальная премия (обсуждается по телефону). Гибридный график работы 2/3 (офис + удаленный формат). Офис расположен: г. Москва, ул. Островная д.4 (рядом с офисом собственная, большая, бесплатная парковка). Корпоративный транспорт от ст. м. «Октябрьское поле» и «Кунцевская»","Python,Математическая статистика,SQL,Pandas,Статистический анализ,Машинное обучение,Data Science,MS SQL,Аналитическое мышление,Data Analysis,Математическое моделирование,Библиотеки: Statsmodels CatBoost GLM,СУБДД: MS SQL PostgreSQL Oracle,Apache Airflow,MLflow","ВСК, САО","Москва, Островная улица, 4"
16859,77818891,Data Scientist middle+/senior (Транскодинг),з/п не указана,3–6 лет,"Полная занятость,полный день","Сейчас в Okko создается новый продукт – Видеоплатформа. Это B2B-инструмент для работы с видеоконтентом. Ключевое значение для разработки продукта имеют обработка видео (транскодинг) и оптимизация процессов, связанных с ней. В команду транскодинга мы ищем человека, который сможет сформировать и вывести ML-решения для улучшения продукта, а также найдет баланс между математическими способами решения задач и ML. Обязанности: исследование применимости различных алгоритмов в рекомендательной системе и в системах с применением компьютерного зрения моделирование входных данных интеграция исследованных моделей в системах проведение экспериментов с созданными моделями автоматизация процессов подготовки данных оптимизация потребления ресурсов сервисами, а также повышение утилизации ресурсов и применения ML интеграция сервисов с распределенными системами (Базы данных, Очереди). Требования: высшее техническое/математическое образование знание математической статистики и высшей математики критичны для решения наших задач умение инициализировать новое направление от идеи и построения инфраструктуры до вывода решения в прод для конечных пользователей знание основ статистики понимание классических ML-алгоритмов способность анализировать статьи и имплементировать описываемые алгоритмы базовые знания о Сomputer Vision знание Python желателен опыт работы с видео, изображениями, с рекомендательными системами. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,Machine learning,Сomputer Vision",Okko,"Москва, Баррикадная, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с13"
16860,78686420,Data Scientist в команду CVM AI,з/п не указана,1–3 года,"Полная занятость,полный день","Мы вам доверим развитие контекстной online рекомендательной системы ценообразование аплифт-моделирование и рекомендашки для промо-акций и программы лояльности улучшение ML-пайплайнов для batch и streaming режимов внедрение платформы для дизайна и анализа A/B тестов. Наши ожидания отличное знание классического ML и DL Python + ML стек, PySpark, SQL опыт построения MLOps процессов Bash, Git знание статистики опыт менторинга младших коллег умение переводить бизнес-задачу в DS-формулировку, обосновывать выбор методов и метрик, интерпретировать результаты исследований и тестирования. Будет плюсом опыт работы с алгоритмами оптимизации наличие статей или выступлений на конференциях. Мы предлагаем гибридную модель работы – работаем в основном удаленно, встречаемся в офисе раз в две недели по договоренности, возможен полностью удаленный формат обучение: мы оплачиваем профессиональные тренинги и образовательные курсы (karpov.courses, NewProLab, Otus, Slurm), отправляем на российские и зарубежные конференции и активно поддерживаем участие в конференциях в качестве спикеров корпоративные льготы: социальный пакет, включающий ДМС со стоматологией и массажем, страхование жизни, страхование выезжающих за рубеж, доплаты по больничным",,Райффайзен Банк,
16861,77815752,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","«Самокат» - это технологическая компания и один из самых быстрорастущих проектов в России. Мы предоставляем сервис моментальной доставки продуктов. У нас десятки маленьких складов (dark stores) в Москве и Санкт-Петербурге. Каждый — как продуктовый магазин у дома, но без торгового зала, с заказом через приложение и доставкой курьером за 15-30 минут. Мы встраиваемся в ежедневную жизнь клиентов и меняем паттерн потребления. Уже сегодня мы №1 в России среди продуктовых онлайн-магазинов по количеству заказов. Компания ""Самокат"" открывает вакансию Data Scientist. Мы ищем опытного специалиста в области machine learning в команду прогноза спроса. Вы будете вместе с нами решать сложную задачу поддержания оптимального запаса товаров на складе для тысяч товаров. Результат вашей работы будет влиять на реальную систему уже в первый месяц работы. Мы предлагаем: стать частью сильной data science команды пул задач, у которых нет тривиальных решений поле для экспериментов и ресурсы для их реализации новый офис у метро Горьковская и возможность удаленной работы отсутствие вертикальной структуры управления и возможность обсудить реализацию любых идей Мы ожидаем: опыт работы в data science от 3-х лет математический бэкграунд знания и опыт работы с алгоритмами классического машинного обучения умение превращать сложную и туманную бизнес-задачу в математическую постановку постановка гипотез, дизайн и оценка экспериментов, презентация результатов для представителей бизнеса Будет плюсом: опыт участия в полном цикле проекта машинного обучения (от постановки задачи до вывода в продакшн)  опыт вывода модели в эксплуатацию умение и желание быстро поставлять минимальное базовое решение задачи интерес к retail или опыт работы в этой области Технологии: sql, python, lightgbm, docker, kubernetes, airflow","Python,SQL,Machine Learning",Самокат (ООО Умное пространство),
16862,73139690,Data scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Требования: Высшее техническое или физико-математическое образование. Релевантный опыт в сфере от 4 лет. Знание классического Machine Learning, матстатистики. Опыт использования стека DS на Python: Numpy, Pandas, SciPy, визуализация (Matplotlib, Plotly). Теоретические/практические знания Deep Learning: полносвязные, свёрточные, рекуррентные, сети. Будет плюсом понимание работы автоэнкодеров, GAN, трансформеров Опыт обучения ML-моделей: Постановка задачи, выбор архитектуры модели, метрики качества и т.д. Опыт разработки на Python, опыт работы с различными форматами и хранилищами данных. Будет преимуществом: Опыт в Fullstack разработке. Призовое место в соревновании Kaggle. Знание алгоритмов и структур данных. Что предстоит сделать: Лидирование проектов, постановка задач команде и контроль их выполнения Проведение исследований и создание ML/DL моделей Предварительная обработка и анализ данных Разработка архитектуры решений Генерация и тестирования гипотез в рамках воронки исследований и разработок Экспериментирование со state-of-the-art методами машинного обучения Оценка и интерпретация результатов экспериментов, подготовка выводов для бизнес-заказчика. Участие в реализаций, как клиентской, так и серверной стороны прототипов решений Примеры задач: предиктивная и описательная аналитика, NLP , CV а также решения других прикладных задач в области Supply Chain Условия: Официальное оформление График работы 5/2, рассматривается удаленный и гибридный формат работы ДМС и социальный пакет Возможность профессионального роста и развития в рамках Компании","Python,SQL,Machine Learning,Pandas,Deep Learning,алгоритмы",Газпром нефть,
16863,77656659,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","IT-подразделение IEK GROUP ищет коллегу в распределенную команду разработки аналитических систем, которому было бы интересно вместе с нами развивать data-driven подход в IEK GROUP. Многое уже сделано, построено Хранилище данных (SQL SERVER EE 2019), создан портал бизнес-аналитики (SharePoint), бизнес ""вошел во вкус"" и активно использует OLAP и POWER BI. Данные для подобной аналитики приходится собирать в различных системах - 1С, WMS,CRM ... Мы плотно интегрированы с партнёрами нашей компании, поэтому обмен данных у нас не только внутренний, но и с внешними контрагентами. Мы предлагаем новые подходы к данным, разрабатываем различные ML- сервисы, которые помогают стать компании более эффективной. Уже реализована собственная система прогнозирования спроса, управления эластичностью цен и т.д. Работа построена в основном на принципах Agile, с MVP и желанием сделать хороший и полезный продукт! Работаем в Azur DevOps GIT. так, вливаясь к нам в команду Вам предстоит: Разрабатывать модели машинного обучения Поиск инсайтов в данных, проведение экспериментов Оценка качества и совершенствования моделей Участвовать в выводе моделей в продакшен вместе с командой разработки. Что ждём от Вас: Реализованные кейсы в области DS/ML Phyton+SQL Понимание основных принципов и алгоритмов ML Хороший математический бэкграунд Опыт перевода бизнес-задач в термины ml. Что предлагаем: Удаленный график работы Рабочий день с 09:00 до 17:30 (мскв) Достойный уровень дохода (зависит от профессиональных компетенций) Расширенный социальный пакет: ДМС, дополнительные отпускные дни, оплата больничного листа, материальная помощь в критических ситуациях, бесплатные оздоровительные/спортивные мероприятия Правительственные льготы – мы аккредитованная IT-компания Комфортная, доброжелательная рабочая атмосфера Корпоративные традиции и праздники, коллективные мотивационные программы Офис: 10-15 минут от м. ""Бульвар Дмитрия Донского"" на корпоративном транспорте (г. Щербинка).","SQL,Python,Olap (online analytical processing),Аналитическое мышление,MS SQL",IEK GROUP,
16864,73254140,Data Scientist (Predict),з/п не указана,1–3 года,"Полная занятость,полный день","В связи с расширением команды ищем Middle Data Scientist (в особых случаях готовы рассмотреть Junior+/Middle-) на проект VK Predict (https://vk.company/ru/company/business/predict/), основной фокус которого - создание и внедрение аналитических сервисов, основанных на ML-решениях. О нашем подразделении: - Мы представляем B2B-направление, то есть у вас будет возможность принести пользу российскому бизнесу и повлиять на развитие экономики. - Также вы получите уникальный опыт взаимодействия с компаниями из различных сфер и приобретёте уникальные компетенции в моделировании. - Ценим классический ML во всех его проявлениях. - Любим заниматься инфраструктурными задачами (автоматизацией рутинных задач, оптимизацией) и выкатывать модели в production. - Работаем в гибридном формате. Есть возможность работать в тех городах, где есть офисы VK. Задачи: выполнение adhoc задач по применению существующих моделей и сервисов. разработка различных моделей машинного обучения на новых данных. изучение и обработка данных из различных источников. внедрение регулярного расчёта новых признаков, улучшение мониторинга качества данных. генерация и проверка гипотез по повышению качества текущих моделей и создания новых, более высокого качества. развитие инфраструктуры существующих сервисов. написание продуктивизируемых пайплайн скриптов (не просто Jupyter Notebook) для внедрения моделей, признаков, а также для создания и поддержки функционирования новых продуктов. Требования: высшее техническое образование (с обязательным IT-профилем). Готовы также рассмотреть кандидатов с экономическим образованием или студентов последних курсов при условии наличия повышения квалификации на специализированных курсах (например, MADE VK, ШАД и так далее). наличие релевантного коммерческого опыта от 1 года. умение разрабатывать пайплайны для эффективной обработки данных в Python, Pyspark. желание заниматься и развиваться в задачах с классическим ML и DS, а также в задачах с развитием инфраструктуры development и production. глубокие знания классического ML. сильные математические знания (особенно по теории вероятностей и статистике), понимание математических основ алгоритмов машинного обучения. уверенное программирование на Python (базовый ООП и прикладные библиотеки - NumPy, Pandas, Sklearn, LightGBM, CatBoost, Pyspark). знание SQL и основ баз данных. Будет плюсом: опыт в задачах DE/MLE. опыт работы с PySpark, Hadoop. написание bash-скриптов, понимание возможностей интерфейса командной строки Unix-подобных операционных систем. опыт решения базовых задач обработки текстовых данных и последовательностей. знание luigi.","Python,SQL,Математическая статистика,machine learning,Big Data,Hadoop,Spark",VK,"Москва, Аэропорт, Ленинградский проспект, 39с79"
16865,78707376,Data Scientist (ML Space),з/п не указана,1–3 года,"Полная занятость,полный день","В направление ML Space требуется DS-специалист для разработки облачных AI-сервисов. Приглашаем Data Scientist в команду ML Space, которая занимается развитием продукта ML Space - платформы для ML-разработки полного цикла: от трансфера и хранения BigData до деплоя и автоматического масштабирования готовой модели. Вам предстоит на основе данных заказчика и открытых источников создавать воспроизводимые ML-пайплайны, которые другими заказчиками смогут переиспользоваться на своих данных для решения схожих бизнес-задач. Будет необходимо заниматься уточнением бизнес-задачи, помощью в формализации потребностей, подготовкой данных для моделирования, написанием кода от baseline-модели до полноценного ML-пайплайна и публикации его на ML Space. Обязанности: Разработка ML-пайплайнов (AI-сервисов), в том числе в экспресс-режиме (разработка MVP, проверка/тестирование гипотез), подготовка EDA с помощью библиотек Python на данных клиентов Умение формулировать гипотезы, проверяемые с помощью ML Подготовка шаблона для запроса данных у клиента под конкретную задачу Помощь в формализации потребностей и формировании бизнес-требований, экспертный контроль качества полученных ML-моделей, достижение бизнес-целей заказчика Участие в развитии передовой платформы для полного цикла ML-разработки «ML Space» https://sbercloud.ru/ru/aicloud/mlspace. Требования: Хорошее знание Python, опыт разработки ML-пайплайнов (MLOps) Опыт в решении задач прогнозной (предиктивной) аналитики, например, предсказание спроса, динамическое ценообразование, предсказание поломок оборудования Понимание методологий минимум в 3 из перечисленных направлений: технологии CV, NLP, рекомендательные системы, временные ряды Уверенные знания в области классического машинного обучения (метрики, оценки качества, визуализации, интерпретации результатов моделирования) Коммерческий опыт работы с большими данными с помощью библиотек pandas, numpy, scikit-learn, знание и опыт разработки на фреймворке PyTorch и использование других фреймворков глубинного обучения (JAX, TensorFlow) Опыт работы с контейнерами Docker и с системами оркестрации (Kubernates) Опыт работы в Linux-средах обязателен Высшее образование по направлениям ПМ, программная инженерия. Преимущество отдается кандидатам из ШАДа, AI Masters (OzonMasters), MADE. Будет плюсом: Понимание REST, опыт работы с python-фреймворками инференса Kserve, Nvidia Triton (FastAPI, Flask и т. п.), понимание gRPC Умение работать с большими данными через Spark Знание SOTA-алгоритмов, умение их применить в практических кейсах Опыт продуктивизации ML-подобных решений/моделей (в идеале – продуктов, основанных на технологиях машинного обучения/компьютерного зрения/NLP), вывод ML-модели машинного обучения за стадию MVP Понимание механизмов распределенных вычислений (MPI, torch.distributed, horovod) Практический опыт работы с системами контроля версий (у нас GitLab) и системами управления проектами (стек Atlassian: Jira, Confluence и т. д.) в командной разработке Опыт реализации кейсов на данных компаний из разных отраслей (например, металлургия, АПК, ритейл и др.). Что мы предлагаем: Оформление в соответствии с трудовым законодательством РФ Конкурентный уровень дохода (оклад + годовой бонус) ДМС со стоматологией и возможностью подключения к программе своих детей и родственников Прозрачную систему мотивации, которая позволяет влиять на уровень дохода Работу в команде профессионалов Участие в создании инновационных продуктов Гибкое начало рабочего дня, пятница - сокращённый рабочий день Возможность работать удаленно Офис в центре Москвы Корпоративную мобильную связь Льготную программу ипотечного и потребительского кредитования Ещё у нас: Возможность вертикального и горизонтального роста Бонусные программы от компаний партнёров Возможность получения бонуса за закрытие вакансии по вашей рекомендации Материальная помощь при рождении детей и др. семейных обстоятельствах Обучение в Корпоративном университете Участие в профильных конференциях в качестве спикера или слушателя Корпоративная жизнь: спортивные комьюнити, клубы по интересам (настолки, интеллектуальные игры Обучение и развитие в компании.",,Cloud,"Москва, Улица 1905 года, 2-я Звенигородская улица, 12с2"
16866,78117577,Специалист Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день",,,нститут геологии и разработки горючих ископаемых,"Москва, Академическая, ул. Вавилова, 25к1"
16867,78775402,Senior Data Scientist (Research Scientist),з/п не указана,3–6 лет,"Полная занятость,полный день","We are a highly performing research team at Sber. Our goal is to implement cutting edge technologies into risk management processes. We work with such data as graphs, click-streams, transactions, geo-data, etc. We are looking for a researcher to develop the most advanced AI technologies for risk management. Key responsibilities: Conduct, direct, and coordinate all phases of research projects, demonstrating skill in all stages of the research process: • Define key research questions, work with multiple information sources • Review research papers, algorithms, models, and code, and evaluate their applicability to the problem at hand • Formulate research plan, experiment methodology and design • Create proof-of-concept implementations of new models and techniques, carry out experiments • Interpret and communicate results, including to non-technical stakeholders • Contribute to internal research community by producing publications. Our expectations: • Research-based BSc/MSc in Computer Science, Statistics, Mathematics or related quantitative field • 1+ years of academic or industrial research experience, including reviewing research papers • Excellent programming skills in Python, PyTorch, including implementation of research algorithms • Excellent knowledge of Probability and Statistics, Linear Algebra • Ability to convey rigorous mathematical concepts and considerations to non-technical stakeholders • Good knowledge of modern neural networks: Transformer, GPT, etc • Publications at NeurIPS, ICML, ICLR or similar are preferred. We offer: • Excellent IT architecture • Comfortable office • NVIDIA HGX • Continuous learning and development • DS community.","Data Mining,Python,Анализ данных,Английский — C1 — Продвинутый",Сбер. Data Science,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
16868,78579825,Data Scientist Time Series,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы команда AI в SberНадежности, занимаемся детекцией аномалий и инцидентов по метрикам систем в Сбере. Наша цель - научиться заранее определять поломки и узкие места. Объем данных измеряется петабайтами. На текущий момент используем CatBoost для прогноза тренда, фильтр Калмана, экспериментируем с автоэнкодерами, прогнозируем будущую нагрузку на системы. Так же развиваем многомерные модели. Задачи: Общаться с заказчиком, анализировать его потребности и проводить R&D Писать и внедрять модели связанные с временными рядами Управлять внедрением модели в процесс, взаимодействовать с командой внедрения, отвечать за конечный результат Требования: Опыт работы с временными рядами Умение работы оценки бизнес-эффекта (в т.ч. A/A-, A/B-тестирование) Умение визуализировать результаты с помощью python Опыт взаимодействия с заказчиком и работы в команде Большим плюсом будет опыт промышленного программирования и написания кода Мы используем: Python: dаsk, spark, стандартные библиотеки ML SQL Hadoop: hive Плюсом будет опыт работы с Zabbix Работаем по Agile Условия: потека выгоднее для каждого сотрудника и льготные условия кредитования Бесплатная подписка СберПрайм+ Скидки на продукты компаний-партнеров ДМС с первого дня и льготное страхование для близких Корпоративная пенсионная программа Обучение за счет Компании: онлайн курсы в Виртуальной школе Сбера и неограниченный доступ к библиотеке, обучение в Корпоративном университете, Тренинги, митапы и возможность получить новую квалификацию Крупнейшее DS&AI community - более 600 DS банка, включая: регулярный обмен знаниями, опытом и лучшими практиками, интерактивные лекции и мастер-классы от ведущих ВУЗов и экспертов технологических компаний, дайджест о самых последних разработках в области DS&AI и отчеты с крупнейших конференций мира, регулярные внутренние митапы.","Time Series,ML,Анализ временных рядов,Python,SQL,Hadoop,Hive",Сбер. Data Science,
16869,72736408,Data Scientist (Global Markets),з/п не указана,1–3 года,"Полная занятость,полный день","О проекте – что мы делаем и зачем Наша agile-команда создает информационную платформу GM TA (Global Markets Trading Analytics) в интересах Департамента Глобальных Рынков (ДГР). ДГР – предоставляет корпоративным и розничным клиентам широкий спектр продуктов и услуг на локальных и зарубежных финансовых рынках. Ключевые направления бизнеса – Fx trading, Commodities, Equity, Founding, Fixed Income, Rates, Credit Valuation Adjustment, Structured Products, Investment Banking. Этот бизнес потребляет и порождает огромное количество данных, которые должны обрабатываться c целью: поддержки регулярных бизнес-операций проведения Ad hoc анализа подготовки регулярной аналитической / управленческой отчетности разработки моделей машинного обучения, направленных на решение широкого спектра прикладных задач прогнозирования, классификации, кластеризации, выявления поведенческих паттернов и отклонений от них, сентимент-анализ и т.д. Разрабатываемая нами информационная платформа – высоконагруженное решение, призванное обеспечить достижение всех этих целей. Текущий инструментальный стек платформы: Python-скрипты, Java Kafka, AirFlow MS SQL, Greenplum, PostgreSQL, InfluxDB Grafana, Qlik Sense Python ML/DL libraries, PySpark, PyTorch, TensorFlow Вот примеры некоторых наших задач: Анализ чатов трейдеров. Чаты трейдеров представляют собой поток текстовых сообщений (переписку), которыми обмениваются трейдеры в процессе проведения торгов. Переписка содержит много сокращений и аббревиатур, причем один и тот же объект может обозначаться по-разному. Необходимо анализировать этот поток в режиме near-real-time (не реже 1 раз в 5 секунд) и извлекать из полученных сообщений данные о торговых фактах, в том числе: инструменты, цены, объемы сделок, начало/конец аукционов, текущие котировки, факты продаж и любую другую информацию, которая может быть выделена и систематизирована. Полученные результаты должны быть обработаны и приведены к единому формату (инструменты, даты, факты) с целью профилирования и сегментации трейдеров, формирования объемного представления о рынке и принятия оптимальных решений о проведении сделок Анализ новостного потока. Необходимо в приходящем из разных источников новостном потоке определять тематику каждой новости и ее эмоциональную окраску (позитив/негатив), выделять в контенте новости объекты, с которыми она связана – компании, государства и т.п. Кроме того, необходимо отслеживать каждую тему во времени, находить дубликаты новостей, оценивать интенсивность новостного потока и его влияние на спрос и котировки финансовых инструментов, прямо или косвенно связанных с объектами новостей Анализ отклонений в поведении клиентов. Клиенты, совершающие операции на валютном рынке, характеризуются определенными паттернами своих операций. Количество таких клиентов огромно, соответственно каждый день возникает значимый поток транзакций, связанных с ошибками/проблемами на стороне клиентов – выбор не той валютной пары, ошибка в порядке суммы операции, несвойственное клиенту отсутствие активности (как правило, из-за проблем с доступом к торговому терминалу). Необходимо выявлять отклонения от паттернов клиентских операций и формировать сигналы, позволяющие нормализовать ситуацию Сегментация клиентов для оптимизации продуктового предложения и цены. Клиенты характеризуются набором атрибутов, включающих принадлежность к отрасли, размер выручки, потребляемые финансовые продукты, паттерны движения денег на счетах, связанные с этим операции и т.д. Необходимо анализировать такие данные о клиентах с целью их сегментации и определения для сформированных сегментов перечней наиболее подходящих финансовых продуктов в допустимых ценовых диапазонах. Также необходимо выявлять факторы, сигнализирующие о наиболее подходящем моменте для предложения сделки клиенту Выявление фрода. Клиенты на валютном рынке, могут совершать операции, характеризуемые как fraud в отношении банка. Необходимо выявлять паттерны таких операций и своевременно реагировать на их появление в клиентском профиле, регулируя, соответствующим образом, ценовое предложение для таких клиентов Анализ данных аукционов. Во время проведения аукционов на различных торговых площадках необходимо, в режиме near-real-time (не реже 1 раз в 5 секунд), извлекать и анализировать данные об инструментах и ценах, опубликованных на этих торговых площадках с целью формирования объемного представления о рынке и принятия оптимальных решений о проведении сделок Хеджирование риска курсовых разниц по карточным операциям. Риск курсовых разниц возникает при оплате товаров и услуг в валюте, отличной от валюты счета карты. Валютные куры на день авторизации платежа и день расчета с международной платежной системой (МПС), как правило, разные, что может приводить к финансовым потерям. Необходимо в день авторизации прогнозировать объемы резервирования валют для будущих расчетов с МПС и сроки такого резервирования, учитывая, что авторизуемые суммы и суммы фактических платежей отличаются разнонаправленно Теоретические знания Математика Теория вероятностей и статистика Машинное обучение Прикладное программирование Уверенные практические навыки (hand zone) ностранный язык. Понимание разговорного английского языка и свободное ведение деловой переписки Языки программирования ANSI SQL и Python Постановка задач, работа с бизнес-заказчиком Разработка полнофункционального прототипа ML/DL модели Операционализация модели и ввод ее в эксплуатацию (ОЭ/ПЭ) Условия Развитая IT архитектура. Мощный GPU кластер, возможность расчётов на суперкомпьютере top-30 в мире Комфортный офис по ул. Вавилова, 19 Скидки на продукты банка и экосистемы Постоянное развитие: обучающие курсы от лучших университетов и компаний, участие в международных конференциях Развитое DS community","Python,SQL,ML,Машинное обучение",Сбер. Data Science,
16870,75601449,Senior Аналитик / Senior Data Science (Москва),до 300 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Zaymigo – это современная FinTech компания на рынке онлайн кредитования. Работаем с 2013 года. У нас более 2 000 000 клиентов. В команде больше 130 человек. Мы создаем сервис, дающий людям простой доступ к деньгам в любой стране. Наша компания имеет гибкий подход к решению задач, реализуем лучшие предложения наших сотрудников, поощряем нестандартный подход к делу. Сейчас находимся в поиске аналитика данных (data scientist). Над какими задачами будем работать: Построение рисковых скоринговых моделей Мониторинг работы моделей и их валидация Анализ рисковой отчетности работы компании и подготовка рекомендаций Участие в проектах внутри команды риск-аналитиков. Наставничество команды риск моделистов Мы ждем от Вас: Серьезную математическую подготовку Опыт применения методов статистического анализа и моделирования Опыт работы с алгоритмами машинного обучения Уверенное знание языка Python для анализа больших данных Будут плюсом навыки владения любым программным обеспечением для статистического анализа данных: SPSS, Statistica, Stata, R и т.п. Опыт работы от 1 года в fintech компаниях, банках Присутствие в офисе. Что мы предлагаем: Возможность делать крутые проекты, участвовать во всех этапах деятельности аналитического отдела 8-часовой график работы Посещение отраслевых конференций за счет компании Официальное трудоустройство по ТК РФ Комплектация рабочего места по Вашим запросам Рост ЗП согласно уровню выполняемых задач Молодой, сплоченный коллектив, дружественный микроклимат в отделе Услуги корпоративного психолога Трудоустройство в аккредитованную IT компанию.","Python,Статистический анализ,Математическая статистика,Machine Learning,Анализ данных,Математическое моделирование,Регрессионный анализ,Data Science,Аналитическое мышление,Pandas,Numpy,Анализ временных рядов",Займиго МФК,"Москва, Курская, Курская, улица Земляной Вал, 8"
16871,78711110,Data scientist (Управление рисками корпоративных клиентов),з/п не указана,1–3 года,"Полная занятость,полный день","Мы — амбициозная и дружная команда, ежедневно исследующая данные корпоративных клиентов Сбербанка. Наши модели – двигатель не имеющих аналогов в России продуктов в сфере управления рисками корпоративных клиентов. Сводная статистика о нас: Мы решаем задачи по 8 основным направлениям (от монументального ПВР до всеобъемлющих графов и молодого и амбициозного ESG) 95% наших моделей разрабатываются с применением облачных технологий Мы придерживаемся единого стандарта работы, используем JIRA/Confluence/BitBucket, у нас есть единый бэклог 25% нашей команды имеют западное образование и опыт работы в странах Европы Мы сотрудничаем с передовыми ВУЗами в 3-ёх городах России Просрочка по кредитному продукту на основе наших моделей стремится к 0. В команде с заказчиками мы: Погружаемся в предметную область Прорабатываем постановку задачи щем и исследуем данные Выбираем оптимальные методы моделирования Разрабатываем и верифицируем модели Готовим отчеты о разработке и презентуем результаты Мониторим модели Наслаждаемся результатом. В рамках работы над задачей мы будем: Разрабатывать и улучшать инструменты для машинного обучения (внутренние наработки, библиотеки) спользовать прогнозное моделирование, чтобы оптимизировать бизнес риск метрики Работать в команде с портфельными менеджерами, чтобы понять нужды бизнеса и предложить возможные решения Разрабатывать модели машинного обучения Разрабатывать архитектуру пилотов для тестирования гипотез Прокачивать коллег и развиваться самим. Качественные факторы кандидатов с высоким Feature important: Диплом в области компьютерных наук, статистики, прикладной математики или другой релевантной области Опыт работы от 3х лет с одной или несколькими СУБД: Oracle, MS SQL, Teradata либо СУБД стэка Bigdata Опыт работы с хранилищами данных от 1го года Опыт работы в роли аналитика с функцией подготовки выгрузки данных для заказчика Сильные компетенции в области реляционных СУБД и хранилищ данных: Глубокое понимание статистических подходов и методов (регрессия, свойства распределений, оценка максимального правдоподобия, проверка гипотез и их правильное использование) и опыт их применения Знания и опыт применения алгоритмов машинного обучения (GLM/Regression, Trees, Random Forest, Boosting), а также знание их преимуществ, недостатков и ограничений Приветствуется знание принципов работы нейронных сетей и опыт использования библиотек для их обучения (Keras/PyTorch/TensorFlow) Знание Python и основных DS библиотек Отличные знания английского языка (устный и письменный) как преимущество Опыт в распределённых/параллельных вычислениях с помощью следующих технологий: Hadoop, Spark, Dask и другие как преимущество А ещё у нас есть: Развитая IT архитектура. Мощный GPU кластер, возможность расчётов на суперкомпьютере top30 в мире Работа над передовыми задачами в банковском секторе Постоянное развитие: обучающие курсы от лучших университетов и компаний (МФТ, ВШЭ, NVIDIA и другие), участие в международных конференциях Большую сильную команду Развитое DS community.",,Сбер. Data Science,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
16872,76491071,Middle+ Data Scientist на продукт Маркетолог (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Data Scientist на продукт Маркетолог Описание продукта: Маркетолог является 2-ым самым крупным В2В продуктом по выручке в МТС. Мы занимаемся не только классическим вариантом телеком-рекламы (sms, mms, обзвон), но также имеем собственную DSP и активно размещаемся в digital каналах. Модели помогают эффективнее таргетироваться на абонентов в различных каналах (dsp, sms, обзвон), тем самым повышая эффективность рекламных кампаний. Обязательно: знание python на продвинутом уровне (ds, ml библиотеки – sklearn/catboost, lgbtm) опыт работы с Docker и AirFlow опыт работы с Hadoop, Apache Spark, SQL сильные теоретические знания ML умение переложить бизнес задачу на язык анализа данных, умение простым языком объяснять сложные вещи, интерпретировать результат (придется работать, как с внешними, так и с внутренними заказчиками) опыт работы в телекоме, маркетинге, рекламе Что предстоит делать? строить модели предсказания поведения пользователя работать с базами данных (проводить проверку и приемку витрин для дальнейшей работы по части ML) документировать процессы и процедуры, связанные с разработкой моделей проводить А/В тесты, дизайн экспериментов, введение культуры проведения A/B тестов в продукте писать ТЗ для инженеров Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Docker,AirFlow,Hadoop,SQL,Machine Learning,Маркетинг,Spark,sklearn,Catboost,ML,Big Data,Python",МТС,
16873,78407364,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Команда аналитического управления Центра комплаенс в поиске Главного аналитика Обязанности сследование новых источников данных, формирование новых признаков, проведение их оценки на значимость и стабильность во времени Сбор выборки для обучения и валидации моделей Проверка различных моделей для решения задачи (классификация, регрессия, выявление аномалий), выбор лучшей модели Формирование требования к витринам для команды инженеров Участие в пилотировании моделей, интерпретация полученных результатов Анализ результатов мониторинга работы моделей на Проме Требования Профильное высшее образование DS Хорошее знание теории вероятностей и статистики, умение проверять гипотезы на стат. значимость Знание Python и основных библиотек (numpy, pandas, scipy, sklearn) Умение производить отбор признаков различными методами Уверенное владение популярными алгоритмами машинного обучения и специализированными библиотеками (LightGBM, CatBoost и др.) Знание SQL Будет плюсом: Умение работать с Git, PySpark, Airflow Опыт применения DL моделей, понимание одного из популярных фреймворков PyTorch/Tensorflow/Keras Опыт построения моделей на графовых данных (задачи link prediction, anomaly detection) Базовое понимание архитектуры Transformers, опыт применения в NLP Успешное участие в соревнованиях или хакатонах Условия интересные задачи и работа в команде профессионалов социальные гарантии и стабильность (трудоустройство по ТК РФ ДМС, страхование от несчастных случаев и тяжелых заболеваний программы материальной помощи и социальной поддержки, корпоративная пенсионная программа льготные условия кредитования, скидки от компаний-партнёров) комфортные условия работы - Офис, пр-кт Старо-Петергофский, 30 к1 литер А достойная заработная плата (оклад + квартальные и годовые премии) возможности для развития (регулярное корпоративное обучение, возможность профессиональной сертификации, перспективы для развития карьеры) насыщенная корпоративная жизнь (социальные инициативы, волонтерство, спортивные, творческие мероприятия и поддержка в реализации новых бизнес-идей).",,Сбер для экспертов,
16874,78149835,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день",,,КомплТех,"Минск, улица Филимонова, 25Г"
16875,78249285,Ведущий аудитор - Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","В управление внутреннего аудита по ДВБ, отдел планирования и развития, требуется аудитор - Data Scientist Обязанности Проект/Задачи Участие / лидерство в проектах Службы внутреннего аудита в качестве Т-разработчика. Например, разработка и сопровождение сервисов на Qlik Sence, реализации IT-проектов с применением Python, Process Mining, Graph mining, разработка и сопровождение сервисов с помощью фреймворка Django и др. Требования Требования Кандидат должен обладать навыками: 1. Python: знания и опыт работы с библиотеками pandas, matplotlib, numpy, sklearn 2. Работа с БД – Уверенные знания SQL (от базового синтаксиса до написания оконных функций), Oracle, PostgreSQL, Hive. 3. Знания основ Machine Learning и Data Science. 4. Приветствуется: - опыт работы с Qlik Sense (построение дэшбордов и написание скриптов) - опыт работы с библиотеками для компьютерного зрения (pytorch, tensorflow, opencv) - опыт написания скриптов для парсинга и автоматизации (beautifulsoup, scrapy) - опыт работы с git, jira - опыт применения Process Mining - знания Django фреймворк 5. Аналитическое мышление, ориентированность на результат, умение работать в команде, порядочность, ответственность, стрессоустойчивость, развитые коммуникативные навыки. Внимание к деталям, ответственность за качество результата. Условия Плюсы быть в команде Сбера: · ипотека выгоднее на 4% для каждого сотрудника · льготные условия кредитования · ДМС с первого дня и льготное страхование для близких · бесплатная подписка СберПрайм+, скидки на продукты компаний-партнеров: Okko, Сбер Маркет, Delivery Club, Самокат, Ситимобил, Сбер Еаптека и другие · корпоративная пенсионная программа · обучение за счет компании: онлайн курсы в Виртуальной школе Сбера, возможность получить новую квалификацию · курсы для будущих родителей, материальная поддержка молодых мам, детский отдых и подарки за счет компании Работая в Сбере, ты меняешь жизнь людей вокруг себя к лучшему!",,Сбер для экспертов,
16876,77434962,Middle Data Scientist (Проект Управление ценообразованием),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Компания MagnitTech— это опытная команда IT, которая создает экосистему современных цифровых продуктов Магнит: доставка продуктов, лекарств, инструменты для обеспечения лояльности клиентов, специальные проекты и продукты для внутренних нужд. Сейчас у нас набирается команда на новый проект по управлению ценообразованием и мы в поисках Data Scientist специалиста! Чем будешь заниматься: Участвовать в разработке стратегии и выполнять задачи по оптимизации ассортимента и ценообразования Разрабатывать технологии и внедрять лучшие практики в области Big Data и Machine Learning в бизнес-процессы и системы компании Создавать и внедрять решения в области Data Science Работать в тесном сотрудничестве с бизнесом для улучшения прозрачности и понимания посредством презентаций моделей и BI инструментов Улучшать, масштабировать и поддерживать корректную работу моделей. Мы ожидаем: Опыт в прогнозировании различных временных рядов от 2 лет с применением таких алгоритмов как LightGBM, SARIMA, LSTM, т.д. Опыт со следующим стеком технологий: Python, Spark, Yandex Cloud, HDFS. Знание алгоритмов оптимизации и опыт в ритейле как большой плюс. Мы предлагаем: Работу в максимально уютном и современном офисе в Москве или в Краснодаре, или удаленно График работы 5/2 с гибким началом Конкурентоспособную заработную плату Мы любим учиться! А компания всегда поддерживает и способствует профессиональному развитию специалиста Корпоративную технику для успешной и удобной работы Дружескую атмосферу и поддержку команды профессиональных и активных коллег Корпоративные скидки и программы лояльности от наших партнеров.","Spark,SQL,Python,Data Science","МАГНТ, Розничная сеть",
16877,78405101,Data Scientist / ML-engineer (Middle+) со знание python в проект по искусственному интеллекту,от 150 000 руб. до вычета налогов,1–3 года,"Полная занятость,полный день","Привет! Мы разрабатываем продукт для птицеводческих ферм, основанный на компьютерном зрении и искусственном интеллекте. Наши девайсы работают по всему миру от Тайланда до Латинской Америки и помогают фермерам отслеживать состояние птиц, их вес и процесс роста. Московская команда тесно сотрудничает с командой из Малайзии, ндии и Америки. Мы шагаем широкими шагами и нам в команду нужен дополнительный человек, который бы помогал нам искать закономерности в Big Data, обучать модели, проверять гипотезы и помогать с автоматизацией процессов на python. Требования: - ответственный, думающий человек с быстрым умом аналитического склада - опыт работы DataScience/ML-engineer или опыт коммерческой разработки 2+ года - уверенное знание Python 3.x, SQL-запросов - хорошее знание Git - опыт разработки моделей для работы с табличными данными (временные ряды) - английский уровня B1+ Что предстоит делать: - обучение нейросетей на табличных данных - проверка гипотез (генерация как своих гипотез, так и помощь команде в реализации их идей) AB-тестирование - сбор и анализ датасетов для обучения/тестирования - работа с данными, поиск общих корреляций в разнородных данных, позволяющих повысить точность моделей - выявление и работа с аутлаерами в данных, кластеризация данных - автоматизация подготовки данных к обучению, обучение и деплой модели. Автоматизация ML пайплайна - инцидентные задачи, реагирование на запросы членов международной команды. Будет плюсом: - опыт работы с сервисами AWS & AWS S3 - опыт работы с базами данных PostgresSQL, Mongo DB - Docker, Airflow Что мы предлагаем: - стартаперский дух разработки - молодая веселая команда - погружение в современные технологии искусственного интеллекта, компьютерного зрения и робототехники - возможность попробовать себя в различных направлениях: программирование, анализ данных, обучение нейросетей, компьютерное зрение, робототехника - участие в других различных проектах от разработки ПО до создания роботов - аккредитованная IT-компания. Условия работы: - Полный день в офисе, территориально м. Селигерская. - Удаленная работа возможна, но большую часть времени надо будет находиться в офисе хотя бы на время испытательного срока. - Официальное трудоустройство по ТК РФ.","Python,Machine Learning,Базы данных,PyCharm,SQL,Английский язык,Big Data,AWS,Ответственный подход к работе,Анализ данных,Обучение и развитие,MongoDB,PostgreSQL",ПАВЛН ТЕХНО,"Москва, Селигерская, Дмитровское шоссе, 100с2"
16878,77472643,Middle/Senior Data Scientist (Operations),з/п не указана,3–6 лет,"Полная занятость,полный день","СберМаркет — технологический онлайн-сервис, помогающий делать покупки не выходя из дома. СберМаркет был создан на основе стартапа Instamart, присоединившегося к экосистеме Сбера в сентябре 2019 года. Наша миссия: экономить время, энергию и деньги людей для чего-то более важного. СберМаркет это: Один из лидеров рынка e-grocery в России Рост в 11 раз год к году Передовые технологии и собственная разработка Возможность задавать тренды в своей профессии и быть первопроходцем Классная команда и открытая корпоративная культура Быстрый рост и самостоятельное управление проектами Конкурентная зарплата и надежность. Мы хотим, чтобы клиент мог заказать продукты и товары с доставкой через нашу платформу из своих любимых магазинов, поэтому сотрудничаем уже с более 60 федеральными и региональными ретейлерами. Среди наших партнеров крупнейшие торговые сети: METRO, ЛЕНТА, АШАН, О'КЕЙ, Твой Дом и многие другие. Мы работаем на одном из самых крупных и динамичных потребительских рынков. СберМаркет-это дух, скорость и независимость стартапа, а так же сила и мощь крупнейшей в России экосистемы Сбера. Операции - сердце бизнеса. DS-команда операций работает на проектах, которые повышают операционную эффективность и помогают бизнесу стать прибыльным. Что предстоит делать: Стандартный ML (Гипотеза->Дизайн эксперимента->Построение модели->Анализ результатов->Гипотеза…) Катать модели в продакшн в виде микросервисов или задач по расписанию Строить аналитику и анализировать поведение моделей для новых инсайтов. Что ждем от тебя? Ты любишь погружаться в бизнес процессы и оптимизировать их с помощью математики Умеешь быстро делать MVP и тестировать гипотезы Слушал курс по методам оптимизации в университете и кайфанул с него Очень близок с классическим ML Умеешь писать код на Python эффективно (может отличить O(n) от O(n^2)) Хорошо владеешь SQL(можешь пояснить, чем OLAP от OLTP отличается) Наш стэк: Пишем в основном на Python, прототипируем в Jupyter, успешные эксперименты переносим на Airflow+Kubernetes Микросервисы разрабатываем на Python+GRPC, разворачиваем на собственной PaaS (Kubernetes,Gitlab CI,Helm, Prometheus) Аналитику, дашборды, мониторинги строим в Tableau, Metabase, Grafana Что мы предлагаем? Удаленный формат работы на территории РФ: Гибкое время начала дня Белая заработная плата Сильная команда коллег с kaggle grand и просто мастерами, выпускниками ШАДа Предоставляем всё необходимое оборудование для работы Развитие и рост (внешнее и внутреннее менторство, семинары, курсы, тренинги, внутреннее обучение) Поддержка участия в хакатонах - команда из опытных хакатонщиков, days off, сервера.","Python,Машинное обучение,Системное мышление,Аналитическое мышление,Умение принимать решения",СберМаркет,
16879,78253085,Data Scientist (Северсталь Диджитал),з/п не указана,1–3 года,"Полная занятость,полный день","Мы продолжаем развивать наше ML направление в Северстали, наши модели управляют обжиговыми и агломерационными машинами, помогают производить чугун, определяют неисправное оборудование по изображению и данным с датчиков, детектируют поверхностные дефекты листа, экономят цинк, управляют скоростью нескольких ключевых агрегатов в плоском и трубном прокате, в том числе с помощью Reinforcement Learning, прогнозируют рыночные цены на сталелитейную продукцию, экономят мазут и электроэнергию, повышают безопасность на предприятии. Наш технологический стек включает в себя: Python 3 со стандартнми DS пакетами (numpy, pandas, scikit-learn, xgboost/lightgbm Технологии Big Data (Hadoop, Hive, Spark) Git, Graylog, Grafana, Kubernetes, Docker В твои обязанности будет входить: Собирать данные из внутренних баз данных и работать с внешними источниками информации Применять анализ данных и алгоритмы машинного обучения для решения производственных адач Реализовывать и поддерживать end-to-end продакшн решений (в команде с дата-инженером и разработчиком) Тесно взаимодействовать с технологами на производстве Взаимодействовать с заказчиком и презентация продукта. Тебе нужно знать: Python и пакеты нашего стека SQL на уровне запросов средней сложности Теорию вероятностей и математическую статистику Принципы работы алгоритмов машинного обучения (линейная регрессия, логистическая регрессия, деревья решений, случайный лес, градиентный бустинг, нейронные сети и др.) Тебе нужно уметь: Писать понятный и воспроизводимый код Формулировать и проверять на данных статистические гипотезы Подбирать предпосылки и алгоритм машинного обучения, соответствующие поставленной бизнес-задаче, выбирать метрики и оценивать работу алгоритма Трансформировать бизнес-постановку задачи в математическую формулировку и код Ожидаем: Опыт самостоятельной реализации DS проектов и готовность о них рассказать Опыт дизайна экспериментов и проведения пилотных испытаний Плюсом будет: Опыт работы с промышленными данными Опыт работы с алгоритмами оптимизации (пакеты gurobi/cplex/pulp) Опыт работы с семействами моделей ARIMA-GARCH Участие в ML-соревнованиях Знание Tensorflow/Pytorch. Мы предлагаем: Работу в профессиональной команде, которая готова делиться знаниями и опытом Официальное трудоустройство График работы 5/2 (40 часов в неделю) Корпоративную мобильную связь, ДМС и страхование жизни Возможность своими глазами увидеть процесс производства на металлургическом комбинате Командировки на производство в г. Череповец ( не более 10%).","ML,Python,SQL,Docker,Big Data,Git",Северсталь. IT & Digital,
16880,76420732,Senior/Lead Data Scientist на продукт MTS Travel (Big Data),з/п не указана,более 6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior/Lead Data Scientist на продукт MTS Travel Описание продукта: MTS Travel - молодая дочерняя компания МТС, которая создает и развивает сервисы для путешественников по России и миру. Ее цель - стать №1 на рынке онлайн-бронирования отелей в РФ. MTS Big Data помогает сервису создавать и усиливать конкурентные преимущества через работу с большими данными. На данный момент команды поставили перед собой план по развитию проекта: 1) Собираем, обогащаем и подготавливаем данные из различных источников. 2) Строим рекомендательную систему, как для путешественников, так и для организаций предоставляющие услуги в путешествии. 3) Планируется устанавливать рейтинг отелям, рекомендовать цены, находить точки интереса вокруг отелей, предлагать альтернативные цены по текущему рынку, строить маршруты по достопримечательностям. 4) Проектирование системы аналитики для отелей Обязательно: коммерческий опыт работы в Data Science от 4-х лет умение вместе с продуктом сформировать Data-стратегию, ключевые задачи, и приоритизировать их знание A/B, Causal inference умение понять какие данные, в каком формате, в каком объеме понадобятся и сформировать задачу для DE на витрину / поток данных знание теоретической базы и опыт в построении RecSys, NBO-моделей практический опыт применения deep learning алгоритмов в NLP, CV направлениях (для подключения к R&D задачам) высокий уровень инженерной культуры работы с Git*(GitLab,GitHub, Bitbucket), работы с версионностью и стендами практический опыт вывода ML моделей в продакшн (нструменты AirFlow, MlFlow) Что предстоит делать? строить сильную команду, для решения амбициозных целей извлекать и обрабатывать массивы данных, а также автоматизировать эти процессы участвовать в разработке/проверке гипотез вместе с руководителем проекта и бизнес-заказчиком, интерпретировать результаты и оценивать качество разработанных моделей разрабатывать модели машинного обучения промышленного уровня вести техническую команду и ставить задачи дата-инженеру, дата-Science и дата-аналитику Стек технологий: Hadoop, Pyspark, Python, ML, Tableau, Jira, Confluence. Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","SQL,Python,A/B тесты,Математическая статистика,Аналитическое мышление,NLP,ML,RecSys",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
16881,76274433,Data Scientist Middle/Senior (Моделирование RnD),з/п не указана,3–6 лет,"Полная занятость,полный день","Вместе с нами ты будешь: Работать с данными для обучения моделей (текст и звук) Заниматься выгрузкой данных из корпоративного хранилища Подготавливать данные для разметки Дорабатывать и запускать скрипты тестирования Подготавливать манифесты для обучения моделей Обучать модели – запуск обучения, подбор гиперпараметров, контроль хода обучения тоговое тестирование Подготавливать скрипты применения моделей для передачи в эксплуатацию Задачи – классификация, кластеризация текстов, в том числе задачи речевой аналитики, распознавание речи, сентимент - анализ, идентификация спикера Какие знания и навыки для нас важны: высшее физико-математическое / техническое образование основы математического анализа, линейной алгебры, методов оптимизации, теории вероятностей и математической статистики основы машинного обучения и методов анализа данных основы стандартного стека: python + sklearn, pandas, numpy, scipy, matplotlib, pytorch, tensorflow. знакомство с основными архитектурами нейронных сетей знания SQL, git, bash, docker, conda опыт самостоятельного решения задач с выбором архитектуры и дообучением НС опыт участия в проектах по машинному обучению Является преимуществом: наличие github опыт написания кода в прод призовые места в хакатонах, соревнованиях по машинному обучению","Python,Моделирование,Big Data","ннотех, Группа компаний",
16882,78373823,Data scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Банки.ру — самый большой финансовый маркетплейс в России, высокотехнологичная компания, которая успешно конкурирует на рынке труда как работодатель в сфере IT и цифрового маркетинга. Более 70% нашего штата — это IT-специалисты и digital-маркетологи. Мы помогаем клиентам в выборе самых выгодных финансовых продуктов, предоставляем оперативную и достоверную информацию о финансовом рынке, являемся площадкой для обсуждения вопросов, связанных с работой банков и страховых, микрофинансовых и инвестиционных компаний. Мы создаём сервисы, которыми ежемесячно пользуемся сами, пользуются наши близкие и друзья. Ежемесячный трафик Банки.ру составляет около 20 млн посещений ( по данным SimilarWeb).  Чем предстоит заниматься: Сбор данных, выбор модели, тестирование, внедрение Построение алгоритмов Next Best Action, Uplift сследование данных (ad-hoc аналитика, сегментация/кластеризация) Разработка и тестирование новых признаков, интерпретируемых и не интерпретируемых (эмбеддингов) Создание метрик оценки качества data-продуктов Построение продакшен пайплайнов ML-моделей, ведение с АБ-тестирования. Наши ожидания: Уверенное владение Python и SQL Знание ML (алгоритмы, метрики) и опыт работы с ML-библиотеками Знание классических алгоритмов и структур данных Хорошая математическая подготовка Знание границ применимости алгоритмов и метрик, умение выбрать подходящие под задачу Опыт работы с TensorFlow/ PyTorch.  Будет плюсом: Опыт работы с RL моделями Понимание базовых принципов работы с CUDA Опыт построения рекомендательных систем. Опыт разработки продакшн решений Опыт построение CI/CD для ML-моделей. Мы предлагаем: Достойная оплата труда (обсуждается индивидуально на встрече) + полугодовые премии. Официальное оформление по ТК РФ с первого рабочего дня. Участие в конференциях, митапах, обучающих курсах. Возможность карьерного роста внутри команды. ДМС+ стоматология, иностранный язык, фитнес, профессиональное обучение, такси, отсутствие дресс-кода, гибкое начало рабочего дня. Формат работы: офис, частичная или полная удаленка. Офис в шаговой доступности от м. Нахимовский пр-т.","Python,SQL,CUDA,Data Analysis,TensorFlow",Банки.ру,"Москва, Нахимовский проспект, Одесская улица, 2кА"
16883,73728017,Аналитик данных / Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Департамент информационных технологий внедряет технологии, которые делают Москву комфортнее и безопаснее, а жизнь горожан — удобнее и мобильнее. Записаться к врачу с помощью сервиса ЕМАС, проверить домашнее задание и оценки ребенка в Московской электронной школе, подать показания счетчиков через портал mos.ru — это лишь часть услуг и сервисов, доступных москвичам и реализуемых ДТ. Мы хотим, чтобы возможности, которые дают сегодня информационные технологии, помогали каждому жителю Москвы, вне зависимости от того, где он находится, получать актуальную именно для него информацию, оперативно решать важные вопросы и экономить самое ценное, что у него есть — время. Аналитическое направление ДТ постоянно обрабатывает массу внешних и внутренних данных по широкому спектру тем. Наши специалисты не только обеспечивают Департамент качественной информацией для разработки стратегического видения и повседневной деятельности, но и выпускают открытые исследования, востребованные отраслью. Сейчас команда активно растёт и продолжает набирать темп, поэтому мы в поисках опытного Аналитика данных / Data Scientist. Наши преимущества: нтересные проекты Значимая роль в молодой команде экспертов, в которой коллеги всегда поддерживают друг друга Развивающие задачи и карьерные вызовы, реальные возможности для роста Открытую атмосферу, где ценят обратную связь, инициативность, креатив Развитую корпоративную культуру, мероприятия и бенефиты для сотрудников Офис в 5 мин. пешком от метро Тверская. Что предстоит: Участие в построении логической и физической модели данных Проработка и реализация процессов по извлечению данных из различных источников (БД, сторонние системы, файлы различных форматов, сайты и т.п.) Применение DS для выдвижения и проверки гипотез на основе данных Подготовка решений и предложений по итогам анализа Контроль качества данных в хранилище Организация процессов очистки и валидации данных Поиск закономерности в наборах данных Проведение семантического анализа данных. Что требуется: Высшее математическое / техническое образование Опыт работы с большими массивами данных Уверенные знания SQL: агрегация, джойны, вложенные запросы, индексы, оптимизация запросов Уверенное владение Python Знания теории вероятностей, математической статистики, теории информации.","Python,SQL,Анализ данных,Аналитические исследования,Математическая статистика,NLP,Data Science,Big Data,Machine Learning,Работа с большим объемом информации",ГКУ нфогород,
16884,78685496,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Wialon Hosting servers store 140 terabytes of data, and more than 1 million requests come to them every minute. We are open to expanding our expertise in Data Science, so we are looking for reinforcements in the team. The new colleague will have to work with large arrays of real data, on which the success of numerous companies (from taxi companies to oil corporations) depends. Tasks for you: Working with hypotheses and goals: Construction, validation and implementation of advanced machine learning algorithms in the field of telematics and IoT, for example: detection of anomalies in time series (fuel theft, equipment wear, car theft, etc.) driving quality control transport typification cost optimization in the field of logistics Analysis of large volumes of structured information to identify patterns and build hypotheses. Interaction with product managers and engineers. Help in solving algorithmic problems. Formation of hypotheses / formation of ML backlog. Advice and assistance in the construction of a Data-driven approach in the company as well as the requirements for the formation of DWH. We will appreciate: Python development experience. Strong knowledge of machine learning frameworks: PyTorch, Tensorflow, Keras. Strong knowledge of libraries: scikit-learn, numpy, pandas. Data visualization: bokeh/plotly, matplotlib, seaborn. Experience with big data (Dask, PySpark). Practical experience in the development of AI / ML algorithms Understanding the main ideas and theoretical foundations of machine learning. Analytic mind. Communication skills (the ability to express thoughts clearly and clearly, the ability to listen and hear). Autonomy and learning. Will be an advantage: Experience in API development in Python (FastApi/Django). Experience with MLflow, Airflow, Docker. What we offer: Work in an international company where yet each person matters and where work in a satellite office does not leave you with an isolation feeling Result-driven, friendly, and supportive team - we do an amazing job and are good friends after work Developing a product of excellent quality that makes our world a better place Flexible work options without time and location tracking Social package: professional and business training, individual foreign language training, corporate library, 20 fully covered psychological sessions, team building events, corporate presents, health insurance.  Looking forward to your applications and resumes )","Python,ML,Machine Learning,PyTorch,Numpy,Big Data",Gurtam,"Тбилиси, улица Михаила Тамарашвили, 13"
16885,78271476,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Мы в Space307 разрабатываем международную торговую платформу. Каждый день у нас в онлайне 255 тысяч уникальных пользователей из 100+ стран. У нас плоская структура и нет просто исполнителей. Каждый из нас — спец в своей области, и принцип работы простой: к нам приходят с проблемой, а мы отвечаем решением. Наш проект с большим количеством фич и вся разработка ведется в кросс-функциональных командах. Мы ищем Data Scientist в команду DS Team. ЧТО ПРЕДСТОТ ДЕЛАТЬ?: Работать над моделью Market Mixture Models: строить модели на имеющихся данных, структурировать и валидировать источники данных Работать с data analytics, data engineers с целью разработки устойчивого пайплайна для MMM модели Создавать ML модели для скоринга пользователей (user acquisition), churn prediction, LTV Разрабатывать ML модели, backtesting Тестировать моделей в real-time Создавать методологии и инструменты мониторинга качества и обновления моделей МЫ ОЖДАЕМ, ЧТО ТЫ: меешь 2+ года работы в ML проектах Уверенно владеешь Python и работал с ML библиотеками (sklearn, pandas, numpy, catboost, lightgbm, etc.) Применял ML алгоритмы к табличными данным: понимаешь принципы работы основных ML методов, feature engineering, validation strategy меешь базовое понимание статистики Работал с Linux, bash меешь опыт работы с базами данных: мы активно пользуемся Vertica, Hadoop, MySQL Самостоятельный в формулировании гипотез, дизайне ML решения от постановки задачи до способов валидации. БУДЕТ ПЛЮСОМ: Опыт работы с Time Series, Survival Analysis Опыт работы с графовыми БД Опыт работы с Docker, Flask/FastAPI Опыт дизайна и проведения A/B тестов, Casual Impact. ЧТО ТЕБЯ ЖДЁТ В SPACE307: Комфорт и достойные условия: гибкий график, удалённая работа ворлдвайд и, конечно же, конкурентный уровень заработной платы. Честность, прозрачность и отсутствие бюрократии. Структура, в которой нет «СЕО минус четыре» — мы все равны и каждый отвечает за результат. Мероприятия на любой вкус: тренинги, семинары, конференции, лекции, мастер-классы. А также тимбилдинги и корпоративы, впечатляющие своим масштабом. Хакатоны, марафоны, квесты и турниры: коллеги объединяются в команды, создают крутые идеи и проекты и получают за это не менее крутые призы. Настоящая команда: здесь дают честный фидбэк, приходят на помощь и болеют за результат.","Linux,Bash,ML,Machine Learning,Data Science,Python,Data Analysis,Математическая статистика,Pandas,sklearn",Space307,"Санкт-Петербург, Горьковская, Чкаловская, улица Кропоткина, 1"
16886,78633730,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Международный холдинг «ЕвроХим» специализируется на производстве минеральных удобрений. «ЕвроХим» - это 26 000 человек, 25 стран, 75 предприятий.  В направлении R&D компании АО «МХК «ЕвроХим» открыта вакансия ""Data Scientist"". Основная задача данной позиции - развитие направления по повышению операционной эффективности действующих производств и предприятий за счет применения цифровых технологий (ндустрия 4.0). Глобальная цель направления – реализация полномасштабной программы по внедрению на предприятиях группы компаний лучших научных, технических и цифровых решений и их взаимная интеграция.  Обязанности: Обработка данных, построение аналитических решений Формирование гипотез и определение источников данных Применение алгоритмов машинного обучения и инструментов для сбора и трансформации данных спользования и настройка инструментов для работы с большими массивами структурированных данных Разработка прототипов и работающих решений с помощью программных сред на Python. Требования: Опыт разработки в роли аналитика данных (Data science) не менее 3-х лет Опыт применения машинного обучения для реальных бизнес-задач, работы с сырыми данными, разработки моделей и их валидации Уверенное владение Python и знание библиотек (NumPy, Scikit-learn, XGBoost и пр.) Опыт работы с СУБД, умение писать сложные SQL-запросы Готовность к командировкам. Приветствуется: Знание Kafka, Spark, MLFlow Применения стека технологий разработки: Git. Условия: Оформление в соответствии с нормами ТК РФ, социальные гарантии Крупные проекты в компании–лидере отрасли Возможность модернизировать процессы реального производственного бизнеса в команде сильнейших экспертов Полис ДМС (включая стоматологию) Удаленная работа Доступ к корпоративной OnLine библиотеке Обучение в программах Корпоративного университета Корпоративный спорт, конференции, культурные мероприятия.","Python,SQL,Анализ данных,Data Science,Data Analysis","ЕвроХим, Минерально-Химическая Компания",
16887,78330725,Middle Data Scientist (модели кредитного риска),з/п не указана,1–3 года,"Полная занятость,полный день","Чем предстоит заниматься: Разрабатывать и поддерживать модели кредитного риска для поточного кредитования малого и среднего бизнеса (PD, LGD, EAD) Развивать и поддерживать внутренний фреймворк для разработки моделей Генерировать и применять в моделях новые фичи на основе слабоструктурированных данных из Hadoop Проводить эксперименты с нестандартными для классического скоринга подходами к моделированию Анализировать эффективность новых источников данных и применять их в моделях Что ожидаем от кандидата: Умение работать с данными (анализ, очистка, подготовка, отбор и создание признаков), навыки написания SQL-запросов Хорошее знание теории вероятностей, математической статистики и методов машинного обучения Опыт в разработке моделей машинного обучения от 2 лет Опыт работы c пакетами для анализа данных на Python3 (numpy, pandas, scikit-learn, xgboost, lightgbm, catboost, etc) Опыт работы с git Желателен опыт работы с юридическими лицами, понимание, как устроена отчетность, какие модели и как можно применять для анализа компаний Условия: Дух лидерства, амбиций, авантюризма - то, что мы называем Альфа-ДНК Работа в крупнейшем частном банке с высоким уровнем экспертизы и классной командой Стабильный и прозрачный доход: размер заработной платы обсуждается по итогам собеседования Для желающих работать из офиса - комфортные рабочие места. Для остальных - возможность полноценной удаленки и гибридного формата работы Сервера с Tesla и 1500гб оперативы Понятный и общеизвестный модельный и технологический стек Коллектив единомышленников (все DS-подразделения Альфы собраны в единый департамент, порог для обмена опытом минимален) Заинтересованность со стороны заказчиков, гарантирующая, что все модели строятся для промышленного применения и будут выведены в ПРОД с ощутимым влиянием на бизнес-процесс ДМС, корпоративное обучение, коворкинг в Сочи и другие предложения от банка только для сотрудников",,Альфа-Банк. Digital & IT,"Москва, Технопарк, проспект Андропова, 18к3"
16888,78786481,"Senior Data Scientist (""Платформа экспериментов"")",з/п не указана,3–6 лет,"Полная занятость,полный день","A/B эксперименты – ключевой инструмент для принятия решений в компании Okko. Все гипотезы мы проверяем через эксперименты. Сейчас наш бизнес довольно быстро растёт, растёт и количество запускаемых экспериментов, которые нужно качественно и быстро анализировать. Во многом от того, насколько точно будут проанализированы эксперименты, зависят принимаемые решения и, как следствие, будущее нашего бизнеса. Если ты понимаешь, что соответствуешь требованиям и веришь в то, что вместе мы сможем построить лучшую платформу экспериментов на рынке СНГ, откликайся на вакансию! Обязанности: улучшение текущего процесса проведения экспериментов аналитическая разработка новой платформы моделирования, сплитования, мониторинга и оценки экспериментов поддержка и развитие новой платформы моделирования, сплитования, мониторинга и оценки экспериментов повышать общий уровень культуры экспериментирования в компании. Что мы используем: Python (sklearn, seaborn, numpy, scipy, statsmodels) ClickHouse, PostgreSQL, Redis, etc. Airflow, FlaskAPI/FastAPI Bitbucket, Jira, Confluence. Требования: знание математической статистики и A/B тестирования уверенное владение и опыт разработки на Python уверенное владение SQL опыт в классическом ML бизнес-ориентированное мышление. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,ML",Okko,"Москва, Баррикадная, Краснопресненская, Улица 1905 года, Рочдельская улица, 15с13"
16889,78524520,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Функциональная область: участие в разработке ML-решения с использованием данных промышленного интернета вещей (IIoT). Предметная область включает работу с: временными рядами (телеметрия IIoT), структурированными данными (производственные операции и простои, производственные показатели и данные), геоинформационными данными (местоположение и передвижение техники). Требования: Уверенное использование языка Python (pandas, etc) для анализа данных и построения моделей, расширенные функции SQL (Postgres / PostGis). Опыт работы в проектах логистической, транспортной оптимизации. Опыт работы - от 5 лет в области анализа данных, математического моделирования. Условия: График работы - 5/2. Командировки на Сахалин - 1 раз в квартал на 2 недели. ДМС. Благодарим за интерес к нашей вакансии! Ваше резюме будет рассмотрено в течение 7 дней. В случае положительного решения по Вашему резюме, мы обязательно свяжемся с Вами.",,Восточная горнорудная компания,"Москва, 1-й Красногвардейский проезд, 15"
16890,78042103,"Senior Data Scientist, Анализ текста (DS/NLP)",з/п не указана,3–6 лет,"Полная занятость,полный день","Мы — команда инженеров и датасаентистов в крупнейшем маркетплейсе с миллионами пользователей, хайлоадом и бигдатой. Нас знают все.  щем разработчиков в команду «Управления машинного интеллекта и исследований» WB.  Мы занимаемся повышением качества поисковой выдачи. Совершенствуем алгоритмы распознавания текстов, чтобы люди получали точные ответы даже на самые замысловатые запросы. Угадываем намерения наших пользователей с учетом опечаток и неточностей.  Чем предстоит заниматься: проводить А/Б-эксперименты, анализировать ранжирование и смотреть в данные оптимизировать поисковые алгоритмы с помощью ML и много экспериментировать. Мы ожидаем: знание Python (интерес к Go будет плюсом) знание алгоритмов и структур данных интерес к аналитике, ML и NLP (опыт с GPT — большой плюс). Предлагаем: сложные интересные задачи хорошую зарплату ДМС свободу в принятии решений профессиональный рост в команде увлеченных инженеров удаленку или офис минимум формализма и гибкий график ротацию между проектами (если захотелось чего-то нового). Аккредитация Минцифры: предоставляем все льготы для Т-специалистов.","NLP,ML,Data Analysis,Python,GPT",WILDBERRIES,
16891,78330086,Data scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Разработка и валидация предиктивных моделей с применением методов машинного обучения (python) Взаимодействие с риск-технологами при внедрении моделей в production-контур, формирование бизнес-требований, участие в scrum-команде, приемочное тестирование Формирование и сопровождение витрин данных для целей моделирования, прогнозирования и data-аналитики Статистический анализ факторов риска Расширение, автоматизация и систематизация архитектуры риск-хранилища Требования: Профильный опыт работы в банке в области оценки кредитных рисков Знание SQL на уровне написания сложных запросов, разработки и автоматизации регулярных витрин Базовый математический бэкграунд (теория вероятностей, математическая статистика) Базовые знания Python (обработка данных с помощью pandas, NumPy) Базовые знания процесса кредитования и портфельных рисков Знакомство с основными алгоритмами и инструментами машинного обучения Знание Excel на уровне построения сводных отчётов и навыки автоматизации на VBA Условия: Оформление в соответствии с ТК РФ Офисный форматы работы Режим работы: с 9.30 до 18.30, в пятницу с 9.30 до 17.30 Финансовые условия обсуждаются индивидуально, в зависимости от профессионального опыта и стажа работы Социальный пакет: компенсация ДМС, льготное кредитование, скидки на туристические и иные услуги от партнеров Банка.","Python,SQL,Excel,Анализ данных",ЛОКО-БАНК,"Москва, Аэропорт, Ленинградский проспект, 39с80"
16892,76165484,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы запускаем амбициозный проект CVM в компании с ""0"" и ищем профессионалов в продвинутую команду! CVM - это системная работа с клиентской базой, на основании персонализированных предложений (учитывающих потребности клиентов), которые создаются с использованием продвинутой аналитики и нацелены на повышение долгосрочной ценности клиента (LTV) через повышение частоты покупок, размера средней корзины или предотвращение оттока. Обязанности: Запрос, подготовка и анализ данных Построение и совершенствование моделей машинного обучения Еженедельный анализ промо-кампаний до и после их внедрения (вкл. проверку гипотез) Синтез и представление результатов анализа эффективности кампании Поиск новых возможностей реализации персонализации промо-кампаний в данных Проведение А/B тестов и проверка эффекта для подтверждения коммерческой эффективности промо-кампании Разработка и поддержка общих моделей микросегментации, измерения эффекта от промо-кампаний, прогнозирования предпочтений клиента для использования во многих use cases, расчет LTV Разработка методологии и инструментов мониторинга качества и обновления моделей Создание и поддержка общих ML-библиотек, поддержание архитектуры среды разработки моделей Требования: Отличное знание SQL на уровне оконных функций Уверенные знания и применение методов математической статистики Наличие успешно завершенных проектов с использованием технологий анализа данных и машинного обучения Знание моделей машинного обучения, принципов их работы, методов оценки качества моделей, ключевых особенностей и ограничений Методы оценки значимости и отбора признаков Владение языками и средами для создания регулярно обновляемых моделей машинного обучения (Python, библиотеки pandas, sklearn, xgboost, tensorflow, PyTorch) Желательно: Релевантный опыт работы 2-3 года Желательно: опыт работы в экосистеме Hadoop Желательно: понимание принципов распределенных систем Опыт работы с Docker Высшее образование (Ведущие вузы), желательно математическое/техническое Ключевые навыки: Python SQL A/B тесты Математическая статистика Модели машинного обучения Linux Условия: Официальное оформление в соответствии с ТК РФ, полная стабильность Отсутствие бюрократии и плоская организационная структура Возможность вносить коррективы в процессы, в архитектуру и лояльный бизнес, постоянные коммуникации, возможность на равных обсуждать бизнес-фичи на стадии формирования Действительно высокий уровень дохода, оклад + годовая премия, полностью ""белый"". Гибкое начало работы, но 5/2, полный день. Возможен частично-удаленный формат работы. Офис- м/мцд Окружная или корп.транспорт 7 минут от м.Петровско-Разумовская. Хорошее техническое оснащение, никаких проблем с доступами на удаленной работе Расширенный полис ДМС До 20% скидка на продукцию компании Мы являемся официальной IT компанией в РФ (льготная ипотека, отсрочка от армии). ндексация дохода","Python,SQL,Linux,Power BI",Детский Мир,"Москва, Окружная, Окружная, Петровско-Разумовская, 3-й Нижнелихоборский проезд, 3с6"
16893,78663639,Senior Data Scientist в Scoring Platform (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Senior Data Scientist в Scoring Platform Описание продукта: Продукт “Скоринг” - выявление потенциальных дефолтников и мошенников (фродеров) в банках, МФО и на интернет-площадках с помощью ML-моделей. Мы создаем скоринговую платформу, которая должна сократить и упростить путь от сбора данных до получения нашим клиентом вероятностной оценки в виде сервиса в личном кабинете. Обязательно: углубленное знание математической статистики, теории вероятности и ML методов анализа данных опыт в области промышленного применения методов DS от 3 лет уверенное владение Python, PySpark, SQL понимание принципов MLOps, навыки работы с Git английский язык на уровне, позволяющем читать профессиональную литературу Что предстоит делать? строить модели для внешних клиентов в предметных областях: банковские и не банковские риски, различные виды мошенничества. Формальных ограничений по методам моделирования нет создавать библиотеки python с ML инструментами, релевантными для DS и экспериментов аналитиков, в т.ч. autoML Стек технологий: Python, MLFlow, Hadoop, airflow, gitlab Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные и международные конференции, митапы. Корпоративный университет МТС и масштабная виртуальная библиотека. А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта","Python,MLFlow,gitlab,airflow,Hadoop,PySpark,SQL,Математическая статистика,теория вероятности",МТС,"Москва, Технопарк, проспект Андропова, 18к9"
16894,78146526,Middle Data scientist / Аналитик (Нижний Новгород),от 100 000 до 150 000 руб. на руки,1–3 года,"Полная занятость,полный день",,,Займиго МФК,"Нижний Новгород, Горьковская, Ковровская улица, 21А"
16895,78102902,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день",,,"ВСК, САО","Москва, Островная улица, 4"
16896,78082039,"Middle Data Scientist (NLP, NER)",з/п не указана,1–3 года,"Полная занятость,полный день",,,ФГБУ ЦСП ФМБА России,"Москва, 1-й Волоколамский проезд, 10"
16897,77470908,Middle/Senior Data Scientist [команда Content],з/п не указана,1–3 года,"Полная занятость,полный день","СберМаркет — технологический онлайн-сервис, который помогает делать покупки не выходя из дома. СберМаркет был создан на основе стартапа Instamart, присоединившегося к экосистеме Сбера в сентябре 2019 года. Наша миссия: экономить время, энергию и деньги людей для чего-то более важного. СберМаркет это: один из лидеров рынка e-grocery в России рост в 11 раз год к году передовые технологии и собственная разработка возможность задавать тренды в своей профессии и быть первопроходцем классная команда и открытая корпоративная культура быстрый рост и самостоятельное управление проектами конкурентная зарплата и надежность Мы хотим, чтобы клиент мог заказать продукты и товары с доставкой через нашу платформу из своих любимых магазинов, поэтому сотрудничаем уже с более 60 федеральными и региональными ретейлерами. Среди наших партнеров крупнейшие торговые сети: METRO, ЛЕНТА, АШАН, О'КЕЙ, Твой Дом и многие другие. Сегодня мы работаем на одном из самых крупных и динамичных потребительских рынков. В СберМаркете по-прежнему живы дух, скорость и независимость стартапа. В то же время мы располагаем силой и мощью крупнейшей в России экосистемы Сбера. Мы находимся в поиске Middle/Senior Data Scientist в команду Content. Отдел Контента в СберМаркете отвечает за наполнение сайта. DS-команда помогает автоматизировать процесс разработки карточки товара: с момента ее создания до момента отображения в каталоге.  Что предстоит делать: Развивать модель Out-of-stock модель. Мы уже выкатили первую версию, получив значимый прирост GMV. Хотим повысить интерпретируемость модели и превратить технологию в полноценный продукт для ритейлеров Оптимизировать работу контент-отдела Развивать алгоритм мэтчинга для предотвращения создания дублей в базе. Мы уже выкатили первую версию с использованием трансформеров в прод, но хотим значимо улучшить top-1 accuracy модели для полного отказа от человеческой работы Улучшать алгоритм автозаполнения карточки товара Улучшать алгоритм обработки изображений товаров. Необходимо ускорить процесс создания фото для карточки товара - первый этап фотопродакшна это удалить фон от основного товара. Что мы ждём от кандидата: Знание алгоритмов ML Решал задачи NLP / Graph analysis Опыт от 2х лет выкатки в прод Умение делать итерации в разработке моделей A/B тесты - знание стат. критериев, антипаттернов, умение сформулировать гипотезу и придумать дизайн теста под эту гипотезу Уверенное владение git, CI/CD, docker, k8s Самостоятельно может подготовить данные для анализа/моделей (SQL, hive, spark) Разработка простых архитектурных решений. Будет плюсом, если ты: Владеешь PyTorch меешь опыт применения BERT-like моделей Наш стэк: Пишем на Python и SQL Данные храним в ClickHouse, S3 Прототипируем в Jupyter, успешные эксперименты переносим на Airflow + Kubernetes Микросервисы разрабатываем на Python + GRPC, разворачиваем на собственной PaaS (Kubernetes, Gitlab CI, Helm, Prometheus) Аналитику, дашборды, мониторинги строим в Tableau, Metabase, Grafana. Что мы предлагаем: Смешанный формат: можно работать из офиса в Москве (Садовническая улица, 9А) или удаленно Соц.пакет — ДМС, спорт, промокоды на заказ продуктов или билеты в отпуск Предоставляем технику для работы на ваш выбор Команда: Мы стараемся нанимать тех, с кем нам хорошо, поэтому работой дело не ограничивается Вместе мы занимаемся спортом, ездим на шашлыки, ходим на внешние хакатоны, играем в настолки, ну и бары, куда же без них Возможности для роста и развития: Сбермаркет активно развивается и растет, что дает возможности роста горизонтально, вертикально и диагонально Внешнее и внутреннее менторство. Если вы знаете классного эксперта и хотите обсудить ваш рабочий проект, это приветствуется и финансируется Бюджет на обучение Поддержка участия в хакатонах - команда из опытных хакатонщиков, days off, сервера Корпоративная культура: Открытость: мы умеем давать обратную связь корректно и вовремя Свобода и ответственность: мы верим, что выдающийся результат достижим при максимальной свободе в принятии решений Fail fast: ошибки это “ок”, для инноваций они необходимы, главное не повторять одни и те же и быстро тестировать гипотезы А еще: Мы не работаем ""в стол"", мы сами отвечаем за полный цикл жизни гипотезы - от рисерча в ноутбуке до выкатки на продакшн Мы уделяем большое внимание обучению сотрудников, поэтому в нашей knowledge base можно найти много интересных курсов, книг и записей конференций Мы сами участвуем в конференциях, как спикеры Проводим внутренние митапы и дискуссионные клубы Не боимся экспериментировать с новыми решениями и технологиями У нас Pet friendly офис. Отправляй своё резюме и становись частью огромной дружной команды!","Python,SQL,Git,Tableau,Spark,A/B тесты,Обработка изображений,Алгоритмы,Обработка фото",СберМаркет,
16898,76663333,Middle Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Департамент анализа данных и моделирования создан в 2019 году для стратегического развития функции анализа данных в ВТБ. Управление процессных и Финансовых моделей специализируется на разработке моделей для управления активами и пассивами Банка, структурой баланса, управления процентным риском, риском ликвидности и достаточностью капитала.  Обязанности: разработка поведенческих моделей досрочного погашения срочных продуктов Банка и моделей динамики продуктов неопределенной срочности для прогноза метрик структурных балансовых рисков Банка разработка прогностических моделей эластичности спроса на банковские продукты по цене и другим факторам для управления структурой баланса Банка, ликвидностью и ценовой политики по продуктам разработка финансовых моделей для ценообразования продуктов Банка с учетом риска и анализа финансовой рентабельности продуктовых предложений Банка прикладной анализ данных и разработка моделей по другим направлениям для повышения эффективности бизнес-процессов, снижения затрат Банка и снижения рисков. Требования: хорошие знания и опыт практического применения теории вероятностей и математической статистики знание основных алгоритмов и методов машинного обучение и анализа данных: линейные модели, ансамблевые методы, анализ и прогнозирование временных рядов опыт разработки моделей на языках Python или R знание основного инструментария стэка Python: Jupyter, Pandas, Scikit-learn, Statsmodels или аналогов в R опыт работы с базами данных, владение языком запросов SQL хорошие знания английского языка. БУДЕТ ПРЕМУЩЕСТВОМ: опыт работы в Казначействе, подразделениях управления рисками банковской книги знание финансовых рынков, рынков банковских продуктов, финансового учета опыт работы с экосистемой Apache Hadoop (HDFS, Impala, Hive, Hue) опыт работы с фреймворком Apache Spark (Pyspark, MLlib, Spark SQL) знания финансовой математики, случайных процессов и стохастического анализа опыт работы с системой контроля версий Git. УСЛОВЯ: трудоустройство согласно Законодательству конкурентная заработная плата профессиональное обучение и развитие добровольное медицинское страхование, льготные условия кредитования корпоративная пенсионная программа, материальная помощь спортивная жизнь и корпоративные мероприятия возможность построить карьеру в ведущем банке России.","Python,SQL,Математическая статистика,Pandas,Машинное обучение,Моделирование","ПАО ВТБ, Технологический блок",
16899,77472379,Middle/Senior Data Scientist (RecSys),з/п не указана,3–6 лет,"Полная занятость,полный день","СберМаркет — технологический онлайн-сервис, помогающий делать покупки не выходя из дома. СберМаркет был создан на основе стартапа Instamart, присоединившегося к экосистеме Сбера в сентябре 2019 года. Наша миссия: экономить время, энергию и деньги людей для чего-то более важного. СберМаркет это: Один из лидеров рынка e-grocery в России Рост в 11 раз год к году Передовые технологии и собственная разработка Возможность задавать тренды в своей профессии и быть первопроходцем Классная команда и открытая корпоративная культура Быстрый рост и самостоятельное управление проектами Конкурентная зарплата и надежность. Мы хотим, чтобы клиент мог заказать продукты и товары с доставкой через нашу платформу из своих любимых магазинов, поэтому сотрудничаем уже с более 60 федеральными и региональными ретейлерами. Среди наших партнеров крупнейшие торговые сети: METRO, ЛЕНТА, АШАН, О'КЕЙ, Твой Дом и многие другие. Мы работаем на одном из самых крупных и динамичных потребительских рынков. СберМаркет-это дух, скорость и независимость стартапа, а так же сила и мощь крупнейшей в России экосистемы Сбера. Команда RecSys существует 2 года. За это время мы успели: с нуля создать ключевые рекомендательные алгоритмы и в честном А/В-тесте значимо победить рекомендации от внешнего вендора пройти непростой путь от offline до online рекомендаций проверить в А/В-тестах множество гипотез по улучшению рекомендательных алгоритмов для всего сервиса запустить в А/В-тест проект персонализации UI приложения и многое другое. Кроме того, мы сами занимаемся разработкой и развитием рекомендательной платформы, сами катим свои модели в продакшн и сами отвечаем за стабильность работы сервиса рекомендаций. Что предстоит делать: зучать статьи в поисках лучших подходов к созданию рекомендаций в фудтехе Выдвигать гипотезы по улучшению существующих алгоритмов рекомендаций, а также придумывать новые по запросу от бизнеса Проверять гипотезы на данных Обучать ML-модели Запускать А/В-тесты. Что ждем от тебя? Для кандидатов уровня Middle и выше: совокупный опыт работы в ML от 2-х лет умение сделать качественный EDA и донести результаты до команды уверенное владение Python и базовые знания SQL практический опыт работы с ML (в частности, опыт работы с алгоритмами CF и ранжирования) опыт полного цикла внедрения моделей (сбор данных, обучение и оценка модели, проведение А/Б-тестов) самостоятельность, проактивность и умение декомпозировать при решении задач. Для кандидатов уровня Senior и выше: предыдущий опыт работы в сфере нформационного поиска/RecSys/NLP/E-commerce на позиции уровня Middle и выше практический опыт проектирования ML-систем. Будет плюсом, если ты: Знаешь, как правильно готовить алгоритмы бустинга и разрабатывать для них жгущие факторы меешь опыт работы с нейронными сетями меешь опыт работы, связанный с выкатками на продакшн Умеешь писать надежный и эффективный продакшн-код на Python. Наш стэк: Пишем на Python и SQL Данные храним в ClickHouse, S3 Прототипируем в Jupyter, успешные эксперименты переносим на Airflow + Kubernetes Микросервисы разрабатываем на Python + GRPC, разворачиваем на собственной PaaS (Kubernetes, Gitlab CI, Helm, Prometheus) Аналитику, дашборды, мониторинги строим в Tableau, Metabase, Grafana. Что мы предлагаем? Удаленный формат: Гибкое время начала дня Белая заработная плата Сильная команда коллег с kaggle grand и просто мастерами, выпускниками ШАДа Предоставляем всё необходимое оборудование для работы Развитие и рост (внешнее и внутреннее менторство, семинары, курсы, тренинги, внутреннее обучение) Поддержка участия в хакатонах - команда из опытных хакатонщиков, days off, сервера.","Python,SQL,Машинное обучение,ML",СберМаркет,
16900,78096858,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день",,,«UZUM TECHNOLOGIES».,
16901,78280966,Data Scientist (ML Engineer),з/п не указана,3–6 лет,"Полная занятость,полный день","Задачи: • Дообучение Модели машинного обучения на основании новых данных, в том числе: Контроль предобработки и обогащения новых данных, формирование обучающей выборки Мониторинг целевых метрик качества и контроль кривой обучения Модели Корректировка гиперпараметров Модели при возникновении такой необходимости (тюнинг) Доработка Модели с точки зрения факторов, входных данных и т.д. • Доработка интерфейса и логики системы ручных проверок.  Будет важным: • Хорошее знание Python • Опыт разработки или доработки моделей машинного обучения • Опыт работы с Linux консолью • Готовность быстро освоить использование библиотек с которым ранее не было опыта работы • Желание и готовность работать самостоятельно с заказчиком, собирать и реализовывать требования. Желательно, будет плюсом: • Уверенный опыт разработки реляционных баз данных (PostgreSQL, Oracle или MSSQL) • Опыт применения любых из перечисленных средств: Cython, TensorFlow, Keras, PyTorch, lightGBM, XGboost, Pymorphy, nltk, genism, Pymystem, Hyperopt , SMAC, Pandas, Numpy, sklearn, scipy • Опыт использования Nginx, Django, React, Docker, SOAP, HTML, CSS, Bootstrap. Условия работы: • Оформление по ТК РФ • Стабильная окладная часть, а также система премирования • Социальный пакет (ДМС со стоматологией, специальные предложения по страхованию (КАСКО, имущество, жизнь), льготное кредитование, корпоративный фитнес и другие программы от партнеров) • Страхование жизни и страхование от несчастных случаев и болезней • Забота компании о детях сотрудника: скидки в детские лагеря и подарки на Новый год • Удобное расположение офиса в центре города (Чистые пруды/Сретенский бульвар/Тургеневская) - 6 минут.","Python,SQL,CSS,Django Framework,HTML,postgree,ORACLE,MSSQL,Cython,TensorFlow,Keras,PyTorch,lightGBM,XGboost,Pymorphy,nltk,genism,Pymystem,Hyperopt,Nginx,Django,React,Docker,SOAP,Bootstrap,Qlick View,MS SQL,Работа с базами данных,Oracle BI",СОГАЗ: г. Москва,"Москва, Красные ворота, проспект Академика Сахарова, 10"
16902,78505752,Data Scientist (Deep Learning for Demand Forecast),з/п не указана,3–6 лет,"Полная занятость,полный день","В связи с расширением Департамента математической оптимизации и моделирования ищем специалиста на позицию Data Scientist (Senior). Флагманской задачей команды является прогнозирование спроса для in-house заказчика - компании Деловые Линии, крупнейшего в РФ перевозчика сборных грузов. Наш прогноз используется для финансового планирования, ценообразования и планирования операций (S&OP). За время работы накоплена экспертиза и проделан путь от классических моделей временных рядов до градиентного бустинга. Постоянно работая над повышением качества прогноза, мы изучаем современные подходы и видим, что будущее прогнозирования за глубоким обучением. щем профессионала, способного применять методы глубокого обучения для прогнозирования временных рядов.  Направления исследований: Применение глубокого обучения для прогнозирования спроса на услуги компании Эластичность спроса по цене и ценам конкурентов, влияние промо-акций, эффекты гало и каннибализации Работа с большим количеством временных рядов и разреженным спросом. Что мы ждем от кандидата: Знание архитектур глубоких нейронных сетей Знание методов и принципов ML Опыт применения глубоких нейронных сетей для работы с временными рядами или табличными данными Опыт прогнозирования спроса методами машинного обучения (линейные модели, градиентный бустинг) или классическим методами (arima, ets, mstl) Опыт внедрения или поддержки разработанных моделей в продуктовой среде Понимание специфики временных рядов и прогнозирования спроса. Мы предлагаем: Сильная команда. Люди, которые увлечены и любят свою работу работают у нас. Достойный уровень заработной платы, официальное оформление в аккредитованной Т компании, социальные гарантии Комфортные условия: гибкий график и формат работы, свободный дресс-код. ДМС + Программа «Кафетерий льгот»: сотрудники за счет компании могут компенсировать расходы на страхование, обучение, спорт, спортивный инвентарь Развитие и обучение: оплата внешних тренингов, семинаров и конференций, корпоративная библиотека Бизнес центр класса ""А"" (адрес: Московский проспект, ближайшая станция метро - Фрунзенская), полная инфраструктурная обеспеченность.","Deep Learning,Прогнозирование,Time Series",БиАйЭй-Технолоджиз,"Санкт-Петербург, Фрунзенская, Московский проспект, 94"
16903,78094820,Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день",,,Сбер для экспертов,
16904,78410566,Senior Data Scientist (ML),з/п не указана,3–6 лет,"Полная занятость,полный день","Группа НЛМК — крупнейший в России и один из самых эффективных в мире производителей стальной продукции. Производственные активы в России, Европе, Азии и США. Мы создаем совершенную сталь для ключевых отраслей: от строительства до ветроэнергетики. Разрабатываем новые технологии и внедряем передовые цифровые решения. ОПСАНЕ ПОЗЦ: Разработка решений с использованием машинного обучения в промышленности. Полный цикл разработки от сбора данных и тренировки моделей на собственном кластере до их тестирования, интеграции и деплоя. Развитие внутренней DSML платформы, участие в подготовке релиза платформы в open-source. Работа в дружном коллективе, прямое влияние на производственные процессы ВАС ЖДЕТ: Работа с данными (EDA, чистка, feature engineering) Выдвижение и проверка гипотез Обсуждение задачи с людьми с производства Разработка и реализация моделей машинного обучения Проведение экспериментов, подбор метрик, валидация моделей и мониторинг их качества Доведение моделей до Production с использованием собственной DSML-платформы Написание отчётов о разработке Доработка существующих решений МЫ ЖДЕМ ОТ ВАС : Высшее техническое образование Стек: Python, Linux, Git, Docker, Spark Опыт в ML от 3-х лет Знание основ мат.статистики Понимание принципа работы основных алгоритмов классического ML Опыт работы с табличными данными, временными рядами Опыт решения задач кластеризации, регрессии, классификации Опыт работы с xgboost/catboost/lightgbm Хорошие коммуникативные навыки Умение самостоятельно строить план работы и оценивать свои силы Будет плюсом: опыт работы в промышленности МЫ ПРЕДЛАГАЕМ: Москва – офис/гибрид/удалённо ДМС + стоматология (с первого месяца работы) Компенсация обеда Возможность стать частью команды цифровизации реального сектора экономики Полностью удаленный график работы Конкурентный уровень заработной платы и ежегодная индексация. Корпоративные льготы: ДМС, льготное страхование родственников, банковские продукты сотрудникам и скидки партнеров. Обучение и развитие: английский язык в лучших языковых школах, большое количество обучающих курсов от внутреннего корпоративного университета, посещение митапов и конференций Возможность принять участие в интересных и сложных проектах с лучшими специалистами индустрии",,Группа НЛМК Т и Диджитал,
16905,76913797,Data-Scientist / Дата-сайентист,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Employcity,
16906,78259386,Team lead Data scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Привет, ищем к себе в команду тим лида, проект включает в себя развитие CVM (Customer Value Management) и повышение коммерческой эффективности одной из ведущих телеком компаний СНГ. Нужно будет создавать компетенции DS и ML, развивать КХД, каналы коммуникаций с клиентами и разрабатывать продукты. Формат работы: офис/гибрид/удаленный только по РФ. Чем предстоит заниматься Анализ данных, проверка гипотез и разработка моделей машинного обучения по оценке кредитных рисков и лидогенерации Написание production-ready кода для быстрого деплоя пайплайна с моделью на регулярную эксплуатацию Планирование и соблюдение сроков по разработке ML продуктов Экспертная поддержка data science команды Дополнительно для тимлида Постановка задач на команду дата-сайнтистов и обеспечение качества разработанных ML продуктов сполнение DS командой технологических процессов (версионирование, документация, code review и т.д.) в соответствии с принятыми в подразделении регламентами и SLA Что для этого нужно Фундаментальные знания в области математики, теории вероятности, мат. статистики (высшее образование, наличие ученой степени будет дополнительным плюсом) Наличие успешно завершенных проектов с использованием технологий анализа данных и машинного обучения Знание алгоритмов машинного обучения, принципов их работы, ключевых особенностей и ограничений Отличное владение инструментами анализа данных, библиотеками машинного обучения Python, SQL Опыт работы в области Data Science от 3х лет","SQL,Python,A/B тесты,Hadoop","МегаФон, IT","Москва, Маяковская, Новослободская, Чеховская, Оружейный переулок, 41"
16907,76261820,Data Scientist Middle (КБ и СМБ),з/п не указана,3–6 лет,"Полная занятость,полный день","Вместе с нами ты будешь: Участвовать в проектах по разработке моделей оценки кредитного риска для клиентов малого и среднего бизнеса: Анализировать данные для моделирования (подготовка, обработка, анализ качества) Прорабатывать архитектуру модели и согласовывать с заказчиком Формировать выборки для моделирования Проводить однофакторный, многофакторный анализ, калибровку модели Оценка различных метрик качества модели (ранжирующая способность, стабильность, точность и др.) Защита результатов перед заказчиком Подготавливать модельную документацию и бизнес-требования на внедрение модели Примеры моделей, в разработке которых успешный кандидат сможет принять участие: модели оценки вероятности дефолта (PD), аппликативные / поведенческие модели PD lifetime в соответствии с требованиями МСФО 9 модели оценки уровня потерь при дефолте (LGD) модели оценки суммы задолженности, подверженной риску дефолта (EAD / CCF) модели определения лимита с учетом риска контрагента (Risk-based limit) модели для использования в целях расчета достаточности капитала Банка в соответствии с требованиями ПВР (483-П) проведение пилотов на предмет использования различных обучающих алгоритмов для построения моделей, а также анализ данных внешних поставщиков (телеком, операторы фискальных данных, бюро кредитных историй и др.) Какие знания и навыки для нас важны: высшее образование (математическое / техническое / финансовое) хорошие навыки письменного и устного общения уверенное знание математики, статистики, эконометрики и машинного обучения владение Python и классическим ML-стэком (pandas, numpy, scikit-learn и т.д.) стремление развивать навыки количественного анализа и их использования в моделировании наличие успешно завершенных проектов: практический опыт реализации полного цикла разработки модели от идеи до постановки требований на внедрение инициативность – необходимо предлагать новые идеи по используемым подходам и моделям, их усовершенствование опыт работы в области управления рисками / риск моделировании в банковской / консалтинговой организации от трёх лет. Является преимуществом: опыт работы с Hadoop/Spark наличие сертификатов FRM / PRM / CFA / CQF участие в хакатонах, обучение в ШАД понимание методологии оценки кредитного риска клиентов корпоративного сегмента.","Python,Spark,ML,Моделирование,Big Data,Hadoop","ннотех, Группа компаний",
16908,78334481,Data Scientist (Валидация моделей кредитного риска КБ),з/п не указана,1–3 года,"Полная занятость,полный день","В Сбере в Управлении валидации, в Центре валидации моделей корпоративно-инвестиционного бизнеса открыта вакансия. Управление валидации Сбера – это внутренний консалтинг в области Data Science. Сотрудники управления участвуют в проектах по улучшению предиктивных моделей, моделей машинного обучения и оптимизации их применения в бизнес-процессах Банка. Мы создаем инструменты для мониторинга, управления и митигации модельного риска по всем бизнес-направлениям. Основные задачи: Валидация математических моделей, используемых в корпоративном и инвестиционном бизнесе Банка. Валидация включает: Независимую проверку модели и рекомендации по ее улучшению, в т.ч. создание альтернативных моделей (challenger) Оценку чувствительности бизнес-метрики процессов ожидаемого финансового эффекта от точности/стабильности работы модели Оценку импакта от рекомендаций по редизайну моделей/альтернативной модели, полученной на этапе валидации. щем DS на направление риск-моделей по корпоративным клиентам. К данному стриму относятся модели кредитного риска (PD, LGD, EAD), ПВР, МСФО, а также модели ранней диагностики проблемности клиентов (в том числе blackbox алгоритмы), модели оптимальной суммы/срока кредита (RBL/RBP/RBT). Работа также предполагает: Анализ бизнес-процессов применения модели. Оценка оптимальности применения модели в процессе Оптимизация моделей с точки зрения достижения бизнес-результата от применения модели нтерпретация результатов валидации и разработка плана необходимых мероприятий по устранению недостатков модели совместно с владельцами и разработчиками моделей Создание инструментов для валидации и разработки моделей (Python) Участие в проектах Управления Валидации по развитию IT инфраструктуры и автоматизации процессов. Требования Высшее образование в области экономики/математики (предпочтение отдаётся выпускникам ВШЭ, МФТ, МГУ, РЭШ) Знание математической статистики, эконометрики, машинного обучения. Приветствуется опыт участия в соревнованиях по анализу данных и опыт разработки моделей в банковской сфере Владение навыками работы как минимум с одним из следующих языков - Python, R Уровень владения английским языком для чтения статей по best-practice подходам в риск-менеджменте, моделировании, посещения международных конференций Опыт программирования и работы с базами данных (например, Oracle), навыки работы с Python Системное мышление и экономический склад ума, понимание, желание разбираться в предметной области, в бизнес-процессах. Желательно знание основ управления рисками в Банке, в частности регуляторных требований (Basel II, III) С опытом работы в моделировании / валидации в банках топ-20, либо в большой четверке по направлению риск-практики от 1 года рассматриваем на Главного специалиста. Условия потека выгоднее для каждого сотрудника и льготные условия кредитования Бесплатная подписка СберПрайм+ Скидки на продукты компаний-партнеров ДМС с первого дня и льготное страхование для близких Корпоративная пенсионная программа Обучение за счет Компании: онлайн курсы в Виртуальной школе Сбера и неограниченный доступ к библиотеке, обучение в Корпоративном университете, Тренинги, митапы и возможность получить новую квалификацию.",,Сбер. Data Science,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
16909,72736422,Middle/Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Наша команда Департамента развития корпоративного бизнеса разрабатывает ML модели в следующих направлениях: предотвращение оттока оценка CLTV омниканальная рекомендательная система котирование кредитов и депозитов и т.д. отраслевые модели классификация комментариев, обратной связи оценка силы связи в графе Обязанности В роли Senior Data Scientist вы будете отвечать за end-to-end процесс создания data-продукта, от исследования релевантных данных, построения и проверки гипотез, создания признаков до тестирования и подготовки готового продукта к промышленной эксплуатации Требования Высшее образование в области компьютерных наук, статистики, прикладной математики или другой релевантной области Глубокое понимание статистических подходов и методов (регрессия, свойства распределений, проверка гипотез и их правильное использование) и опыт их применения Свободное владение основными DS библиотеками на Python (pandas, numpy, scikit-learn, pytorch, lightgbm) Опыт применения алгоритмов машинного обучения (GLM/Regression, Trees, Random Forest, Boosting), понимание их преимуществ, недостатков и ограничений Достойный уровень инженерной культуры (умение писать адекватный код за вменяемое время, использовать контроль версий) Опыт с языком SQL, навыки работы с Apache Spark Английский язык (устный и письменный) как преимущество Опыт в распределённых/параллельных вычислениях с помощью следующих технологий: Hadoop, Spark, Dask и другие как преимущество Стремление вникнуть в бизнес соответствующей отрасли Умение общаться с бизнес-заказчиком, слышать собеседника и доказывать свою точку зрения Условия Развитая IT архитектура Комфортный офис, большой выбор вариантов по питанию, бесплатный фитнес в офисе Скидки на продукты банка и экосистемы Постоянное развитие: обучающие курсы от лучших университетов и компаний (МФТ, ВШЭ, NVIDIA и другие), участие в международных конференциях Развитое DS community, регулярные митапы, дайджесты и конференции","Python,SQL,Машинное обучение,Spark,Hadoop,Machine Learning",Сбер. Data Science,
16910,78169151,Data Scientist (Динамическое ценообразование),з/п не указана,1–3 года,"Полная занятость,полный день",,,Сбер для экспертов,
16911,78786488,"Senior Data Scientist (""Платформа экспериментов"")",з/п не указана,3–6 лет,"Полная занятость,полный день","A/B эксперименты – ключевой инструмент для принятия решений в компании Okko. Все гипотезы мы проверяем через эксперименты. Сейчас наш бизнес довольно быстро растёт, растёт и количество запускаемых экспериментов, которые нужно качественно и быстро анализировать. Во многом от того, насколько точно будут проанализированы эксперименты, зависят принимаемые решения и, как следствие, будущее нашего бизнеса. Если ты понимаешь, что соответствуешь требованиям и веришь в то, что вместе мы сможем построить лучшую платформу экспериментов на рынке СНГ, откликайся на вакансию! Обязанности: улучшение текущего процесса проведения экспериментов аналитическая разработка новой платформы моделирования, сплитования, мониторинга и оценки экспериментов поддержка и развитие новой платформы моделирования, сплитования, мониторинга и оценки экспериментов повышать общий уровень культуры экспериментирования в компании. Что мы используем: Python (sklearn, seaborn, numpy, scipy, statsmodels) ClickHouse, PostgreSQL, Redis, etc. Airflow, FlaskAPI/FastAPI Bitbucket, Jira, Confluence. Требования: знание математической статистики и A/B тестирования уверенное владение и опыт разработки на Python уверенное владение SQL опыт в классическом ML бизнес-ориентированное мышление. Условия: работа в сильной команде, состоящей из топовых аналитиков, аналитиков-разработчиков и инженеров топовое оборудование и весь необходимый софт официальное трудоустройство ДМС со стоматологией, офисный врач, доплата больничного листа, корпоративные скидки льготные условия ипотеки в рамках зарплатного проекта бесплатная подписка на сервисы партнеров. насыщенная корпоративная жизнь.","Python,SQL,ML",Okko,"Санкт-Петербург, Беговая, улица Савушкина, 126Б"
16912,78164928,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Бюро кредитных историй Скоринг Бюро,
16913,77471270,Lead Data Scientist (RecSys),з/п не указана,более 6 лет,"Полная занятость,полный день","СберМаркет — технологический онлайн-сервис, помогающий делать покупки не выходя из дома. СберМаркет был создан на основе стартапа Instamart, присоединившегося к экосистеме Сбера в сентябре 2019 года. Наша миссия: экономить время, энергию и деньги людей для чего-то более важного. СберМаркет это: Один из лидеров рынка e-grocery в России Рост в 11 раз год к году Передовые технологии и собственная разработка Возможность задавать тренды в своей профессии и быть первопроходцем Классная команда и открытая корпоративная культура Быстрый рост и самостоятельное управление проектами Конкурентная зарплата и надежность. Мы хотим, чтобы клиент мог заказать продукты и товары с доставкой через нашу платформу из своих любимых магазинов, поэтому сотрудничаем уже с более 60 федеральными и региональными ретейлерами. Среди наших партнеров крупнейшие торговые сети: METRO, ЛЕНТА, АШАН, О'КЕЙ, Твой Дом и многие другие. Мы работаем на одном из самых крупных и динамичных потребительских рынков. СберМаркет-это дух, скорость и независимость стартапа, а так же сила и мощь крупнейшей в России экосистемы Сбера. щем тимлида в ML-команду рекомендательных систем. Команда RecSys существует 2 года. За это время мы успели: с нуля создать ключевые рекомендательные алгоритмы и в честном А/В-тесте значимо победить рекомендации от внешнего вендора пройти непростой путь от offline до online рекомендаций проверить в А/В-тестах множество гипотез по улучшению рекомендательных алгоритмов для всего сервиса запустить в А/В-тест проект персонализации UI приложения и многое другое. Кроме того, мы сами занимаемся разработкой и развитием рекомендательной платформы, сами катим свои модели в продакшн и сами отвечаем за стабильность работы сервиса рекомендаций. Что предстоит делать: Управлять командой от 3 до 5 человек Развивать команду через процессы, принятые в компании: 1-1, feedback sessions, ПР, perfomance review Растить денежные метрики СберМаркета и повышать пользовательский опыт путём улучшения рекомендательных алгоритмов на основе имеющейся экспертизы Определять направление развития ML-компоненты рекомендательной платформы Создавать квартальные планы совместно с продактом команды. Планировать спринты Участвовать в code review. Что ждем от тебя? Совокупный опыт работы в ML от 5 лет, в том числе опыт управления командой от 1 года Предыдущий опыт в сфере нформационного поиска/RecSys/NLP/E-commerce на Senior/Lead позиции Опыт полного цикла внедрения моделей (сбор данных, обучение и оценка модели, проведение А/Б-тестов) Практический опыт проектирования ML-систем Опыт работы, связанный с выкатками на продакшн Уверенное владение Python и SQL. Будет плюсом, если ты: меешь опыт работы с нейронными сетями Умеешь писать надежный и эффективный продакшн-код на Python. Наш стэк: Пишем на Python и SQL Данные храним в ClickHouse, S3 Прототипируем в Jupyter, успешные эксперименты переносим на Airflow + Kubernetes Микросервисы разрабатываем на Python + GRPC, разворачиваем на собственной PaaS (Kubernetes, Gitlab CI, Helm, Prometheus) Аналитику, дашборды, мониторинги строим в Tableau, Metabase, Grafana. Что мы предлагаем? Удаленный формат работы Гибкое время начала дня Белая заработная плата Сильная команда коллег с kaggle grand и просто мастерами, выпускниками ШАДа Предоставляем всё необходимое оборудование для работы Развитие и рост (внешнее и внутреннее менторство, семинары, курсы, тренинги, внутреннее обучение) Поддержка участия в хакатонах - команда из опытных хакатонщиков, days off, сервера.","Python,Машинное обучение,Алгоритмы",СберМаркет,
16914,78102671,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Обязанности: Подготавливать исторические данные, необходимые для построения моделей Разрабатывать предиктивные модели определения склонности клиента к банковским продуктам Повышать точность предиктивных моделей Осуществлять валидацию и контроль качества используемых моделей Выполнять ревизию предиктивных алгоритмов и программного кода (code review) разрабатываемых моделей Реализовывать систему валидации и мониторинга качества модели и данных. Требования: Опыт работы от 3 до 6 лет Высшее образование (математическое моделирование, прикладное моделирование) Опыт разработки скоринговых моделей в банках (подразделении CVM) Знание базовых алгоритмов машинного обучения, уверенное знание Python, SQL Опыт использования библиотека для реализации ML-моделей: scikit-learn. Мы предлагаем Вам: Стать частью крупного, динамично развивающегося банка Работу в команде единомышленников, неравнодушных к передовым технологиям и практикам Неограниченные возможности для совершенствования Ваших навыков и знаний, обучаясь у лучших и решая сверхамбициозные задачи Позитивную рабочую атмосферу, дружный коллектив Удобное расположение офисов Достойную и конкурентную заработную плату, квартальные и годовые премии, размер которых зависит от результатов Вашей работы Разнообразный социальный пакет: ДМС, страхование жизни, страхование для выезжающих за границу, льготные условия приобретения банковских продуктов, скидки в фитнес-клубах и в компаниях-партнерах.","Python,SQL,Machine Learning,Машинное обучение,Data Science,Моделирование",Банк Открытие,"Москва, улица Большая Ордынка, 40с4"
16915,78711069,Senior Data scientist (Управление рисками корпоративных клиентов),з/п не указана,3–6 лет,"Полная занятость,полный день","Мы — амбициозная и дружная команда, ежедневно исследующая данные корпоративных клиентов Сбербанка. Наши модели – двигатель не имеющих аналогов в России продуктов в сфере управления рисками корпоративных клиентов. Сводная статистика о нас: Мы решаем задачи по 8 основным направлениям (от монументального ПВР до всеобъемлющих графов и молодого и амбициозного ESG) 95% наших моделей разрабатываются с применением облачных технологий Мы придерживаемся единого стандарта работы, используем JIRA/Confluence/BitBucket, у нас есть единый бэклог 25% нашей команды имеют западное образование и опыт работы в странах Европы Мы сотрудничаем с передовыми ВУЗами в 3-ёх городах России Просрочка по кредитному продукту на основе наших моделей стремится к 0. В команде с заказчиками мы: Погружаемся в предметную область Прорабатываем постановку задачи щем и исследуем данные Выбираем оптимальные методы моделирования Разрабатываем и верифицируем модели Готовим отчеты о разработке и презентуем результаты Мониторим модели Наслаждаемся результатом. В рамках работы над задачей мы будем: Разрабатывать и улучшать инструменты для машинного обучения (внутренние наработки, библиотеки) спользовать прогнозное моделирование, чтобы оптимизировать бизнес риск метрики Работать в команде с портфельными менеджерами, чтобы понять нужды бизнеса и предложить возможные решения Разрабатывать модели машинного обучения Разрабатывать архитектуру пилотов для тестирования гипотез Прокачивать коллег и развиваться самим. Качественные факторы кандидатов с высоким Feature important: Диплом в области компьютерных наук, статистики, прикладной математики или другой релевантной области Опыт работы от 3х лет с одной или несколькими СУБД: Oracle, MS SQL, Teradata либо СУБД стэка Bigdata Опыт работы с хранилищами данных от 1го года Опыт работы в роли аналитика с функцией подготовки выгрузки данных для заказчика Сильные компетенции в области реляционных СУБД и хранилищ данных: Глубокое понимание статистических подходов и методов (регрессия, свойства распределений, оценка максимального правдоподобия, проверка гипотез и их правильное использование) и опыт их применения Знания и опыт применения алгоритмов машинного обучения (GLM/Regression, Trees, Random Forest, Boosting), а также знание их преимуществ, недостатков и ограничений Приветствуется знание принципов работы нейронных сетей и опыт использования библиотек для их обучения (Keras/PyTorch/TensorFlow) Знание Python и основных DS библиотек Отличные знания английского языка (устный и письменный) как преимущество Опыт в распределённых/параллельных вычислениях с помощью следующих технологий: Hadoop, Spark, Dask и другие как преимущество А ещё у нас есть: Развитая IT архитектура. Мощный GPU кластер, возможность расчётов на суперкомпьютере top30 в мире Работа над передовыми задачами в банковском секторе Постоянное развитие: обучающие курсы от лучших университетов и компаний (МФТ, ВШЭ, NVIDIA и другие), участие в международных конференциях Большую сильную команду Развитое DS community.",,Сбер. Data Science,"Москва, Кутузовская, Кутузовская, Кутузовский проспект, 32к1"
16916,78241386,Data scientist (middle),з/п не указана,3–6 лет,"Полная занятость,полный день","Data scientist (middle) Компания: федеральный ритейл Офис: Москва Формат работы: удаленка, гибрид Оформление: ТК РФ Условия: з/п в рынке, ежеквартальный бонус, корпоративный ноутбук, ДМС, сотовая связь. Наш Стэк: BI Qlick sense, axapta, SQL, R, Python Наш кандидат: • Опыт от 3 лет • Опыт работы в области анализа данных (воронки, когортный анализ, регрессия, AB-тесты) • Уверенное владение SQL, умение писать сложные запросы к базам данных • Умение и желание решать нетривиальные задачи в условиях неполных данных • хорошее владение Python (включая стандартный ML-стек) • способен предлагать метрики для оптимизации и различные методы решения задачи • Опыт в Deep Learning в Computer Vision от 2 лет Что делать: • Моделирование и разработка сервисов для динамического ценообразования, динамического меню. • Построение рекомендательных систем. • Оптимизационные задачи, анализ временных рядов. Computer Vision, NLP, аудио аналитика.","Python,Deep Learning,Data Science,Математическая статистика,Machine Learning,ML,Многозадачность,Аналитика,Mathematical Statistics",Звено Успеха,
16917,76281676,Middle Data Scientist (Скоринги Партнерств и ПБД),з/п не указана,1–3 года,"Полная занятость,полный день","Вместе с нами ты будешь: Заниматься построением моделей на основе временных рядов Заниматься построением моделей на графах Заниматься построением look-alike моделей Работать по задачам с текстом, табличными данными, графами связанности сследовательские проекты (AutoML) совместно с научной средой (Сколтех, МФТ, МГУ) Какие знания и навыки для нас важны: Техническое образование, опыт работы ds от 2-ух лет Знание классических ML-алгоритмов и нейросетей Уверенное владение стандартным стеком python-библиотек (sklearn, pandas, numpy, matplotlib, LightGBM и т.д.) Опыт работы с Hadoop и PySpark SQL Способность самостоятельно рисерчить новые темы, читать статьи на английском и реализовывать их","Python,Spark,ML,Моделирование,Big Data,Hadoop","ннотех, Группа компаний",
16918,78374362,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Мы ATOMMINING - cоздатели бизнеса в области майнинга криптовалют. Наша главная задача – сделать работу в криптоиндустрии максимально понятной и прозрачной для каждого! Команда ATOMMINING предлагает оптимальные решения в майнинг бизнесе для своих клиентов. У нас собственное производство майнинг ферм на GPU, прямые поставки комплектующих, размещаемся в собственных дата центра и владеем комплексными бизнес решениями для майнинга. На сегодняшний день компания распологает площадями более 7000 кв.м. Медиа отдел ATOMMINING создает информационно-познавательный контент о деятельности компании, где мы делимся собственным опытом и компетенциями, а также анализируем мировые новости майнинга и криптоиндустрии. Теперь о вакансии)  Что предстоит делать: Разработка моделей для классификации(на входе преимущественно биомедицинские сигналы, аудио или видео данные или их производные) Постановка задач для группы младших специалистов, контроль выполнения проекта и тактическое планирование.  Что мы ждем от кандидата: Понимание принципов и алгоритмов классического машинного обучения (machine learning, МL) и статистического анализа данных Опыт работы с временными рядами, построения автоэнкодеров, генерации extra features Навыки автоматизации разработки моделей и проверки гипотез Уверенное владение: Python, SQL, MinIO, библиотека TensorFlow Понимание принципов распараллеливания, опыт работы с большими данными (big data) Понимание принципов проектирования ПО, тестирования, непрерывной интеграции (continuous integration) Опыт работы с системами контроля версий  Будет плюсом: опыт работы портирования нейронных сетей в embedded решения Опыт работы с OpenCV Опыт работы с распознаванием графических образов Опыт в обработке цифровых сигналов, FFT, DFFT Опыт разработки ПО под iOS/Android  С нашей стороны: Оформление по ТК РФ, мы аккредитованная IT компания Комфортный офис в Москва-сити, где мы предоставим вам самую лучшую технику для реализации ваших идей График работы 5/2 с гибким началом рабочего дня Оплачиваемый отпуск и больничный лист Компания поддержит и поможет справиться с трудностями По результатам работы мы будем рады оплатить вам профессиональное обучение, если оно понадобится","Нейронные сети,Machine Learning,Big Data,Data Analysis,Data Science",Атом Майнинг,"Москва, Деловой центр, Пресненская набережная, 8с1"
16919,77687838,Data Engineer (ДАДМ),з/п не указана,3–6 лет,"Полная занятость,полный день","Вместе с нами ты будешь: Заниматься проектированием и разработкой витрин данных для анализа и моделирования Заниматься мониторингом и оптимизацией процессов сборки витрин Заниматься загрузкой и обработкой данных из различных источников Заниматься поддержкой и развитием базы знаний Предоставлять экспертную поддержку внутренним потребителям(data analysts,data scientists) Какие знания и навыки для нас важны: Знание SQL Хорошее знание устройства Hadoop,Spark,Hive/Impala Опыт разработки на Python/Scala/Java Понимание основных концепций DWH Понимание базовых команд Git и основных приципов работы Будет плюсом: Опыт работы с банковскими данными Опыт работы с различными СУБД в роли разработчика/аналитика витрин данных Опыт работы с Airflow","DWH,Hadoop,Hive,Git,Python,SCALA,SQL","ннотех, Группа компаний",
16920,78523579,Middle+/Senior Data Scientist в Блок Финансы,з/п не указана,3–6 лет,"Полная занятость,полный день","Управление моделирования и исследования данных в поисках Data Scientist. Наша команда занимается внедрением инструмента для анализа и оценки ценности клиента CLTV (Client Life-Time Value) для Экосистемы Сбербанка. Мы ищем Data Scientist’a, который видит связь между ML-разработкой и бизнес-применением и проведет анализ данных и поможет сформулировать предложения по изменению параметров существующих продуктов и запуску новых. Основные зоны ответственности в рамках направления: · Построение и проверка бизнес-гипотез под ключ: от сбора ТЗ до реализации пилота · Разработка ML-моделей (классификация, кластеризация, регрессия) на базе 100+ млн розничных клиентов Сбербанка · Работа с огромными массивами данных (Spark, Hadoop, GreenPlum) · Анализ влияния особенностей продуктов на клиентское предпочтение (эластичность к свойствам продуктов) · Поиск, объединение и нормализация данных · Разработка ML-моделей для выявления инсайтов · Участие в отчете перед руководством по результатам анализа · Работа с командой DS-разработчиков, менторство, постановка задач на разработку · Подведение итогов пилотов, участие в A/B тестировании · Тестирование целесообразности применения SOTA подходов в моделировании Требования · Опыт работы от 2-3 лет в DS · Отличные знания в области классического data science / математики / статистики / эконометрики · Продвинутое использование SQL · Опыт работы с BigData (Hadoop, hdfs, pyspark) – преимущество · Опыт A/B тестирования – преимущество · Понимание принципа работы банковского или финансового бизнеса – преимущество · Опыт решения бизнес-задач «под ключ»: от постановки задачи до вывода в пром Мы предлагаем: · Конкурентную компенсацию · Огромные массивы данных · Дружную команду профессионалов (ВШЭ, МГУ, РЭШ) · Комфортабельный офис недалеко от метро Кутузовская с корпоративным фитнесом · Оформление по ТК РФ",,Сбер для экспертов,
16921,77471529,Lead Data Scientist (Operations),з/п не указана,более 6 лет,"Полная занятость,полный день","СберМаркет — технологический онлайн-сервис, помогающий делать покупки не выходя из дома. СберМаркет был создан на основе стартапа Instamart, присоединившегося к экосистеме Сбера в сентябре 2019 года. Наша миссия: экономить время, энергию и деньги людей для чего-то более важного. СберМаркет это: Один из лидеров рынка e-grocery в России Рост в 11 раз год к году Передовые технологии и собственная разработка Возможность задавать тренды в своей профессии и быть первопроходцем Классная команда и открытая корпоративная культура Быстрый рост и самостоятельное управление проектами Конкурентная зарплата и надежность. Мы хотим, чтобы клиент мог заказать продукты и товары с доставкой через нашу платформу из своих любимых магазинов, поэтому сотрудничаем уже с более 60 федеральными и региональными ретейлерами. Среди наших партнеров крупнейшие торговые сети: METRO, ЛЕНТА, АШАН, О'КЕЙ, Твой Дом и многие другие. Мы работаем на одном из самых крупных и динамичных потребительских рынков. СберМаркет-это дух, скорость и независимость стартапа, а так же сила и мощь крупнейшей в России экосистемы Сбера.  Мы ищем тимлида в ML-команду Operations Операции - сердце бизнеса. DS-команда операций работает на проектах, которые повышают операционную эффективность и помогают бизнесу стать прибыльным. Что предстоит делать: Управлять командой от 5 до 10 человек Развивать команду через процессы, принятые в компании: 1-1, feedback sessions, ПР, perfomance review Повышать операционную эффективность бизнеса за счет ML Определять направление развития ML в операциях Создавать квартальные планы совместно с продактом команды. Планировать спринты Участвовать в code review. Что ждем от тебя? Совокупный опыт работы в ML от 5 лет, в том числе опыт управления командой от 1 года Предыдущий опыт в сфере E-commerce на Senior/Lead позиции Опыт работы с задачами операционной части бизнеса (supply/demand balance, dispatch, surge и другие) Умеешь говорить на одном языке с бизнесом Любишь погружаться в бизнес-процессы и оптимизировать их с помощью математики Умеешь писать код на Python эффективно (может отличить O(n) от O(n^2)) Наш стэк: Пишем в основном на Python, прототипируем в Jupyter, успешные эксперименты переносим на Airflow+Kubernetes Микросервисы разрабатываем на Python+GRPC, разворачиваем на собственной PaaS (Kubernetes,Gitlab CI,Helm, Prometheus) Аналитику, дашборды, мониторинги строим в Tableau, Metabase, Grafana. Что мы предлагаем? Удаленный формат работы: Гибкое время начала дня Белая заработная плата Сильная команда коллег с kaggle grand и просто мастерами, выпускниками ШАДа Предоставляем всё необходимое оборудование для работы Развитие и рост (внешнее и внутреннее менторство, семинары, курсы, тренинги, внутреннее обучение) Поддержка участия в хакатонах - команда из опытных хакатонщиков, days off, сервера.","Обучение и развитие,Машинное обучение,Системное мышление,ML,Математика",СберМаркет,
16922,75916094,Middle Data Scientist (e-commerce),з/п не указана,1–3 года,"Полная занятость,полный день","Компания MagnitTech— это опытная команда IT, которая создает экосистему современных цифровых продуктов Магнит: доставка продуктов, лекарств, инструменты для обеспечения лояльности клиентов, специальные проекты и продукты для внутренних нужд. Магнит сейчас — это не только оффлайн покупки в ближайшем магазине города. Мы активно развиваемся в онлайн! Наша команда занимается тем, что развивает наше приложение доставки, делая его удобным и комфортным для пользователей. Наша команда расширяется и мы ищем специалиста Data Scientist, который поможет развивать наше приложение! Чем предстоит заниматься: Прогнозировать почасовую динамику спроса товаров Прогнозировать доступность товара в магазине/dark store (out-of-stock) Разрабатывать рекомендательную систему по заменам при out-of-stock Прогнозировать временя сборки и доставки заказа Оптимизация количества сборщиков и курьеров Работать с динамическим ценообразованием сборки и доставки. Мы ожидаем: Опыт работы с распределенными системами (HADOOP, YC DataProc) посредством Spark Опыт работы с данными посредством SQL (Teradata, MS SQL, Postgres, Oracle) Опыт решения практических задач прогнозирования Знание математической статистики, систем контроля версий кода, основных моделей и принципов машинного обучения Опыт работы с временными рядами Опыт работы с docker, airflow Знание ООП Знание принципов глубокого обучения. Мы предлагаем: Работу в максимально уютном и современном офисе в Москве или в Краснодаре, или удаленно График работы 5/2 с гибким началом Конкурентоспособную заработную плату Мы любим учиться! А компания всегда поддерживает и способствует профессиональному развитию специалиста Корпоративную технику для успешной и удобной работы Дружескую атмосферу и поддержку команды профессиональных и активных коллег Корпоративные скидки и программы лояльности от наших партнеров.","Spark,Hadoop,SQL,ORACLE","МАГНТ, Розничная сеть",
16923,78347781,Data Analyst,до 4 000 USD на руки,1–3 года,"Полная занятость,полный день","At Neiro.ai we are developing entertainment products using generative AI Why us? We have a strong engineering team (ex-Samsung AI, Yandex, JetBrains, VK, PicsArt, VisionLabs) We have raised money from investors of Looksery and AI Factory (both acquired by Snap for $150M and $166M) We develop state-of-the-art generative AI (Lip-Sync, Text-to-speech, Voice Conversion, Dialogue Engine) and build unique entertainment products More than 500 000 000 video views on TikTok with content generated by our apps Your Responsibility Selection and development of a system for collecting, analyzing, and visualizing product metrics Create a plan for the integration of analytical systems with products Verify the correctness of analytical pipelines with developers Analyzing data from mobile analytics systems based on the user's behavior Own dashboards and maintain analytical pipelines Proactively propose product/marketing changes based on insights from data & setting up experiments Looking for anomalies/patterns/bugs in data and data collection pipelines Product metrics comparison with market benchmarks & competitors Key Qualifications: 1+ years of experience in Data Analyst / Product Analyst / Data Scientist roles Experience setting up mobile analytical systems SQL + Python Experience in A/B testing Excellent knowledge of statistics relevant to product analytics Intermediate analytical, verbal, and written English communication skills Fast learner. You should pick up and run with new workflows quickly Understanding of product metrics, unit economics, and principles of their optimization Proactivity and Autonomy It would be great to have Track record of collaborating with engineers on solving problems What do we offer The ability to understand how entertaining mobile products are built Direct work with C-level. Fast communication between UA/Mobile/Marketing teams. Our products are based on our own Generative AI (Computer Vision, Speech, NLP). Working with us is an excellent opportunity to understand how modern Machine Learning works. Opportunity to become Head of Analytics Salary & stock options to be discussed Remote work or Relocation package to Tbilisi Necessary equipment/software/education Our Process Test assignment HR interview  CEO Interview","Amplitude,Firebase,Google Analytics,Retention,Play Console,SQL,Python,Data Analysis,Английский — C1 — Продвинутый",Botan Investments,
16924,78300280,Data Scientist senior,з/п не указана,3–6 лет,"Полная занятость,полный день","Вам предстоит участвовать в развитии система фрод-мониторинга Сбербанка, которая обеспечивает защиту клиентов банка во всех каналах обслуживания от мобильных приложений и покупок в интернет до визитов клиентов в офисы. Эта система признана одной из лучших в мире: 17th Annual 2021 Cyber Security Global Excellence Awards winners. Fraud Prevention GOLD WINNER - SberBank Anti-Fraud System Fraud Prevention Editor’s Choice – SberBank Наша команда принимает активное участие в развитии этой системы и сосредоточена на разработке и внедрении AI-моделей по выявлению мошенничества. Вам предоставляется уникальная возможность поработать с действительно большими объемами данных, широким перечнем передовых технологий и сделать значимый вклад в борьбу с мошенничеством в стране. Вы будете участвовать в развитии система форд-мониторинга Сбербанка, которая обеспечивает защиту клиентов банка во всех каналах обслуживания от мобильных приложений и покупок в интернет до визитов клиентов в офисы. Обязанности Разработка и развитие моделей и алгоритмов противодействия мошенничеству: скоринг транзакций для выявления фрода/«отмывания» средств, оценка риска сущностей (клиенты, устройства и пр.), анализ и выявление связей, транзакционных аномалий и пр. Мониторинг и регулярный контроль качества работающих в пром. моделей Анализ доступных источников данных и информации в них, оценка качества для решения задач Обсуждение задач и методов их решения совместно с фрод-аналитиками и бизнес-заказчиками, формулирование гипотез и их проверка Построение воспроизводимых и переиспользуемых решений для работы с данными и моделями Взаимодействие с командами инженеров и участие в интеграции решений в промышленную эксплуатацию Требования Хорошие знания Python 3 Опыт работа с Pandas, SQL, Spark/PySpark, Hive и др. инструментами для анализа малых и больших данных Опыт использования ML библиотек и алгоритмов на Python (xgboost/lightgbm/catboost, sklearn, …), понимание особенностей и границ применимости Знание мат. статистики и теории вероятностей, линейной алгебры, математического анализа Опыт внедрения ML решений в бизнес процессы и доведение их до прома, последующий мониторинг Хорошее понимание методов машинного обучения с точки зрения математики и умение адаптировать их под конкретные задачи Опыт работы с Git Опыт работы с Linux Знание английского языка (чтение документации и статей) Будет плюсом: Знание Scala Знание одного из фреймворков DeepLearning (Keras/Tensorflow/PyTorch) Опыт автоматизации пайплайнов работы с данными (Airflow и др.), а также ML-пайплайнов (DVC и др.) Опыт работы с AutoML Условия Молодая и активная команда, состоящая преимущественно из DS и DE. Наличие мощного кластера и сред разработки, включая GPU Возможность поработать с действительно большими объемами данных и сделать значимый вклад в борьбу с мошенничеством в стране",,Сбер для экспертов,
16925,78043382,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","О проекте: В продуктовой команде Квант в рамках Газпром-Медиа Холдинга открыта новая позиция Data Scientist на активно растущее направления Adtech-продукта DSP Getintent. В портфеле компании множество data, martech и аналитических продуктов, в числе которых: DSP, CDP, комплекс решений для DOOH, обогащение CRM, O2O, аналитика и другие продукты. Наш стек технологий: Python, Java, Hadoop MR, Spark, Airflow, SQL (PostgreSQL, Clickhouse), NSQL (Aerospike). Все проекты работают на Linux, поэтому нужно иметь базовые представления о Linux, уметь пользоваться командной строкой и писать простые скрипты на bsh. Вам предстоит заниматься: Созданием и оптимизацией рекомендательной системы рекламы спользованием моделей для улучшения торговых стратегий Анализом работы предикторов в рекламных кампаниях нтеграцией построенных моделей в проект Работой с данными высоконагруженных сервисов (порядка 100 млн. событий в день) Автоматизацией процессов анализа Улучшением существующей микросервисной архитектуры системы процессинга данных Вы нам подходите, если есть: Отличное знание Python Знание математической анализа, алгоритмов, структур данных и теории вероятности Знание классических алгоритмов машинного обучения Знание основных библиотеки машинного обучения: xgboost, catboost, scipy, pandas и т.п. Знание методов обработки категориальных признаков меете опыт проведения A/B- тестов и анализа их результатов меете опыт работы с Hadoop, Spark, SQL, Airflow Опыт работы с Java будет преимуществом Мы предлагаем: Официальное трудоустройство, полностью белая заработная плата без задержек ДМС (включая стоматологию и госпитализацию) сразу после испытательного срока, возможность страхования членов семьи Доплаты по больничному листу Удаленная работа с возможностью выхода в офис по желанию Корпоративные программы кредитования и страхования Скидки на спорт, кино, языковые курсы",,ГПМ Партнер,"Москва, Киевская, улица Раевского, 4с1А"
16926,78440207,Data Scientist (Senior),з/п не указана,1–3 года,"Полная занятость,полный день","Чем нужно будет заниматься: Полный цикл разработки моделей для перформанс маркетинга Банка: 1) аналитика данных, аккумулируемых о лидах, проработка совместно с дата-инженерами и заказчиком состава данных, необходимых для построения моделей 2) обсуждение целевых метрик модели с бизнесом 3) построение моделей для системы сквозной аналитики в сплите каналов коммуникаций по банку, моделей для оптимизации рекламных затрат с сегментированием пользователей по группам, оценка вклада перфоманса в органические выдачи через сайт, определение оптимальную цепочки «касаний» по клиенту для привлечения 4) передача моделей на внедрение и сопровождение внедрения 5) подготовка пилота по эффективности модели, запуск А/Б тестирования 6) подведение результатов пилота, аналитика результатов промышленного внедрения 7) мониторинг модели и последующее перестроение. Требования: опыт построения моделей для перформанс маркетинга (Банки, Т-компании: Яндекс, Мэйл.ру и тп) уверенное знание статистики, мат анализа, теории вероятностей, линейной алгебры глубокое понимание ML алгоритмов (линейная регрессия, бустинг, и т.д.) и оптимизационных алгоритмов - Impala Hadoop - Python (pandas, sklearn, numpy, xgboost, matplotlib, flask and etc.)) - умение представлять результаты в понятном бизнесу виде (Excel/Powerpoint).","Python,SQL,MS PowerPoint,Анализ данных,Математическая статистика,ml",Газпромбанк,
16927,78466689,Senior/Team Lead Data Scientist,до 250 000 руб. на руки,3–6 лет,"Полная занятость,полный день","Для основного продукта Wallcraft (более 100 млн. загрузок, 6 млн активных пользователей в месяц) ищем Senior/Team lead Data Scientist, который сможет усилить нашу команду. Тебе предстоит: заниматься исследованием и имплементацией различных алгоритмов в рекомендательной системе проводить эксперименты и оптимизировать SOTA генеративных моделей организацией эффективной работы ML отдела адаптацией и совершенствованием существующих алгоритмов. пользуемый стэк: Python, Pytorch, BigQuery, Clickhouse, Postgres Мы рассчитываем, что у тебя есть опыт и знания для этой позиции. А именно: 3+ года опыта в роли Data Scientist (желателен опыт в мобильных приложениях) знание основ статистики опыт и понимание классических ML-алгоритмов и DL опыт реализации и применения моделей машинного обучения в продакшене уверенное владение Python (numpy, pandas, scipy, pytorch, sklearn). Мы предлагаем: полную занятость с гибким началом рабочего дня высокую заработную плату, бонусы за результат офис в центре Пензы с панорамным видом предоставление всей необходимой для работы техники сильную команду разработчиков, где можно серьезно прокачать свои скиллы.","ML,Mathematical Statistics,Statistics",Волкрафт,"Penza, Revolyutsionnaya Street, 71"
16928,78271635,Middle Data Scientist в центр маркетинговой аналитики (Big Data),з/п не указана,3–6 лет,"Полная занятость,полный день","Big Data МТС – место, где телеком данные превращаются в реально работающие IT-продукты. Мы создали и протестировали несколько десятков сервисов. Самые успешные из них уже стали частью экосистемы МТС. Например, МТС Маркетолог, рекомендации в KION (МТС ТВ), услуга “Кто звонит?” или Спам blacklist. Кого мы ищем? Middle Data Scientist в центр маркетинговой аналитики Описание продукта: В задачи нового Центра маркетинговой аналитики в Big Data входит помощь маркетинговым командам экосистемы принимать решения на основе больших данных и развитие, поддержка инструмента для оценки эффектов от инвестиций в маркетинг. Обязательно: от 2-х лет коммерческого опыта в построении ML- моделей знание Python на уровне уверенного пользователя, самостоятельное написание кода (не только встроенные библиотеки) знание основ математической статистики, дискретной математики знание методов визуального представление данных опыт работы с маркетологами Что предстоит делать? разрабатывать ML – модели, описывающие продукт изнутри собирать, очищать, обрабатывать и верифицировать данные совместно с внутренними командами МТС, используя внутренние инструменты МТС для сбора данных строить и презентовать рекомендации внутреннему заказчику на основе созданных моделей давать практические рекомендации внутреннему заказчику на основе эконометрических моделей искать продуктовые инсайты, основанные на данных проводить А/В тесты, решить задачи классификации Условия: каждый месяц - аванс и зарплата, дважды в год - премия. ДМС + стоматология, корпоративная связь, специальные предложения от партнеров и друзей МТС, отпуск 31 день в год. Выдаем 16 MacBook Pro или Dell на выбор. Есть ли обучение? Локальные конференции, митапы Корпоративный университет МТС и масштабная виртуальная библиотека А ещё мы регулярно обмениваемся опытом на совместных синках с лидами экспертизы Какой график? Гибкое начало рабочего дня в промежутке с 8 до 11. Есть возможность работать несколько дней вне офиса по договоренности с командой. Сколько этапов при отборе? Не более трех: HR + первое тех. интервью с лидом направления Тестовое задание/второе интервью - по необходимости Собеседование с PO и командой, выбор кандидатом проекта",,МТС,"Москва, Технопарк, проспект Андропова, 18к9"
16929,78347782,Data Analyst,до 4 000 USD на руки,1–3 года,"Полная занятость,полный день","At Neiro.ai we are developing entertainment products using generative AI Why us? We have a strong engineering team (ex-Samsung AI, Yandex, JetBrains, VK, PicsArt, VisionLabs) We have raised money from investors of Looksery and AI Factory (both acquired by Snap for $150M and $166M) We develop state-of-the-art generative AI (Lip-Sync, Text-to-speech, Voice Conversion, Dialogue Engine) and build unique entertainment products More than 500 000 000 video views on TikTok with content generated by our apps Your Responsibility Selection and development of a system for collecting, analyzing, and visualizing product metrics Create a plan for the integration of analytical systems with products Verify the correctness of analytical pipelines with developers Analyzing data from mobile analytics systems based on the user's behavior Own dashboards and maintain analytical pipelines Proactively propose product/marketing changes based on insights from data & setting up experiments Looking for anomalies/patterns/bugs in data and data collection pipelines Product metrics comparison with market benchmarks & competitors Key Qualifications: 1+ years of experience in Data Analyst / Product Analyst / Data Scientist roles Experience setting up mobile analytical systems SQL + Python Experience in A/B testing Excellent knowledge of statistics relevant to product analytics Intermediate analytical, verbal, and written English communication skills Fast learner. You should pick up and run with new workflows quickly Understanding of product metrics, unit economics, and principles of their optimization Proactivity and Autonomy It would be great to have Track record of collaborating with engineers on solving problems What do we offer The ability to understand how entertaining mobile products are built Direct work with C-level. Fast communication between UA/Mobile/Marketing teams. Our products are based on our own Generative AI (Computer Vision, Speech, NLP). Working with us is an excellent opportunity to understand how modern Machine Learning works. Opportunity to become Head of Analytics Salary & stock options to be discussed Remote work or Relocation package to Tbilisi Necessary equipment/software/education Our Process Test assignment HR interview  CEO Interview","Amplitude,Firebase,Google Analytics,Retention,Play Console,SQL,Python,Data Analysis,Английский — C1 — Продвинутый",Botan Investments,
16930,75656293,Data Scientist (Computer Vision),з/п не указана,3–6 лет,"Полная занятость,полный день",,,БиАйЭй-Технолоджиз,"Санкт-Петербург, Фрунзенская, Московский проспект, 94"
16931,78300370,Data Scientist – Senior/Chief,з/п не указана,более 6 лет,"Полная занятость,полный день","Вам предстоит участвовать в развитии система фрод-мониторинга Сбербанка, которая обеспечивает защиту клиентов банка во всех каналах обслуживания от мобильных приложений и покупок в интернет до визитов клиентов в офисы. Эта система признана одной из лучших в мире: 17th Annual 2021 Cyber Security Global Excellence Awards winners. Fraud Prevention GOLD WINNER - SberBank Anti-Fraud System Fraud Prevention Editor’s Choice – SberBank Наша команда принимает активное участие в развитии этой системы и сосредоточена на разработке и внедрении AI-моделей по выявлению мошенничества. Вам предоставляется уникальная возможность поработать с действительно большими объемами данных, широким перечнем передовых технологий и сделать значимый вклад в борьбу с мошенничеством в стране. Обязанности Руководство по нескольким направлениям, участие в формировании стратегии развития AI-инициатив, разработка целей и road map их достижений Обсуждение задач и методов их решения совместно с фрод-аналитиками и бизнес-заказчиками, формулирование гипотез и их проверка Взаимодействие с командами инженеров и участие в интеграции решений в промышленную эксплуатацию Разработка и развитие моделей и алгоритмов противодействия мошенничеству: скоринг транзакций для выявления фрода/«отмывания» средств, оценка риска сущностей (клиенты, устройства и пр.), анализ и выявление связей, транзакционных аномалий и пр. Мониторинг и регулярный контроль качества работающих в пром. моделей Анализ доступных источников данных и информации в них, оценка качества для решения задач Построение воспроизводимых и переиспользуемых решений для работы с данными и моделями Требования Успешные внедрения ML решений в бизнес-процессы и доведение их до прома, практический опыт их последующего мониторинга и развития Опыт руководством гурппы DS/DE от 3х человек Опыт автоматизации пайплайнов работы с данными (Airflow и др.), а также ML-пайплайнов (DVC и др.) Хорошие знания Python 3 Большой практический опыт работа с Pandas, SQL, Spark/PySpark, Hive и др. инструментами для анализа малых и больших данных Большой практический опыт использования ML библиотек и алгоритмов на Python (xgboost/lightgbm/catboost, sklearn, …), понимание особенностей и границ применимости Знание одного из фреймворков DeepLearning (Keras/Tensorflow/PyTorch) Знание мат. статистики и теории вероятностей, линейной алгебры, математического анализа Хорошее понимание методов машинного обучения с точки зрения математики и умение адаптировать их под конкретные задачи Опыт работы с Git Опыт работы с Linux Знание английского языка (чтение документации, статей, просмотр видео) Будет плюсом: Опыт работа в сфере противодействия мошенничеству/AML Знание Scala Опыт работы с AutoML-инстурментами Условия Молодая и активная команда, состоящая преимущественно из DS и DE. Наличие мощного кластера и сред разработки, включая GPU Возможность поработать с действительно большими объемами данных и сделать значимый вклад в борьбу с мошенничеством в стране",,Сбер для экспертов,
16932,78381736,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Контур — экосистема для бизнеса. Каждая четвертая компания в стране решает бизнес-задачи, используя наши сервисы. Мы автоматизируем документооборот, бухгалтерию и отчетность. Делаем эти процессы простыми и быстрыми, а сервисы — удобными для клиента.  Data Science в Контуре помогает оптимизировать внутренние процессы и добавляет ценности в продукты. Например, чат-бот Сирена экономит около 25% времени консультантов техподдержки в чатах, а технология распознавания речи обрабатывает тысячи лет записей в год. Мы постоянно следим за прогрессом в технологиях и разрабатываем новые методы и алгоритмы, чтобы сделать инновации доступными для использования в продуктах и процессах компании. В Центре искусственного интеллекта представлены разные роли: есть дата сайентисты, разработчики и аналитики данных, девопсы, QA-специалисты, системные аналитики, проджекты и продакт-менеджеры. Свое железо (V100/A100) и асессорская служба позволяют нам не ограничивать себя при работе с чувствительными данными, а также крутая инфраструктурная команда создает, улучшает и развивает инструменты MLOps на любой вкус от ресерча до прода. Мы ищем Senior Data Scientist в направление оптимизации процессов продаж и маркетинга. Нам нужен человек, который разовьет направление продаж и маркетинга с точки зрения машинного обучения: составит дорожную карту применения Data Science в процессах продаж согласует с бизнесом и приоритизирует сам проверит и доведет до продакшена гипотезы, и, как результат, повысит эффективность продаж и маркетинга. Примеры задач, которые уже решали Речевая аналитика (после ASR): оценка эффективности работы менеджеров по продажам на основании анализа текста звонков. Работа с конверсией: оценка вероятности оплаты клиентом счета по сделке по набору параметров. Что ожидаем от вас Опыт работы в аналогичной роли от двух лет. Опыт решения задач и понимание работы алгоритмов NLP и Classic ML. Умение общаться на языке заказчика, погружаться в продуктовый контекст. Умение работать в команде. Опыт декомпозиции, приоритизации больших задач. Опыт доведения задач до продакшена. Желательно иметь опыт доведения задачи от формулировки на языке бизнеса до прода (от начала до конца) работы с высокой неопределенностью: прокапывание проблематики, осознанный выбор решения. Технологии Python, SQL. GitLab. Docker, Kubernetes, AirFlow. Classic ML, языковые модели (BERT etc.). Мы предлагаем Зарплата зависит от ваших технических знаний и навыков. Пересматриваем ее два раза в год. Нам важно, чтобы вам было комфортно: непринципиально, где вы находитесь и во сколько начинаете рабочий день, главное – выполненные задачи. Умеем работать в команде, находясь в разных точках мира (Таллин, Ташкент, Астана, Лимассол, Екатеринбург, Москва и т. д.). Мы поддерживаем участие в конференциях, митапах и обучающих проектах. Наши деврелы помогут написать статью на Хабр, снять видео или подготовиться к выступлению на конференции. У нас сильное инженерное сообщество: регулярно проводим техническую конференцию КонфУР, обмениваемся опытом между командами, проводим дизайн-ревью с экспертами в разных технологиях. Всегда найдется, с кем посоветоваться. А еще у нас есть инженерный совет. Он придумывает и реализует проекты, которые улучшают жизнь инженеров в компании. Максимум горизонтальных связей в коллективе, чтобы быстрее договариваться и решать рабочие задачи. Присоединяйтесь :)","NLP,Machine Learning,Python,Data Science",Контур,
16933,75936388,Lead Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Сбер для экспертов,
16935,78272278,Senior Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Объединенное Кредитное Бюро – крупнейшее Бюро кредитных историй в России. Небольшой спойлер: мы не выдаем кредиты, мы храним и обрабатываем крупнейший в России массив данных о кредитных историях. Наш уникальный ресурс – самая большая база данных, в которой более 560 миллионов кредитных историй, и мы уделяем большое внимание не только количеству данных, но и качеству их обработки. Мы помогаем нашим частным клиентам контролировать свою кредитную историю и получать лучшие финансовые предложения, а компаниям – принимать взвешенные решения и оценивать риски на основе аналитики данных. Роль: Постоянное совершенствования аналитических механизмов, используемых в розничных продуктах ОКБ (создание и прокачка умных мозгов «под капотом» наших сервисов) Построение новых аналитических методов для внедрения в бизнес-процессы розничного бизнеса. Функции: Построение скоринговых моделей различной направленности, используя любые самые новые методы, без каких-либо ограничений со стороны регулирующих органов Разработка методов классификации пользователей по их интересу к определенным продуктам Разработка гипотез, грамотное формирование выборок для проверок этих гипотез, а потом составление итогового решения по данной гипотезе с использованием различных известных статистических тестов Разработка и улучшение текущих рекомендательных систем. Требования: Опыт работы не менее одного года в области аналитики и моделирования Уверенный уровень работы с реляционными СУБД и корпоративными хранилищами данных – SQL (Oracle, MSSQL, PostgreSQL) Уверенный уровень работы с Python для анализа данных и обучения предиктивных моделей Опыт разработки и внедрения регрессионных и классификационных алгоритмов обучения, знание их преимуществ, недостатков и ограничений Знание статистики и теории вероятности Опыт работы с git Опыт работы с PyCharm. Плюсами будут: Опыт разработки моделей в финансовом секторе или рекламном секторе Знание других алгоритмических языков для анализа данных Способность написать свои алгоритмы, а также оценивать их сложность Уметь писать Python-код, соответствующий PEP8 стандарту Успешное участие в соревнованиях по машинному обучению Профильное технической образование. Мы предлагаем: В ОКБ хранится ~600 млн. кредитных историй – это уникальная огромная база знаний о финансовых предпочтениях, финансовой жизни людей на протяжении последних 18 лет, так что будет на чём строить модели и статистические решения любой направленности Возможность создать любой аналитический инструмент с минимальной документацией и бюрократией Уникальный опыт по разработке нестандартных моделей с учётом пользовательского опыта и ожиданий Модели не уходят «в стол», а результат работы виден всем сразу в промышленной среде Дружный профессиональный коллектив, который заточен под решения проблем «здесь и сейчас» Достойную твоего профессионального уровня зарплату и годовой бонус Современную технику для комфортной работы Заботу о здоровье: оформим полис ДМС со стоматологией, дадим 3 дополнительных дня к отпуску, компенсируем затраты на абонемент в зал По-настоящему дружескую атмосферу: поддерживаем, когда вы приводите своих друзей, и выплачиваем реферальный бонус.","Python,SQL,PostgreSQL,Анализ данных,ORACLE,Git",ОКБ,"Москва, Павелецкая, Павелецкая, Таганская, Шлюзовая набережная, 4"
16936,78128781,Middle Data scientist (Промо Прогноз),з/п не указана,1–3 года,"Полная занятость,удаленная работа","Компания MagnitTech— это опытная команда IT, которая создает экосистему современных цифровых продуктов Магнит: доставка продуктов, лекарств, инструменты для обеспечения лояльности клиентов, специальные проекты и продукты для внутренних нужд. Чем предстоит заниматься: Работать в команде с высокой экспертизой в прогнозировании AI-алгоритмами (статистические модели, ML алгоритмы, Deep Learning) Развивать прод-системы прогнозирования промо спроса Разрабатывать алгоритмы учета каннибализации спроса Выявлять аномалий во временных рядах Кластеризировать объекты и предсказывать редкие события: Разрабатывать адаптивные подходы. Стек технологий: Python, Spark, Airflow, Hive, Hadoop, Linux. Мы ожидаем: Опыт работы с распределенными системами (HADOOP, YC DataProc, Azure) посредством Spark Опыт работы с данными посредством SQL (Teradata, MS SQL, Postgres, Oracle) Опыт решения практических задач прогнозирования Опыт настройки гиперпараметров в сложных алгоритмах Опыт работы с временными рядами Знание математической статистики и систем контроля версий кода Знание основных моделей и принципов машинного обучения Понимание устройства нейросетей. Мы предлагаем: Работу в максимально уютном и современном офисе в Москве или в Краснодаре, или удаленно График работы 5/2 с гибким началом Конкурентоспособную заработную плату Мы любим учиться! А компания всегда поддерживает и способствует профессиональному развитию специалиста Корпоративную технику для успешной и удобной работы Дружескую атмосферу и поддержку команды профессиональных и активных коллег Корпоративные скидки и программы лояльности от наших партнеров.","Python,SQL,Математическая статистика,Spark,Big Data,Hadoop,Machine Learning","МАГНТ, Розничная сеть",
16937,73595622,Data scientist (Антиспам),з/п не указана,3–6 лет,"Полная занятость,полный день","Одноклассники — это крупнейшая развлекательная социальная сеть в России. Место, где можно всегда оставаться на связи со своими друзьями и близкими, выкладывать и редактировать фотографии, слушать любимую музыку, смотреть самые популярные видео и многое другое! На данный момент, мы в поиске специалиста по машинному обучению, который возьмет на себя computer vision направление в нескольких сервисах OK.RU, в задачи которых входит обеспечение безопасности портала. В команде мы в основном практикуем end-to-end решения задач, поэтому предполагается, что кандидат не боится ""испачкать руки"" в продакшен коде. Наш стек: Языки: Python, Java, Scala Технологии которые часто используем в работе: PyTorch, DVC, MlFlow, Hadoop,Spark, Airflow, Kafka. Примеры того, чем мы занимаемся: Определение объектов на фотографии (предметы одежды, окружение) Детекция и распознавание жестов пользователей по фото/видео для восстановления профиля Определение подлинности фотографии Задачи OCR Автоматическая генерация изображений, перенос стилей Мы ожидаем, что ты: Обладаешь уверенными навыками программирования на Python и хотя бы в одном статически типизированном языке меешь опыт с DL библиотеками (Pytorch/TF) меешь хорошие теоретические знания классического ML Следишь за SOTA в CV (задачи сегментации/детекции/классификации и тд) Знаешь методы классического CV Работаешь с современным BigData стеком (Hadoop/Spark/Airflow). Будет плюсом: Опыт оптимизации DL решений на инференс Уметь прочитать, а затем воспроизвести в коде статью Опыт промышленной разработки на Java/Scala/Python Опыт разработки промышленных AI сервисов Опыт применения DevOps практик в контексте разработки ML моделей Опыт применения ML в cybersecurity и общее представление об этой сфере. Условия: сложные и интересные задачи: высоконагруженные быстрорастущие сервисы, которые задают уровень для конкурентов качеством и технологиями оборудование: мощное железо, десятки петабайт данных, GPU-кластера и облачный инструментарий команда: с нами работают професcионалы экстра класса, каждый из которых может поделиться своей экспертизой профессиональное развитие: прямо в офисе мы организуем митапы, конференции, семинары и тренинги, куда открыт доступ каждому сотруднику, а также регулярно посещаем лучшие мировые конференции новый опыт: лучшие сотрудники преподают в наших образовательных проектах, выступают на российских и международных конференциях офис в 5 минутах от метро, крытый паркинг для сотрудников, велопарковка возможность работать в гибридном формате (как удаленно, так и из офиса) спорт: компания компенсирует затраты на спортивные активности — занятия в фитнес-клубе, индивидуальные тренировки, участия в соревнованиях регулярно пересматриваемая зарплата, годовые бонусы, социальный пакет с первого дня (ДМС, английский язык).","Python,PyTorch,Spark,Hadoop,Java,SCALA,Машинное обучение","VK, Одноклассники","Санкт-Петербург, Херсонская улица, 12-14"
16938,78447935,Senior Data Scientist (оценка моделей),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","В команду валидации моделей и рейтинговых систем ищем SENIOR DATA SCIENTIST с сильной математической базой и отличным знанием статистики и методов Machine Learning. Для нас важно, чтобы наш будущий коллега умел сохранять спокойствие и объективно аргументировать свою точку зрения перед внешними и внутренними контрагентами. ПРО БАНК: Росбанк – частный универсальный банк, работающий на российском рынке с 1993 года. Росбанк обслуживает порядка 1,5 млн активных розничных клиентов, около 83 тысяч активных клиентов малого бизнеса и около 10 тысяч активных клиентов корпоративного бизнеса более чем в 60 регионах России. Росбанк входит в ТОП 5 самых надежных российских банков по версии журнала Forbes и включен Банком России в число 13 системно-значимых кредитных организаций России. Наш банк имеет наивысшие кредитные рейтинги российских и международных рейтинговых агентств. ПРО КОМАНДУ: Наша команда занимается анализом практически всех моделей банка для проверки их качества, поиска и выявлением областей риска этих моделей, информирует и консультирует по результатам владельцев моделей и CRO. У нас большое разнообразие моделей для анализа, возможности участия в крупном проекте по выстраиванию жизненного цикла моделей в банке. Сейчас в нашей команде 5 сотрудников – все занимаются валидацией моделей, ищем коллегу для расширения команды. Наша цель – улучшать качество моделей банка, автоматизировать рутинные задачи, уменьшать модельный риск. ПРСОЕДНВШСЬ К НАМ ВЫ БУДЕТЕ: Валидировать, оценивать качество ML-моделей (benchmark) моделей Банка Оценивать их бизнес-применение Оформлять результаты валидации в отчет и предоставлять их владельцам моделей. МЫ ЖДЕМ ОТ ВАС: Опыта моделирования/проведения оценки качества моделей от 3х лет Хороших знаний статистики и методов Machine Learning Опыта работы с большими данными Умения программировать на Python и разбираться в чужом коде. СО СВОЕЙ СТОРОНЫ МЫ ПРЕДЛАГАЕМ: Стабильный и прозрачный доход: зарплата и премии по результатам работы Комбинированный (офис/дом) или полностью дистанционный формат работы (на территории РФ) Личностное развитие и рост: корпоративная электронная библиотека Альпина, возможность прохождения бесплатного обучения и тренингов, участия в регулярных встречах корпоративных клубов и скидки на курсы онлайн школ Программа корпоративных скидок и привилегий Primezone: развлечение, отдых, товары и услуги, обучение Сообщества по интересам сотрудников Скидки и привилегии по кредитам, ипотека на льготных условиях, льготные условия обслуживания и т.п. Забота о здоровье сотрудников: программа ДМС, включая стоматологию и страхование при выезде за рубеж, корпоративные спортивные команды и скидки на абонементы в фитнес-клубы Дополнительная оплата за больничный лист: доплата сверх пособия по болезни до оклада (до 5 рабочих дней в год) Программа волонтерства и благотворительности.","Python,Machine Learning",«РОСБАНК»,
16939,78381741,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,полный день","Контур — экосистема для бизнеса. Каждая четвертая компания в стране решает бизнес-задачи, используя наши сервисы. Мы автоматизируем документооборот, бухгалтерию и отчетность. Делаем эти процессы простыми и быстрыми, а сервисы — удобными для клиента.  Data Science в Контуре помогает оптимизировать внутренние процессы и добавляет ценности в продукты. Например, чат-бот Сирена экономит около 25% времени консультантов техподдержки в чатах, а технология распознавания речи обрабатывает тысячи лет записей в год. Мы постоянно следим за прогрессом в технологиях и разрабатываем новые методы и алгоритмы, чтобы сделать инновации доступными для использования в продуктах и процессах компании. В Центре искусственного интеллекта представлены разные роли: есть дата сайентисты, разработчики и аналитики данных, девопсы, QA-специалисты, системные аналитики, проджекты и продакт-менеджеры. Свое железо (V100/A100) и асессорская служба позволяют нам не ограничивать себя при работе с чувствительными данными, а также крутая инфраструктурная команда создает, улучшает и развивает инструменты MLOps на любой вкус от ресерча до прода. Мы ищем Senior Data Scientist в направление оптимизации процессов продаж и маркетинга. Нам нужен человек, который разовьет направление продаж и маркетинга с точки зрения машинного обучения: составит дорожную карту применения Data Science в процессах продаж согласует с бизнесом и приоритизирует сам проверит и доведет до продакшена гипотезы, и, как результат, повысит эффективность продаж и маркетинга. Примеры задач, которые уже решали Речевая аналитика (после ASR): оценка эффективности работы менеджеров по продажам на основании анализа текста звонков. Работа с конверсией: оценка вероятности оплаты клиентом счета по сделке по набору параметров. Что ожидаем от вас Опыт работы в аналогичной роли от двух лет. Опыт решения задач и понимание работы алгоритмов NLP и Classic ML. Умение общаться на языке заказчика, погружаться в продуктовый контекст. Умение работать в команде. Опыт декомпозиции, приоритизации больших задач. Опыт доведения задач до продакшена. Желательно иметь опыт доведения задачи от формулировки на языке бизнеса до прода (от начала до конца) работы с высокой неопределенностью: прокапывание проблематики, осознанный выбор решения. Технологии Python, SQL. GitLab. Docker, Kubernetes, AirFlow. Classic ML, языковые модели (BERT etc.). Мы предлагаем Зарплата зависит от ваших технических знаний и навыков. Пересматриваем ее два раза в год. Нам важно, чтобы вам было комфортно: непринципиально, где вы находитесь и во сколько начинаете рабочий день, главное – выполненные задачи. Умеем работать в команде, находясь в разных точках мира (Таллин, Ташкент, Астана, Лимассол, Екатеринбург, Москва и т. д.). Мы поддерживаем участие в конференциях, митапах и обучающих проектах. Наши деврелы помогут написать статью на Хабр, снять видео или подготовиться к выступлению на конференции. У нас сильное инженерное сообщество: регулярно проводим техническую конференцию КонфУР, обмениваемся опытом между командами, проводим дизайн-ревью с экспертами в разных технологиях. Всегда найдется, с кем посоветоваться. А еще у нас есть инженерный совет. Он придумывает и реализует проекты, которые улучшают жизнь инженеров в компании. Максимум горизонтальных связей в коллективе, чтобы быстрее договариваться и решать рабочие задачи. Присоединяйтесь :)","NLP,Machine Learning,Python,Data Science",Контур,
16940,76655978,Senior / Lead Data scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы предлагаем стать частью сильной Т-команды, где ты сможешь применять опыт Data science и решать пул задач, у которых нет тривиальных решений. Условия: Удалённая работа по ТК с гибким утром Возможность оплаты курсов и конференций Автозапчасти со скидкой до 30% ДМС после испытательного срока Поддержку инициатив и возможность обсудить реализацию любых идей Чем предстоит заниматься: Создание моделей машинного обучения связанных с оптимизацией запасов, клиентским сервисом, прогнозом спроса, ценообразованием Ожидания от твоего опыта: Опыт работы в Data science от 3-х лет Знание технологий: sql, python, lightgbm, docker, kubernetes, airflow Опыт работы с алгоритмами классического машинного обучения Постановка гипотез, дизайн и оценка экспериментов, презентация результатов Будет плюсом: Опыт участия в полном цикле проекта машинного обучения (от постановки задачи до вывода в продакшн) Опыт вывода модели в эксплуатацию.","Python,SQL,Машинное обучение",ПартКом,
16941,78103204,ML engineer/Data engineer,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Сбер для экспертов,
16942,78141390,Python Developer/Data Engineer (Samokat.tech),з/п не указана,3–6 лет,"Полная занятость,удаленная работа",,,Самокат (ООО Умное пространство),
16943,78375052,Data engineer,з/п не указана,1–3 года,"Полная занятость,удаленная работа","КОМПАНЯ «АЙ-ТЕКО» - ведущий российский системный интегратор и поставщик информационных технологий для корпоративных заказчиков. Активно действует на рынке IT России с 1997 года, входит в ТОП-400 крупнейших российских компаний, ТОП-10 крупнейших IT-компаний России. В связи с активным развитием внутренних проектов в компании открыта вакансия DATA ENGINEER ЗАДАЧ: • Анализ требований к витринам данных (взаимодействие с владельцем продукта, BI-разработчиками, data scientist-ами) • Поиск и исследование источников данных для последующей интеграции • Оценка пригодности, качества исходных данных • Разработка ETL процессов на Spark • Оркестрация ETL процессов в Airflow • Проектирование баз данных • Создание конвейеров данных NiFi ТРЕБОВАНЯ: • Проработал от 1 года и более в таких областях как: коммуникационные технологии, безопасность, маркетинг и продажи, финансы. • Знает SQL на высоком уровне (в т. ч. DDL, табличные выражения, оконные функции) • Работал с Hive, PostgreSQL • Умеет разрабатывать ETL процессы Spark на Scala (потоковая обработка как преимущество) • Пользовался AirFlow или другими оркестраторами – Oozie, Luigi, ну или cron • Может что-то написать на Python – в объеме чтобы пользоваться AirFlow или еще круче • меет опыт потоковой разработки конвейеров данных в NiFi или Flink • нтересуется Flink, пробовал применять его в проектах • Умеет проектировать базы данных (знает Data Vault 2.0 например) • Понимает принципы работы реляционных СУБД и HDFS • меет представление о колоночных и NoSQL СУБД • Понимает подходы к работе с качеством данных • Применяет системный подход к работе, думает о конечной бизнес-задаче, мыслит логически, уделяет внимание деталям ТРЕБОВАНЯ К ЗНАНЮ СТЕКА ТЕХНОЛОГЙ: • Экосистема Hadoop – HDFS, YARN, Hive, HBase • ETL-процессы – Spark (Scala) • Потоковая обработка – NiFi, Flink • Брокер сообщений – Kafka • Оркестрация ETL процессов – Airflow • СУБД – PostgreSQL, Greenplum, Aerospike, Oracle, SQL Server • CI/CD – GitLab НАШ УСЛОВЯ: • Работа в стабильной компании, белая заработная плата • График работы 5/2• Формат работы: удаленка • Социальный пакет (медицинская страховка, включая стоматологию) • Корпоративный спорт: скидки на посещение фитнес-клубов, футбольная и волейбольная секции • Работа в команде, использующей гибкий подход к разработке • Оформление в соответствии с ТК РФ с первого дня работы • Работа в развивающемся IT-проекте с командой специалистов высокого уровня, возможность развития и обмена опытом, корпоративное обучение.","HDFS,YARN,Hive,HBase,GitLab,PostgreSQL,Kafka,Airflow,NiFi,Flink",Ц АЙ-ТЕКО,
16945,78125945,Senior Data Scientist (Промо Прогноз),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Компания MagnitTech— это опытная команда IT, которая создает экосистему современных цифровых продуктов Магнит: доставка продуктов, лекарств, инструменты для обеспечения лояльности клиентов, специальные проекты и продукты для внутренних нужд. Чем предстоит заниматься: Работать в команде с высокой экспертизой в прогнозировании AI-алгоритмами (статистические модели, ML алгоритмы, Deep Learning): Лидировать команды из 4-6 человек, проводить codereview, Unit тесты, постановка решений на бой Развивать прод-системы прогнозирования промо спроса до уровня Торговая точка - Товарная позиция Разрабатывать адаптивные алгоритмы с учетом особенностей товарных категорий и форматов сети Магнит Разрабатывать алгоритмы учета каннибализации спроса Выявлять аномалии во временных рядах. Стек технологий: Python, Spark, Airflow, Hive, Hadoop, Linux. Мы ожидаем: Опыт лидирования команды из 3-4 человек, наставничество Опыт работы с распределенными системами (HADOOP, Azure, YC DataProc) посредством Spark Опыт работы с данными посредством SQL (Teradata, MS SQL, Postgres, Oracle) Опыт создания mission critical систем Опыт решения практических задач прогнозирования Опыт работы с временными рядами Знание математической статистики Знание систем контроля версий кода Понимание устройства нейросетей. Мы предлагаем: Работу в максимально уютном и современном офисе в Москве или в Краснодаре, или удаленно График работы 5/2 с гибким началом Конкурентоспособную заработную плату Мы любим учиться! А компания всегда поддерживает и способствует профессиональному развитию специалиста Корпоративную технику для успешной и удобной работы Дружескую атмосферу и поддержку команды профессиональных и активных коллег Корпоративные скидки и программы лояльности от наших партнеров.","SQL,Hadoop,Spark,Python,Airflow,Linux","МАГНТ, Розничная сеть",
16946,78826330,Ментор по курсу Data Scientist,от 10 000 000 сум на руки,1–3 года,"Полная занятость,гибкий график","Обязанности: Запись онлайн уроков (гибкий график) Проведение открытых онлайн вебинаров Требования: Грамотная речь. Знание любого языка (узбекский, русский ,английский) Умение чётко формулировать свои мысль . Ответственность Пунктуальность Умение интересно преподнести материал Условия: Гибкий график работы. Офис в удобной локации Молодой и дружный коллектив Своевременная выплата заработной платы",,AIF-EDU,"Ташкент, улица Ахмада Дониша, 20"
16947,79144555,Data engineer,з/п не указана,1–3 года,"Полная занятость,полный день","В Центр поддержки и сопровождения инструментов мониторинга защиты объектов открылся набор java разработчиков. Мы ждем именно твой отклик! Обязанности Анализ исходных данных в различных системах и форматах для решения бизнес-задач (оценка структуры, качества, полноты и применимости данных) Загрузка, очистка и трансформация больших объемов данных из различных источников в базу данных Проектирование и разработка аналитических витрин данных Мониторинг и оптимизация процессов загрузки, преобразования данных и сборки витрин Контроль качества загружаемых данных, разработка автоматизированных инструментов для оценки качества данных Разработка, поддержка и оптимизация инфраструктуры и внутренних сервисов для обработки больших объемов данных Разработка инструментов для автоматизации рутинных задач, связанных с обработкой данных Разработка и поддержка сопроводительной документации и спецификаций данных, развитие и поддержка базы знаний по вопросам работы с данными Предоставление экспертной поддержки внутренним потребителям (data analysts, data scientists) по вопросам, связанным с использованием данных. Требования Опыт работы в качестве Data Engineer / Data Analyst / ETL Developer Знание SQL на продвинутом уровне (аналитические функции, подзапросы, хранимые процедуры, оптимизация производительности) Опыт работы с большими объемами данных Знание основных понятий и концепций из области Data Warehouse Желателен опыт разработки витрин данных Опыт работы со стеком технологий Big Data является большим преимуществом Опыт работы по Agile (SCRUM, Kanban, и т.д.) приветствуется. Условия месторасположения офиса: ул. Академика Сахарова 2а График работы: 8:00-17:00 работа в крупнейшем банке России трудоустройство согласно ТК РФ регулярное корпоративное обучение ДМС, страхование от несчастных случаев и тяжелых заболеваний материальная помощь и социальная поддержка, корпоративная пенсионная программа льготные условия кредитования яркая и насыщенная корпоративная жизнь.",,Сбер для экспертов,
16948,79263907,Senior Data Scientist Управления портфельного анализа кредитных рисков,з/п не указана,3–6 лет,"Полная занятость,полный день","Крупнейший универсальный коммерческий банк Казахстана приглашает тебя в свою команду. Мы ищем талантливых людей, готовых развиваться и расти вместе с нами. Группа Halyk – это более 17 000 сотрудников в Казахстане и ряде других стран. Наш банк успешно работает на благо своих клиентов уже более 95 лет. Мы оказываем услуги во всех сегментах финансового рынка: банковском, страховом, ценных бумаг, лизинговом. Что ты будешь делать: Валидация скорринговых моделей Применение скорринговых моделей для расчета провизий (PD / LGD) Формирование аналитической отчетности по кредитным рискам. Что мы ждем от соискателя: Наличие степени магистра (или эквивалента) в областях статистики, математики, науки о данных или связанной с ней количественной области Наличие более 4 лет опыта разработки и проверки моделей в финансовых услугах, работы с инструментами обработки и анализа данных и статистическими инструментами, в сфере статистического анализа, обработки больших объемов данных и анализа тенденций. Мы предлагаем: Уникальный опыт, интересные задачи и проекты Применение инновационных технологий в работе Заинтересовала вакансия? Откликайся! Обучение и тренинги Конкурентная оплата труда в соответствии с международными стандартами.","Умение работать с большими объемами данных,Работа с большим объемом информации,Статистический анализ,Расчет провизий,скоринговая модель",Народный банк Казахстана,"Алматы, проспект Аль-Фараби, 40"
16953,78854296,Data Engineer (удалённо),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Компания «АЙ-ТЕКО» — ведущий российский системный интегратор и поставщик информационных технологий для корпоративных заказчиков. Активно действует на рынке IT России с 1997 года, входит в ТОП-400 крупнейших российских компаний, ТОП-10 крупнейших IT-компаний России. В СВЯЗ С АКТВНЫМ РАЗВТЕМ ВНУТРЕННХ ПРОЕКТОВ В КОМПАН ОТКРЫТА ВАКАНСЯ DATA ENGINEER. ТРЕБОВАНЯ: Опыт работы от 1 года и более в таких областях как: коммуникационные технологии, безопасность, маркетинг и продажи, финансы Знание SQL на высоком уровне (в т. ч. DDL, табличные выражения, оконные функции)  Опыт работы с Hive, PostgreSQL  Опыт разработки ETL процессов Spark на Scala (потоковая обработка как преимущество) Опыт использования AirFlow или другими оркестраторами – Oozie, Luigi, ну или cron Знание Python – в объеме чтобы пользоваться AirFlow или еще круче Опыт потоковой разработки конвейеров данных в NiFi или Flink Опыт проектирования базы данных (знает Data Vault 2.0 например) Понимание принципов работы реляционных СУБД и HDFS меет представление о колоночных и NoSQL СУБД нтересуется Flink, пробовал применять его в проектах. ЗАДАЧ: Анализ требований к витринам данных (взаимодействие с владельцем продукта, BI-разработчиками, data scientist-ами) Поиск и исследование источников данных для последующей интеграции Оценка пригодности, качества исходных данных Разработка ETL процессов на Spark Оркестрация ETL процессов в Airflow Проектирование баз данных Создание конвейеров данных NiFi . УСЛОВЯ: Работа в аккредитованной Т-компании Оформление в соответствии с ТК РФ с первого дня работы Возможность работать в удаленном формате Мы заботимся о здоровье наших сотрудников: предоставляем скидки на посещение фитнес-клубов, ДМС с первого месяца работы (включая стоматологию) Работа в команде, использующей гибкий подход к разработке Работа в развивающемся IT-проекте с командой специалистов высокого уровня, возможность развития и обмена опытом.","SQL,NiFi,Spark,Python,Data Vault 2.0,ETL,Airflow,SCALA,PostgreSQL",Ц АЙ-ТЕКО,
16954,78062870,GCP Data Architect/Team Lead,от 5 000 до 6 000 USD на руки,более 6 лет,"Полная занятость,полный день",,,E-book Applications,
16955,79018174,Manager / Senior Manager to Data & Analytics department,з/п не указана,более 6 лет,"Полная занятость,полный день","About the Data & Analytics Department PwC is one of the first Big-4 companies in Kazakhstan to invest in a dedicated Data & Analytics department. At the moment, the team consists of almost 20 professionals with different backgrounds and work experiences. Main directions of the department are: Decision Intelligence, Business Intelligence Engineering, Digital Analytics, Data Governance, and Research & Analytics. Data & Analytics team has many common projects with PwC Strategy & Operations Consulting, ESG Consulting, and Digital Consulting teams. The team operates in Kazakhstan, Uzbekistan, Kyrgyzstan, Azerbaijan, Georgia, and Mongolia. PwC Kazakhstan is looking for a Manager / Senior Manager to join our Data & Analytics department. The main focus will be on: business development, people management, project management, and sales. Requirements: 5+ years of experience in the Data & Analytics field with at least two years of experience in a managerial or leadership role to lead a team of analysts and data scientists, set goals, and establish priorities Strong understanding of database technologies, data management, data visualization, and data warehousing. Experience with SQL and / or other relevant programming languages Familiarity with ETL tools and business intelligence platforms such as Tableau, Power BI, or QlikView. Experience with cloud technologies, such as Microsoft Azure or Google Cloud Platform, would be a plus Experience in managing multiple projects, setting timelines and budgets, and overseeing project execution to ensure the timely delivery of results Excellent communication skills to present complex data analysis to non-technical stakeholders, build relationships with cross-functional teams, and communicate effectively with a client’s senior executives A deep understanding of the business and its goals, with the ability to translate business needs into data-driven solutions Familiarity with industry-specific data trends, regulations, and compliance requirements, as well as the ability to stay up-to-date with emerging data technologies and tools","SQL,Tableau,Big Data,Power BI,QlikView",PricewaterhouseCoopers,"город Алматы, проспект Аль-Фараби, 34"
16956,78902782,Data Engineer/Analyst DWH (Управление валидации),з/п не указана,3–6 лет,"Полная занятость,полный день","Команда Центра подготовки данных и отчетности Управления валидации Блока риски занимается сбором и проверкой качества данных, используемых при разработке моделей машинного обучения, выступает в качестве заказчика при разработке промышленных витрин данных, используемых в регулярных процессах валидации моделей, обеспечивает единовременными выгрузками данных по ad-hoc запросам. Мы ищем в команду Data-инженера по направлению работы с корпоративным сегментом клиентов. Обязанности Взаимодействие с разработчиками моделей (Data Scientists) и витрин с целью сбора данных Аналитика используемых источников (промышленные, пользовательские и т.д.), данных в этих источниках, алгоритмов сбора и обработки на соответствие сопроводительной документации (целям и задачам моделирования) Верификация корректности сбора данных Подготовка актуальных наборов данных для проведения валидации моделей и автоматизация их сбора для целей дальнейшего мониторинга Выработка рекомендаций по сбору и обогащению данных, подготовка требований на разработку/доработку витрин с целью автоматизации процесса. Навыки: Знание SQL на хорошем уровне Умение читать и разбираться в чужом коде Работа со сложными SQL запросами и большими объемами данных Знакомство с Python Знакомство с технологией Hadoop, Spark. Требования Высшее образование (техническое/математическое) Навыки коммуникации и взаимодействия с контрагентами Понимание принципов работы БД, построения кода Навыки работы с etl-инструментами приветствуются Опыт написания ТЗ на разработку витрин приветствуется Аналитический склад ума, системное мышление, командная работа Умение работать в режиме многозадачности. Условия График работы: 5/2, сокращенный рабочий день в пятницу Конкурентные условия труда, достойная заработная плата (оклад + годовая премии) ДМС для сотрудников и родственников Профессиональное обучение, семинары, тренинги, конференции Льготные условия по кредитам Сбербанка, а также скидки от партнеров Сбербанка Большой и комфортный офис со спортзалом.",,Сбер для экспертов,
16957,78843112,Data Engineer направления разработки витрин данных,з/п не указана,1–3 года,"Полная занятость,полный день","Data Engineer Вместе с нами ты будешь: Заниматься проектированием и разработкой витрин данных для анализа и моделирования Заниматься мониторингом и оптимизацией процессов сборки витрин Заниматься загрузкой и обработкой данных из различных источников Заниматься поддержкой и развитием базы знаний Предоставлять экспертную поддержку внутренним потребителям(data analysts,data scientists) Какие знания и навыки для нас важны: Знание SQL Хорошее знание устройства Hadoop,Spark,Hive/Impala Опыт разработки на Python/Scala/Java Понимание основных концепций DWH Понимание базовых команд Git и основных приципов работы Будет плюсом: Опыт работы с банковскими данными Опыт работы с различными СУБД в роли разработчика/аналитика витрин данных Опыт работы с Airflow","Hive,Hadoop,Git,Python,SCALA","ннотех, Группа компаний",
16958,78889781,Data Engineer (relocation to Germany),з/п не указана,более 6 лет,"Полная занятость,полный день","Our partner, a well-known German online platform, is looking for a Data Engineer Advanced Analytics (m/f/d) to resolve technical data issues, and optimize their data architecture. This is a full-time position in Dusseldorf metropolitan area, Germany (partial work from home is possible). Relocation from abroad is possible. We will take care of your visa application and relocation to Germany. Your family members (spouse, children under 18 years old) will get a visa as well. About the company: In the team, everything revolves around one topic: creating data-based added value for the company and its customers around the world In international projects, they develop customized data & analytics solutions for their business and IT teams They support the entire organization in making important decisions based on reliable data and state-of-the-art analyses Your responsibilities: Design, develop, optimize and maintain squad-specific data architecture and pipelines that adhere to defined ETL and data lake principles Prepare, coordinate and organize the handover of data architecture and pipeline artifacts to the platform team Resolve technical data issues Participate in building data products for Analytics and Data Scientists / Machine Learning Engineers to improve their productivity Mentor data and analytics professionals on data standards and practices Propose and contribute to training and improvement plans regarding analytical data engineering skills, evaluation of new tools for analytical data engineering or data science Educating in machine learning, data science, computer vision, artificial intelligence, statistics, or applied mathematics Required qualifications: At least a Bachelor’s degree in Information Technologies or a related field Experience in data engineering and solutions for cloud computing services in the area of data and analytics Knowledge of SQL and data analytics and experience with at least one programming language (e.g., Python, Scala) Experience in database development and data modeling, ideally with Databricks/Spark and SQL Server DB Knowledge of relational, NoSQL, and cloud database technologies Would be a plus: experience with MS Azure tools such as Data Factory, Event Hub, Databricks, ML, Synapse, Purview. Knowledge of data and analytics, e.g. dimensional modeling, ETL, reporting tools, data governance, data warehousing, and structured and unstructured data Excellent English (at least C1 level) Benefits: Mobile working within Germany incl. equipment and flexible working hours State-of-the-art technologies Attractive remuneration Vacation and Christmas bonus Future-oriented training & development Modular onboarding and an onboarding buddy Health perks Relocation package If you are interested in joining the team as Data Engineer, do not hesitate to apply for the job and send us your CV","SAP MM,Ariba,Procurement,Logistics,SAP MDG,SAP S/4HANA,English,Английский — C1 — Продвинутый",Transparent Hiring,
16959,78769342,Data Analyst,з/п не указана,1–3 года,"Полная занятость,полный день","Команда создает платформу данных для розничного бизнеса, обеспечивающую сбор и обработку данных о клиентах-физических лицах для запуска AI-решений, комплексной аналитики и формирования максимально персонализированных предложений по продуктам экосистемы Сбера. Обязанности · Поиск корневых причин некорректной работы витрин данных · Проверка качества данных в источниках и витринах · Разработка и применение методов по восстановлению консистентности и актуальности витрин данных · Формирование требований к командам разработки для оптимизации/улучшения сервиса сопровождения витрин данных · Предоставление экспертной поддержки внутренним потребителям (data analysts, data scientists) по вопросам, связанным с использованием данных Требования · Не менее 1 года работы в качестве Data Engineer / Data Analyst / ETL Developer · Знание SQL на продвинутом уровне (аналитические функции, подзапросы, хранимые процедуры, оптимизация производительности), · Умение разбираться в чужом коде · Навыки работы с БД Hadoop или Greenplum. · Опыт подготовки документации: функциональных и бизнес требований, модели данных, сопроводительной документации при прохождении тестовых и приемо-сдаточных испытаний, спецификаций на загрузку данных, расчет сайзингов · Навыки декомпозиции бизнес-требований, формирования ТЗ для разработчиков · Опыт работы с инструментами Atlassian Confluence, Jira, Nexus Приветствуем, но не ожидаем от кандидата: · Знание банковского бизнеса · Apache Flink, HBase, Scala, Python, Apache Airflow, Java · Опыт работы по Agile (SCRUM, Kanban, и т.д.) Условия · Профессиональное обучение, семинары, тренинги, конференции · Годовые премии · ДМС, сниженные ставки по кредитованию, программы лояльности для сотрудников · Самые инновационные, амбициозные проекты и задачи · Комфортный офис с просторными оупенспейсами, лаунж зонами, кафе на Кутузовском. · Дисконт-программа от множества компаний партнеров.",,Сбер для экспертов,
16961,72127423,Senior data scientist (разработка моделей для казначейства и рыночных рисков),з/п не указана,более 6 лет,"Полная занятость,полный день","Обязанности: выстраивание эффективных партнерских взаимоотношений с внутренними клиентами подразделения самостоятельное ведение проектов по разработке моделей: управление командой проекта, планирование, постановка задач, оценка сроков задач, контроль качества результатов, коммуникация результатов заказчику поддержка и обучение коллег в команде разработка поведенческих моделей досрочного погашения срочных продуктов Банка и моделей динамики продуктов неопределенной срочности для прогноза метрик структурных балансовых рисков Банка разработка прогностических моделей эластичности спроса на банковские продукты по цене и другим факторам для управления структурой баланса Банка, ликвидностью и ценовой политики по продуктам разработка финансовых моделей для ценообразования продуктов Банка с учетом риска и анализа финансовой рентабельности продуктовых предложений Банка прикладной анализ данных и разработка моделей по другим направлениям для повышения эффективности бизнес-процессов. Требования: высшее образование (желательно техническое) опыт разработки моделей от 5-ти лет хорошие знания и опыт практического применения теории вероятностей и математической статистики знание основных алгоритмов и методов машинного обучение и анализа данных: линейные модели, ансамблевые методы, анализ и прогнозирование временных рядов опыт разработки моделей на языках Python или R знание основного инструментария стэка Python: Jupyter, Pandas, Scikit-learn, Statsmodels или аналогов в R опыт работы с базами данных, владение языком запросов SQL хорошие знания английского языка опыт работы в Казначействах банков или подразделениях банков по управлению рисками банковской книги будет большим плюсом знание финансовых рынков, финансовых продуктов, рынков банковских продуктов, финансового риска-менеджмента преимуществом будет опыт работы с экосистемой Apache Hadoop (HDFS, Impala, Hive, Hue), опыт работы с фреймворком Apache Spark (Pyspark, MLlib, Spark SQL), знания финансовой математики, случайных процессов и стохастического анализа. Условия: трудоустройство согласно Законодательству конкурентная заработная плата профессиональное обучение и развитие добровольное медицинское страхование, льготные условия кредитования корпоративная пенсионная программа, материальная помощь спортивная жизнь и корпоративные мероприятия возможность построить карьеру в ведущем банке России.","Python,SQL,Математическая статистика,Hadoop,Математическое моделирование,Spark,ML","ПАО ВТБ, Технологический блок","Москва, Выставочная, Московское центральное кольцо, станция Деловой центр"
16964,78587217,ECommerce Data Engineer,з/п не указана,1–3 года,"Полная занятость,полный день","Accountabilities: Own development of ETL data pipelines, taking responsibility for designing, data modelling, coding, testing, scalability, operability, and ongoing metrics. Collaborate with product manager, business stakeholders, BI engineers, data analysts, data scientists, IT to deliver sustainable and quality results Partner with Sector team to leverage global solutions and best practices Build tools and libraries that reduce new pipeline development time Create metrics to measure the quality and validity of 2nd and 3rd party vendor data Research existing solutions internally and externally to identify gaps between business needs and offerings Research and document data abnormalities and track them as bugs with the engineering teams responsible Key Skills/Experience Required : Bachelor’s Degree (Computer Science or related preferred) 2+ years of professional experience using Python or similar programming language Knowledge of engineering best practices for the full software development life cycle, including coding standards, code reviews, source control management, continuous integrations, testing, and operations RDBMS databases and SQL language Microsoft Azure stack, AWS and GCP is a plus Nice to have: Knowledge of Web Scraping, Airflow, Kubernetes and Docker","azure,SQL,Airflow,Kubernetes,Docker,RDBMS,Python,data engineer,eComm,Databases,Английский — B2 — Средне-продвинутый",PepsiCo,"Москва, Сокол, Ленинградский проспект, 72к4"
16965,77856030,GCP Data Architect/Team Lead,от 5 000 до 6 000 USD на руки,более 6 лет,"Полная занятость,полный день","IMPORTANT!!! We need a specialist who is Senior/Lead level and has 6+ years of experience! We need a specialist who is practically fluent (C1/B2) in spoken English! Please do not apply if your skills are lower. Please save your and our time! Thank you! DESCRIPTION We are looking for a GCP Data Architect/Team Lead on one of the most exciting projects in the bioinformatics domain supporting the scientific community or geneticists at the forefront of single-cell genetic research. This is a role where you will use your data engineering and Google Cloud Platform skills to design and implement a modern, scalable data platform for our single-cell scientific community and project Human Cell Atlas. As a GCP Data Architect, you will: Act as a subject matter expert in data engineering and GCP data technologies. Work with client teams and scientists to design and implement data models for transactional and big data environments as an input into Machine Learning processing Work with Agile and DevOps techniques and implementation approaches in the delivery Assess supporting new technologies and science-specific use cases To be successful in this role, you should have: Experience in designing and building data pipelines using GCP services such as BigQuery, Dataflow, Dataproc, Pub/Sub, Cloud Functions etc. Experience in working with SQL and NoSQL databases such as Cloud SQL, Cloud Spanner, Firestore etc. Experience in using Python or Java for data processing and scripting Knowledge of data governance principles and best practices Experience in driving team and guiding team members. Practical skills in code review, architecture design, coding, etc.Experience in driving team and guiding team members. Practical skills in code review, architecture design, coding, etc.","Architecture,Python,SQL,Java,Machine Learning,Data Science,Data Analysis,Deep Learning,Big Data,Team management,Fluent English,NoSQL,ML,Administrating Skills,Английский — C1 — Продвинутый",E-book Applications,
16967,79004051,"Data Scientist, ML (Удаленно)",от 100 000 до 250 000 руб. на руки,1–3 года,"Частичная занятость,удаленная работа","Привет, я Виктор Комаров, основатель чат-бот платформы для автоматизации взаимодействия с клиентами в мессенджерах - IntellectDialog. Мы ищем Data Scientist, ML инженера (с хорошим опытом) на проектную работу (по задачам с почасовой оплатой) с дальнейшим получением доли в компании. Можно работать в удобное для вас время и совмещать с основной работой. Требования: Опыт работы в разработке NLP-приложений и знание инструментов по обработке естественного языка на Python, таких как SpaCy, NLTK, Gensim и т.д. Понимание основных приемов обработки естественного языка, включая способы извлечения ключевых слов, именованных сущностей, анализ синтаксиса, грамматические модели и обработку структурных данных. Опыт работы с такими инструментами, как Tensorflow, PyTorch, NumPy, Pandas, Jupyter Notebook, понимание системы контроля версий (Git). Базовые знания математической статистики и теории вероятности. Глубокое понимание методов для работы с данными и алгоритмов машинного обучения, таких как классификация, кластеризация, регрессия, обработка последовательностей и т.д. Понимание принципов построения диалоговых систем, в том числе умения разрабатывать и применять техники генерации ответов и распознавания речи. Опыт работы с облачной инфраструктурой. Понимание архитектуры и дизайна диалоговых систем с использованием фреймворка на основе правил и/или машинного обучения. Ответственность, коммуникативные навыки для работы в команде. + Желание развиваться и изучать новые инструменты и технологии для оптимизации работы и улучшения результатов. Заинтересовала вакансия? Тогда ждем от Вас отклика и надеемся, что в скором времени Вы присоединитесь к нашей команде IntellectDialog","Data Scientis,ML,Машинное обучение,Machine Learning",нтеллектДиалог,
16968,79004050,"Data Scientist, ML (Удаленно)",от 100 000 до 250 000 руб. на руки,1–3 года,"Частичная занятость,удаленная работа","Привет, я Виктор Комаров, основатель чат-бот платформы для автоматизации взаимодействия с клиентами в мессенджерах - IntellectDialog. Мы ищем Data Scientist, ML инженера (с хорошим опытом) на проектную работу (по задачам с почасовой оплатой) с дальнейшим получением доли в компании. Можно работать в удобное для вас время и совмещать с основной работой. Требования: Опыт работы в разработке NLP-приложений и знание инструментов по обработке естественного языка на Python, таких как SpaCy, NLTK, Gensim и т.д. Понимание основных приемов обработки естественного языка, включая способы извлечения ключевых слов, именованных сущностей, анализ синтаксиса, грамматические модели и обработку структурных данных. Опыт работы с такими инструментами, как Tensorflow, PyTorch, NumPy, Pandas, Jupyter Notebook, понимание системы контроля версий (Git). Базовые знания математической статистики и теории вероятности. Глубокое понимание методов для работы с данными и алгоритмов машинного обучения, таких как классификация, кластеризация, регрессия, обработка последовательностей и т.д. Понимание принципов построения диалоговых систем, в том числе умения разрабатывать и применять техники генерации ответов и распознавания речи. Опыт работы с облачной инфраструктурой. Понимание архитектуры и дизайна диалоговых систем с использованием фреймворка на основе правил и/или машинного обучения. Ответственность, коммуникативные навыки для работы в команде. + Желание развиваться и изучать новые инструменты и технологии для оптимизации работы и улучшения результатов. Заинтересовала вакансия? Тогда ждем от Вас отклика и надеемся, что в скором времени Вы присоединитесь к нашей команде IntellectDialog","Data Scientis,ML,Машинное обучение,Machine Learning",нтеллектДиалог,
16969,79115585,Junior Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Разработка, поддержка и развитие ML-моделей, нейронных сетей для сервисов / продуктов трайба Анализ данных и проверка гипотез при помощи инструментов программирования и анализа данных Консультирование заказчика при постановке/ утверждении задачи при необходимости Консультирование на этапе реализации/ автоматизации моделей на этапе внедрения/ тиражирования при необходимости Определение требований к перечню, объему и качеству данных, необходимых для решения бизнес-задачи Подготовка прототипа для тестирования/ пилотирования/внедрения в том числе MLOps решений при необходимости Подтверждение выполнения требований к данным для перехода на этап ""моделирование"" Формирование предложений по решению бизнес-задач аналитическими способами/ методами Требования: Законченное высшее техническое образование Знания в области теории вероятностей, статистики, эконометрики, оптимизации, численных методов Понимание ML-моделей (регрессии, классификации, кластеризация и т. д.), достаточное для отсечения заведомо плохих моделей на старте решения Умение построить пайплайн для полного решения задачи: получение данных (PySpark, SQL, Excel, etc), обработка данных (Pandas, etc), визуализация данных (Seaborn, etc) Хорошие навыки программирования, знание Python, PySpark, SQL Знание библиотек машинного обучения (Numpy, Pandas, SkLearn) Условия: Работа в команде разделяющей ценности Agile Хорошо мотивирующий оклад + система премирования Отсутствие дресс-кода Проекты национального уровня Оформление по ТК РФ, расширенный ДМС Обучение в корп. университете, участие в конференциях, обучение вне компании (компенсируем) Атмосферу стартапа внутри одной из самых сильных компаний страны Крупнейшее DS&AI community - более 600 DS банка, включая: регулярный обмен знаниями, опытом и лучшими практиками возможность переиспользования кода и библиотек из централизованного репозитория интерактивные лекции и мастер-классы от ведущих ВУЗов и экспертов технологических компаний дайджест о самых последних разработках в области DS&AI и отчеты с крупнейших конференций мира регулярные внутренние митапы Бесплатный фитнес, парковка для сотрудников, комфортные условия труда со всеми необходимыми ресурсами Работа в команде не предусматривает удаленный режим.","Python,SQL",Сбер. Data Science,
16970,78170079,Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа",,,Цифровые привычки,
16971,79000975,Data Scientist (Junior),з/п не указана,1–3 года,"Полная занятость,полный день","Чем нужно будет заниматься: анализ различных источников данных, генерация признаков для построения модели разведочный анализ данных (EDA) построение моделей машинного обучения внедрение моделей машинного обучения проверять гипотезы, проводить A/B тестирования и пилотные проекты работать на внедрение результатов в продакшн. Кто нам нужен: профильное образование (техническое, компьютерные науки, статистика, математика) 0-1 года опыта профессиональной разработки моделей машинного обучения уверенное знание python опыт практического применения прикладных библиотек (pandas, sklearn, numpy и др.) твердые знания в области мат статистики и машинного обучения знание алгоритмов supervised и unsupervised уверенное знание sql уверенное знание Linux-систем Будет плюсом знание веб-фреймворков (django/flask) опыт работы с Hadoop, Spark, Airflow - пройденные курсы по ds/ml/cv - опыт участия в хакатонах/соревнованиях по машинному обучению - опыт участия в kaggle соревнованиях.","Python,SQL,ml,DS",Газпромбанк,
16972,77075807,Data Scientist,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Мы – департамент Ленты, который отвечает за работу с данными и за монетизацию данных в онлайн бизнесах Ленты Онлайн и Утконос. Мы развиваем и поддерживаем ETL-процессы, выстраиваем Data Governance, поддерживаем BI, встраиваем ML модели в наш CRM, сайт и приложение, встраиваем ML модели в процессы Коммерции и Операций. Сейчас мы расширяемся и ищем в свою команду Data Scientist. Чем предстоит заниматься: Анализ эластичности спроса по цене, построение моделей краткосрочного прогнозирования продаж Построение моделей динамического ценообразования (оптимизация регулярных цен, распродаж, промо). Мы ожидаем, что ты: меешь опыт применения DS/ML в реальных задачах, где твоя работа принесла пользу бизнесу (лучше в e-commerce) Умеешь проводить AB тесты Отлично владеешь Python (DS/ML библиотеки) Знаком с алгоритмами математической оптимизации и их реализацией в различных солверах Уверенно используешь SQL (Oracle/Postgres) Можешь сделать простой интерфейс на Streamlit/Plotly Dash меешь опыт работы такими инструментами как Apache Airflow и MLFlow Умеешь эффективно коммуницировать с заказчиками из различных бизнес-подразделений, коллегами из Т и командой можешь четко формулировать свои идеи и объяснять сложные вещи простым языком. Условия: Активное участие в реализации значимых проектов в одной из лидирующих розничных сетей ДМС класса Люкс со стоматологией Оформление по ТК РФ, полный спектр социальных льгот Дружный коллектив профессионалов с развитой корпоративной культурой Программа личного развития, включающая внешнее и внутреннее обучение Возможность работать удаленно до 100% времени Премирование на основании результатов оценки деятельности.","Python,SQL,Английский язык","Лента, федеральная розничная сеть, IT",
16974,72888902,Data Scientist,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Перед нашей командой стоят крайне амбициозные цели - одними из первых в мире совершить прорыв в части Big data в девелопменте. Всю нашу команду вдохновляет возможность изменить индустрию не только в России, но и во всем мире. Если ты готов решать задачи, которые до тебя никто не решал, мыслишь масштабно и обладаешь гибкостью мышления - добро пожаловать к нам в команду. Что мы точно можем обещать - крайне интересные задачи и быстрый профессиональный рост. Приглашаем на позицию – Data Scientist Ваша зона ответственности: Проведение аналитических работ в своем направлении Построение моделей ML, стат анализа Выявлять проблемы и находить узкие места с которыми сталкивается бизнес Предлагать через анализ данных способы решения Наши пожелания: Уверенные знания высшей математики, теории вероятностей и математической статистики Знание классических алгоритмов и структур данных Опыт внедрения ML-решений в промышленную эксплуатацию Желание решать аналитические задачи для получения практически полезных выводов Желание глубоко погружаться в предметную область и разбираться с особенностями работы Умение объяснять и обосновывать выбранный способ решения задачи Знания и навыки практического применения методов статистического анализа данных Высшее образование, желательно математическое / Т / физика / статистика Знания SQL, Python (уровень не ниже middle) и библиотек для ML (Scikit-learn, Pandas и т.д) Работа со стеком hadoop/spark будет преимуществом Мы предлагаем: Полная удаленка (при желании можно работать из офиса БЦ Кунцево Плаза, м. Молодежная (кстати, наш офис получил премию «Трансформация года» в 2021г.) Расширенный пакет ДМС и страхование от несчастных случаев с первого месяца работы, льготное ДМС для близких родственников, страхование имущества и пр. Компенсация мобильной связи (корпоративная сим-карта) для тех, кому нужно всегда быть на связи Рост и развитие в компании: регулярная обратная связь каждому сотруднику, обучающие мероприятия и широкий доступ к материалам, в том числе ведущих образовательных платформ Скидки для сотрудников на недвижимость группы “Самолет”, индивидуальные условия по рассрочке","Python,SQL,Математическая статистика,Big Data,Hadoop",Группа Самолет,
16975,77425208,Data scientist (Управление скоринга и Биг Дата),з/п не указана,1–3 года,"Полная занятость,полный день","Наша задача построить модели для оптимального с т.з. Клиента и Банка ценообразования в кредитах наличными. Подбирая индивидуальные условия по ставке кредитования и сумме для каждого клиента, максимизируется прибыль банка. Взаимодействуем с коллегами в Блоке Риски, с Блоками Финансов и Бизнес с целью оптимизации ценообразования продукта под разные клиентские сегменты. ЧЕМ ВЫ БУДЕТЕ ЗАНМАТЬСЯ: Разработка классических ML моделей Решение задач оптимизации Внедрение и мониторинг моделей и оптимизационного решения Оценка эффективности разработанных моделей с финансовой т.з. Подготовка отчетов об эффективности для руководства и смежных подразделений ЧТО ВАМ ДЛЯ ЭТОГО НЕОБХОДМО: Хорошее знание статистики, математического анализа, алгоритмов линейного программирования Знание основ финансовой математики Знание основных алгоритмов ML и понимание принципов их работы Навыки в программировании (Python), опыт работы со средами программирования (PyCharm / MS Code) Опыт построения ML моделей Понимание архитектуры БД, знания SQL Опыт работы с GIT Понимание принципов работы Банка, процесса одобрения кредита Опыт работы с BI инструментами (н-р, Tableau) как преимущество Опыт работы с экосистемой Hadoop как преимущество МЫ ПРЕДЛАГАЕМ: Фиксированный оклад + система премирования Социальный пакет Офис: м. Белорусская Гибридный формат работы Команда, открытая самым смелым идеям Внутренние программы обучения и развития Высокий уровень ответственности и возможность самостоятельно принимать решения Атмосфера, где легко оставаться собой: минимум формализма, открытые коммуникации и отсутствие дресс-кода","ML,Python,SQL,Математический анализ,Математическое моделирование,Теория вероятностей,Линейная алгебра,Big Data,Data scientist,мониторинг моделей,Моделирование",Банк Хоум Кредит,"Москва, Белорусская, Правды, 8 к.1"
16976,78995690,Data Scientist,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Приглашаем DATA SCIENTIST-A присоединиться к нашей команде. В Росбанке возможен полностью дистанционный формат работы: откуда работать - решать только тебе! Ты можешь работать из любой точки! Приходи к нам, чтобы работать над амбициозными и интересными проектами и наслаждаться балансом между работой и личной жизнью! Росбанк – частный универсальный банк, работающий на российском рынке с 1993 года. Росбанк обслуживает порядка 1,5 млн активных розничных клиентов, около 83 тысяч активных клиентов малого бизнеса и около 10 тысяч активных клиентов корпоративного бизнеса более чем в 60 регионах России. Росбанк входит в ТОП 5 самых надежных российских банков по версии журнала Forbes и включен Банком России в число 13 системно-значимых кредитных организаций России. Наш банк имеет наивысшие кредитные рейтинги российских и международных рейтинговых агентств. ОБЯЗАННОСТ: Анализ данных и постановка ТЗ на сборки витрин моделирования в части малого и среднего бизнеса Разработка моделей склонности, прогнозирования, классификации, приоритезации и пр. Выстраивание и поддержание системы скоринга клиентов и обновления моделей Разработка и внедрение в промышленный контур готовых моделей. ТРЕБОВАНЯ: Отличное знание SQL и баз данных Опыт моделирования: SAS EM, Python или R Желательно знание математической статистики, предиктивной аналитики, методов (regression, decision tree, neural network и т.д.) и опыт их применения на практике. УСЛОВЯ: Полностью дистанционный формат работы – это возможность работать из любой точки Стабильный и прозрачный доход: зарплата и премии по результатам работы График 5/2 31 календарный день оплачиваемого отпуска Забота о здоровье сотрудников: программа ДМС, включая стоматологию и консультации психолога, страхование при выезде за рубеж, скидки на абонементы в фитнес-клубы, страхование жизни Дополнительная оплата за больничный лист: доплата сверх пособия по болезни до оклада (до 5 рабочих дней в год) Кадровый электронный документооборот, который позволяет подписывать кадровые документы (дополнительные соглашения к трудовому договору, приказы и т.п.) в электронном виде Личностное развитие и рост: корпоративная электронная библиотека Альпина с книгами, курсами, тестами по бизнесу и саморазвитию, возможность прохождения бесплатного обучения и тренингов, участия в регулярных встречах корпоративных клубов и скидки на курсы он-лайн школ Скидки и привилегии по кредитам, ипотека на льготных условиях, льготные условия обслуживания и т.п. Программа корпоративных скидок и привилегий Primezone: развлечение, отдых, товары для взрослых и детей, услуги (авиакомпании, рестораны, магазины электроники и т.п.), обучение Программа волонтерства и благотворительности Сообщества по интересам сотрудников.","Python,Sas,SQL,R",«РОСБАНК»,
16977,77725684,Data Scientist / ML-разработчик,з/п не указана,1–3 года,"Полная занятость,полный день","Наша компания «СтандартПроект» является лидером в области разработки высокоинтеллектуальных информационных корпоративных систем масштаба Big Data в России. Также у нас есть собственная лаборатория digital-продуктов на основе наших разработок. Мы 20 лет работаем с крупнейшими государственными, промышленными и финансовыми организациями.  сейчас у Вас есть возможность присоединиться к команде в качестве Data scientist. ВАМ ПРЕДСТОТ: 1. 50% Разработка ML моделей для высоконагруженных систем (+ доработка и переобучение этих моделей после внедрения) 2. 30% Анализ данных 3. 20% Подготовка сложных выгрузок с использованием SQL и python НАШ ОЖДАНЯ: Обязательно: 1. Опыт работы аналитиком от 1 года. Ждем от кандидата проактивного подхода к решению задач и критическое восприятие результатов собственных исследований. 2. Высшее техническое и/или экономическое образование. 3. Основы машинного обучения (CatBoost, Scikit-learn, XGBoost, Random forest, деревья решений). Желание применять и развиваться в области ML. 4. Знание Python (numpy, pandas, scipy и т.п.), умение работать в jupyter notebook. 5. SQL (сложные запросы, join’ы, вложенные запросы, оконные функции и т.д.). 6. Аналитический склад ума. 7. Знания в области математики, теории вероятности и мат. статистики. 8. Основы моделирования баз данных. 9. Знание английского на уровне чтения технической документации. Желательно: 1. Опыт внедрения алгоритмов машинного обучения 2. Опыт работы с Postgre SQL. 3. Опыт работы с распознаванием образов. 4. Опыт работы с Clickhouse. 5. Опыт работы с Linux. 6. Умение работать с гео-данными в python. Приветствуется: 1. Пройденные курсы по анализу данных. 2. Участия и победы в конкурсах и хакатонах. 3. Наличие пет-проектов с применением ML и оптимизационных алгоритмов. Условия: Конкурентную заработную плату Гибкое начало работы (старт работы 08.00 – 10.00) График работы: 5/2, СБ и ВС, праздники - выходные дни Формат работы: офис первые 3 месяца, далее офис или гибрид Офис в стиле Loft в 10-ти мин. пешком от метро Таганская БЦ Фабрика Станиславского Корпоративное питание в офисе - завтраки, обеды и ужины Полис ДМС Опыт работы над социально значимыми проектами Официальное трудоустройство в соответствии с ТК РФ с первого рабочего дня Работу в стабильной и активно развивающейся IT-компании, где нет бюрократии, и все сотрудники знают друг друга в лицо Регулярные корпоративные мероприятия (настолки, квесты и т.д.), подарки на НГ детям сотрудников и другие мероприятия для поддержания шикарного настроения.  Если укажите в резюме свой ник telegram, считайте, у Вас дополнительное преимущество :)","Python,SQL,ML,Machine Learning,Машинное обучение",СтандартПроект,"Москва, улица Станиславского, 21с2"
16978,77957886,Data Scientist (Разработчик AI/ML),з/п не указана,1–3 года,"Полная занятость,полный день","Мы аккредитованная Т компания! Наши сотрудники получают всё необходимые подтверждающие документы для военкоматов! Рассматриваем кандидатов разного уровня компетенций - Junior - Middle - Lead Обязанности: Выполнение функций Data Scientist-а при реализации проектов по предиктивной аналитике на промышленных предприятиях: Анализ производственных процессов и выработка требований к сбору данных Сбор, преобразование, очистка данных. Разработка и стандартизация ML-пайплайнов Конструирование признаков для ML-моделей (feature engineering) Выбор и обоснование моделей машинного обучения для решения бизнес-задач. Выбор и обоснование метрик для оценки моделей машинного обучения. нтерпретация результатов функционирования моделей машинного обучения. Поддержка и контроль метрик моделей в prod, консультирование пользователей по работе ML-моделей. Участие в разработке концепции и программы консультирования ключевых пользователей. Проведение обучения пользователей создаваемых систем предиктивного анализа. Полный цикл DS моделирования. Встраивание модели в Tibbo. Сбор требований и формирование разделов технических заданий систем предиктивного анализа.. Требования: опыт работы в должности Data Scientist или аналитик данных знание основных библиотек и фреймворков машинного обучения (sklearn, scipy, numpy, pyspark…), сертификаты о профессиональной подготовке в ML/DL знание Python, Jupyter notebook, PySpark, TensorFlow, PyTorch, Linux, bash Опыт работы по проектной деятельности Опыт участия в проектах по внедрению моделей машинного обучения в production Опыт разработки проектной документации: отчет по НР и разделов проектной документации по предиктивному анализу Личностные качества : самостоятельный поиск информации, ответственность за результат, умение планировать свою работу Условия: - Заработная плата по итогам собеседования - График работы с 8:00-17:00, пт до 15:45, возможен гибридный график - Офис м. Нагатинская - спытательный срок 3 месяца - ДМС (после испытательного срока) - Оформление по ТК РФ - Дружелюбный и профессиональный коллектив",,Промышленные инновации,"Москва, Нагатинская, 1-й Нагатинский проезд, 10"
16979,76930898,"Data scientist / Machine learning engineer (команда рекомендаций и машинного обучения, ВКонтакте)",з/п не указана,1–3 года,"Полная занятость,гибкий график","Мы применяем алгоритмы машинного обучения к рекомендациям контента. Мы не просто берем готовые решения, но и создаем собственные, пригодные к работе в условиях высоких нагрузок и больших данных. Помимо классического ML, мы используем deep learning и байесовские методы. Типичный пример нашего проекта — система, которая на ходу учится определять перспективность нового контента и аудиторию, среди которой он будет наиболее востребован. щем специалиста, который будет вместе с нами разрабатывать рекомендательную систему, искать возможности для роста и формировать планы по развитию продукта. Вам предстоит: • математически формулировать бизнес-задачи • использовать огромное количество разных данных • создавать гипотезы по улучшению сервиса, внедрять их и проверять работоспособность в офлайне, а в случае удачи искать способы реализации • проводить A/B-тесты и анализировать результаты экспериментов. У нас интересно, потому что вы сможете поработать с разнообразными state-of-the-art решениями в области рекомендательных систем, например: • с продвинутыми методами матричной факторизации для извлечения информации из истории просмотров и поиска • построением текстовых эмбеддингов • методами reinforcement learning • SNA-техниками для анализа социального графа • разработками big data и аналитикой поверх стека Apache Spark • product science для инсайтов и генерирования продуктовых гипотез • анализом границ применимости моделей, техниками explanation для понимания работы моделей и их специфик. Мы ожидаем, что вы: • имеете отличную математическую и алгоритмическую подготовку • знаете методы машинного обучения и умеете грамотно их использовать • работали с рекомендательными системами или интересуетесь ими • уверенно владеете Python, Java или Scala, а также любым из диалектов SQL. Будет плюсом, если вы: • умеете работать с фреймворками big data — Spark, Hadoop • знакомы с байесовскими методами машинного обучения. Приглашаем кандидата, который сможет посещать офис в Санкт-Петербурге или работать в гибридном графике. Ждем ваших откликов. Удачи!","Python,Machine Learning,SQL,SCALA,Hadoop,Spark","VK, Одноклассники",
16980,52581749,"Senior Consultant, Data Scientist, Technology Group",з/п не указана,3–6 лет,"Полная занятость,полный день","Department: IT Advisory, Astana and Almaty A Senior Data Scientist would typically work, works collaboratively with our business teams and our clients to show the art of the possible and to assess possible value and feasibility of applying data science in order to help solve specific business problems. This could include demoing to prospective clients, developing data strategies, leading feasibility studies, explorative data analysis, delivering minimal viable products or fully fledged projects including putting our models into production either on our own or our client’s environments Requirements: Completed university degree in Computer Science, Statistics, Engineering or similar technical field A combination of one or more of the following (proficient with programming languages like Python, R, Scala, Java, C++ skills in data engineering technologies like Hadoop, HDFS, Spark, Elasticsearch SQL and NoSQL databases) Experience in data, data science, data engineering and/or other technology related capabilities: Experience applying advanced analytical techniques to large and varied data sets, generated and flowing at a rapid rate. Sample techniques include, but are not limited to applied machine learning, NLP, collaborative filtering and recommender systems, neural networks (including recurrent, convolutional), event detection and tracking, graph analytics. Experience with: Generating and test working hypotheses, prepare and analyze historical data, identify patterns from samples for reporting of trends and support Predictive Analytics Leveraging data visualization techniques and tools to effectively demonstrate patterns, outliers and exceptional conditions in the data Creating performance metrics and tracking processes to measure the effectiveness of Data Science solutions Conceptualizing necessary data governance models to support the technical solution and assure the veracity of the data Operating within the exploratory and experimental aspects of Data Science, e.g. to tease out interesting and previously unknown insights from vast pools of data Working collaboratively with other members of the Data Science and Information Architecture teams to innovate and create compelling data-centric stories and experiences Experience in demonstrating data science consultancy skills, e.g. running hypotheses workshops, mentoring more junior team members, preparing reports and presenting data science results. Responsibilities: Build data science assets (aka accelerators’), in line with our global strategy, to ensure we have the platforms and core assets in place to meet market demand. This could also include supporting our continuous improvement process around our own design and development processes e.g. about how we ensure the high quality that our clients require in an efficient manner. As a fast growing highly specialized team, you will be involved in the running and growing of our team, e.g. through coaching colleagues, helping with knowledge management. Support client engagements focused on large data sets and applying advanced analytical techniques, in diverse domains such as retail price optimization, marketing strategies, customer intelligence, financial crime, risk management, smart grids, etc. Develop new, or tailor existing, analytical solutions designed for processing large data sets (e.g. using an Hadoop framework) and by applying advanced analytical techniques (e.g. machine learning, neural networks, NLP, A/B testing, etc.) Develop big data management and data analytics strategies and roadmaps for their implementation Planning and organisation skills so as to work with a team, handle demanding clients and multitask effectively","Java,Python,Data Mining,SCALA,C++,Data Science,NLP,Английский — C1 — Продвинутый",KPMG,
16981,77907673,Junior Data Scientist (сопровождение процесса разработки и использования моделей),з/п не указана,1–3 года,"Полная занятость,полный день","Наша команда контроля и управления моделями является владельцем и заказчиком всех моделей оценки розничного кредитного риска банка. Мы участвуем во всех этапах создания и применения модели: постановка задачи, сопровождение разработки с командой DE, приемка результатов, оценка калибровок и уровней отсечения, мониторинг корректной работы модели. Непосредственной разработкой моделей занимаются наши коллеги из департамента моделирования, внедрением – владельцы системы. За все остальные этапы жизненного цикла модели отвечаем мы. Сейчас мы находимся в поиске коллеги, имеющего опыт в розничном риск-менеджменте, в разработке или мониторинге скоринговых моделей. ОБЯЗАННОСТ: участвовать в процессе управления разработкой новых и модификацией существующих моделей количественной оценки кредитного риска, включая: постановку задачи, предварительный анализ сегмента и параметров, передачу и уточнение требований, приемку результатов, согласование и подготовку материалов для утверждения использования моделей участвовать в расчете значений фактических и прогнозных риск-показателей участвовать в расчете (оценке) экономического эффекта от внедрения скоринговых моделей, уровней отсечения контролировать корректность работы скоринговых моделей, участвовать (в рамках полномочий) в процессе мониторинга и валидации моделей исследование возможностей повышения эффективности прогнозных моделей участие в разработке и согласовании функциональных требований и технических заданий по доработке информационных систем Банка в части применения моделей для принятия кредитных решений и управления кредитным риском розничного портфеля. Требования: высшее образование (математическое, физическое,техническое, экономическое) уверенное владение SQL, MS Office навыки работы в одном или нескольких инструментах по анализу данных: R (RStudio), Python, SAS Guide/Miner знание основ математической статистики, навык применения знаний математической статистики и теории вероятностей на практике при разработке моделей умение делать экономические выводы на основании статистического анализа, интерпретировать результаты и давать рекомендации хорошее понимание интерпретируемых методов моделирования: линейные и логистические регрессии, деревья решений (преимущества, недостатки и ограничения этих методов). Условия: трудоустройство согласно Законодательству конкурентная заработная плата профессиональное обучение и развитие добровольное медицинское страхование, льготные условия кредитования корпоративная пенсионная программа, материальная помощь спортивная жизнь и корпоративные мероприятия возможность построить карьеру в ведущем банке России.","Оценка рисков,MS PowerPoint,Статистический анализ,Управление рисками,Математическое моделирование,PD, LGD, EAD,SQL,Портфельные риски,кредитные риски","ПАО ВТБ, Подразделения Поддержки и Контроля",
16982,78425859,Junior Data Scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Обязанности: Разработка, поддержка и развитие ML-моделей, нейронных сетей для сервисов / продуктов трайба Анализ данных и проверка гипотез при помощи инструментов программирования и анализа данных Консультирование заказчика при постановке/ утверждении задачи при необходимости Консультирование на этапе реализации/ автоматизации моделей на этапе внедрения/ тиражирования при необходимости Определение требований к перечню, объему и качеству данных, необходимых для решения бизнес-задачи Подготовка прототипа для тестирования/ пилотирования/внедрения в том числе MLOps решений при необходимости Подтверждение выполнения требований к данным для перехода на этап ""моделирование"" Формирование предложений по решению бизнес-задач аналитическими способами/ методами Требования: Законченное высшее техническое образование Знания в области теории вероятностей, статистики, эконометрики, оптимизации, численных методов Понимание ML-моделей (регрессии, классификации, кластеризация и т. д.), достаточное для отсечения заведомо плохих моделей на старте решения Умение построить пайплайн для полного решения задачи: получение данных (PySpark, SQL, Excel, etc), обработка данных (Pandas, etc), визуализация данных (Seaborn, etc) Хорошие навыки программирования, знание Python, PySpark, SQL Знание библиотек машинного обучения (Numpy, Pandas, SkLearn) Условия: Работа в команде разделяющей ценности Agile Хорошо мотивирующий оклад + система премирования Отсутствие дресс-кода Проекты национального уровня Оформление по ТК РФ, расширенный ДМС Обучение в корп. университете, участие в конференциях, обучение вне компании (компенсируем) Атмосферу стартапа внутри одной из самых сильных компаний страны Крупнейшее DS&AI community - более 600 DS банка, включая: регулярный обмен знаниями, опытом и лучшими практиками возможность переиспользования кода и библиотек из централизованного репозитория интерактивные лекции и мастер-классы от ведущих ВУЗов и экспертов технологических компаний дайджест о самых последних разработках в области DS&AI и отчеты с крупнейших конференций мира регулярные внутренние митапы Бесплатный фитнес, парковка для сотрудников, комфортные условия труда со всеми необходимыми ресурсами Работа в команде не предусматривает удаленный режим.","Python,SQL",Сбер. Data Science,
16983,78879508,Data Scientist,з/п не указана,1–3 года,"Полная занятость,удаленная работа","Команда развития рекомендательной платформы группы нго формирует сильную команду для развития ML направления. Присоединяйтесь к нам — будем развивать платформу вместе! Кто нам нужен: щем активного и целеустремленного коллегу, который имеет опыт работы с большими данными, знает и применяет инструменты DS в своей работе. Готовы рассмотреть кандидатов разного профиля как classic ML, так и CV и NLP. Что предстоит: Полный цикл (data collection, feature engineering, model fitting, model management, visualization, model serving) создания набора моделей на основе транзакционной и поведенческой информации Модели предложений для рекламных кампаний Скоринговые модели для страховых продуктов Ранжирование списков продуктов и услуг по вероятности отклика Построение моделей оттока и ретаргетинга Комплекс моделей по обработке аудио-текстовой информации контактного центра OCR и Image Segmentation Участие в разработке и стандартизации ML-пайплайнов Анализ и обработка больших массивов данных. RND и code-review. Что ждем от вас: Высшее техническое образование, (будет преимуществом - МФТ, МГТУ им. Баумана, МГУ, СПбГУ, ВШЭ, Сколтех, НГУ) Уверенное понимание моделей классического машинного обучения Четкое понимание метрик и их интерпретации Специалистам CV профиля нужно разбираться в следующих темах: OCR, OpenCV, image classification, image segmentation, object detection Специалистам NLP профиля: classic NLP, Word2Vec, Transformers, NER, Seq2Seq, Intent Recognition, Question Answering, NLI, Triplet Extraction Знание алгоритмов и метрик машинного обучения Знание SQL, T-SQL Желателен опыт работы с python, spark, airflow Желателен опыт работы с docker, kubernetes Знание математической статистики и теории вероятности Умение работать в команде на результат Знание английского языка на уровне чтения технических материалов. Будет дополнительным преимуществом: Участие в DS соревнованиях, например Kaggle Участие в разработке open sourсe библиотек, пройденные за последний год оффлайн и онлайн курсы (coursera, udemy и пр.) Предлагаем: Оформление в штат по бессрочному трудовому договору, полностью белую заработную плату: оклад + стабильная ежеквартальная премия + годовой бонус После 3 месяцев работы базовый пакет ДМС (поликлиника) спустя 9 месяцев работы – расширенный ДМС (стоматология, имуннотерапия, диспансеризация, лечение сложных заболеваний, телемедицина, плановая и экстренная помощь) + ДМС для родственников Удаленный формат работы (однако если хотите работать в офисе, то в Москве и Санкт-Петербурге это можно организовать) Гибкое начало рабочего дня на ваше усмотрение: с 8:00 до 17:00, с 9:00 до 18:00, с 10:00 до 19:00 Бесплатный корпоративный доступ к электронной библиотеке «Альпина» Льготный отдых в ГК «меретинский» в г.Сочи Скидки на обучение в языковых школах Speak English и Skyeng – от 15 – 25% Корпоративные предложения от сетей фитнес-клубов: WORLD CLASS, Зебра, X-fit Скидки от партнеров на приобретение недвижимости, авто и др. Подарки на Новый Год детям Льготные страховые продукты (Страхование-Тур, Страхование-Авто, Страхование-мущество) У вас будет наставник на период испытательного срока (3 мес), который поможет адаптироваться в компании + будет команда, которая ответит на ваши вопросы в процессе работы Возможность внести свой вклад в развитие нового проекта и самой команды Мы не ограничиваем и даем возможность дальше прокачивать hard skills на других проектах.","Python,Linux,Spark,Английский язык,SQL,Big Data",нгосстрах,
16984,78352002,Программист-стажер Data Scientist/Python,з/п не указана,не требуется,"Стажировка,полный день","Обязанности: Ведение проекта под руководством лида (наставника) Работа с сырыми данными, с последующей обработкой под задачи Проверка гипотез с помощью методов машинного обучения Участие во всем цикле работ по построению, оценке и внедрению моделей машинного обучения Построение и поддержка аналитических моделей (Python) Подготовка аналитических отчетов. Требования: Высшее техническое/ экономическое образование или в том числе студенты последних курсов с возможностью работать полный рабочий день Высшее образование/не законченное высшее (Т/техническое/математическое/экономико-математическое) Последние курсы бакалавриата и магистратуры ВУЗов: МФТ, МГУ, ВШЭ ФКН, МГТУ, МФ и др. Геологическое образование, нефтегазовое дело как преимущество Программирование на хорошем уровне Python в качестве основного языка, основы SQL Знание основных алгоритмов интеллектуального анализа данных (линейная/логистическая регрессия, random forest, xgboost и т.д.) Парсинг данных из разнородных источников как дополнительное преимущество Желание развиваться и изучать новейшие методы Data Science Умение работать в команде. Мы предлагаем: Оплачиваемую стажировку на 3 месяца с возможностью продления по результатам График работы 5/2 Оформление в соответствии с трудовым законодательством в аккредитованную Т-компанию Рыночные условия оплаты труда Программу развития начинающих специалистов Поддержку опытных менторов Добровольное медицинское страхование со стоматологией с первого дня Кафе и столовую на территории БЦ Возможность присоединиться к нашим спортивным командам по мини-футболу, баскетболу, волейболу или чирлидингу, и принять участие в Спартакиаде Участие в Благотворительных проектах Прекрасный офис с панорамными видами и удобным местоположением. А также: Амбициозные задачи Применение передовых технологий на практике Работу в команде лучших экспертов рынка Огромные возможности для совершенствования навыков и знаний, обучения и развития Позитивную рабочую атмосферу и дружный коллектив.","Деловая переписка,Грамотная речь,Административная поддержка руководителя,Делопроизводство,Организаторские навыки",К СБНТЕК,"Москва, Беговая, Беговая улица, 3с1"
16985,78177657,Стажер Data Scientist,з/п не указана,не требуется,"Стажировка,полный день","Мы — команда математиков-датасаентистов в крупнейшем маркетплейсе с миллионами пользователей, хайлоадом и бигдатой. Нас знают все. Собираем начинающих математиков и датасаентистов для прокачки в прикладных историях: большие данные, анализ текстов, поиск аномалий, оптимизация логистики, рекомендательные и поисковые системы. Ключевые навыки: фундаментальные науки: математический анализ, теория вероятности, алгебра, статистика основы ML/DL Git Python (pandas, numpy, sklearn, pytorch, pyspark) работа с данными Будет плюсом: базовый SQL поисковые алгоритмы собственные проекты участие в соревнованиях (олимпиады, хакатоны, Kaggle, Numer и т.д.) Предлагаем: обучение/стажировку на реальных кейсах интересные нестандартные задачи в топовом маркетплейсе команду увлеченных специалистов свободу творчества и рост работу после стажировки офис красивый, но работайте откуда хотите",,WILDBERRIES,
16986,78657529,Data scientist,з/п не указана,1–3 года,"Полная занятость,полный день","Ключевые задачи: Разработка и улучшение моделей МО для формирования клиентам персональных предложений(классификация, регрессия, кластеризация) Развитие модели данных для портфеля задач МО Презентация результатов работы моделей и защита новых подходов перед руководством команды / направления. Что важно для нас: Знание основ математической статистики Знание SQL Навыки работы с БД (CRUD) Опыт работы с Hadoop, Spark Знание Python Опыт работы моделирования на табличных данных Понимание работы алгоритмов машинного обучения и умение интерпретировать результаты моделей Владение стеком библиотек работы с данными и алгоритмами МО на Python (Pandas, PySpark, Sklearn, PyTorch, XGBoost, LGBM, CatBoost и тд) Навыки работы с GIT Опыт проведения А/Б тестирования и опыт написания ETL пайплайнов - будут являться преимуществом. Что мы предлагаем: График работы: 5/2 Официальное оформление в соответствии с ТК РФ Конкурентный уровень дохода: оклад + премии Медицинская страховка, страховка для выезжающих заграницу Доплата к отпуску и больничному листу Дополнительные льготы при заключении брака и рождении детей Социальная поддержка при сложных жизненных ситуациях Льготное кредитование для сотрудников Обучение в корпоративном университете банка Корпоративная библиотека.","SQL,Python,Pandas,Spark,Машинное обучение,Моделирование",ПСБ (Промсвязьбанк),"Москва, Павелецкая, Дербеневская набережная"
16987,77536865,Data Scientist Junior/Junior+,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
16988,77536865,Data Scientist Junior/Junior+,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Вкусно — и точка,"Москва, Добрынинская, Павелецкая, Серпуховская, Валовая улица, 26"
16989,78387709,Data Scientist в команду лояльности СберСпасибо,з/п не указана,1–3 года,"Полная занятость,полный день","Мы ищем талантливого молодого ML-разработчика, чтобы вместе разрабатывать и выводить в production модели для более 60 млн клиентов программы лояльности СберСпасибо. В нашей команде семь специалистов, все студенты или выпускники МФТ. Кандидат должен обладать техническим складом характера и широким кругозором, самостоятельностью, знанием высшей математики и статистики, опытом разработки моделей машинного обучения, знать SOTA архитектуры, любить и уметь писать качественный код на Python. Обязанности Полный цикл разработки и внедрения ML-моделей — от постановки задачи до внедрения модели в highload prod на регламент - Применение статистических методов для проверки гипотез и валидации эффекта от внедрения ML-моделей - Взаимодействие с бизнес-заказчиками и data engineers, напрямую, без посредников - Непрерывное обучение, участие в соревнованиях на Kaggle в составе команды - Внедрение современных инструментов в культуру совместной разработки Требования - Студент (от 3-го курса) или выпускник технического ВУЗа, в приоритете — МФТ, далее — МГТУ им. Баумана, МФ, МГУ - Не менее полгода работы/стажировки на позиции ML-разработчика - Знание Python, следование стандартам PEP 8, в разработке ориентируемся на Google python style guide - Знание SQL и устройства баз данных - Опыт разработки в фреймворках на выбор Tensorflow / Pytorch / Pytorch Lightning. Знание numpy. - Знание и опыт применения базовых ML-алгоритмов, современных архитектур NN - нтерес к MLOps и DWH — Docker / k8s, Airflow, FastAPI, MLFlow, Kafka, Redis, Greenplum, MongoDB, Clickhouse - Уверенное владение UNIX - (Опционально) опыт участия в DS-соревнованиях Условия - 100% удаленный, гибридный или офисный (м. Кутузовская) режим работы, оформление в Сбер - Возможность совмещать с учебой / аспирантурой, 50% команды учится - Годовая премия, карьерный и зарплатный рост. Все преимущества Сбера для сотрудников (льготная ипотека и кредитование, скидки, современный офис). - Разработка по Agile (scrum) - Минимум бюрократии, прямые коммуникации с бизнес-заказчиками - Выделенный доступ к GPU-кластеру - Бесплатные курсы, в том числе на платформе Udemy, участие в соревнованиях Kaggle","ML-модель,Kaggle,СберСпасибо,МФТ,SQL,Python,Машинное обучение,Data Analysis,Big Data,data",Сбер для экспертов,
16990,79263907,Senior Data Scientist Управления портфельного анализа кредитных рисков,з/п не указана,3–6 лет,"Полная занятость,полный день","Крупнейший универсальный коммерческий банк Казахстана приглашает тебя в свою команду. Мы ищем талантливых людей, готовых развиваться и расти вместе с нами. Группа Halyk – это более 17 000 сотрудников в Казахстане и ряде других стран. Наш банк успешно работает на благо своих клиентов уже более 95 лет. Мы оказываем услуги во всех сегментах финансового рынка: банковском, страховом, ценных бумаг, лизинговом. Что ты будешь делать: Валидация скорринговых моделей Применение скорринговых моделей для расчета провизий (PD / LGD) Формирование аналитической отчетности по кредитным рискам. Что мы ждем от соискателя: Наличие степени магистра (или эквивалента) в областях статистики, математики, науки о данных или связанной с ней количественной области Наличие более 4 лет опыта разработки и проверки моделей в финансовых услугах, работы с инструментами обработки и анализа данных и статистическими инструментами, в сфере статистического анализа, обработки больших объемов данных и анализа тенденций. Мы предлагаем: Уникальный опыт, интересные задачи и проекты Применение инновационных технологий в работе Заинтересовала вакансия? Откликайся! Обучение и тренинги Конкурентная оплата труда в соответствии с международными стандартами.","Умение работать с большими объемами данных,Работа с большим объемом информации,Статистический анализ,Расчет провизий,скоринговая модель",Народный банк Казахстана,"Алматы, проспект Аль-Фараби, 40"
16993,78465611,Управляющий директор \ Data Scientist (Сопровождение процесса разработки и использования моделей),з/п не указана,3–6 лет,"Полная занятость,полный день","Наша команда контроля и управления моделями является владельцем и заказчиком всех моделей оценки розничного кредитного риска банка. Мы участвуем во всех этапах создания и применения модели: постановка задачи, сопровождение разработки с командой DE, приемка результатов, оценка калибровок и уровней отсечения, мониторинг корректной работы модели. Непосредственной разработкой моделей занимаются наши коллеги из департамента моделирования, внедрением – владельцы системы. За все остальные этапы жизненного цикла модели отвечаем мы. Сейчас мы находимся в поиске коллеги, имеющего опыт в розничном риск-менеджменте, в разработке или мониторинге скоринговых моделей. ОБЯЗАННОСТ: участие в процессе управления разработкой новых и модификацией существующих моделей количественной оценки кредитного риска, включая: постановку задачи, предварительный анализ сегмента и параметров, передачу и уточнение требований, приемку результатов, согласование и подготовку материалов для утверждения использования моделей участие в расчете значений фактических и прогнозных риск-показателей участие в расчете (оценке) экономического эффекта от внедрения скоринговых моделей, уровней отсечения контроль орректности работы скоринговых моделей, участие (в рамках полномочий) в процессе мониторинга и валидации моделей исследование возможностей повышения эффективности прогнозных моделей участие в разработке и согласовании функциональных требований и технических заданий по доработке информационных систем Банка в части применения моделей для принятия кредитных решений и управления кредитным риском розничного портфеля. ТРЕБОВАНЯ: высшее образование (экономическое, техническое, математическое) опыт разработки и/или валидации скоринговых моделей розничного (не корпоративного!) сегмента. Подходит опыт в разных направлениях (маркетинг, коллекшен), но именно опыт в оценке кредитного риска розничного сегмента (модели PD, LGD, EAD для целей принятий кредитных решений, ПВР или МСФО9) является существенным преимуществом уверенное владение SQL, MS Office навыки работы в одном или нескольких инструментах по анализу данных: R (RStudio), Python, SAS Guide/Miner знание основ математической статистики, навык применения знаний математической статистики и теории вероятностей на практике при разработке моделей умение делать экономические выводы на основании статистического анализа, интерпретировать результаты и давать рекомендации опыт разработки и/или мониторинга, валидации моделей оценки кредитного риска розничного сегмента является преимуществом опыт работы в коммерческом банке (предпочтительно в розничных рисках) приветствуется понимание специфики процесса розничного кредитования хорошее понимание интерпретируемых методов моделирования: линейные и логистические регрессии, деревья решений (преимущества, недостатки и ограничения этих методов). УСЛОВЯ: трудоустройство согласно Законодательству конкурентная заработная плата профессиональное обучение и развитие добровольное медицинское страхование, льготные условия кредитования корпоративная пенсионная программа, материальная помощь спортивная жизнь и корпоративные мероприятия возможность построить карьеру в ведущем банке России.","Оценка рисков,MS PowerPoint,Статистический анализ,Управление рисками,Математическое моделирование,PD, LGD, EAD,SQL,Портфельные риски,кредитные риски","ПАО ВТБ, Подразделения Поддержки и Контроля",
17018,78851235,Data Scientist (digital marketing),з/п не указана,3–6 лет,"Полная занятость,полный день","О проекте Наш клиент – крупнейший западный фармацевтический производитель расширяет свою команду digital аналитики и приглашает рассмотреть позицию Senior digital/omnichannel marketing analysts. В распоряжении отдела богатая цифровая инфраструктура. CRM, email marketing platform, MDM, Web портал (1С Битрикс), чат-боты, мобильные приложения, сопутствующие каналы (SMS/SEO/Paid media). Эта инфраструктура генерирует внушительные объемы транзакционных данных. меть стройную сквозную аналитику и уметь интерпретировать данные в бизнес-кейсы – главная задача успешного кандидата. Чем предстоит заниматься: Лидирование направления сквозной аналитики в области digital marketing в компании (в команде уже есть 2 аналитика и аутсорс-команда для гибкости) Разработка аналитических отчетов в области цифрового маркетинга Поиск точек роста рекламных кампаний и дистрибуция знаний до внутреннего заказчика Контролировать внедрение новых функций в постоянно развивающейся omnichannel экосистеме Обильно взаимодействовать с зарубежной командой с целью приведения в соответствие аналитику локальную и глобальную (таксономия, naming convention, подходы, глобальные изменения в инфраструктуре). Что ожидаем от кандидата: Опыт построения экосистемы сквозной digital marketing аналитики – обязателен Портфолио через данные. Умение погрузиться в дату ad-hock’ом, найти корреляции и аномалии, положить их на слайды и объяснить бизнес-языком – твоя супер способность Широкий кругозор в области построения отчетов. Ты эмпатичен к бизнесу и знаешь наверняка, на что хочет смотреть бизнес Ты знаешь основы прототипирования отчетов. Где круговые диаграммы незаменимы, а где они вредят Опыт управления командой и кросс-функционального взаимодействия Hard skills – Pbi, DAX, Python, SQL, BigQuery, Data studio, ETL, MDM, AWS а также глубокое понимание принципов и инструментов в digital promo (CPC, LTV, CPM, MAU, DAU, Retention, CDP, SEO, Paid media, GA/YM, принципы работы веб-сайта, веб-сервера, UA, cookies и т.п.) Широкий кругозор в принципах проектирования реляционных (и не очень) баз данных и построения BI моделей Опыт работы с SalesForce будет плюсом Уверенный английский язык. Условия: Официальное трудоустройство согласно ТК РФ через кадрового провайдера (входит в реестр IT компаний), белая з\п. Доступ к цифровой инфраструктуре и проектам международного уровня. Компания в партнерстве с ведущими технологическими игроками мира - AWS, Microsoft, Google, Salesforce и т.д. Обширный горизонт для развития. Компания ориентирована на предиктивную/продуктовую аналитику, ML, и имеет необходимые технологии. Молодой дружный коллектив с международной культурой. Agile, Scrum, Waterfall – применяется там, где это полезно. Дополнительное медицинское страхование (поликлиника, стоматология, стационар). Уютный офис в центре города. Full time с удобным графиком.","Английский язык,Power BI,ETL,Data Analysis,DAX,AWS,Digital Marketing,Python,LTV,CPC,Pbi,Google Analytics,Яндекс.Метрика,Английский — B2 — Средне-продвинутый",AUXO (Атос АйТи Солюшенс энд Сервисез),
17026,78941888,Системный аналитик Big Data,з/п не указана,1–3 года,"Полная занятость,полный день","щем аналитика в команду, которая занимается развитием продукта Супермаркет Данных. Супермаркет Данных является частью инфраструктуры рабочего места D-People (Data Scientist, Data Engineer). Позволяет найти и получить данные Банка для исследования и промышленных процессов в режиме self-service. Мы разрабатываем единственную платформу по поиску и заказу данных No vendor lock на нашем рынке. У нас несколько десятков интеграций с различными системами, современные стандарты построения архитектуры продукта, и амбициозные планы по развитию. Все это делает работу в команде продукта интересной и нескучной, а также дает возможности для развития профессиональных навыков. Наш техстек: TypeScript, React, Apollo, Formik, Jest, React Testing Library, Node.js, PostgreSQL, Mocha, Chai, ElasticSearch, Logstash, Kibana, Grafana, Docker, OpenShift Обязанности: постановка задач на разработку на основе бизнес и функциональных требований документирование разработанной функциональности формализация контрактов взаимодействия между сервисами подготовка инструкций для сопровождения. Требования к кандидату: опыт работы в роли бизнес или системного аналитика понимание принципов микросервисной архитектуры знание нотаций описания процессов – UML, BPMN (в первую очередь диаграммы Sequence, ER) опыт описания интеграций через Rest, SOAP, GraphQL, очереди сообщений (RabbitMQ, Kafka) опыт написания SQL-запросов Будет плюсом: опыт работы на продуктах с микросервисной архитектурой знакомство с GraphQL и Apollo знакомство с Docker, Kubernetes, OpenShift знакомство с ElasticSearch, Logstash, Kibana, Grafana Условия работы: режим работы офис \ удаленка стабильный оклад и социальная поддержка сотрудников расширенный ДМС с первого дня работы для сотрудников и льготная медицинская страховка для близких бесплатная подписка СберПрайм +, скидки на продукты компаний партнеров: СберМаркет, Delivery Club, Самокат, СберЕаптека и других корпоративная пенсионная программа корпоративное обучение за счет компании реферальная программа для сотрудников: можно пригласить в команду знакомых профессионалов и получить денежное вознаграждение.","BPMN,REST,GraphQL,SQL,UML",Сбер. IT,"Самара, Алабинская, проспект Ленина, 17"
17030,78884329,Data engineer (Middle),з/п не указана,1–3 года,"Полная занятость,полный день","ОБЯЗАННОСТ: Анализ требований к витринам данных (взаимодействие с владельцем продукта, BI-разработчиками, data scientist-ами) Поиск и исследование источников данных для последующей интеграции Оценка пригодности, качества исходных данных Разработка ETL процессов на Spark Оркестрация ETL процессов в Airflow Проектирование баз данных Создание конвейеров данных NiFi. ТРЕБОВАНЯ: Опыт работы от 1 года и более в таких областях как: коммуникационные технологии, безопасность, маркетинг и продажи, финансы Знание SQL на высоком уровне (в т. ч. DDL, табличные выражения, оконные функции) Опыт работы с Hive, PostgreSQL Умение разрабатывать ETL процессы Spark на Scala (потоковая обработка как преимущество) Опыт работы AirFlow или другими оркестраторами – Oozie, Luigi, ну или cron Умение что-то написать на Python – в объеме чтобы пользоваться AirFlow или еще круче Опыт потоковой разработки конвейеров данных в NiFi или Flink нтерес Flink, пробовали применять его в проектах Умение проектировать базы данных (знает Data Vault 2.0 например) Понимание принципов работы реляционных СУБД и HDFS Есть представление о колоночных и NoSQL СУБД Понимание подходов к работе с качеством данных. ТРЕБОВАНЯ К ЗНАНЮ СТЕКА ТЕХНОЛОГЙ: Экосистема Hadoop – HDFS, YARN, Hive, HBase ETL-процессы – Spark (Scala) Потоковая обработка – NiFi, Flink Брокер сообщений – Kafka Оркестрация ETL процессов – Airflow СУБД – PostgreSQL, Greenplum, Aerospike, Oracle, SQL Server CI/CD – GitLab. УСЛОВЯ: Работа в стабильной компании Белая заработная плата Возможность работать удалённо Оформление в соответствии с ТК РФ с первого дня работы Расширенный социальный пакет: ДМС (включая стоматологию), корпоративные скидки на посещение фитнес-клубов, футбольная и волейбольная секции Профессиональное обучение и развитие.",,Ц АЙ-ТЕКО,
17031,78848653,Старший data engineer,з/п не указана,1–3 года,"Полная занятость,полный день","КОМПАНЯ «АЙ-ТЕКО» - ведущий российский системный интегратор и поставщик информационных технологий для корпоративных заказчиков. Активно действует на рынке IT России с 1997 года, входит в ТОП-400 крупнейших российских компаний, ТОП-10 крупнейших IT-компаний России. В связи с активным развитием внутренних проектов в компании открыта вакансия DATA ENGINEER. ОПСАНЕ: Проведение аналитики и разработки программного обеспечения с целью создания Т-решения в рамках создания платформы автоматизации процессов производства компонета Commission для ПАО ""ВымпелКом"" ТРЕБОВАНЯ: • Проработал от 1 года и более в таких областях как: коммуникационные технологии, безопасность, маркетинг и продажи, финансы. • Знает SQL на высоком уровне (в т. ч. DDL, табличные выражения, оконные функции) • Работал с Hive, PostgreSQL • Умеет разрабатывать ETL процессы Spark на Scala (потоковая обработка как преимущество) • Пользовался AirFlow или другими оркестраторами – Oozie, Luigi, ну или cron • Может что-то написать на Python – в объеме чтобы пользоваться AirFlow или еще круче • меет опыт потоковой разработки конвейеров данных в NiFi или Flink • нтересуется Flink, пробовал применять его в проектах • Умеет проектировать базы данных (знает Data Vault 2.0 например) • Понимает принципы работы реляционных СУБД и HDFS • меет представление о колоночных и NoSQL СУБД • Понимает подходы к работе с качеством данных • Применяет системный подход к работе, думает о конечной бизнес-задаче, мыслит логически, уделяет внимание деталям ТПОВЫЕ ЗАДАЧ: • Анализ требований к витринам данных (взаимодействие с владельцем продукта, BI-разработчиками, data scientist-ами) • Поиск и исследование источников данных для последующей интеграции • Оценка пригодности, качества исходных данных • Разработка ETL процессов на Spark • Оркестрация ETL процессов в Airflow • Проектирование баз данных • Создание конвейеров данных NiFi ТРЕБОВАНЯ К ЗНАНЮ СТЕКА ТЕХНОЛОГЙ: • Экосистема Hadoop – HDFS, YARN, Hive, HBase • ETL-процессы – Spark (Scala) • Потоковая обработка – NiFi, Flink • Брокер сообщений – Kafka • Оркестрация ETL процессов – Airflow • СУБД – PostgreSQL, Greenplum, Aerospike, Oracle, SQL Server • CI/CD – GitLab МЫ ПРЕДЛАГАЕМ: Работу в стабильной компании, ""белую"" заработную плату Оформление в соответствии с ТК РФ с первого дня работы Расширенный социальный пакет: ДМС (включая стоматологию), корпоративные скидки на посещение фитнес-клубов, футбольная и волейбольная секции Профессиональное обучение и развитие Яркая и насыщенная корпоративная жизнь Снабжаем всей необходимой современной техникой: мощный ноут привезут прямо в день оформления  ОТКЛКАЙСЯ =) ЖДУ КОГДА ВМЕСТЕ ПОРАДУЕМСЯ ТВОЕМУ ОФФЕРУ)",,Ц АЙ-ТЕКО,
17049,78038162,Data Product Lead (eCommerce),з/п не указана,более 6 лет,"Полная занятость,полный день","Project: building a data platform for eCommerce reporting in RU Team: Data Engineers, Data Scientists, BI Engineers, UX Researchers. What you'll do: Oversight over the holistic data and tech program from planning/alignment to delivery inc RU components within European roadmap Ensure that teams are aligned to efficiently deliver on shared goals and meet higher strategic objectives of the organization In partnership with Business Owners and stakeholders uncover and understand customer needs and translate them into requirements, product vision and deliverables Plan, Own and maintain data Integrations roadmap, business intelligence and reporting solutions portfolio Proactively identify, assess risks throughout the overarching agenda and propose resolutions Identification and management of interdependencies across cross-functional teams to ensure timely product delivery Serve as a product evangelist and subject matter expert Preferred qualifications: 5+ years as a program or product manager, with beneficial consideration for experience working across matrix and geographically distributed organizations Experience delivering tech programs or products from inception to delivery, inc experience working with products that deal with data engineering, data science, analysis or visualization Strong leadership, networking, relationship-building, communication and influencing skills Extraordinary organizational and planning skills Experience of managing delivery across cross-functional product and tech teams In-depth knowledge of program and project management methods and principles Great stakeholder management and communication skills Outstanding working knowledge of change management principles and performance evaluation processes Ability to ensure that plans are kept to, and expectations are well managed Experience operating autonomously across multiple teams, demonstrated critical thinking, and though","azure,Data Analysis,ecommerce,Английский — C1 — Продвинутый",PepsiCo,"Москва, Сокол, Ленинградский проспект, 72к4"
17051,76477548,Data Engineer (Рекламные технологии),з/п не указана,1–3 года,"Полная занятость,полный день","Команда DWH агрегирует в себе накопленную экспертизу и лучшие практики холдинга в области построения хранилищ данных и аналитических приложений. Мы превращаем информационный хаос в четко организованную систему, которая позволяет собирать, обрабатывать и анализировать любые объемы данных. В нашей команде убеждены, что системы хранилищ данных должны максимально помогать людям — автоматизировать рутинные задачи, собирать и анализировать сырые данные, подготавливать почву для удобного и аргументированного принятия решений. Мы ищем BigData-инженера, готового принять активное участие в разработке одного из крупнейших хранилищ группы компании: десятки петабайт данных, количество узлов кластера — более 400, ежедневный прирост информации составляет десятки Тб. В хранилище собрана информация большинства ключевых бизнес-юнитов компании, которая описывает поведение пользователей Рунета: события посещений сайтов, клики/показы рекламы, использование мобильных приложений, профили соцсетей пользователя, действия пользователей в соцсетях и их публичные сообщения и т.д. Все это позволяет составить достаточно полную картину поведения пользователя во всех сервисах VK и строить на полученных данных сложные математические модели. Наш стек технологий включает, но не ограничивается: Database Systems: MySQL, Tarantool, ClickHouse Hadoop: Hive, Spark, MapReduce, Kafka DataFlow / ETL: Luigi, Airflow Business Inteligence: Tableau, Redash, SuperSet Continuous Integration: Jenkins, GitLab CI IssueTracking / KnwoledgeBase : Jira, Confluence Monitoring: Sentry, Graphite, Grafana, Prometheus, Telegraf. Задачи: участие в роли BigData Engineer в проекте построения системы обработки и хранения разнородной информации из различных бизнес-юнитов компании на базе Hadoop (BigData DWH) исследование большого объема необработанных данных, накопленных в компании построение и оптимизация нетривиальных ETL процессов обработки больших данных, участие в построении процессов потребления данных на всех этапах, их трансформации от появления информации в конкретном бизнес-юните до монетизации полученных знаний взаимодействие с командой Data Scientist и совместная реализация стабильного расчета математический моделей поддержка и модификация созданного решения, ответственность за доступность сервиса для внутренних потребителей и корректность предоставляемых для принятия решений данных. Требования: не менее 1 года релевантного опыта работы опыт работы с большими объемами данных, понимание стека технологий hadoop, глубокое знание Spark или Hive (плюсом будет знание Java, Scala в контексте обработки больших данных) опыт организации ETL процессов обработки данных (плюсом будет знание code-driven ETL Luigi, Airflow) знание классических алгоритмов и структур данных (плюсом будет опыт разработки на python) знания в области теории обработки и хранения информации ссылки на публичные репозитории, статьи с примерами работы — приветствуются.","DWH,ETL,Hadoop,Python,Big Data",VK,"Москва, Аэропорт, Ленинградский проспект, 39с79"
17053,77321671,Владелец продукта (продукты Data Science),з/п не указана,3–6 лет,"Полная занятость,полный день","Чем вам предстоит заниматься Управление проектами/портфелем проектов Data Science по направлению оптимизации производства (улучшение технологического режима, предиктивная диагностика оборудования, повышение качества продукции). Организация ритуалов разработки. Взаимодействие с бизнес-заказчиком. Подбор и управление командой разработки в рамках ритуалов Agile. Управление сроками/ресурсами/дорожной картой проекта. Управление мотивацией команды и Заказчика. Организация внутреннего финансирования инициатив. Что мы ожидаем от вас: Высшее образование по направлению Т, программирование, математики, кибернетики. Понимание Agile методологии и роли Владельца продукта. Опыт работы в качестве Владельца продукта – от 2 лет, с подтвержденным опытом успешного создания продуктов. Технологический бэкграунд – опыт работы в роли аналитика данных, Data Scientist. Опыт работы в проектах Big Data, понимание методов машинного обучения. Развитые аналитические и коммуникативные способности. Умение принимать решения в условиях неопределенности. Приветствуется опыт создания и управления собственным бизнесом. Что мы предлагаем: Работа в аккредитованной Т-компании со всеми преимуществами. Гибридный формат работы (график обсуждается индивидуально в зависимости от роли). Заработная плата по результатам собеседования, премии за эффективную работу и результат. Действительно нестандартные задачи, которые требуют креатива и новых подходов, мы работаем в реальном секторе, наши пользователи - реальные люди. Современный стек и гибкие методологии разработки, работа в команде высококлассных профессионалов из разных технологических областей. Возможность обучения и участия в жизни IT-сообщества: большой выбор курсов в нашем корпоративном университете, посещение митапов, конференций. Корпоративные льготы: ДМС, льготное страхование родственников, большой выбор внутренних спортивных секций, скидки на абонементы сети World Class.","Data science,Agile",Сибур,
17054,78446978,Руководитель центра монетизации Big Data,з/п не указана,3–6 лет,"Полная занятость,полный день","SIMBLE – это IT-продукт для управления автостраховкой, помогающий не переплачивать, а страховать авто только тогда, когда это действительно необходимо. Совместно с нашими партнёрами мы создали сервис доступного и справедливого страхования по законам IT: с персональными тарифами и гибкими настройками полисов. Мы решаем сложные задачи на стыке аналитики данных, пользовательского опыта и новых бизнес-моделей, чтобы страхование стало доступным для всех. Приглашаем в команду Simble эксперта с подтверждёнными компетенциями по развитию и коммерциализации больших данных (Big Data). В Ваши непосредственные обязанности будет входить создание стратегий по поиску (майнингу), изучению, обработке и запуску коммерческих проектов вокруг больших данных, которые аккумулирует наша компания. В процессе взаимодействия Simble с пользователями у нас появляются и хранятся различные дата-сеты, например, данные с мобильной телематики, данные о поездках по автомобильным дорогам, данные об авто и страхователях, данные из открытых внешних источников. Одной из основных задач успешного кандидата станет создание цифровых профилей клиентов на основе хранящихся и новых данных для дальнейшего создания персонализированных страховых тарифов, специальных предложений, маркетинга и т.д. деальный кандидат должен фундаментально разбираться в техниках анализа данных, уметь выявлять ключевые бизнес-идеи и обладать креативностью в разработке стратегий монетизации больших данных. Успешный опыт монетизации данных и коммерческих проектов в этой области является значительным плюсом для кандидата. Руководитель центра монетизации Big Data будет фокусироваться на выявлении потенциальных рынков для данных Simble и на выстраивании партнёрских взаимоотношений для монетизации этих данных с компаниями -лидерами своих индустрий. Руководитель центра монетизации Big Data имеет опыт создания моделей машинного обучения, искусственного интеллекта, обработки больших данных и может самостоятельно реализовывать эти модели и эффективно взаимодействовать с выделенными командами разработки, data-scientists с целью быстрого получения финансового результата для компании. Что нужно будет делать: Проводить маркетинговые исследования для определения потенциальных отраслей и рынков для наших данных. Сотрудничать с кросс-функциональными командами для разработки стратегий монетизации на основе полученных из данных идей. Строить и поддерживать отношения с потенциальными партнёрами в различных отраслях. Вести переговоры и заключать соглашения с партнёрами о лицензионном использовании наших данных. Разрабатывать и внедрять процессы управления и предоставления данных партнёрам. Следить за тенденциями в отрасли и новыми аналитическими техниками. Разрабатывать стратегии ценообразования для соглашений о лицензионном использовании наших данных. Что нам важно: Диплом бакалавра и выше в предметной области (например, статистика, Computer Science, Data Science). Подтвержденный опыт в анализе данных и способность работать с большими данными. Сильные аналитические и проблемно-ориентированные навыки. Отличные коммуникационные навыки и умение выстраивать сотрудничество. Опыт в разработке стратегий монетизации данных. Опыт в коммерческих переговорах и заключении соглашений по лицензионному использованию данных. Знание различных отраслей и областей потенциального применения больших данных, включая, но не ограничиваясь, банковские, розничным и страховым секторами. Опыт работы с инструментами визуализации данных (например, Tableau, PowerBl) является плюсом. Мы предлагаем: Работа в аккредитованной IT-компании. Конкурентная заработная плата. Комбинированный формат работы: 4 дня в офисе, пятница-удаленно. Оформление по ТК РФ. Работа в просторном офисе в центре рядом с парком, где можно прогуляться в обеденное время. Дружную команду, нацеленную на бизнес-результат и Клиента.",,Simble,"Москва, Выставочная, Улица 1905 года, Краснопресненская набережная, 12"
17055,78441128,Middle/Senior Data Engineer (Маркетплейс),з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Мы делаем Т для ритейла реального времени. Наши Т-продукты автоматизируют разное: закупки, логистику, работу дарксторов, сборку и доставку заказа до двери, управление промокампаниями и остальные этапы большого процесса. спользуем интеллектуальные системы прогнозирования, а разные этапы выполнения заказа автоматизируем роботическими системами. Наши ключевые направления: Быстрая доставка, Маркетплейс, Логистика. Наша цель — сделать все необходимые Т-инструменты и инфраструктуру, чтобы все нужные товары могли попадать домой к людям мгновенно (насколько это возможно в физическом мире). Сейчас мы ищем Middle/Senior Data Engineer в группу маркетинговых и продуктовых алгоритмов в Маркетплейсе. Маркетплейс создаёт технологии для онлайн-магазина, где можно купить всё необходимое среди товаров в 20+ категориях, от телевизора до свежих фруктов. Масштаб: 15 миллионов уникальных посетителей в месяц, 8 тысяч продавцов, более 4 миллионов товаров. Направления работы Рекомендательные системы (не только товаров, но и всего контента на сайте) ранжирование продуктового каталога контентная оптимизация - интеллектуальное управление содержанием витрины (наличие и перестановка блоков). Чем предстоит заниматься: реализация сервисов для готовых моделей машинного обучения на языке Python, включая обвязку тестами и мониторингом. интегрирование сервисов в существующие автоматизированные системы. поддержка работоспособности сервисов. проведение код ревью и обучение специалистов DS техническому стеку. Главные требования: опыт реализации, масштабирования, поддержки, интеграции высокогонагруженных сервисов, внутри которых жили построенные Data Scientist’ами алгоритмы и ML-модели знание концепций баз данных и программирования структурное мышление и умение излагать свои мысли опыт работы в электронной коммерции будет плюсом. Стек: разработка: Python, GitLab, Docker, Kubernetes, AirFlow, MLFlow данные: Hadoop, SQL, Kafka отчеты и мониторинги: Prometheus, Grafana задачи: Jira, Confluence Мы предлагаем  Все классические условия с запасом Samokat.tech – аккредитованная IT-компания, поэтому: белая зарплата и ДМС, возможность работать удалённо или ходить в офис в Москве, Санкт-Петербурге или Твери. Т-сообщество Развиваем комьюнити по функциональным направлениям, проводим внутренние митапы. Участвуем во внешних конференциях – ходим послушать, рассказать о своём опыте и пообщаться. Делаем собственное внешнее мероприятие Samokat Tech Meetup. Помогаем нашим ребятам делиться опытом друг с другом и с внешним сообществом: готовим доклады, пишем статьи, публикуем опенсорс, дружим с экспертами и соседями по индустрии.  Атмосфера Дни рождения команд, неформальные встречи, English-клуб и много другого — чтобы развиваться, отдыхать и жить чуть-чуть интереснее.","Python,Docker,PostgreSQL",Самокат (ООО Умное пространство),
17062,78177414,Data Engineer в команду Operational DWH,з/п не указана,3–6 лет,"Полная занятость,полный день",,,Райффайзен Банк,
17065,78130357,Преподаватель по направлению Data Scientist и UI - UX дизайн,до 150 000 KZT на руки,1–3 года,"Частичная занятость,полный день",,,IT - Online,"Астана, проспект Мангилик Ел, С4/6"
17067,79079444,Data Scientist (Middle+/Senior),з/п не указана,1–3 года,"Полная занятость,полный день","Мы в поисках скилловых специалистов в команду классического ML :) Команда распределенная, основные ячейки находятся в Новосибирске, Томске, СПб и также по всей России. Сейчас нас 100+ человек. Активно расширяем команду, которая работает над проектами: оценка платежеспособности клиента поиск аномального и фродерского поведения идентификация пользователей постпроцессинг данных. Задачи, которыми тебе предстоит заниматься: выгрузка данных из БД, парсинг логов сервисов обработка и подготовка данных с использованием Python создание и проверка признаков оценка качества и анализ данных доработка пайплайна расчета признаков для транзакций/заявок обучение классических ML моделей доставка моделей до боя, мониторинг моделей на бою доработка внутренних библиотек общение с бизнес-заказчиком анализ экономического эффекта изменений логики принятия решений. Что для нас важно: опыт работы с задачами машинного обучения/ опыт работы с данными в проектах, желательно по статистической обработке от 2-3 лет опыт разработки на Python опыт работы с библиотеками pandas, numpy, sklearn, catboost уверенные навыки использования Linux, Jupyter notebook, git, SQL знание основных моделей машинного обучения: деревья решений на градиентном бустинге, логистическая регрессия с регуляризацией, метод ближайших соседей и др. методов снижения размерности и кластеризации навыки визуализации результатов опыт самостоятельного ведения темы: дизайн, постановка задачи, проведение и оценка результатов А/Б тестов, оценка результата работы по задаче для позиции уровня senior: ожидаем опыт ведения более обширной темы (от идеи до прода), опыт ревью кода мидлов/опыт лидства команды доп. навыки: базовые навыки в airflow, pyspark, dvc. Мы предлагаем: Понятную траекторию роста (performance review, карьерные консультации, индивидуальная карта развития и т.д.) Обучение и развитие за счёт ресурсов компании (Учебный центр, корпоративная библиотека, оплата внешнего обучения) Социальный пакет (ДМС с первого рабочего дня, скидки от партнёров, детская программа, поддержка спорта, корпоративный транспорт и т.д.) Насыщенная корпоративная жизнь (радио, подкасты, кибертурнир, собственные мероприятия и участие в крупных событиях отрасли) Возможность быть преподавателем, наставником, автором корпоративного блога, спикером – каждый выбирает то, что подходит именно ему Официальное трудоустройство с первого дня, полностью белая зарплата.",,Центр финансовых технологий,
17068,79079446,Data Scientist (Middle+/Senior),з/п не указана,1–3 года,"Полная занятость,полный день","Мы в поисках скилловых специалистов в команду классического ML :) Команда распределенная, основные ячейки находятся в Новосибирске, Томске, СПб и также по всей России. Сейчас нас 100+ человек. Активно расширяем команду, которая работает над проектами: оценка платежеспособности клиента поиск аномального и фродерского поведения идентификация пользователей постпроцессинг данных. Задачи, которыми тебе предстоит заниматься: выгрузка данных из БД, парсинг логов сервисов обработка и подготовка данных с использованием Python создание и проверка признаков оценка качества и анализ данных доработка пайплайна расчета признаков для транзакций/заявок обучение классических ML моделей доставка моделей до боя, мониторинг моделей на бою доработка внутренних библиотек общение с бизнес-заказчиком анализ экономического эффекта изменений логики принятия решений. Что для нас важно: опыт работы с задачами машинного обучения/ опыт работы с данными в проектах, желательно по статистической обработке от 2-3 лет опыт разработки на Python опыт работы с библиотеками pandas, numpy, sklearn, catboost уверенные навыки использования Linux, Jupyter notebook, git, SQL знание основных моделей машинного обучения: деревья решений на градиентном бустинге, логистическая регрессия с регуляризацией, метод ближайших соседей и др. методов снижения размерности и кластеризации навыки визуализации результатов опыт самостоятельного ведения темы: дизайн, постановка задачи, проведение и оценка результатов А/Б тестов, оценка результата работы по задаче для позиции уровня senior: ожидаем опыт ведения более обширной темы (от идеи до прода), опыт ревью кода мидлов/опыт лидства команды доп. навыки: базовые навыки в airflow, pyspark, dvc. Мы предлагаем: Понятную траекторию роста (performance review, карьерные консультации, индивидуальная карта развития и т.д.) Обучение и развитие за счёт ресурсов компании (Учебный центр, корпоративная библиотека, оплата внешнего обучения) Социальный пакет (ДМС с первого рабочего дня, скидки от партнёров, детская программа, поддержка спорта, корпоративный транспорт и т.д.) Насыщенная корпоративная жизнь (радио, подкасты, кибертурнир, собственные мероприятия и участие в крупных событиях отрасли) Возможность быть преподавателем, наставником, автором корпоративного блога, спикером – каждый выбирает то, что подходит именно ему Официальное трудоустройство с первого дня, полностью белая зарплата.",,Центр финансовых технологий,
17069,79079449,Data Scientist (Middle+/Senior),з/п не указана,1–3 года,"Полная занятость,полный день","Мы в поисках скилловых специалистов в команду классического ML :) Команда распределенная, основные ячейки находятся в Новосибирске, Томске, СПб и также по всей России. Сейчас нас 100+ человек. Активно расширяем команду, которая работает над проектами: оценка платежеспособности клиента поиск аномального и фродерского поведения идентификация пользователей постпроцессинг данных. Задачи, которыми тебе предстоит заниматься: выгрузка данных из БД, парсинг логов сервисов обработка и подготовка данных с использованием Python создание и проверка признаков оценка качества и анализ данных доработка пайплайна расчета признаков для транзакций/заявок обучение классических ML моделей доставка моделей до боя, мониторинг моделей на бою доработка внутренних библиотек общение с бизнес-заказчиком анализ экономического эффекта изменений логики принятия решений. Что для нас важно: опыт работы с задачами машинного обучения/ опыт работы с данными в проектах, желательно по статистической обработке от 2-3 лет опыт разработки на Python опыт работы с библиотеками pandas, numpy, sklearn, catboost уверенные навыки использования Linux, Jupyter notebook, git, SQL знание основных моделей машинного обучения: деревья решений на градиентном бустинге, логистическая регрессия с регуляризацией, метод ближайших соседей и др. методов снижения размерности и кластеризации навыки визуализации результатов опыт самостоятельного ведения темы: дизайн, постановка задачи, проведение и оценка результатов А/Б тестов, оценка результата работы по задаче для позиции уровня senior: ожидаем опыт ведения более обширной темы (от идеи до прода), опыт ревью кода мидлов/опыт лидства команды доп. навыки: базовые навыки в airflow, pyspark, dvc. Мы предлагаем: Понятную траекторию роста (performance review, карьерные консультации, индивидуальная карта развития и т.д.) Обучение и развитие за счёт ресурсов компании (Учебный центр, корпоративная библиотека, оплата внешнего обучения) Социальный пакет (ДМС с первого рабочего дня, скидки от партнёров, детская программа, поддержка спорта, корпоративный транспорт и т.д.) Насыщенная корпоративная жизнь (радио, подкасты, кибертурнир, собственные мероприятия и участие в крупных событиях отрасли) Возможность быть преподавателем, наставником, автором корпоративного блога, спикером – каждый выбирает то, что подходит именно ему Официальное трудоустройство с первого дня, полностью белая зарплата.",,Центр финансовых технологий,
17070,78883015,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Чем занимается Positive Technologies Мы создаем продукты для кибербезопасности. Это решения и технологии, которые защищают от хакеров и помогают проводить расследования инцидентов. Мы разрабатываем сложные высоконагруженные системы, используем алгоритмы машинного обучения, обработки и анализа данных, опенсорс-решения и адаптируем их к нашим задачам. Часть наработок мы публикуем на GitHub. Прежде чем отдавать продукты заказчикам, мы проверяем их на себе. У нас семь офисов в России (в Москве, Санкт-Петербурге, Самаре, Нижнем Новгороде, Томске и два в Новосибирске), поэтому продуктовые команды часто территориально распределены. Нас больше 1500 человек. Мы сейчас ищем Специалиста по машинному обучению в нашу команду Департамента разработки WAF (Web Application Firewall). WAF - это межсетевой экран, который обнаруживает и блокирует атаки, обеспечивает непрерывную защиту приложений, пользователей и инфраструктуры и помогает соответствовать стандартам безопасности. Чем предстоит заниматься: Проектирование математических моделей обнаружения атак на веб-приложения Разработка и прототипирование статистических методов обнаружения аномалий в трафике Поддержка и улучшение существующих алгоритмов машинного обучения в Application Firewall. Что ждём от кандидата: Уверенное знание Python, git Знание основных алгоритмов/методов машинного обучения Владение библиотеками Pytorch, sklearn. Будет плюсом: Знание основных веб-технологий и протоколов Опыт работы с docker, k8s и микросервисной архитектурой. Что ещё, кроме работы? У нас дружелюбная и открытая команда, нет бюрократии и лишних уровней управления. Есть работающая схема профессионального развития сотрудников. А также: Можно работать удалённо или в офисе в минуте от метро Преображенская площадь (на 15 этаже с красивыми видами на Москву) Гибкое начало рабочего дня ДМС со стоматологией, вызовом врача на дом, экстренной госпитализацией Две недели дополнительного отпуска Частичная компенсация спорта В офисе есть спортивная зона с душевыми и массажное кресло Можно присоединиться к футбольной, баскетбольной или волейбольной сборным, для которых мы арендуем спортивные площадки Книги в библиотеку и настольные игры покупаем два раза в год Фрукты и печенье, микромаркет “ВкусВилл” и кофепоинт Есть клубы по интересам (шахматы, клуб инвесторов, мафия по спортивным правилам, винный клуб и другие).","Python,machine learning,web security,sklearn,pytorch,docker",Positive Technologies,
17071,78883016,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Чем занимается Positive Technologies Мы создаем продукты для кибербезопасности. Это решения и технологии, которые защищают от хакеров и помогают проводить расследования инцидентов. Мы разрабатываем сложные высоконагруженные системы, используем алгоритмы машинного обучения, обработки и анализа данных, опенсорс-решения и адаптируем их к нашим задачам. Часть наработок мы публикуем на GitHub. Прежде чем отдавать продукты заказчикам, мы проверяем их на себе. У нас семь офисов в России (в Москве, Санкт-Петербурге, Самаре, Нижнем Новгороде, Томске и два в Новосибирске), поэтому продуктовые команды часто территориально распределены. Нас больше 1500 человек. Мы сейчас ищем Специалиста по машинному обучению в нашу команду Департамента разработки WAF (Web Application Firewall). WAF - это межсетевой экран, который обнаруживает и блокирует атаки, обеспечивает непрерывную защиту приложений, пользователей и инфраструктуры и помогает соответствовать стандартам безопасности. Чем предстоит заниматься: Проектирование математических моделей обнаружения атак на веб-приложения Разработка и прототипирование статистических методов обнаружения аномалий в трафике Поддержка и улучшение существующих алгоритмов машинного обучения в Application Firewall. Что ждём от кандидата: Уверенное знание Python, git Знание основных алгоритмов/методов машинного обучения Владение библиотеками Pytorch, sklearn. Будет плюсом: Знание основных веб-технологий и протоколов Опыт работы с docker, k8s и микросервисной архитектурой. Что ещё, кроме работы? У нас дружелюбная и открытая команда, нет бюрократии и лишних уровней управления. Есть работающая схема профессионального развития сотрудников. А также: Можно работать удалённо или в офисе в минуте от метро Преображенская площадь (на 15 этаже с красивыми видами на Москву) Гибкое начало рабочего дня ДМС со стоматологией, вызовом врача на дом, экстренной госпитализацией Две недели дополнительного отпуска Частичная компенсация спорта В офисе есть спортивная зона с душевыми и массажное кресло Можно присоединиться к футбольной, баскетбольной или волейбольной сборным, для которых мы арендуем спортивные площадки Книги в библиотеку и настольные игры покупаем два раза в год Фрукты и печенье, микромаркет “ВкусВилл” и кофепоинт Есть клубы по интересам (шахматы, клуб инвесторов, мафия по спортивным правилам, винный клуб и другие).","Python,machine learning,web security,sklearn,pytorch,docker",Positive Technologies,
17072,78883014,Senior Data Scientist,з/п не указана,3–6 лет,"Полная занятость,удаленная работа","Чем занимается Positive Technologies Мы создаем продукты для кибербезопасности. Это решения и технологии, которые защищают от хакеров и помогают проводить расследования инцидентов. Мы разрабатываем сложные высоконагруженные системы, используем алгоритмы машинного обучения, обработки и анализа данных, опенсорс-решения и адаптируем их к нашим задачам. Часть наработок мы публикуем на GitHub. Прежде чем отдавать продукты заказчикам, мы проверяем их на себе. У нас семь офисов в России (в Москве, Санкт-Петербурге, Самаре, Нижнем Новгороде, Томске и два в Новосибирске), поэтому продуктовые команды часто территориально распределены. Нас больше 1500 человек. Мы сейчас ищем Специалиста по машинному обучению в нашу команду Департамента разработки WAF (Web Application Firewall). WAF - это межсетевой экран, который обнаруживает и блокирует атаки, обеспечивает непрерывную защиту приложений, пользователей и инфраструктуры и помогает соответствовать стандартам безопасности. Чем предстоит заниматься: Проектирование математических моделей обнаружения атак на веб-приложения Разработка и прототипирование статистических методов обнаружения аномалий в трафике Поддержка и улучшение существующих алгоритмов машинного обучения в Application Firewall. Что ждём от кандидата: Уверенное знание Python, git Знание основных алгоритмов/методов машинного обучения Владение библиотеками Pytorch, sklearn. Будет плюсом: Знание основных веб-технологий и протоколов Опыт работы с docker, k8s и микросервисной архитектурой. Что ещё, кроме работы? У нас дружелюбная и открытая команда, нет бюрократии и лишних уровней управления. Есть работающая схема профессионального развития сотрудников. А также: Можно работать удалённо или в офисе в минуте от метро Преображенская площадь (на 15 этаже с красивыми видами на Москву) Гибкое начало рабочего дня ДМС со стоматологией, вызовом врача на дом, экстренной госпитализацией Две недели дополнительного отпуска Частичная компенсация спорта В офисе есть спортивная зона с душевыми и массажное кресло Можно присоединиться к футбольной, баскетбольной или волейбольной сборным, для которых мы арендуем спортивные площадки Книги в библиотеку и настольные игры покупаем два раза в год Фрукты и печенье, микромаркет “ВкусВилл” и кофепоинт Есть клубы по интересам (шахматы, клуб инвесторов, мафия по спортивным правилам, винный клуб и другие).","Python,machine learning,web security,sklearn,pytorch,docker",Positive Technologies,
17073,78936775,Data Engineer (ДАДМ),з/п не указана,3–6 лет,"Полная занятость,полный день","Вместе с нами ты будешь: Заниматься проектированием и разработкой витрин данных для анализа и моделирования Заниматься мониторингом и оптимизацией процессов сборки витрин Заниматься загрузкой и обработкой данных из различных источников Заниматься поддержкой и развитием базы знаний Предоставлять экспертную поддержку внутренним потребителям(data analysts,data scientists) Какие знания и навыки для нас важны: Знание SQL Хорошее знание устройства Hadoop,Spark,Hive/Impala Опыт разработки на Python/Scala/Java Понимание основных концепций DWH Понимание базовых команд Git и основных приципов работы Будет плюсом: Опыт работы с банковскими данными Опыт работы с различными СУБД в роли разработчика/аналитика витрин данных Опыт работы с Airflow","DWH,Hadoop,Hive,Git,Python,SCALA,SQL","ннотех, Группа компаний",
17074,78937116,Data Engineer (ДАДМ),з/п не указана,3–6 лет,"Полная занятость,полный день","Вместе с нами ты будешь: Заниматься проектированием и разработкой витрин данных для анализа и моделирования Заниматься мониторингом и оптимизацией процессов сборки витрин Заниматься загрузкой и обработкой данных из различных источников Заниматься поддержкой и развитием базы знаний Предоставлять экспертную поддержку внутренним потребителям(data analysts,data scientists) Какие знания и навыки для нас важны: Знание SQL Хорошее знание устройства Hadoop,Spark,Hive/Impala Опыт разработки на Python/Scala/Java Понимание основных концепций DWH Понимание базовых команд Git и основных принципов работы Будет плюсом: Опыт работы с банковскими данными Опыт работы с различными СУБД в роли разработчика/аналитика витрин данных Опыт работы с Airflow","DWH,Hadoop,Hive,Git,Python,SCALA,SQL","ннотех, Группа компаний",